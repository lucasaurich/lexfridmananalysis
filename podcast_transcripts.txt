Segment 1: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=0, Text: The following is a conversation with Jeff Bezos, founder of Amazon and Blue Origin. This is his first time doing a conversation of this kind and of this length. And as he told me, it felt like we could have easily talked for many more hours, and I’m sure we will. This is the Lex Fridman Podcast. And now, dear friends, here’s Jeff Bezos.
Segment 2: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=24, Text: You spent a lot of your childhood with your grandfather on a ranch here in Texas.
Segment 3: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=29, Text: Mm-hmm.
Segment 4: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=30, Text: And I heard you had a lot of work to do around the ranch. So, what’s the coolest job you remember doing there?
Segment 5: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=35, Text: Wow. Coolest?
Segment 6: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=37, Text: Most interesting? Most memorable?
Segment 7: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=39, Text: Most memorable?
Segment 8: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=39, Text: Most impactful?
Segment 9: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=41, Text: It’s a real working ranch, and I spent all my summers on that ranch from age four to 16. And my grandfather was really taking me and in the early summers, he was letting me pretend to help on the ranch, because of course, a four-year-old is a burden, not a help in real life. He was really just watching me and taking care of me. And he was doing that because my mom was so young. She had me when she was 17, and so he was sort of giving her a break. And my grandmother and my grandfather would take me for these summers.
Segment 10: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=75, Text: But as I got a little older, I actually was helpful on the ranch and I loved it. My grandfather had a huge influence on me, a huge factor in my life. I did all the jobs you would do on a ranch. I’ve fixed windmills, and laid fences, and pipelines, and done all the things that any rancher would do, vaccinated the animals, everything. But after my grandmother died, I was about 12 and I kept coming to the ranch, so then it was just him and me, just the two of us. And he was completely addicted to the soap opera, Days of Our Lives. And we would go back to the ranch house every day around 1:00 PM or so to watch Days of Our Lives. Like sands through an hourglass, so are the Days of Our Lives.
Segment 11: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=127, Text: Just the image of that, the two of you sitting there watching a soap opera, two ranchers.
Segment 12: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=133, Text: He had these big crazy dogs. It was really a very formative experience for me. But the key thing about it for me, the great gift I got from it was that my grandfather was so resourceful. He did everything himself. He made his own veterinary tools. He would make needles to suture the cattle up with. He would find a little piece of wire and heat it up and pound it thin and drill a hole in it and sharpen it. So, you learn different things on a ranch than you would learn growing up in a city.
Segment 13: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=163, Text: So, self-reliance?
Segment 14: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=164, Text: Yeah, figuring out that you can solve problems with enough persistence and ingenuity. And my grandfather bought a D6 bulldozer, which is a big bulldozer, and he got it for like $5,000 because it was completely broken down. It was like a 1955 Caterpillar D6 bulldozer. New it would’ve cost, I don’t know, more than $100,000. And we spent an entire summer repairing that bulldozer. And we’d use mail order to buy big gears for the transmission, and they’d show up, they’d be too heavy to move, so we’d have to build a crane. Just that problem-solving mentality. He had it so powerfully. He did all of his own… He didn’t pick up the phone and call somebody, he would figure it out on his own. Doing his own veterinary work.
Segment 15: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=219, Text: But just the image of the two of you fixing a D6 bulldozer and then going in for a little break at 1:00 PM to watch soap operas.
Segment 16: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=227, Text: Days of Our Lives. Laying on the floor, that’s how he watched TV. He was a really, really remarkable guy.
Segment 17: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=232, Text: That’s how I imagine Clint Eastwood also in all those westerns, when he’s not doing what he’s doing, he’s just watching soap operas. All right. I read that you fell in love with the idea of space and space exploration when you were five, watching Neil Armstrong walking on the moon. So, let me ask you to look back at the historical context and impact of that. So, the space race from 1957 to 1969 between the Soviet Union and the US was, in many ways, epic. It was a rapid sequence of dramatic events. First satellite to space, first human to space, first spacewalk, first uncrewed landing on the moon. Then, some failures, explosions, deaths on both sides actually. And then, the first human walking on the moon. What are some of the more inspiring moments or insights you take away from that time, those few years at just 12 years?
Segment 18: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=291, Text: Well, I mean there’s so much inspiring there. One of the great things to take away from that, one of the great von Braun quotes is, “I have come to use the word impossible with great caution.” And so, that’s kind of the big story of Apollo is that going to the moon was literally an analogy that people used for something that’s impossible. “Oh, yeah, you’ll do that when men walk on the moon.” And of course, it finally happened. So, I think it was pulled forward in time because of the space race.
Segment 19: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=331, Text: I think with the geopolitical implications and how much resource was put into it. At the peak, that program was spending 2% or 3% of GDP on the Apollo program. So, much resource. I think it was pulled forward in time. We kind of did it ahead of when we, quote, unquote, should have done it. And so, in that way, it’s also a technical marvel. I mean it’s truly incredible. It’s the 20th century version of building the pyramids or something. It’s an achievement that because it was pulled forward in time and because it did something that had previously been thought impossible, it rightly deserves its place in the pantheon of great human achievements.
Segment 20: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=377, Text: And of course, you named the rockets that Blue Origin is working on after some of the folks involved.
Segment 21: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=384, Text: Yeah.
Segment 22: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=384, Text: I don’t understand why I didn’t say New Gagarin. Is that-
Segment 23: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=387, Text: There’s an American bias in the naming. I apologize-
Segment 24: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=390, Text: That’s very strange.
Segment 25: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=391, Text: … Lex.
Segment 26: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=391, Text: Was just asking for a friend, clarifying.
Segment 27: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=393, Text: I’m a big fan of Gagarin’s though. And in fact, I think his first words in space I think are incredible. He purportedly said, “My God, it’s blue.” And that really drives home. No one had seen the Earth from space. No one knew that we were on this blue planet. No one knew what it looked like from out there, and Gagarin was the first person to see it.
Segment 28: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=421, Text: One of the things I think about is how dangerous those early days were for Gagarin, for Glenn, for everybody involved. How big of a risk they were all taking.
Segment 29: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=431, Text: They were taking huge risks. I’m not sure what the Soviets thought about Gagarin’s flight, but I think that the Americans thought that the Alan Shepard flight, the flight that New Shepherd is named after, the First American in space, he went on his suborbital flight, they thought he had about a 75% chance of success. So, that’s a pretty big risk, a 25% risk.
Segment 30: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=456, Text: It’s kind of interesting that Alan Shepard is not quite as famous as John Glenn. So, for people who don’t know, Alan Shepard is the first astronaut-
Segment 31: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=464, Text: The first American in space.
Segment 32: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=466, Text: American in suborbital flight.
Segment 33: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=468, Text: Correct.
Segment 34: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=468, Text: And then, the first orbital flight is-
Segment 35: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=471, Text: John Glenn is the first American to orbit the Earth. By the way, I have the most charming, sweet, incredible letter from John Glenn, which I have framed and hanging on my office wall.
Segment 36: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=484, Text: What did he say?
Segment 37: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=484, Text: Where he tells me how grateful he is that we have named New Glenn after him. And he sent me that letter about a week before he died. And it’s really an incredible… It’s also a very funny letter. He’s writing and he says, “This is a letter about New Glenn from the original Glenn.” And he’s got a great sense of humor and he’s very happy about it and grateful. It’s very sweet.
Segment 38: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=510, Text: Does he say, “P.S. Don’t mess this up,” or is that-
Segment 39: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=514, Text: No, he doesn’t.
Segment 40: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=515, Text: “Make me look good.”
Segment 41: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=515, Text: He doesn’t do that. But John, wherever you are, we’ve got you covered.
Segment 42: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=519, Text: Good. So, back to maybe the big picture of space. When you look up at the stars and think big, what do you hope is the future of humanity, hundreds, thousands of years from now out in space?
Segment 43: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=534, Text: I would love to see a trillion humans living in the solar system. If we had a trillion humans, we would have, at any given time, 1,000 Mozarts and 1,000 Einsteins. That our solar system would be full of life and intelligence and energy. And we can easily support a civilization that large with all of the resources in the solar system.
Segment 44: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=561, Text: So, what do you think that looks like? Giant space stations?
Segment 45: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=564, Text: Yeah, the only way to get to that vision is with giant space stations. The planetary surfaces are just way too small. So, I mean, unless you turn them into giant space stations or something. But yeah, we will take materials from the moon and from near-Earth objects and from the asteroid belt and so on, and we’ll build giant O’Neill style colonies and people will live in those. They have a lot of advantages over planetary surfaces. You can spin them to get normal Earth gravity. You can put them where you want them. I think most people are going to want to live near Earth, not necessarily in Earth orbit, but near Earth vicinity orbits. And so, they can move relatively quickly back and forth between their station and Earth. I think a lot of people, especially in the early stages, are not going to want to give up Earth altogether.
Segment 46: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=624, Text: They go to earth for vacation?
Segment 47: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=626, Text: Yeah, same way that you might go to Yellowstone National Park for vacation, people will… And people will get to choose where they live on Earth or whether they live in space, but they’ll be able to use much more energy and much more material resource in space than they would be able to use on Earth.
Segment 48: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=645, Text: One of the interesting ideas you had is to move the heavy industry away from Earth. So, people sometimes have this idea that somehow space exploration is in conflict with the celebration of the planet Earth, that we should focus on preserving Earth. And basically, your idea is that space travel and space exploration is a way to preserve Earth.
Segment 49: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=666, Text: Exactly. We’ve sent robotic probes to all the planets, we know that this is the good one.
Segment 50: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=677, Text: Not to play favorites or anything, but…
Segment 51: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=679, Text: Earth really is the good planet. It’s amazing. The ecosystem we have here, all of the life and the lush plant life and the water resources, everything. This planet is really extraordinary. And of course, we evolved on this planet, so of course it’s perfect for us, but it’s also perfect for all the advanced life forms on this planet, all the animals and so on. And so, this is a gem. We do need to take care of it. And as we enter the Anthropocene, as we humans have gotten so sophisticated and large and impactful, as we stride across this planet, that is going to… We want to use a lot of energy. We want to use a lot of energy per capita. We’ve gotten amazing things. We don’t want to go backwards.
Segment 52: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=730, Text: If you think about the good old days, they’re mostly an illusion. In almost every way, life is better for almost everyone today than it was say 50 years ago or 100 years ago. We live better lives by and large than our grandparents did, and their grandparents did, and so on. And you can see that in global illiteracy rates, global poverty rates, global infant mortality rates. Almost any metric you choose, we’re better off than we used to be. And we get antibiotics and all kinds of lifesaving medical care, and so on, and so on. And there’s one thing that is moving backwards, and it’s the natural world.
Segment 53: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=774, Text: So, it is a fact that 500 years ago, pre-industrial age, the natural world was pristine. It was incredible. And we have traded some of that pristine beauty for all of these other gifts that we have as an advanced society. And we can have both, but to do that, we have to go to space. And the most fundamental measure is energy usage per capita. You do want to continue to use more and more energy, it is going to make your life better in so many ways, but that’s not compatible ultimately with living on a finite planet. And so, we have to go out into the solar system. And really, you could argue about when you have to do that, but you can’t credibly argue about whether you have to do that.
Segment 54: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=829, Text: Eventually we have to do that.
Segment 55: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=831, Text: Exactly.
Segment 56: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=832, Text: Well, you don’t often talk about it, but let me ask you on that topic about the Blue Ring and the Orbital Reef space infrastructure projects. What’s your vision for these?
Segment 57: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=843, Text: So, Blue Ring is a very interesting spacecraft that is designed to take up to 3,000 kilograms of payload up to geosynchronous orbit or in lunar vicinity. It has two different kinds of propulsion. It has chemical propulsion and it has electric propulsion. And so, you can use Blue Ring in a couple of different ways. You can slowly move, let’s say up to geosynchronous orbit using electric propulsion. That might take 100 days or 150 days, depending on how much mass you’re carrying. And reserve your chemical propulsion, so that you can change orbits quickly in geosynchronous orbit. Or you can use the chemical propulsion first to quickly get up to geosynchronous and then use your electrical propulsion to slowly change your geosynchronous orbit.
Segment 58: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=895, Text: Blue Ring has a couple of interesting features. It provides a lot of services to these payloads. So, it could be one large payload or it can be a number of small payloads, and it provides thermal management, it provides electric power, it provides compute, provides communications. And so, when you design a payload for Blue Ring, you don’t have to figure out all of those things on your own. So, kind of radiation tolerant compute is a complicated thing to do. And so, we have an unusually large amount of radiation tolerant compute on board Blue Ring, and your payload can just use that when it needs to. So, it’s sort of all these services… It’s like a set of APIs. It’s a little bit like Amazon Web Services, but-
Segment 59: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=951, Text: For space?
Segment 60: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=952, Text: … for space payloads that need to move about in Earth vicinity or lunar vicinity.
Segment 61: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=957, Text: AWSS space. So, compute and space. So, you get a giant chemical rocket to get a payload out to orbit. And then, you have these admins that show up, this Blue Ring thing that manages various things like compute?
Segment 62: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=973, Text: Exactly. And it can also provide transportation and move you around to different orbits.
Segment 63: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=979, Text: Including humans, do you think?
Segment 64: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=981, Text: No, Blue Ring is not designed to move humans around. It’s designed to move payloads around. So, we’re also building a lunar lander, which is of course designed to land humans on the surface of the moon.
Segment 65: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=994, Text: I’m going to ask you about that, but let me ask you to just step back to the old days. You were at Princeton with aspirations to be a theoretical physicist.
Segment 66: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1005, Text: Yeah.
Segment 67: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1007, Text: What attracted you to physics and why did you change your mind and not become… Why are you not Jeff Bezos, the famous theoretical physicist?
Segment 68: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1017, Text: So, I loved physics and I studied physics and computer science, and I was proceeding along the physics path. I was planning to major in physics, and I wanted to be a theoretical physicist. And the computer science was sort of something I was doing for fun. I really loved it and I was very good at the programming and doing those things, and I enjoyed all my computer science classes immensely. But I really was determined to be a theoretical physicist. That’s why I went to Princeton in the first place. It was definitely… And then, I realized I was going to be a mediocre theoretical physicist. And there were a few people in my classes, like in quantum mechanics and so on, who they could effortlessly do things that were so difficult for me. And I realized there are 1,000 ways to be smart.
Segment 69: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1072, Text: Theoretical physics is not one of those fields where only the top few percent actually move the state-of-the-art forward. It’s one of those things where your brain has to be wired in a certain way. And there was a guy named… One of these people who convinced me, he didn’t mean to convince me, but just by observing him, he convinced me that I should not try to be a theoretical physicist. His name was Yosanta. And Yosanta was from Sri Lanka, and he was one of the most brilliant people I’d ever met. My friend Joe and I were working on a very difficult partial differential equations problem set one night. And there was one problem that we worked on for three hours and we made no headway whatsoever. And we looked up at each other at the same time and we said, “Yosanta.”
Segment 70: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1129, Text: So, we went to Yosanta’s dorm room and he was there. He was almost always there. And we said, “Yosanta, we’re having trouble solving this partial differential equation. Would you mind taking a look?” And he said, “Of course.” By the way, he was the most humble, most kind person. And so, he looked at our problem and he stared at it for just a few seconds, maybe 10 seconds, and he said, “cosine.” And I said, “What do you mean, Yosanta? What do you mean cosine?” He said, “That’s the answer.” And I said, “No, no, no, come on.” And he said, “Let me show you.” And he took out some paper and he wrote down three pages of equations, everything canceled out, and the answer was cosine.
Segment 71: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1170, Text: And I said, “Yosanta, did you do that in your head?” And he said, “Oh, no. That would be impossible. A few years ago I solved a similar problem and I could map this problem onto that problem, and then it was immediately obvious that the answer was cosine.” You have an experience like that, you realize maybe being a theoretical physicist isn’t what the universe wants you to be. And so, I switched to computer science and that worked out really well for me. I enjoy it. I still enjoy it today.
Segment 72: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1207, Text: Yeah, there’s a particular kind of intuition you need to be a great physicist, and applied to physics.
Segment 73: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1212, Text: I think the mathematical skill required today is so high. You have to be a world-class mathematician to be a successful theoretical physicist today. And you probably need other skills too, intuition, lateral thinking and so on. But without just top-notch math skills, you’re unlikely to be successful.
Segment 74: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1239, Text: And visualization skill, you have to be able to really do these kinds of thought experiments if you want truly great creativity. Actually Walter Isaacson writes about you and puts you on the same level as Einstein and-
Segment 75: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1253, Text: Well, that’s very kind. I’m an inventor. If you want to boil down what I am, I’m really an inventor. And I look at things and I can come up with atypical solutions. And then, I can create 100 such atypical solutions for something, 99 of them may not survive scrutiny, but one of those 100 is like, “Hmm, maybe that might work.” And then, you can keep going from there. So, that kind of lateral thinking, that kind of inventiveness in a high-dimensionality space where the search space is very large, that’s where my inventive skills come… I self-identify as an inventor more than anything else.
Segment 76: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1303, Text: Yeah. And he describes in all kinds of different ways, Walter Isaacson does, that creativity combined with childlike wander that you’ve maintained still to this day, all of that combined together. If you were to study your own brain, introspect, how do you think? What’s your thinking process like? We’ll talk about the writing process of putting it down on paper, which is quite rigorous and famous at Amazon. But when you sit down, maybe alone, maybe with others, and thinking through this high-dimensional space and looking for creative solutions, creative paths forward, is there something you could say about that process?
Segment 77: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1346, Text: It’s such a good question, and I honestly don’t know how it works. If I did, I would try to explain it. I know it involves lots of wandering, so when I sit down to work on a problem, I know I don’t know where I’m going. So, to go in a straight line… To be efficient… Efficiency and invention are sort of at odds, because real invention, Not incremental improvement… Incremental improvement is so important in every endeavor, in everything you do, you have to work hard on also just making things a little bit better. But I’m talking about real invention, real lateral thinking that requires wandering, and you have to give yourself permission to wander.
Segment 78: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1391, Text: I think a lot of people, and they feel like wandering is inefficient. And when I sit down at a meeting, I don’t know how long the meeting is going to take if we’re trying to solve a problem, because if I did, then I’d know there’s some kind of straight line that we’re drawing to the solution. The reality is we may have to wander for a long time. And I do like group invention. I think there’s really nothing more fun than sitting at a whiteboard with a group of smart people and spit balling and coming up with new ideas and objections to those ideas, and then solutions to the objections and going back and forth. So, sometimes you wake up with an idea in the middle of the night and sometimes you sit down with a group of people and go back and forth, and both things are really pleasurable.
Segment 79: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1454, Text: And when you wander, I think one key thing is to notice a good idea. And maybe to notice the kernel of a good idea. I’ll maybe pull at that string. Because I don’t think good ideas come fully-formed.
Segment 80: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1471, Text: 100% right. In fact, when I come up with what I think is a good idea and it survives the first level of scrutiny that I do in my own head, and I’m ready to tell somebody else about the idea, I will often say, “Look, it is going to be really easy for you to find objections to this idea, but work with me.”
Segment 81: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1493, Text: There’s something there.
Segment 82: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1494, Text: There’s something there. And that is intuition, because it’s really easy to kill new ideas in the beginning because there’s so many easy objections to them. So, you need to kind of forewarn people and say, “Look, I know it’s going to take a lot of work to get this to a fully-formed idea. Let’s get started on that. It’ll be fun.”
Segment 83: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1517, Text: So, you got that ability to say cosine in you somewhere after all, maybe not on math, but-
Segment 84: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1523, Text: In a different domain.
Segment 85: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1524, Text: Yeah.
Segment 86: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1525, Text: There are 1,000 ways to be smart, by the way, and that is a really… When I go around and I meet people, I’m always looking for the way that they’re smart. And you find that’s one of the things that makes the world so interesting and fun is that it’s not like IQ is a single dimension. There are people who are smart in such unique ways.
Segment 87: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1553, Text: Yeah, you just gave me a good response when somebody calls me an idiot on the internet. “You know, there’s 1,000 ways to be smart, sir.”
Segment 88: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1561, Text: Well, they might tell you, “Yeah, but there are a million to be ways to be dumb.”
Segment 89: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1564, Text: Yeah, right. I feel like that’s a Mark Twain quote. Okay. All right. You gave me an amazing tour of Blue Origin Rocket Factory and Launch Complex in the historic Cape Canaveral. That’s where New Glenn, the big rocket we talked about, is being built and will launch. Can you explain what the New Glenn rocket is and tell me some interesting technical aspects of how it works?
Segment 90: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1589, Text: Sure. New Glenn is a very large heavy-lift launch vehicle. It’ll take about 45 metric tons to LEO, very large class. It’s about half the thrust, a little more than half the thrust of the Saturn V rocket. So, it’s about 3.9 million pounds of thrust on liftoff. The booster has seven BE-4 engines. Each engine generates a little more than 550,000 pounds of thrust. The engines are fueled by liquified natural gas, LNG as the fuel, and LOX as the oxidizer. The cycle is an ox-riched stage combustion cycle. It’s a cycle that was really pioneered by the Russians. It’s a very good cycle. And that engine is also going to power the first stage of the Vulcan rocket, which is the United Launch Alliance rocket. Then the second stage of New Glenn is powered by two BE-3U engines, which is a upper-stage variant of our New Shepard liquid hydrogen engine.
Segment 91: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1664, Text: So, the BE-3U has 160,000 pounds of thrust, so two of those, 320,000 pounds of thrust. And hydrogen is a very good propellant for upper stages because it has very high ISP. It’s not a great propellant in my view for booster stages, because the stages then get physically so large. Hydrogen has very high ISP, but liquid hydrogen is not dense at all. So, to store liquid hydrogen, if you need to store many thousands of pounds of liquid hydrogen, your liquid hydrogen tank gets very large. So, you get more benefit from the higher ISP, the specific impulse, you get more benefit from the higher specific impulse on the second stage. And that stage carries less propellant, so you don’t get such geometrically-gigantic tanks. The Delta IV is an example of a vehicle that is all hydrogen. The booster stage is also hydrogen, and I think that it’s a very effective vehicle, but it never was very cost-effective. So, it’s operationally very capable but not very cost-effective.
Segment 92: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1736, Text: So, size is also costly?
Segment 93: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1738, Text: Size is costly. So, it’s interesting. Rockets love to be big. Everything works better.
Segment 94: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1745, Text: What do you mean by that? You’ve told me that before. It sounds epic, but what does it mean?
Segment 95: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1750, Text: I mean, when you look at the physics of rocket engines, and also when you look at parasitic mass… Let’s say you have an avionic system, so you have a guidance and control system, that is going to be about the same mass and size for a giant rocket as it is going to be for a tiny rocket. And so, that’s just parasitic mass that is very consequential if you’re building a very small rocket, but is trivial if you’re building a very large rocket. So, you have the parasitic mass thing. And then if you look at, for example, rocket engines have turbo pumps. They have to pressurize the fuel in the oxidizer up to a very high pressure level in order to inject it into the thrust chamber where it burns. And those pumps, all rotating machines, in fact, get more efficient as they get larger. So, really tiny turbo pumps are very challenging to manufacture, and any kind of gaps between the housing, for example, and the rotating impeller that pressurizes the fuel, there has to be some gap there. You can’t have those parts scraping against one another, and those gaps drive inefficiencies. And so, if you have a very large turbo pump, those gaps in percentage terms end up being very small. And so, there’s a bunch of things that you end up loving about having a large rocket and that you end up hating for a small rocket. But there’s a giant exception to this rule, and it is manufacturing. So, manufacturing large structures is very, very challenging. It’s a pain in the butt. And so, if you’re making a small rocket engine, you can move all the pieces by hand, you could assemble it on a table, one person can do it. You don’t need cranes and heavy lift operations and tooling and so on and so on. When you start building big objects, infrastructure, civil infrastructure, just like the launchpad and all this we went and visited, I took you to the launchpad. And you can see it’s so monumental.
Segment 96: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1887, Text: Yeah, it is.
Segment 97: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1888, Text: And so, just these things become major undertakings, both from an engineering point of view, but also from a construction and cost point of view.
Segment 98: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1897, Text: And even the foundation of the launchpad. I mean, this is Florida, isn’t it swamp land? How deep do you have to go?
Segment 99: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1904, Text: At Cape Canaveral, in fact, most launch pads are on beaches somewhere on the ocean side because you want to launch over water for safety reasons. Yes, you have to drive pilings, dozens and dozens and dozens of pilings, 50, 100, 150 feet deep to get enough structural integrity for these very large… Yes, these turn into major civil engineering projects.
Segment 100: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1935, Text: I just have to say everything about that factory is pretty badass. You said tooling, the bigger it gets, the more epic it is.
Segment 101: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1942, Text: It does make it epic. It’s fun to look at. It’s extraordinary.
Segment 102: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1946, Text: It’s humbling also because humans are so small compared to it.
Segment 103: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1949, Text: We are building these enormous machines that are harnessing enormous amounts of chemical power in very, very compact packages. It’s truly extraordinary.
Segment 104: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1964, Text: But then, there’s all the different components and the materials involved. Is there something interesting that you can describe about the materials that comprise the rocket? So, it has to be as light as possible, I guess, whilst withstanding the heat and the harsh conditions?
Segment 105: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1983, Text: Yeah-
Segment 106: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1980, Text: Whilst withstanding the heat and the harsh conditions?
Segment 107: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=1983, Text: Yeah, I play a little game sometimes with other rocket people that I run into where say, “What are the things that would amaze the 1960s engineers? What’s changed?” Because surprisingly, some of rocketry’s greatest hits have not changed. They would recognize immediately a lot of what we do today and it’s exactly what they pioneered back in the ’60s. But a few things have changed. The use of carbon composites is very different today. We can build very sophisticated … You saw our carbon tape laying machine that builds the giant fairings and we can build these incredibly light, very stiff fairing structures out of carbon composite material that they could not have dreamed of. The efficiency, the structural efficiency of that material is so high compared to any metallic material you might use or anything else. So that’s one.
Segment 108: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2052, Text: Aluminum-lithium and the ability to friction stir weld aluminum-lithium. Do you remember the friction stir welding that I showed you?
Segment 109: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2060, Text: Yes. It’s incredible.
Segment 110: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2061, Text: This is a remarkable technology that’s invented decades ago, but has become very practical over just the last couple of decades. And instead of using heat to weld two pieces of metal together, it literally stirs the two pieces. There’s a pin that rotates at a certain rate and you put that pin between the two plates of metal that you want to weld together and then you move it at a very precise speed. And instead of heating the material, it heats it a little bit because of friction, but not very much, you can literally immediately after welding with stir friction welding, you can touch the material and it’s just barely warm. It literally stirs the molecules together. It’s quite extraordinary.
Segment 111: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2106, Text: Relatively low temperature and I guess high temperatures, that makes it a weak point.
Segment 112: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2111, Text: Exactly. So …
Segment 113: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2113, Text: Amazing.
Segment 114: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2113, Text: … with traditional welding techniques, you whatever the underlying strength characteristics of the material are, you end up with weak regions where you weld. And with friction stir welding, the welds are just as strong as the bulk material. So it really allows you … Let’s say you’re building a tank that you’re going to pressurize a large liquid natural gas tank for our booster stage, for example, if you are welding that with traditional methods, you have to size those weld lands, the thickness of those pieces with that knockdown for whatever damage you’re doing with the weld and that’s going to add a lot of weight to that tank.
Segment 115: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2154, Text: Even just looking at the fairings, the result of that, the complex shape that it takes and what it’s supposed to do is incredible because some people don’t know, it’s on top of the rock, it’s going to fall apart. That’s its task, but it has to stay strong sometimes and then disappear when it needs to …
Segment 116: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2174, Text: That’s right.
Segment 117: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2175, Text: … which is a very difficult task.
Segment 118: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2177, Text: Yes. When you need something that needs to have 100% integrity until it needs to have 0% integrity, it needs to stay attached until it’s ready to go away, and then when it goes away, it has to go away completely. You use explosive charges for that and so it’s a very robust way of separating structure when you need to.
Segment 119: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2200, Text: Exploding.
Segment 120: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2201, Text: Yeah, little tiny bits of explosive material and it will sever the whole connection.
Segment 121: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2209, Text: So if you want to go from 100% structural integrity to zero as fast as possible is explosives.
Segment 122: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2218, Text: Use explosives.
Segment 123: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2219, Text: The entirety of this thing is so badass. Okay, so we’re back to the two stages. So the first stage is reusable.
Segment 124: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2226, Text: Yeah. Second stage is expendable. Second stage is liquid hydrogen, liquid oxygen. So we get take advantage of the higher specific impulse. The first stage lands down range on a landing platform in the ocean, comes back for maintenance and get ready to do the next mission.
Segment 125: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2247, Text: There’s a million questions, but also is there a path towards reusability for the second stage?
Segment 126: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2252, Text: There is and we know how to do that. Right now, we’re going to work on manufacturing that second stage to make it as inexpensive as possible, two paths for a second stage, make it reusable or work really hard to make it inexpensive, so you can afford to expend it. And that trade is actually not obvious which one is better.
Segment 127: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2280, Text: Even in terms of cost, like time, cost-
Segment 128: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2281, Text: Even in terms of … And I’m talking about cost. Space, getting into orbit is a solved problem. We solved it back in the ’50s and ’60s.
Segment 129: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2291, Text: You’re making it sound easy.
Segment 130: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2293, Text: The only interesting problem is dramatically reducing the cost of access to orbit, which is, if you can do that, you open up a bunch of new endeavors that lots of start-up companies everybody else can do. One of our missions is to be part of this industry and lower the cost to orbit, so that there can be a renaissance, a golden age of people doing all kinds of interesting things in space.
Segment 131: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2327, Text: I like how you said getting to orbit is a solved problem. It’s just the only interesting thing is reducing the cost. You know how you can describe every single problem facing human civilization that way? The physicists would say, “Everything is a solved problem. We’ve solved everything. The rest is just,” what did Rutherford said, “that it’s just stamp collecting. It’s just the details.” Some of the greatest innovations and inventions and brilliance is in that cost reduction stage, right? And you’ve had a long career of cost reduction.
Segment 132: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2358, Text: For sure. What does cost reduction really mean? It means inventing a better way.
Segment 133: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2364, Text: Yeah, exactly.
Segment 134: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2365, Text: Right? And when you invent a better way, you make the whole world richer. So whatever it was, I don’t know how many thousands of years ago, somebody invented the plow. And when they invented the plow, they made the whole world richer because they made farming less expensive. And so it is a big deal to invent better ways. That’s how the world gets richer.
Segment 135: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2388, Text: So what are some of the biggest challenges on the manufacturing side, on the engineering side that you’re facing in working to get to the first launch of New Glenn?
Segment 136: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2401, Text: The first launch is one thing and we’ll do that in 2024, coming up in this coming year. The real thing that’s the bigger challenge is making sure that our factory is efficiently manufacturing at rate. So rate production, so consider if you want to launch New Glenn 24 times a year, you need to manufacture a upper stage since they’re expendable, twice a month. You need to do one every two weeks. So you need to have all of your manufacturing facilities and processes and inspection techniques and acceptance tests and everything operating at rate. And rate manufacturing is at least as difficult as designing the vehicle in the first place and the same thing. So every upper stage has two BE-3U engines.
Segment 137: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2463, Text: So those engines, if you’re going to launch the vehicle twice a month, you need four engines a month. So you need an engine every week. That engine needs to be being produced at rate and there’s all of the things that you need to do that, all the right machine tools, all the right fixtures, the right people, process, etcetera. So it’s one thing to build a first article, right? To launch New Glenn for the first time, you need to produce a first article, but that’s not the hard part. The hard part is everything that’s going on behind the scenes to build a factory that can produce New Glenns at rate.
Segment 138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2507, Text: So the first one is produced in a way that enables the production of the second and third and the fourth and the fifth and sixth-
Segment 139: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2513, Text: You could think of the first article as pushing, it pushes all of the rate manufacturing technology along. In other words, it’s the test article in a way that’s testing out your manufacturing technologies.
Segment 140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2533, Text: The manufacturing is the big challenge.
Segment 141: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2535, Text: Yes. I don’t want to make it sound like any of it is easy. The people who are designing the engines and all this, all of this is hard for sure, but the challenge right now is driving really hard to get to is to get to rate manufacturing and to do that in an efficient way, again back to our cost point. If you get to rate manufacturing in an inefficient way, you haven’t really solved the cost problem and maybe you haven’t really moved the state of the art forward. All this has to be about moving this state of the art forward. There are easier businesses to do. I always tell people, “Look, if you are trying to make money, start a salty snack food company or something.”
Segment 142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2576, Text: I’m going to write that idea down.
Segment 143: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2581, Text: Make the Lex Fridman Potato Chips.
Segment 144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2584, Text: Right. Don’t say it. People are going to steal it. But yeah, it’s hard.
Segment 145: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2590, Text: Do you see what I’m saying? There’s nothing easy about this business, but it’s its own reward. It’s fascinating, it’s worthwhile, it’s meaningful. I don’t want to pick on salty snack food companies, but I think it’s less meaningful. At the end of the day, you’re not going to have accomplished something amazing …
Segment 146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2613, Text: Yeah, there’s-
Segment 147: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2613, Text: … even if you do make a lot of money on it.
Segment 148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2615, Text: Yeah, there’s something fundamentally different about the “business of space exploration.”
Segment 149: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2621, Text: Yeah, for sure.
Segment 150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2622, Text: It’s a grand project of humanity.
Segment 151: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2624, Text: Yes, it’s one of humanity’s grand challenges, and especially as you look at going to the moon and going to Mars and building giant O’Neill colonies and unlocking all the things. I won’t live long enough to see the fruits of this, but the fruits of this come from building a road to space, getting the infrastructure. I’ll give you an analogy. When I started Amazon, I didn’t have to develop a payment system. It already existed. It was called the credit card. I didn’t have to develop a transportation system to deliver the packages. It already existed. It was called the Postal Service and Royal Mail and Deutsche Post and so on. So all this heavy lifting infrastructure was already in place and I could stand on its shoulders. And that’s why, when you look at the internet …
Segment 152: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2680, Text: And by the way, another giant piece of infrastructure that was around in the early, I’m taking you back to 1994, people were using dial-up modems and it was piggybacking on top of the long distance phone network. That’s how the internet … That’s how people were accessing servers and so on. And again, if that hadn’t existed, it would’ve been hundreds of billions of CapEx to put that out there. No startup company could have done that. And so the problem you see, if you look at the dynamism in the internet space over the last 20 years, it’s because you see two kids in a dorm room could start an internet company that could be successful and do amazing things because they didn’t have to build heavy infrastructure. It was already there. And that’s what I want to do. I take my Amazon winnings and use that to build heavy infrastructure so that the next generation, the generation that’s my children and their children, those generations can then use that heavy infrastructure, then there’ll be space entrepreneurs who start in their dorm room. That will be a marker of success when you can have a really valuable space company started in a dorm room, then we know that we’ve built enough infrastructure so that ingenuity and imagination can really be unleashed. I find that very exciting.
Segment 153: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2771, Text: They will, of course, as kids do, take all of this hard infrastructure ability for granted.
Segment 154: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2776, Text: Of course.
Segment 155: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2778, Text: That entrepreneurial spirit.
Segment 156: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2779, Text: That’s an inventor’s greatest dream, is that their inventions are so successful that they are one day taken for granted. Nobody thinks of Amazon as an invention anymore. Nobody thinks of customer reviews as an invention. We pioneered customer reviews, but now they’re so commonplace. Same thing with one-click shopping and so on, but that’s a compliment. You invent something that’s so used, so beneficially used by so many people that they take it for granted.
Segment 157: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2809, Text: I don’t know about nobody. Every time I use Amazon, I’m still amazed, “How does this work, the logistics, the Wazuh?”
Segment 158: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2815, Text: Well, that proves you’re a very curious explorer.
Segment 159: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2817, Text: All right, all right, back to rocket. Timeline, you said 2024. As it stands now, are both the first test launch and the launch of ESCAPADE explorers to Mars still possible in 2024?
Segment 160: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2831, Text: In 2024?
Segment 161: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2832, Text: Yeah.
Segment 162: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2833, Text: Yeah, I think so. For sure, the first launch and then we’ll see if ESCAPADE goes on that or not. I think that the first launch for sure and I hope ESCAPADE too.
Segment 163: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2843, Text: Hope-
Segment 164: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2844, Text: Well, I just don’t know which mission it’s actually going to be slated on. So we also have other things that might go on that first mission.
Segment 165: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2851, Text: Oh, I got it. But you’re optimistic that the launches will still-
Segment 166: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2855, Text: Oh, the first launch. I’m very optimistic that the first launch of New Glenn will be in 2024 and I’m just not 100% certain what payload will be on that first launch.
Segment 167: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2864, Text: Are you nervous about it?
Segment 168: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2866, Text: Are you kidding? I’m extremely nervous about it.
Segment 169: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2871, Text: Oh, man.
Segment 170: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2872, Text: 100%. Every launch I go to, for New Shepherd, for other vehicles too, I’m always nervous for these launches. But yes, for sure, a first launch, to have no nervous about that would be some sign of derangement, I think so.
Segment 171: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2889, Text: Well, I got to visit the launch, man. It’s pretty … I mean, it’s epic.
Segment 172: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2894, Text: We have done a tremendous amount of ground testing, a tremendous amount of simulation. So a lot of the problems that we might find in flight have been resolved, but there are some problems you can only find in flight. So cross your fingers. I guarantee you you’ll have fun watching it no matter what happens.
Segment 173: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2917, Text: 100%. When the thing is fully assembled, it comes up-
Segment 174: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2921, Text: Yeah, the transporter erector.
Segment 175: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2924, Text: It’s the erector, yeah.
Segment 176: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2925, Text: Just the transporter erector for a rocket of this scale is extraordinary.
Segment 177: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2929, Text: That’s an incredible machine.
Segment 178: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2930, Text: The vehicle travels out horizontally and then comes up and-
Segment 179: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2937, Text: Over a few hours?
Segment 180: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2938, Text: Yeah, it’s a beautiful thing to watch.
Segment 181: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2940, Text: Speaking of which, if that makes you nervous, I don’t know if you remember, but you were aboard New Shepard on its first crewed flight. How was that experience? Were you terrified then?
Segment 182: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2960, Text: Strangely, I wasn’t.
Segment 183: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2962, Text: When you ride the rocket, wasn’t nerve wracking? Okay.
Segment 184: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2964, Text: It’s true. I’ve watched other people riding the rocket and I’m more nervous than when I was inside the rocket myself. It was a difficult conversation to have with my mother when I told her I was going to go on the first one. And not only was I going to go, but I was going to bring my brother too. This is a tough conversation to have with a mom.
Segment 185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2984, Text: There’s a long pause when you told her.
Segment 186: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=2987, Text: She’s like, “Both of you?” It was an incredible experience and we were laughing inside the capsule and we’re not nervous. The people on the ground were very nervous for us. It was actually one of the most emotionally powerful parts of the experience happened even before the flight. At 4:30 in the morning, brother and I are getting ready to go to the launch site and Lauren is going to take us there in her helicopter and we’re getting ready to leave. And we go outside, outside the ranch house there in West Texas where the launch facility is and all of our family, my kids and my brother’s kids and our parents and close friends are assembled there and they’re saying goodbye to us, but they’re saying, “Maybe they think they’re saying goodbye to us forever,” and we might not have felt that way, but it was obvious from their faces how nervous they were that they felt that way. And it was powerful because it allowed us to see … It was almost like a attending year old memorial service or something like you could feel how loved you were in that moment and it was really amazing.
Segment 187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3072, Text: Yeah, and there’s just a epic nature to it too.
Segment 188: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3077, Text: The ascent, the floating in zero gravity. I’ll tell you something very interesting, zero gravity feels very natural. I don’t know if it’s because it’s like return to the womb or-
Segment 189: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3091, Text: You just confirmed you’re an alien, but that’s all. I think that’s what you just said.
Segment 190: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3096, Text: It feels so natural to be in zero G. It was really interesting. And then what people talk about the overview effect and seeing Earth from space, I had that feeling very powerfully. I think everyone did. You see how fragile the Earth is. If you’re not an environmentalist, it will make you one. The great Jim Lovell quote, he looked back at the Earth from space and he said he realized, “You don’t go to heaven when you die. You go to heaven when you’re born.” That’s the feeling that people get when they’re in space. You see all this blackness, all this nothingness and there’s one gem of life and it’s Earth.
Segment 191: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3135, Text: It is a gem. You’ve talked a lot about decision making throughout your time with Amazon. What was that decision like to be the first to ride New Shepard? Just before you talk to your mom, the pros and cons? Actually, as one human being, as a leader of a company on all fronts, what was that decision making like?
Segment 192: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3163, Text: I decided that … First of all, I knew the vehicle extremely well. I know the team who built it. I know the vehicle. I’m very comfortable with the escape system. We put as much effort into the escape system on that vehicle as we put into all the rest of the vehicle combined. It’s one of the hardest pieces of engineering in the entire New Shepard architecture.
Segment 193: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3190, Text: Can you actually describe what do you mean by escape system? What’s involved?
Segment 194: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3193, Text: We have a solid rocket motor in the base of the crew capsule, so that if anything goes wrong on ascent, while the main rocket engine is firing, we can ignite this solid rocket motor in the base of the crew capsule and escape from the booster. It’s a very challenging system to build, design, validate, test, all of these things. It is the reason that I am comfortable letting anyone go on New Shepard. So the booster is as safe and reliable as we can make it, but we are harnessing … Whenever you’re talking about rocket engines, I don’t care what rocket engine you’re talking about, you’re harnessing such vast power in such a small compact geometric space. The power density is so enormous that it is impossible to ever be sure that nothing will go wrong.
Segment 195: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3258, Text: And so the only way to improve safety is to have an escape system. And historically, human-rated rockets have had escape systems. Only the space shuttle did not, but Apollo had one. All of the previous Gemini, etcetera, they all had escape systems. And we have on New Shepard an unusual escape … Most escape systems are towers. We have a pusher escape system. So the solid rocket motor is actually embedded in the base of the crew capsule and it pushes and it’s reusable in the sense that, if we don’t use it, so if we have a nominal mission, we land with it. The tower systems have to be ejected at a certain point in the mission and so they get wasted even in a nominal mission.
Segment 196: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3309, Text: And so again, costs really matters on these things, so we figured out how to have the escape system be a reusable. In the event that it’s not used, it can reuse it and have it be a pusher system. It’s a very sophisticated thing. So I knew these things. You asked me about my decision to go and so I know the vehicle very well, I know the people who designed it, I have great trust in them and in the engineering that we did. And I thought to myself, “Look, if I am not ready to go, then I wouldn’t want anyone to go.” A tourism vehicle has to be designed, in my view, to be as safe as one can make it. You can’t make it perfectly safe. It’s impossible, but you have … People will do things. People take risk. They climb mountains, they skydive, they do deep underwater scuba diving and so on. People are okay taking risk. You can’t eliminate the risk, but it is something, because it’s a tourism vehicle, you have to do your utmost to eliminate those risks.
Segment 197: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3376, Text: And I felt very good about the system. I think it’s one of the reasons I was so calm inside and maybe others weren’t as calm. They didn’t know as much about it as I did.
Segment 198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3386, Text: Who was in charge of engaging the escape system? Did you have-
Segment 199: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3388, Text: It’s automated. The escape system is …
Segment 200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3391, Text: Okay. I was visualizing-
Segment 201: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3393, Text: … completely automated. Automated is better because it can react so much faster.
Segment 202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3398, Text: Okay. So yeah, for tourism rockets, safety is a huge, huge, huge priority for space exploration also, but a delta less.
Segment 203: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3406, Text: Yes. I think if you’re doing … There are human activities where we tolerate more risk if you’re saving somebody’s life, if you are engaging in real exploration. These are things where I personally think we would accept more risk in part because you have to.
Segment 204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3429, Text: Is there a part of you that’s frustrated by the rate of progress in Blue Origin?
Segment 205: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3435, Text: Blue Origin needs to be much faster. And it’s one of the reasons that I left my role as the CEO of Amazon a couple of years ago, “I wanted to come in and Blue Origin needs me right now.” And so I had always … When I was the CEO of Amazon, my point of view on this is, “If I’m the CEO of a publicly traded company, it’s going to get my full attention.” And it’s just how I think about things. It was very important to me. I felt I had an obligation to all the stakeholders at Amazon to do that. And so having turned the CEO, I’m still the executive chair there, but I turned the CEO role over, and the primary reason I did that is that I could spend time on Blue Origin, adding some energy, some sense of urgency, “We need to move much faster and we’re going to.”
Segment 206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3494, Text: What are the ways to speed it up? You’ve talked a lot of different ways at Amazon removing barriers for progress or distributing, making everybody autonomous and self-reliant, all those kinds of things. Is that apply at Blue Origin or is-
Segment 207: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3517, Text: It does apply. I’m leading this directly. We’re going to become the world’s most decisive company across any industry. And so at Amazon, for ever since the beginning, I said, “We’re going to become the world’s most customer-obsessed company.” And no matter the industry, one day, people are going to come to Amazon from the healthcare industry and want to know, “How are you so customer-obsessed? How do you not just pay lip service that, but actually do that?” All different industries should come want to study us to see how we accomplish that. And the analogous thing at Blue Origin and will help us move faster is we’re going to become the world’s most decisive company. We’re going to get really good at taking appropriate technology risk and making those decisions quickly, being bold on those things and having the right culture that supports that.
Segment 208: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3580, Text: You need people to be ambitious, technically ambitious, “If there are five ways to do something, we’ll study them, but let’s study them very quickly and make a decision.” We can always change our mind. Changing your mind, I talk about one-way doors and two-way doors, most decisions are two-way doors.
Segment 209: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3603, Text: Can you explain that because I love that metaphor?
Segment 210: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3606, Text: If you make the wrong decision, if it’s a two-way door decision, you pick a door, you walk out and you spend a little time there. It turns out to be the wrong decision, you can come back in and pick another door. Some decisions are so consequential and so important and so hard to reverse that they really are one-way door decisions. You go in that door, you’re not coming back. And those decisions have to be made very deliberately, very carefully. If you can think of yet another way to analyze the decision, you should slow down and do that. So when I was CEO of Amazon, I often found myself in the position of being the chief slow down officer because somebody would be bringing me a one-way door decision and I would say, “Okay, I can think of three more ways to analyze that. So let’s go do that because we are not going to be able to reverse this one easily. Maybe you can reverse it if it’s going to be very costly and very time-consuming. We really have to get this one right from the beginning.”
Segment 211: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3670, Text: And what happens, unfortunately, in companies, what can happen, is that you have a one-size-fits-all decision-making process where you end up using the heavyweight process on all decisions …
Segment 212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3688, Text: For everything, yeah.
Segment 213: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3689, Text: … Including the lightweight ones, the two-way door decisions. Two-way door decisions should mostly be made by single individuals or by very small teams deep in the organization. And one-way door decisions are the irreversible ones. Those are the ones that should be elevated up to the senior-most executives who should slow them down and make sure that the right thing is being done.
Segment 214: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3715, Text: Yeah, part of the skill here is to know the difference between one-way and two-way. I think you mentioned …
Segment 215: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3715, Text: Yes.
Segment 216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3721, Text: I think you mentioned Amazon Prime, the decision to create Amazon Prime as a one-way door. It’s unclear if it is or not, but it probably is and it’s a really big risk to go there.
Segment 217: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3734, Text: There are a bunch of decisions like that are … Changing the decision is going to be very, very complicated. Some of them are technical decisions too because some technical decisions are like quick-drying cement. Once you make them, it gets really hard. Choosing which propellants to use in a vehicle, selecting LNG for the booster stage and selecting hydrogen for the upper stage, that has turned out to be a very good decision. But if you changed your mind, that would be a very big setback. Do you see what I’m saying?
Segment 218: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3771, Text: Yeah, yeah.
Segment 219: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3772, Text: So that’s the kind of decision you scrutinize very, very carefully. Other things just aren’t like that. Most decisions are not that way. Most decisions should be made by single individuals and done quickly in the full understanding that you can always change your mind.
Segment 220: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3791, Text: One of the things I really liked, perhaps it’s not a two-way door decisions, is, “I disagree and commit,” phrase. So somebody brings up an idea to you, if it’s a two-way door, you state that you don’t understand enough to agree, but you still back them. I’d love for you to explain that-
Segment 221: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3815, Text: Well, yes, disagree and commit is a really important principle that saves a lot of arguing. So-
Segment 222: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3819, Text: Yeah, I’m going to use that in my personal life, “I disagree, but commit.”
Segment 223: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3824, Text: It’s very common in any endeavor in life, in business and anybody where you have teammates, you have a teammate and the two of you disagree. At some point, you have to make a decision. And in companies, we tend to organize hierarchically. Whoever’s the more senior person ultimately gets to make the decision. So ultimately, the CEO gets to make that decision. And the CEO may not always make the decision that they agree with. So I would be the one who would disagree and commit. One of my direct reports would very much want to do something in a particular way. I would think it was a bad idea. I would explain my point of view. They would say, ” Jeff, I think you’re wrong and here’s why,” and we would go back and forth.
Segment 224: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3875, Text: And I would often say, “You know what? I don’t think you’re right, but I’m going to gamble with you and you’re closer to the ground truth than I am. I’d known you for 20 years. You have great judgment. I don’t know that I’m right either. Not really, not for sure. All these decisions are complicated. Let’s do it your way.” But at least then you’ve made a decision and I’m agreeing to commit to that decision. So I’m not going to be second guessing it. I’m not going to be sniping at it. I’m not going to be saying, “I told you so.” I’m going to try actively to help make sure it works. That’s a really important teammate behavior.
Segment 225: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3918, Text: There’s so many ways that dispute resolution is a really interesting thing on teams. And there are so many ways when two people disagree about something, even … I’m assuming the case for everybody is well-intentioned. They just have a very different opinion about what the right decision is. And in our society and inside companies, we have a bunch of mechanisms that we use to resolve these kinds of disputes. A lot of them are, I think, really bad. So an example of a really bad way of coming to agreement is compromise. So compromise, we’re in a room here and I could say, “Lex, how tall do you think this ceiling is?”
Segment 226: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=3960, Text: I’m here and I could say, “Lex, how tall do you think this ceiling is?” And you’d be like, “I don’t know, Jeff, maybe 12 feet tall.” And I would say, “I think it’s 11 feet tall.” And then we’d say, “You know what? Let’s just call it 11 and a half feet.” That’s compromise, instead of. The right thing to do is to get a tape measure or figure out some way of actually measuring, but think getting that tape measure and figure out how to get it to the top of the ceiling and all these things, that requires energy. Compromise, the advantage of compromise as a resolution mechanism is that it’s low energy, but it doesn’t lead to truth. And so in things like the height of the ceiling where truth is a noble thing, you shouldn’t allow compromise to be used when you can know the truth.
Segment 227: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4011, Text: Another really bad resolution mechanism that happens all the time is just who’s more stubborn? This is also, let’s say two executives who disagree and they just have a war of attrition, and whichever one gets exhausted first capitulates to the other one. Again, you haven’t arrived at truth and this is very demoralizing. So this is where escalation, I try to ask people on my team and say, “Never get to a point where you are resolving something by who gets exhausted first. Escalate that.” I’ll help you make the decision because that’s so de-energized and such a terrible, lousy way to make a decision.
Segment 228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4060, Text: Do you want to get to the resolution as quickly as possible because that ultimately leads to high velocity of decision?
Segment 229: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4065, Text: Yes, and you want to try to get as close to truth as possible. Exhausting the other person is not truth seeking.
Segment 230: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4073, Text: Yes.
Segment 231: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4074, Text: And compromise is not truth seeking. And there are a lot of cases where no one knows the real truth and that’s where disagree and commit can come in, but escalation is better than war of attrition. Escalate to your boss and say, “Hey, we can’t agree on this. We like each other. We’re respectful of each other, but we strongly disagree with each other. We need you to make a decision here so we can move forward.” But decisiveness, moving forward quickly on decisions, as quickly as you responsibly can is how you increase velocity. Most of what slows things down is taking too long to make decisions at all scale levels. So it has to be part of the culture to get high velocity. Amazon has a million and a half people and the company is still fast. We’re still decisive, we’re still quick, and that’s because the culture supports that.
Segment 232: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4133, Text: At every scale in a distributed way-
Segment 233: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4133, Text: Yes.
Segment 234: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4136, Text: Try to maximize the velocity of decisions.
Segment 235: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4138, Text: Exactly.
Segment 236: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4139, Text: You’ve mentioned the lunar program. Let me ask you about that. There’s a lot going on there and you haven’t really talked about it much. So in addition to the Artemis program with NASA, Blue is doing its own lander program. Can you describe it? There’s a sexy picture on Instagram with one of them. Is it the MK1, I guess?
Segment 237: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4160, Text: Yeah, The Mark 1. The picture here is me with Bill Nelson, the NASA Administrator.
Segment 238: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4166, Text: Just to clarify, the lander is the sexy thing about the [inaudible 01:09:29]. I really want to clarify that.
Segment 239: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4172, Text: I know it’s not me. I know it was either the lander or Bill.
Segment 240: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4174, Text: Okay. I love Bill, but-
Segment 241: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4177, Text: Thank you for clarifying.
Segment 242: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4177, Text: Okay.
Segment 243: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4180, Text: Yes, the Mark 1 lander is designed to take 3,000 kilograms to the surface of the moon and to cargo expendable cargo. It’s an expendable lander. Lands on the moon, stays there, take 3,000 kilograms to the surface. It can be launched on a single New Glenn flight, which is very important. So it’s a relatively simple architecture, just like the human landing system lander, they’re called the Mark 2. Mark 1 is also fueled with liquid hydrogen, which is for high energy emissions like landing on the surface of the moon. The high specific impulsive hydrogen is a very big advantage.
Segment 244: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4224, Text: The disadvantage of hydrogen has always been that since it’s such a deep cryogen, it’s not storable. So it’s constantly boiling off and you’re losing propellant because it’s boiling off. And so what we’re doing as part of our lunar program is developing solar-powered cryo coolers that can actually make hydrogen a storable propellant for deep space. And that’s a real game-changer. It’s a game-changer for any high energy mission. So to the moon, but to the outer planets, to Mars, everywhere.
Segment 245: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4260, Text: So the idea with both Mark 1 and Mark 2 is the New Glenn can carry it from the surface of earth to the surface of the moon?
Segment 246: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4272, Text: Exactly. So the Mark 1 is expendable. The lunar lander we’re developing for NASA, the Mark 2 lander, that’s part of the Artemis program. They call it the Sustaining Lander Program. So that lander is designed to be reusable. It can land on the surface of the moon in a single stage configuration and then take off. So if you look at the Apollo program, the lunar lander and Apollo was really two stages. It would land on the surface and then it would leave the descent stage on the surface of the moon and only the ascent stage would go back up into lunar orbit where it would rendezvous with the command module.
Segment 247: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4316, Text: Here, what we’re doing is we have a single stage lunar lander that carries down enough propellant so that it can bring the whole thing back up so that it can be reused over and over. And the point of doing that, of course, is to reduce cost so that you can make lunar missions more affordable over time, which is that’s one of NASA’s big objectives because this time… The whole point of Artemis is go back to the moon, but this time to stay. So back in the Apollo program, we went to the moon six times and then ended the program and it really was too expensive to continue.
Segment 248: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4355, Text: And so there’s a few questions there, but one is how do you stay on the moon? What ideas do you have about sustaining life where a few folks can stay there for prolonged periods of time?
Segment 249: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4371, Text: Well, one of the things we’re working on is using lunar resources like lunar regolith to manufacture commodities and even solar cells on the surface of the moon. We’ve already built a solar cell that is completely made from lunar regolith stimulant, and this solar cell is only about 7% power efficient. So it’s very inefficient compared to the more advanced solar cells that we make here on earth. But if you can figure out how to make a practical solar cell factory that you can land on the surface of the moon and then the raw material for those solar cells is simply lunar regolith, then you can just continue to churn out solar cells on the surface of the moon, have lots of power on the surface of the moon. That will make it easier for people to live on the moon.
Segment 250: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4431, Text: Similarly, we’re working on extracting oxygen from lunar regolith. So lunar regolith by weight has a lot of oxygen in it. It’s bound very tightly as oxides with other elements. And so you have to separate the oxygen, which is very energy intensive. So that also could work together with the solar cells. And then ultimately, we may be able to find practical quantities of ice in the permanently shadowed craters on the poles of the moon. And we know there is ice water or water ice in those craters, and we know that we can break that down with electrolysis into hydrogen and oxygen. And then you’d not only have oxygen, but you’d also have a very good high efficiency propellant fuel in hydrogen.
Segment 251: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4497, Text: So there’s a lot we can do to make the moon more sustainable over time, but the very first step, the gate that all of that has to go through is we need to be able to land cargo and humans on the surface of the moon at an acceptable cost.
Segment 252: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4516, Text: To fast-forward a little bit, is there any chance Jeff Bezos steps foot on the moon and on Mars, one or the other or both?
Segment 253: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4527, Text: It’s very unlikely. I think it’s probably something that gets done by future generations by the time it gets to me. I think in my lifetime that’s probably going to be done by professional astronauts, sadly. I would love to sign up for that mission. So don’t count me out yet, Lex. Give me a finding shot here maybe, but I think if we are placing reasonable bets on such a thing, in my lifetime, that will continue to be done by professional astronauts.
Segment 254: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4559, Text: So these are risky, difficult missions?
Segment 255: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4562, Text: And probably missions that require a lot of training. You are going there for a very specific purpose to do something. We’re going to be able to do a lot on the moon too with automation. So in terms of setting up these factories and doing all that, we are sophisticated enough now with automation that we probably don’t need humans to tend those factories and machines. So there’s a lot that’s going to be done in both modes.
Segment 256: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4588, Text: So I have to ask the bigger picture question about the two companies pushing humanity forward out towards the stars, Blue Origin and SpaceX. Are you competitors, collaborators? Which and to what degree?
Segment 257: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4604, Text: Well, I would say just like the internet is big and there are lots of winners at all scale levels, there are half a dozen giant companies that the internet has made, but there are a bunch of medium-sized companies and a bunch of small companies, all successful, all with profit streams, all driving great customer experiences. That’s what we want to see in space, that kind of dynamism. And space is big. There’s room for a bunch of winners and it’s going to happen at all skill levels. And so SpaceX is going to be successful for sure. I want Blue Origin to be successful, and I hope there are another five companies right behind us.
Segment 258: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4645, Text: But I spoke to Elon a few times recently about you, about Blue Origin, and he was very positive about you as a person and very supportive of all the efforts you’ve been leading at Blue. What’s your thoughts? You worked with a lot of leaders at Amazon at Blue. What’s your thoughts about Elon as a human being and a leader?
Segment 259: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4666, Text: Well, I don’t really know Elon very well. I know his public persona, but I also know you can’t know anyone by their public persona. It’s impossible. You may think you do, but I guarantee you don’t. So I don’t really know. You know Elon way better than I do, Lex, but in terms of judging by the results, he must be a very capable leader. There’s no way you could have Tesla and SpaceX without being a capable leader. It’s impossible.
Segment 260: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4702, Text: Yeah, I hope you guys hang out sometimes, shake hands and sort of have a kind of friendship that would inspire just the entirety of humanity, because what you’re doing is one of the big grand challenges ahead for humanity.
Segment 261: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4720, Text: Well, I agree with you and I think in a lot of these endeavors we’re very like-minded. So I’m not saying we’re identical, but I think we’re very like-minded. And so I love that idea.
Segment 262: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4736, Text: All right, going back to sexy pictures on your Instagram, there’s a video of you from the early days of Amazon, giving a tour of your, “Offices.” I think your dad is holding the camera.
Segment 263: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4750, Text: He is. Yeah, I know, right? Yes. This is what? The giant orange extension cord.
Segment 264: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4752, Text: And you’re explaining the genius of the extension cord and how this is a desk and the CRT monitor, and that’s where all the magic happened. I forget what your dad said, but this is the center of it all. So what was it like? What was going through your mind at that time? You left a good job in New York and took this leap. Were you excited? Were you scared?
Segment 265: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4777, Text: So excited and scared, anxious. Thought the odds of success were low. Told all of our early investors that I thought there was a 30% chance of success by which I just mean getting your money back, not what actually happened. Because that’s the truth. Every startup company is unlikely to work. It’s helpful to be in reality about that, but that doesn’t mean you can’t be optimistic. So you have to have this duality in your head. On the one hand, you know what the baseline statistics say about startup companies, and the other hand, you have to ignore all of that and just be 100% sure it’s going to work, and you’re doing both things at the same time. You’re holding that contradiction in your head.
Segment 266: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4824, Text: But it was so exciting. From 1994 when the company was founded to 1995 when we opened our doors, all the way until today, I find Amazon so exciting. And that doesn’t mean… It’s full of pain, full of problems. It’s like there’s so many things that need to be resolved and worked and made better and et cetera. But on balance, it’s so fun. It’s such a privilege. It’s been such a joy. I feel so grateful that I’ve been part of that journey. It’s just been incredible.
Segment 267: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4864, Text: So in some sense, you don’t want a single day of comfort. You’ve written about this many times. We’ll talk about your writing, which I would highly recommend people read and just the letters to shareholders. So explaining the idea of day one thinking, I think you first wrote about in 97 letters to shareholders. Then you also in a way wrote it about, sad to say, is your last letter to shareholders as CEO. And you said that, “Day two is stasis followed by irrelevance, followed by excruciating painful decline, followed by death.” And that is why it’s always day one. Can you explain this day one thing? This is a really powerful way to describe the beginning and the journey of Amazon.
Segment 268: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4916, Text: It’s really a very simple, and I think age-old idea about renewal and rebirth and every day is day one. Every day you are deciding what you’re going to do and you are not trapped by what you were or who you were or any self-consistency. Self-consistency even can be a trap. And so day one thinking is we start fresh every day and we get to make new decisions every day about invention, about customers, about how we’re going to operate. Even as deeply as what our principles are, we can go back to that. It turns out we don’t change those very often, but we change them occasionally.
Segment 269: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=4969, Text: And when we work on programs at Amazon, we often make a list of tenants. And the tenants are… They’re not principles, they’re a little more tactical than principles, but it’s the main ideas that we want this program to embody, whatever those are. And one of the things that we do is we put, “These are the tenets for this program and parentheses.” We always put, “Unless you know a better way.” And that idea, “Unless you know a better way,” is so important because you never want to get trapped by dogma. You never want to get trapped by history. It doesn’t mean you discard history or ignore it. There’s so much value in what has worked in the past, but you can’t be blindly following what you’ve done. And that’s the heart of day one, is you’re always starting afresh.
Segment 270: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5031, Text: And to the question of how to fend off day two, you said, “Such a question can’t have a simple answer,” as you’re saying. “There will be many elements, multiple paths, and many traps. I don’t know the whole answer, but I may know bits of it. Here’s a starter pack of essentials, maybe others come to mind. For day one, defense, customer obsession, a skeptical view of proxies, the eager adoption of external trends and high velocity decision-making.”
Segment 271: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5059, Text: So we talked about high velocity decision-making, that’s more difficult than it sounds. So maybe you can pick one that stands out to you as you can comment on. Eager adoption of external trends, high velocity decision-making, skeptical view of proxies. How do you fight off day two?
Segment 272: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5076, Text: Well, I’ll talk about… Because I think it’s the one that is maybe in some ways the hardest to understand, is the skeptical view of proxies. One of the things that happens in business, probably anything where you have an ongoing program and something is underway for a number of years, is you develop certain things that you’re managing to. The typical case would be a metric, and that metric isn’t the real underlying thing. And so maybe the metric is efficiency metric around customer contacts per unit sold or something like. If you sell a million units, how many customer contacts do you get or how many returns do you get? And so on and so on.
Segment 273: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5130, Text: And so what happens is a little bit of a kind of inertia sets in where somebody a long time ago invented that metric and they invented that metric, they decided, “We need to watch for customer returns per unit sold as an important metric.” But they had a reason why they chose that metric, the person who invented that metric and decided it was worth watching. And then fast-forward five years, that metric is the proxy.
Segment 274: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5162, Text: The proxy for truth, I guess.
Segment 275: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5164, Text: The proxy for truth. Let’s say in this case it’s a proxy for customer happiness, but that metric is not actually customer happiness. It’s a proxy for customer happiness. The person who invented the metric understood that connection. Five years later, a kind of inertia can set in and you forget the truth behind why you were watching that metric in the first place. And the world shifts a little and now that proxy isn’t as valuable as it used to be or it’s missing something. And you have to be on alert for that. You have to know, “Okay, I don’t really care about this metric. I care about customer happiness and this metric is worth putting energy into and following and improving and scrutinizing, only in so much as it actually affects customer happiness.”
Segment 276: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5223, Text: And so you’ve got to constantly be on guard and it’s very, very common. This is a nuanced problem. It’s very common, especially in large companies, that they’re managing to metrics that they don’t really understand. They don’t really know why they exist, and the world may have shifted out from under them a little and the metrics are no longer as relevant as they were when somebody 10 years earlier invented the metric.
Segment 277: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5249, Text: That is a nuance, but that’s a big problem. Right?
Segment 278: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5253, Text: It’s a huge problem.
Segment 279: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5254, Text: There’s something so compelling to have a nice metric to try to optimize.
Segment 280: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5258, Text: Yes. And by the way, you do need metrics.
Segment 281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5261, Text: Yes, you do.
Segment 282: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5261, Text: You can’t ignore them. Want them, but you just have to be constantly on guard. This is a way to slip into day two thinking would be to manage your business to metrics that you don’t really understand and you’re not really sure why they were invented in the first place, and you’re not sure they’re still as relevant as they used to be.
Segment 283: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5283, Text: What does it take to be the guy or gal who brings up the point that this proxy might be outdated? I guess what does it take to have a culture that enables that in the meeting? Because that’s a very uncomfortable thing to bring up at a meeting. “We all showed up here, it’s a Friday.”
Segment 284: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5301, Text: You have just asked a million-dollar question. So if I generalize what you’re asking, you are talking in general about truth-telling and we humans are not really truth-seeking animals. We are social animals.
Segment 285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5322, Text: Yeah, we are.
Segment 286: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5324, Text: And take you back in time 10,000 years and you’re in a small village. If you go along to get along, you can survive. You can procreate. If you’re the village truth-teller, you might get clubbed to death in the middle of the night. Truths are often… They don’t want to be heard because important truths can be uncomfortable, they can be awkward, they can be exhausting.
Segment 287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5352, Text: Impolite and all that kind of stuff.
Segment 288: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5354, Text: Yes, challenging. They can make people defensive even if that’s not the intent. But any high performing organization, whether it’s a sports team, a business, a political organization, an activist group, I don’t care what it is, any high performing organization has to have mechanisms and a culture that supports truth-telling. One of the things you have to do is you have to talk about that. You have to talk about the fact that it takes energy to do that. You have to talk to people, you have to remind people, “It’s okay that it’s uncomfortable.” Literally tell people, “It’s not what we’re designed to do as humans.” It’s kind of a side effect. We can do that, but it’s not how we survive. We mostly survive by being social animals and being cordial and cooperative, and that’s really important.
Segment 289: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5410, Text: And so science is all about truth-telling. It’s actually a very formal mechanism for trying to tell the truth. And even in science, you find that it’s hard to tell the truth. Even you’re supposed to have hypothesis and test it and find data and reject the hypothesis and so on, it’s not easy.
Segment 290: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5436, Text: But even in science, there’s like the senior scientists and the junior scientists.
Segment 291: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5436, Text: Correct.
Segment 292: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5441, Text: And then there’s a hierarchy of humans where somehow seniority matters in the scientific process, which it should not.
Segment 293: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5449, Text: Yes, and that’s true inside companies too. And so you want to set up your culture so that the most junior person can overrule the most senior person if they have data. And that really is about trying to… There are little things you can do. So for example, in every meeting that I attend, I always speak last. And I know from experience that if I speak first, even very strong-willed, highly intelligent, high judgment participants in that meeting will wonder, “Well, if Jeff thinks that, I came in this meeting thinking one thing, but maybe I’m not right.” And so you can do little things like if you’re the most senior person in the room, go last, let everybody else go first. In fact, ideally, let’s try to have the most junior person go first and the second and try to go in order of seniority so that you can hear everyone’s opinion in an unfiltered way. Because we really do, we actually literally change our opinions. If somebody who you really respect says something, it makes you change your mind a little.
Segment 294: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5537, Text: So you’re saying implicitly or explicitly, give permission for people to have a strong opinion, as long as it’s backed by data.
Segment 295: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5547, Text: Yes, and sometimes it can even… By the way, a lot of our most powerful truths turn out to be hunches, they turn out to be based on anecdotes, they’re intuition based. And sometimes you don’t even have strong data, but you may know the person well enough to trust their judgment. You may feel yourself leaning in. It may resonate with a set of anecdotes you have, and then you may be able to say, “Something about that feels right. Let’s go collect some data on that. Let’s try to see if we can actually know whether it’s right. But for now, let’s not disregard it. It feels right.”
Segment 296: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5586, Text: You can also fight inherent bias. There’s an optimism bias. If there are two interpretations of a new set of data and one of them is happy and one of them is unhappy, it’s a little dangerous to jump to the conclusion that the happy interpretation is right. You may want to compensate for that human bias of trying to find the silver lining and say, “Look, that might be good, but I’m going to go with it’s bad for now until we’re sure.”
Segment 297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5616, Text: So speaking of happiness bias, data collection and anecdotes, you have to… How’s that for a transition? You have to tell me the story of the call you made, the customer service call you made to demonstrate a point about wait times?
Segment 298: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5637, Text: Yeah. This is very early in the history of Amazon.
Segment 299: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5640, Text: Yes.
Segment 300: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5640, Text: And we were going over a weekly business review and a set of documents, and I have a saying, which is when the data and the anecdotes disagree, the anecdotes are usually right. And it doesn’t mean you just slavishly go follow the anecdotes then. It means you go examine the data because it’s usually not that the data is being miscollected, it’s usually that you’re not measuring the right thing. And so of you have a bunch of customers complaining about something and at the same time, your metrics look like they shouldn’t be complaining, you should doubt the metrics.
Segment 301: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5683, Text: And an early example of this was we had metrics that showed that our customers were waiting, I think less than, I don’t know, 60 seconds when they called a 1-800 number to get phone customer service. The wait time was supposed to be less than 60 seconds, but we had a lot of complaints that it was longer than that. And anecdotally it seemed longer than that. I would call customer service myself. And so one day we’re in a meeting, we’re going through the WBR, the weekly business review, and we get to this metric in the deck, and the guy who leads customer service is defending the metric. And I said, “Okay, let’s call.” Picked up the phone, and I dialed the 1-800 number and called customer service, and we just waited in silence.
Segment 302: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5739, Text: What did it turn out to be?
Segment 303: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5740, Text: Oh, it was really long, more than 10 minutes, I think.
Segment 304: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5742, Text: Oh, wow.
Segment 305: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5743, Text: It was many minutes. And so it dramatically made the point that something was wrong with the data collection. We weren’t measuring the right thing, and that set off a whole chain of events where we started measuring it right. And that’s an example, by the way, of truth-telling is like that’s an uncomfortable thing to do, but you have to seek truth even when it’s uncomfortable, and you have to get people’s attention and they have to buy into it, and they have to get energized around really fixing things.
Segment 306: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5776, Text: So that speaks to the obsession with the customer experience. So one of the defining aspects of your approach to Amazon is just being obsessed with making customers happy. I think companies sometimes say that, but Amazon is really obsessed with that. I think there’s something really profound to that, which is seeing the world through the eyes of the customer, like the customer experience, the human being that’s using the product, that’s enjoying the product, the subtle little things that make up their experience. How do you optimize those?
Segment 307: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5815, Text: This is another really good and deep question because there are big things that are really important to manage, and then there are small things. Internally into Amazon, we call them paper cuts. So we’re always working on the big things, if you ask me. And most of the energy goes into the big things, as it should, and you can identify the big things. And I would encourage anybody, if anybody listening to this is an entrepreneur, has a small business, whatever, think about the things that are not going to change over 10 years. And those are probably the big things.
Segment 308: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5858, Text: So I know in our retail business at Amazon, 10 years from now, customers are still going to want low prices. I know they’re still going to want fast delivery, and I just know they’re still going to want big selection. So it’s impossible to imagine a scenario where 10 years from now where a customer says, “I love Amazon, I just wish the prices were a little higher,” or, “I love Amazon, I just wish you delivered a little more slowly.” So when you identify the big things you can tell they’re worth putting energy into because they’re stable in time.
Segment 309: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5890, Text: Okay, but you’re asking about something a little different, which is in every customer experience, there are those big things. And by the way, it’s astonishingly hard to focus even on just the big things. So even though they’re obvious, they’re really hard to focus on. But in addition to that, there are all these little tiny customer experience deficiencies, and we call those paper cuts. We make long lists of them. And then we have dedicated teams that go fix paper cuts because the teams working on the big issues never get to the paper cuts. They never work their way down the list to get to… They’re working on big things, as they should and as you want them to. And so you need special teams who are charged with fixing…
Segment 310: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5940, Text: Special teams who are charged with fixing paper cuts.
Segment 311: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5944, Text: Where would you put on the paper cut spectrum the Buy now with the 1-Click button? Which is, I think, pretty genius. So to me, okay, my interaction with things I love on the internet, there’s things I do a lot. I, maybe representing a regular human, I would love for those things to be frictionless. For example, booking airline tickets, just saying. But it’s buying a thing with one click, making that experience frictionless, intuitive, all aspects of that, that just fundamentally makes my life better, not just in terms of efficiency, in terms of some kind of-
Segment 312: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5989, Text: Cognitive load.
Segment 313: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=5990, Text: … Yeah, cognitive load and inner peace and happiness. Because, first of all, buying stuff is a pleasant experience. Having enough money to buy a thing and then buying it is a pleasant experience. And having pain around that is somehow just you’re ruining a beautiful experience. And I guess all I’m saying as a person who loves good ideas, is that a paper cut, a solution to a paper cut?
Segment 314: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6017, Text: Yes. So that particular thing is probably a solution to a number of paper cuts. So if you go back and look at our order pipeline and how people shopped on Amazon before we invented 1-Click shopping, there was more friction. There was a whole series of paper cuts and that invention eliminated a bunch of paper cuts. And I think you’re absolutely right by the way, that when you come up with something like 1-Click shopping, again, this is so ingrained in people now, I’m impressed that you even notice it. Most people-
Segment 315: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6054, Text: Every time I click the button, I just-
Segment 316: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6054, Text: … most people never notice.
Segment 317: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6055, Text: … just a surge of happiness.
Segment 318: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6060, Text: There is in the perfect invention for the perfect moment in the perfect context, there is real beauty. It is actual beauty and it feels good. It’s emotional. It’s emotional for the inventor, it’s emotional for the team that builds it. It’s emotional for the customer. It’s a big deal and you can feel those things.
Segment 319: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6083, Text: But to keep coming up with that idea, with those kinds of ideas, I guess is the day one thinking effort.
Segment 320: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6089, Text: Yeah, and you need a big group of people who feel that kind of satisfaction with creating that kind of beauty.
Segment 321: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6098, Text: There’s a lot of books written about you. There’s a book Invent & Wander where Walter Isaacson does an intro. It’s mostly collective writings of yours. I’ve read that. I also recommend people check out the Founders Podcast that covers you a lot and it does different analysis of different business advice you’ve given over the years. I bring all that up because I mentioned that you said that books are an antidote for short attention spans. And I forget how it was phrased, but that when you were thinking about the Kindle that you were thinking about how technology changes us.
Segment 322: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6140, Text: Changes us. We co-evolve with our tools. So we invent new tools and then our tools change us.
Segment 323: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6150, Text: Which is fascinating to think about.
Segment 324: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6152, Text: It goes in a circle
Segment 325: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6153, Text: And there’s some aspect, even just inside business, where you don’t just make the customer happy, but you also have to think about where is this going to take humanity if you zoom out a bit?
Segment 326: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6165, Text: A hundred percent and you can feel your brain. Brains are plastic and you can feel your brain getting reprogrammed. I remember the first time this happened to me was when Tetris who’d first came on the scene. Anybody who’s been a game player has this experience where you close your eyes to lay down to go to sleep and you see all the little blocks moving and you’re kind of rotating them in your mind and you can just tell as you walk around the world that you have rewired your brain to play Tetris. But that happens with everything. I think we still have yet to see the full repercussions of this, I fear, but I think one of the things that we’ve done online and largely because of social media is we have trained our brains to be really good at processing super short form content.
Segment 327: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6232, Text: Your podcast flies in the face of this. You do these long format things.
Segment 328: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6239, Text: Books do too.
Segment 329: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6240, Text: And reading books is a long format thing and if something is convenient, we do more of it. We carry around in our pocket a phone, and one of the things that phone does for the most part is it is an attention shortening device because most of the things we do on our phone shorten our attention spans. And I’m not even going to say we know for sure that that’s bad, but I do think it’s happening. That’s one of the ways we’re co-evolving with that tool. But I think it’s important to spend some of your time and some of your life doing long attention span things.
Segment 330: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6281, Text: Yeah, I think you’ve spoken about the value in your own life of focus, of singular focus on a thing for prolonged periods of time, and that’s certainly what books do and that’s certainly what that piece of technology does. But I bring all that up to ask you about another piece of technology, AI, that has the potential to have various trajectories to have an impact on human civilization. How do you think AI will change us?
Segment 331: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6314, Text: If you’re talking about generative AI, large language models, things like ChatGPT, and its soon successors, these are incredibly powerful technologies. To believe otherwise is to bury your head in the sand, soon to be even more powerful. It’s interesting to me that large language models in their current form are not inventions, they’re discoveries. The telescope was an invention, but looking through it at Jupiter, knowing that it had moons, was a discovery. My God, it has moons. And that’s what Galileo did. And so this is closer on that spectrum of invention. We know exactly what happens with a 787, it’s an engineered object. We designed it. We know how it behaves. We don’t want any surprises. Large language models are much more like discoveries. We’re constantly getting surprised by their capabilities. They’re not really engineered objects.
Segment 332: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6395, Text: Then you have this debate about whether they’re going to be good for humanity or bad for humanity. Even specialized AI could be very bad for humanity. Just regular machine learning models can make certain weapons of war, that could be incredibly destructive and very powerful. And they’re not general AIs. They could just be very smart weapons. And so we have to think about all of those things. I’m very optimistic about this. So even in the face of all this uncertainty, my own view is that these powerful tools are much more likely to help us and save us even than they are to on balance hurt us and destroy us. I think we humans have a lot of ways of we can make ourselves go extinct. These things may help us not do that, so they may actually save us. So the people who are overly concerned, in my view, overly, it is a valid debate. I think that they may be missing part of the equation, which is how helpful they could be in making sure we don’t destroy ourselves.
Segment 333: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6487, Text: I don’t know if you saw the movie Oppenheimer, but to me, first of all, I loved the movie and I thought the best part of the movie is this bureaucrat played by Robert Downey Jr, who some of the people I’ve talked to think that’s the most boring part of the movie. I thought it was the most fascinating because what’s going on here is you realize we have invented these awesome, destructive, powerful technologies called nuclear weapons and they’re managed and we humans, we’re not really capable of wielding those weapons. And that’s what he represented in that movie is here’s this guy, he wrongly thinks… he’s being so petty. He thinks that Oppenheimer said something bad to Einstein about him. They didn’t talk about him at all as you find out in the final scene of the movie. And yet he’s spent his career trying to be vengeful and petty.
Segment 334: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6559, Text: And that’s the problem. We as a species are not really sophisticated enough and mature enough to handle these technologies. And by the way, before you get to general AI and the possibility of AI having agency and there’s a lot of things would have to happen, but there’s so much benefit that’s going to come from these technologies in the meantime, even before there are general AI in terms of better medicines and better tools to develop more technologies and so on. So I think it’s an incredible moment to be alive and to witness the transformations that are going to happen. How quickly will happen, no one knows. But over the next 10 years and 20 years, I think we’re going to see really remarkable advances. And I personally am very excited about it.
Segment 335: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6612, Text: First of all, really interesting to say that it’s discoveries, that it’s true that we don’t know the limits of what’s possible with the current language models.
Segment 336: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6624, Text: We don’t.
Segment 337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6624, Text: And it could be a few tricks and hacks here and there that open doors to hold entire new possibilities.
Segment 338: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6633, Text: We do know that humans are doing something different from these models, in part because we’re so power efficient. The human brain does remarkable things and it does it on about 20 watts of power. And the AI techniques we use today use many kilowatts of power to do equivalent tasks. So there’s something interesting about the way the human brain does this. And also we don’t need as much data. So self-driving cars, they have to drive billions and billions of miles to try to learn how to drive. And your average 16-year-old figures it out with many fewer miles. So there are still some tricks, I think, that we have yet to learn. I don’t think we’ve learned the last trick. I don’t think it’s just a question of scaling things up. But what’s interesting is that just scaling things up, and I put just in quotes because it’s actually hard to scale things up, but just scaling things up also appears to pay huge dividends.
Segment 339: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6700, Text: Yeah. And there’s some more nuanced aspect about human beings that’s interesting if it’s able to accomplish like being truly original and novel. Large language models, being able to come up with some truly new ideas. That’s one. And the other one is truth. It seems that large language models are very good at sounding like they’re saying a true thing, but they don’t require or often have a grounding in a mathematical truth, basically is a very good bullshitter. So if there’s not enough data in the training data about a particular topic, it’s just going to concoct accurate sounding narratives, which is a very fascinating problem to try to solve, how do you get language models to infer what is true or not to introspect?
Segment 340: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6761, Text: Yeah, they need to be taught to say, “I don’t know,” more often and I know several humans who could be taught that as well.
Segment 341: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6770, Text: Sure. And then the other stuff, because you’re still a bit involved in the Amazon side with the AI things, the other open question is what kind of products are created from this?
Segment 342: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6781, Text: Oh, so many. We have Alexa and Echo and Alexa has hundreds of millions of installed base inputs. And so there’s Alexa everywhere. And guess what? Alexa is about to get a lot smarter. And so from a product point of view, that’s super exciting.
Segment 343: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6807, Text: There’s so many opportunities there,
Segment 344: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6810, Text: So many opportunities. Shopping assistant, all that stuff is amazing. And AWS, we’re building Titan, which is our foundational model. We’re also building Bedrock, which are corporate clients at AWS. Our enterprise clients, they want to be able to use these powerful models with their own corporate data without accidentally contributing their corporate data to that model. And so those are the tools we’re building for them with Bedrock. So there’s tremendous opportunity here.
Segment 345: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6843, Text: Yeah, the security, the privacy, all those things are fascinating. Because so much value can be gained by training on private data, but you want to keep this secure. It’s a fascinating technical problem.
Segment 346: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6853, Text: Yes. This is a very challenging technical problem and it’s one that we’re making progress on and dedicated to solving for our customers.
Segment 347: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6861, Text: Do you think there will be a day when humans and robots, maybe Alexa, have a romantic relationship like in the movie Her?
Segment 348: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6869, Text: Well, I think if you look at the-
Segment 349: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6871, Text: Just brainstorming products here.
Segment 350: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6872, Text: … if you look at the spectrum of human variety and what people like, sexual variety, there are people who like everything. So the answer to your question has to be yes.
Segment 351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6883, Text: Okay. I guess I’m asking when-
Segment 352: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6885, Text: I don’t know how widespread that will be.
Segment 353: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6885, Text: … All right.
Segment 354: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6888, Text: But it will happen.
Segment 355: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6889, Text: I was just asking when for a friend, but it’s all right. Moving on. Next question. What’s a perfectly productive day in the life of Jeff Bezos? You’re one of the most productive humans in the world.
Segment 356: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6903, Text: Well, first of all, I get up in the morning and I putter. I have a coffee.
Segment 357: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6909, Text: Can you define putter?
Segment 358: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6911, Text: I slowly move around. I’m not as productive as you might think I am. Because I do believe in wandering and I read my phone for a while. I read newspapers for a while. I chat with Laura and I drink my first coffee. So I move pretty slowly in the first couple of hours. I get up early just naturally, and then I exercise most days. Most days it’s not that hard for me. Some days it’s really hard and I do it anyway, I don’t want to, and it’s painful. And I’m like, “Why am I here?” And I don’t want to do any of this.
Segment 359: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6952, Text: “Why am I here at the gym?”
Segment 360: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6953, Text: “Why am I here at the gym? Why don’t I do something else?” It’s not always easy.
Segment 361: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6959, Text: What’s your social motivation in those moments?
Segment 362: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=6962, Text: I know that I’ll feel better later if I do it. And so the real source of motivation, I can tell the days when I skip it, I’m not quite as alert. I don’t feel as good. And then there’s harder motivations. It’s longer term, you want to be healthy as you age. You want health span. Ideally, you want to be healthy and moving around when you’re 80 years old. And so there’s a lot of… But that kind of motivation is so far in the future, it can be very hard to work in the second. So thinking about the fact I’ll feel better in about four hours if I do it now, I’ll have more energy for the rest of my day and so on and so on.
Segment 363: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7002, Text: What’s your exercise routine, just to linger on that? How much you curl? What are we talking about here? That’s all I do at the gym so I just…
Segment 364: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7012, Text: My routine on a good day, I do about half an hour of cardio and I do about forty-five minutes of weightlifting, resistance training of some kind, mostly weights. I have a trainer who I love who pushes me, which is really helpful. He’ll say, “Jeff, can we go up on that weight a little bit?”
Segment 365: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7038, Text: And I’ll think about it and I’ll be like, “No, I don’t think so.”
Segment 366: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7043, Text: And he’ll look at me and say, “Yeah, I think you can.” And of course he’s right.
Segment 367: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7051, Text: Yeah, of course. Of course.
Segment 368: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7052, Text: So it’s helpful to have somebody push you a little bit.
Segment 369: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7054, Text: But almost every day, you do that?
Segment 370: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7057, Text: Almost every day, I do a little bit of cardio and a little bit of weightlifting and I’d rotate. I do a pulling day and a pushing day and a leg day. It’s all pretty standard stuff.
Segment 371: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7068, Text: So puttering, coffee, gym-
Segment 372: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7069, Text: Puttering, coffee, gym, and then work.
Segment 373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7073, Text: … work. But what’s work look like? What do the productive hours look like for you?
Segment 374: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7079, Text: So a couple years ago, I left as the CEO of Amazon, and I have never worked harder in my life. I am working so hard and I’m mostly enjoying it, but there are also some very painful days. Most of my time is spent on Blue Origin and I’m so deeply involved here now for the last couple of years. And in the big, I love it, and the small, there’s all the frustrations that come along with everything. We’re trying to get to rate manufacturing as we talked about. That’s super important. We’ll get there. We just hired a new CEO, a guy I’ve known for close to 15 years now, a guy named Dave Limp who I love. He’s amazing. So we’re super lucky to have Dave, and you’re going to see us move faster there.
Segment 375: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7126, Text: So my day of work, reading documents, having meetings, sometimes in person, sometimes over Zoom, depends on where I am. It’s all about the technology, it’s about the organization. I have architecture and technology meetings almost every day on various subsystems inside the vehicle, inside the engines. It’s super fun for me. My favorite part of it is the technology. My least favorite part of it is building organizations and so on. That’s important, but it’s also my least favorite part. So that’s why they call it work. You don’t always get to do what you want to do.
Segment 376: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7171, Text: How do you achieve time where you can focus and truly think through problems?
Segment 377: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7176, Text: I do little thinking retreats. So this is not the only way, I can do that all day long. I’m very good at focusing. I don’t keep to a strict schedule. My meetings often go longer than I planned for them to because I believe in wandering. My perfect meeting starts with a crisp document. So the document should be written with such clarity that it’s like angels singing from on high. I like a crisp document and a messy meeting. And so the meeting is about asking questions that nobody knows the answer to and trying to wander your way to a solution. And when that happens just right, it makes all the other meetings worthwhile. It feels good. It has a kind of beauty to it. It has an aesthetic beauty to it, and you get real breakthroughs in meetings like that.
Segment 378: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7237, Text: Can you actually describe the crisp document? This is one of the legendary aspects of Amazon, of the way you approach meetings is this, the six-page memo. Maybe first describe the process of running a meeting with memos.
Segment 379: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7251, Text: Meetings at Amazon and Blue Origin are unusual. When new people come in, like a new executive joins, they’re a little taken aback sometimes because the typical meeting, we’ll start with a six-page narratively structured memo and we do study hall. For 30 minutes, we sit there silently together in the meeting and read.
Segment 380: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7251, Text: I love this.
Segment 381: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7277, Text: Take notes in the margins. And then we discuss. And the reason, by the way, we do study, you could say, I would like everybody to read these memos in advance, but the problem is people don’t have time to do that. And they end up coming to the meeting having only skimmed the memo or maybe not read it at all, and they’re trying to catch up. And they’re also bluffing like they were in college having pretended to do the reading.
Segment 382: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7302, Text: Yeah. Exactly.
Segment 383: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7303, Text: It’s better just to carve out the time for people.
Segment 384: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7307, Text: Yeah. And do it together.
Segment 385: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7307, Text: So now we’re all on the same page, we’ve all read the memo, and now we can have a really elevated discussion. And this is so much better from having a slideshow presentation, a PowerPoint presentation of some kind, where that has so many difficulties. But one of the problems is PowerPoint is really designed to persuade. It’s kind of a sales tool. And internally, the last thing you want to do is sell. Again, you’re truth seeking. You’re trying to find truth. And the other problem with PowerPoint is it’s easy for the author and hard for the audience. And a memo is the opposite. It’s hard to write a six-page memo. A good six-page memo might take two weeks to write. You have to write it, you have to rewrite it, you have to edit it, you have to talk to people about it. They have to poke holes in it for you. You write it again, it might take two weeks. So the author, it’s really a very difficult job, but for the audience it’s much better.
Segment 386: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7365, Text: So you can read a half hour, and there are little problems with PowerPoint presentations too. Senior executives interrupt with questions halfway through the presentation. That question’s going to be answered on the next slide, but you never got there. If you read the whole memo in advance… I often write lots of questions that I have in the margins of these memos, and then I go cross them all out because by the time I get to the end of the memo, they’ve been answered. That’s why I save all that time.
Segment 387: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7391, Text: You also get, if the person who’s preparing the memo, we talked earlier about group think and the fact that I go last in meetings and that you don’t want your ideas to pollute the meeting prematurely, the author of the memos has got to be very vulnerable. They’ve got to put all their thoughts out there and they’ve got to go first. But that’s great because it makes them really good. And you get to see their real ideas and you’re not trompling on them accidentally in a big PowerPoint presentation meeting.
Segment 388: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7430, Text: What’s that feel like when you’ve authored a thing and then you’re sitting there and everybody’s reading your thing?
Segment 389: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7434, Text: I think it’s mostly terrifying.
Segment 390: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7437, Text: Yeah. But maybe in a good way? Like a purifying?
Segment 391: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7442, Text: I think it’s terrifying in a productive way, but I think it’s emotionally, a very nerve-racking experience.
Segment 392: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7453, Text: Is there a art, science to the writing of this six-page memo or just writing in general to you?
Segment 393: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7460, Text: It’s really got to be a real memo. So it means paragraphs have topic sentences. It’s verbs and nouns. That’s the other problem with PowerPoint presentations, they’re often just bullet points. And you can hide a lot of sloppy thinking behind bullet points. When you have to write in complete sentences with narrative structure, it’s really hard to hide sloppy thinking. So it forces the author to be at their best, and so they’re somebody’s really their best thinking. And then you don’t have to spend a lot of time trying to tease that thinking out of the person, and you’ve got it from the very beginning. So it really saves you time in the long run.
Segment 394: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7503, Text: So that part is crisp, and then the rest is messy. Crisp document, messy meeting.
Segment 395: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7507, Text: Yeah, so you don’t want to pretend that the discussion should be crisp. Most meetings, you’re trying to solve a really hard problem. There’s a different kind of meeting, which we call weekly business reviews or business reviews that may be weekly or monthly or daily, whatever they are. But these business review meetings, that’s usually for incremental improvement. And you’re looking at a series of metrics, every time it’s the same metrics. Those meetings can be very efficient. They can start on time and end on time.
Segment 396: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7535, Text: So we’re about to run out of time, which is a good time to ask about the 10,000-Year Clock.
Segment 397: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7543, Text: It’s funny.
Segment 398: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7544, Text: Yes, that’s what I’m known for, is the humor. Okay. Can you explain what the 10,000-Year Clock is?
Segment 399: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7553, Text: Is? 10,000-Year Clock is a physical clock of monumental scale. It’s about 500 feet tall. It’s inside a mountain in west Texas at a chamber that’s about 12 feet in diameter and 500 feet tall. 10,000-Year Clock is an idea conceived by a brilliant guy named Danny Hillis way back in the ’80s. The idea is to build a clock as a symbol for long-term thinking. And you can kind of just very conceptually think of the 10,000-Year Clock as it ticks once a year, it chimes once every a hundred years, and the cuckoo comes out once every a thousand years. So it just sort of slows everything down. And it’s a completely mechanical clock. It is designed to last 10,000 years with no human intervention. So the material choices and everything else. It’s in a remote location, both to protect it, but also so that visitors have to make a pilgrimage.
Segment 400: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7617, Text: The idea is that over time, and this will take hundreds of years, but over time, it will take on the patina of age, and then it will become a symbol for long-term thinking that will actually hopefully get humans to extend their thinking horizons. And in my view, that’s really important as we have become, as a species, as a civilization, more powerful. We’re really affecting the planet now. We’re really affecting each other. We have weapons of mass destruction. We have all kinds of things where we can really hurt ourselves and the problems we create can be so large. The unintended consequences of some of our actions like climate change, putting carbon in the atmosphere is a perfect example. That’s an unintended consequence of the Industrial Revolution, got a lot of benefits from it, but we’ve also got this side effect that is very detrimental.
Segment 401: Speaker: , Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7676, Text: We need to start training ourselves to think longer term. Long-term thinking is a giant lever. You can literally solve problems if you think long-term, that are impossible to solve if you think short-term. And we aren’t really good at thinking long-term. Five years is a tough timeframe for most institutions to think past. And we probably need to stretch that to 10 years and 15 years and 20 years and 25 years, and we’d do a better job for our children or our grandchildren if we could stretch those thinking horizons. And so the clock, in a way, it’s an art project, it’s a symbol. And if it ever has any power to influence people to think longer term, that won’t happen for hundreds of years, but we are going to build it now and let it accrue the patina of age.
Segment 402: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7732, Text: Do you think humans will be here when the clock runs out here on earth?
Segment 403: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7736, Text: I think so. But the United States won’t exist. Whole civilizations rise and fall. 10,000 years is so long. No nation state has ever survived for anywhere close to 10,000 years.
Segment 404: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7752, Text: And the increasing rate of progress makes that even fantastic.
Segment 405: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7755, Text: Even less likely so. Do I think humans will be here? Yes. How will we have changed ourselves and what will we be and so on and so on? I don’t know, but I think we’ll be here.
Segment 406: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7765, Text: On that grand scale, a human life feels tiny. Do you ponder your own mortality? Are you afraid of death?
Segment 407: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7772, Text: No. I used to be afraid of death. I did. I remember as a young person being very scared of mortality, didn’t want to think about it, and so on. And as I’ve gotten older, I’m 59 now, as I’ve gotten older, somehow that fear has sort of gone away. I would like to stay alive for as long as possible, but I’m really more focused on health span. I want to be healthy. I want that square wave. I want to be healthy, healthy, healthy, and then gone. I don’t want the long decay. And I’m curious. I want to see how things turn out. I’d like to be here. I love my family and my close friends, and I’m curious about them, and I want to see. So I have a lot of reasons to stay around, but mortality doesn’t have that effect on me that it did maybe when I was in my twenties.
Segment 408: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7838, Text: Well, Jeff, thank you for creating Amazon, one of the most incredible companies in history, and thank you for trying your best to make humans a multi-planetary species, expanding out into our solar system, maybe beyond, to meet the aliens out there. And thank you for talking today.
Segment 409: Speaker: Jeff Bezos, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7855, Text: Lex, thank you for doing your part to lengthen our attention spans. Appreciate that very much.
Segment 410: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=DcWqzZ3I2cY&t=7864, Text: I’m doing my best. Thanks for listening to this conversation with Jeff Bezos. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Jeff Bezos himself. Be stubborn on vision, but flexible on the details. Thank you for listening and hope to see you next time.
Segment 411: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=0, Text: Every star in the sky probably has planets and life is probably emerging on these planets. But I think the commentorial space associated with these planets is so different. Our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life, why we have to create alien life in the lab as quickly as possible because I don’t know if we are going to be able to build architectures that will intersect with alien intelligence architectures.
Segment 412: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=35, Text: Intersect, you don’t mean in time or space-
Segment 413: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=38, Text: Time and the ability to communicate.
Segment 414: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=40, Text: The ability to communicate.
Segment 415: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=41, Text: Yeah. My biggest fear in a way is that life is everywhere, but we’ve become infinitely more lonely because of our scaffolding in that commentorial space.
Segment 416: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=52, Text: The following is a conversation with Lee Cronin, his third time in this podcast. He’s a chemist from University of Glasgow who is one of the most fascinating, brilliant and fun to talk to scientists I’ve ever had the pleasure of getting to know. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Lee Cronin.
Segment 417: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=76, Text: So your big assembly theory paper was published in Nature. Congratulations.
Segment 418: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=81, Text: Thanks.
Segment 419: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=81, Text: It created, I think it’s fair to say, a lot of controversy, but also a lot of interesting discussion. So maybe I can try to summarize assembly theory and you tell me if I’m wrong.
Segment 420: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=92, Text: Go for it.
Segment 421: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=93, Text: So assembly theory says that if we look at any object in the universe, any object, that we can quantify how complex it is by trying to find the number of steps it took to create it. And also we can determine if it was built by a process akin to evolution by looking at how many copies of the object there are.
Segment 422: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=115, Text: Yep. That’s spot on. Yep.
Segment 423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=116, Text: Spot on.
Segment 424: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=117, Text: Spot on.
Segment 425: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=118, Text: I was not expecting that. Okay, so let’s go through definitions. So there’s a central equation I’d love to talk about, but definition wise, what is an object?
Segment 426: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=131, Text: Yeah, an object. So if I’m going to try to be as meticulous as possible, objects need to be finite and they need to be decomposable into sub-units. All human made artifacts are objects. Is a planet an object? Probably yes, if you scale out. So an object is finite and accountable and decomposable, I suppose, mathematically. But yeah, I still wake up some days and go to think to myself, what is an object? Because it’s a non-trivial question.
Segment 427: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=170, Text: Persists over time, I’m quoting from the paper here. An object is finite, is distinguishable. I’m sure that’s a weird adjective, distinguishable.
Segment 428: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=183, Text: We’ve had so many people help offering to rewrite the paper after it came out. You wouldn’t believe it’s so funny.
Segment 429: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=190, Text: Persists over time. And is breakable such that the set of constraints to construct it from elementary building blocks is quantifiable, such that the set of constraints to construct it from elementary building blocks is quantifiable.
Segment 430: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=205, Text: The history is in the objects. It’s kind of cool, right?
Segment 431: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=209, Text: Okay. So what defines the object is its history or memory, whichever is the sexier word.
Segment 432: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=216, Text: I’m happy with both depending on the day.
Segment 433: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=218, Text: Okay, so the set of steps it took to create the object. So there’s a sense in which every object in the universe has a history. And that is part of the thing that is used to describe its complexity. How complicated it is. Okay, what is an assembly index?
Segment 434: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=240, Text: So the assembly index, if you’re to take the object apart and be super lazy about it or minimal say ’cause it’s like you’ve got a really short-term memory. So what you do is you lay all the parts on the path and you find the minimum number of steps you take on the path to add the parts together to reproduce the object. And that minimum number is the assembly index. It’s minimum bound. And it was always my intuition, the minimum bound and assembly theory was really important that I only worked out why a few weeks ago, which is kind of funny ’cause I was just like, “No, this is sacrosanct. I don’t know why, it’ll come to me one day.”
Segment 435: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=277, Text: And then when I was pushed by a bunch of mathematicians, we came up with the correct physical explanation, which I can get to, but it’s the minimum and it’s really important. It’s the minimum. And the reason I knew the minimum was right is because we could measure it. So almost before this paper came out, we’d published papers, explain how you can measure the assembly index of molecules.
Segment 436: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=301, Text: Okay, so that’s not so trivial to figure out. So when you look at an object, we could say a molecule, we could say object more generally. To figure out the minimum number of steps it takes to create that object, that doesn’t seem like a trivial thing to do.
Segment 437: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=317, Text: So with molecules, it is not trivial, but it is possible because what you can do and because I’m a chemist, so I’m kind of like I see the lens of the world for just chemistry. I break the molecule apart and break bonds. And if you take a molecule and you break it all apart, you have a bunch of atoms and then you say, “Okay, I’m going to then take the atoms and form bonds and go up the chain of events to make the molecule.”
Segment 438: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=346, Text: And that’s what made me realize, take a toy example, literally a toy example, take a Lego object, which is broken up of Lego blocks. So you could do exactly the same thing. In this case, the Lego blocks are naturally the smallest. They’re the atoms in the actual composite Lego architecture. But then if you maybe take a couple of blocks and put them together in a certain way, maybe they’re offset in some way, that offset is on the memory, you can use that offset again with only a penalty of one and you can then make a square, triangle and keep going.
Segment 439: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=379, Text: And you remember those motifs on the chain. So you can then leap from the start with all the Lego blocks or atoms just laid out in front of you and say, “Right, I’ll take you, you, you,” connect and do the least amount of work. So it’s really like the smallest steps you can take on the graph to make the object. And so for molecules, it came relatively intuitively. And then we started to apply it to language. We’ve even started to apply it to mathematical theorems. But I’m so well out of my depth. But it looks like you can take minimum set of axioms and then start to build up mathematical architectures in the same way. And then the shortest path to get there is something interesting that I don’t yet understand.
Segment 440: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=422, Text: So what’s the computational complexity of figuring out the shortest path with molecules, with language, with mathematical theorems? It seems like once you have the fully constructed Lego castle or whatever your favorite Lego world is, figuring out how to get there from the basic building blocks, is that an empty hard problem? It’s a hard problem.
Segment 441: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=448, Text: It’s a hard problem. But actually if you look at it, so the best way to look at it, let’s take a molecule. So if the molecule has 13 bonds, first of all, take 13 copies of the molecule and just cut all the bonds. So cut 12 bonds and then you just put them in order and then that’s how it works. And you keep looking for symmetry or copies so you can then shorten it as you go down.
Segment 442: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=471, Text: And that becomes [inaudible 00:07:53] quite hard. For some natural product molecules, it becomes very hard. It’s not impossible, but we’re looking at the bounds on that at the moment. But as the object gets bigger it becomes really hard. But that’s the bad news. But the good news is there are shortcuts. And we might even be able to physically measure the complexity without computationally calculating it, which is kind of insane.
Segment 443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=500, Text: Wait, how would you do that?
Segment 444: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=500, Text: Well, in the case of molecule, so if you shine light on a molecule, let’s take an infrared. The molecule has each of the bonds absorbs the infrared differently in what we call the fingerprint region. And so it’s a bit like because it’s quantized as well, you have all these discreet kind of absorbances. And my intuition, after we realized we could cut molecules up in mass spec, that was the first go at this. We did it with using infrared. And the infrared gave us an even better correlation assembly index. And we used another technique as well in addition to infrared called NMR, nuclear magnetic resonance, which tells you about the number of different magnetic environments in a molecule. And that also worked out. So we have three techniques which each of them independently gives us the same or tending towards the same assembly index from molecule that we can calculate mathematically.
Segment 445: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=552, Text: So these are all methods of mass spectrometry, mass spec. You scan a molecule, it gives you data in the form of a mass spectrum. And you’re saying that the data correlates to the assembly index?
Segment 446: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=565, Text: Yeah.
Segment 447: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=566, Text: So how generalizable is that shortcut, first of all it’s chemistry. And second of all, beyond that, that seems like a nice hack and you’re extremely knowledgeable about various aspects of chemistry. So you can say, okay, it kind of correlates. But the whole idea behind assembly theory paper and perhaps why it’s so controversial is that it reaches bigger. It reaches for the bigger general theory of objects in the universe.
Segment 448: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=598, Text: Yeah, I’d say so. I’d agree. So I’ve started assembly theory of emoticons with my lab, believe it or not. So we take emojis, pixelate them and work out the assembly index of the emoji and then work out how many emojis you can make on the path of emoji. So there’s the uber emoji from which all other emojis emerge. So you can then take a photograph and by looking at the shortest path, by reproducing the pixels to make the image you want, you can measure that. So then you start to be able to take spatial data.
Segment 449: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=632, Text: Now there’s some problems there. What is then the definition of the object? How many pixels? How do you break it down? And so we’re just learning all this right now.
Segment 450: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=642, Text: So how do you compute, begin to compute the assembly index of a graphical, a set of pixels on a 2D plane that form a thing?
Segment 451: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=654, Text: So you would first of all determine the resolution. So then what is your XY and what the number on the X and Y plane and then look at the surface area. And then you take all your emojis and make sure they’re all looked at the same resolution. And then we would basically then do exactly the same thing we would do for cutting the bonds. You’d cut bits out of the emoji and look at, you’d have a bag of pixels and you would then add those pixels together to make the overall emoji.
Segment 452: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=686, Text: Wait, wait a minute. But first of all, not every pixels, I mean this is at the core, machine learning and computer vision, not every pixels that important. And there’s macro features, there’s micro features and all that kind of stuff.
Segment 453: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=700, Text: Exactly.
Segment 454: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=702, Text: The eyes appear in a lot of them, the smile appears in a lot of them.
Segment 455: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=707, Text: So in the same way in chemistry we assume the bond is fundamental. What we do in they’re and here is we assume the resolution at the scale at which we do it is fundamental and we’re just working that out. And you’re right, that will change because as you take your lens out a bit, it will change dramatically.
Segment 456: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=722, Text: But it’s just a new way of looking at, not just compression. What we do right now in computer science and data, one big kind of misunderstanding as assembly theory is telling you about how compressed the object is. That’s not right. It’s how much information is required on a chain of events. Because the nice thing is if, when you do compression and computer science, we’re wandering a bit here, but it’s kind of worth wandering I think, you assume you have instantaneous access to all the information in the memory. In assembly theory you say, “No, you don’t get access to that memory until you’ve done the work.” And then when you’ve done access to that memory, you can have access but not to the next one.
Segment 457: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=765, Text: And this is how in assembly theory, we talk about the four universes, the assembly universe, the assembly possible, and the assembly contingent, and then the assembly observed. And they’re all scales in this commentorial universe.
Segment 458: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=778, Text: Yeah. Can you explain each one of them?
Segment 459: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=780, Text: Yep. So the assembly universe is like anything goes, just combinatorial kind of explosion in everything.
Segment 460: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=787, Text: So that’s the biggest one?
Segment 461: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=788, Text: That’s the biggest one. It’s massive.
Segment 462: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=789, Text: Assembly universe, assembly possible, assembly contingent, assembly observed. And the Y axis is assembly steps in time and the X axis as the thing expands through time, more and more unique objects appear.
Segment 463: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=809, Text: Yeah, so assembly universe, everything goes. Assembly possible, laws of physics come in this case in chemistry, bonds assembly. So that means-
Segment 464: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=819, Text: Those are extra constraints, I guess?
Segment 465: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=820, Text: Yes. And they’re the only constraints. They’re the constraints at the base. So the way to look at it’s you’ve got all your atoms, they’re contized and you can just bond them together. So then you can become a kind of, so in the way in computer science speak, I suppose the assembly universe is just like no laws of physics. Things can fly through mountains, beyond the speed of light. In the assembly possible. You have to apply the laws of physics, but you can get access to all the motifs instantaneously with no effort. So that means you could make anything.
Segment 466: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=850, Text: Then the assembly contingent says “No, you can’t have access to the highly assembled object in the future until you’ve done the work in the past on the causal chain.” And that’s really, the really interesting shift where you go from assembly possible to assembly contingent. That is really the key thing in assembly theory that says you cannot just have instantaneous access to all those memories. You have to have done the work. Somehow the universe has to have somehow built a system that allows you to select that path rather than other paths.
Segment 467: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=885, Text: And then the final thing the assembly observed is basically us saying, “Oh, these are the things we actually see. We can go backwards now and understand that they have been created by this causal process.”
Segment 468: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=899, Text: Wait a minute. So when you say the universe has to construct the system that does the work, is that like the environment that allows for selection?
Segment 469: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=908, Text: Yeah.
Segment 470: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=909, Text: So that’s the thing that does the selection.
Segment 471: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=910, Text: You could think about in terms of a Von Neumann constructor versus a selection, a ribosome, a Tesla plant assembling Teslas. The difference between the assembly universe in Tesla land and the Tesla factory is everyone says, “No, Teslas are just easy. They just spring out, you know how to make them all. The Tesla factory, you have to put things in sequence and out comes a Tesla.
Segment 472: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=932, Text: So you’re talking about the factory?
Segment 473: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=933, Text: Yes. This is really nice, super important point is that when I talk about the universe having a memory or there’s some magic, it’s not that. It’s that tells you that there must be a process encoded somewhere in physical reality, be it a cell, a Tesla factory or something else that is making that object. I’m not saying there’s some kind of woo-woo memory in the universe, morphic resonance or something. I’m saying that there is an actual causal process that is being directed, constrained in some way. So it’s not kind of just making everything.
Segment 474: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=970, Text: Yeah, but Lee, what’s the factory that made the factory? First of all, you assume the laws of physics is just sprung to existence at the beginning. Those are constraints. But what makes the factory the environment that does the selection?
Segment 475: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=989, Text: This is the question of, well, it’s the first interesting question that I want to answer out of four. I think the factory emerges in the interplay between the environment and the objects that are being built. And let me, I’ll have a go at explain to you the shortest path.
Segment 476: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1008, Text: So why is the shortest path important? Imagine you’ve got, I’m going to have to go chemistry for a moment, then abstract it. So imagine you’ve got a given environment that you have a budget of atoms, you’re just flinging together. And the objective of those atoms that being flung together in say, molecule A, they decompose. So molecules decompose over time. So the molecules in this environment, in this magic environment have to not die, but they do die. They have a half-life.
Segment 477: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1043, Text: So the only way the molecules can get through that environment out the other side, let’s pretend the environment is a box and can go in and out without dying. And there’s just an infinite supply of atoms coming or, well, a large supply, the molecule gets built, but the molecule that is able to template itself being built and survives in the environment will basically reign supreme.
Segment 478: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1069, Text: Now let’s say that molecule takes 10 steps and it is using a finite set of atoms. Now, let’s say another molecule, smart ass molecule we’ll call it, comes in and can survive in that environment and can copy itself, but it only needs five steps. The molecule that only needs five steps continued, both molecules are being destroyed, but they’re creating themselves faster they can be destroyed. You can see that the shortest path reigns supreme. So the shortest path tells us something super interesting about the minimal amount of information required to propagate that motif in time and space. And it seems to be like some kind of conservation law.
Segment 479: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1115, Text: So one of the intuitions you have is the propagation of motifs in time will be done by the things that can construct themselves in the shortest path.
Segment 480: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1127, Text: Yeah.
Segment 481: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1127, Text: So you can assume that most of the objects in the universe are built in the shortest, in the most efficient way. Big leap I just took there.
Segment 482: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1138, Text: Yeah. Yes and no, because there are other things. So in the limit, yes, because you want to tell the difference between things that have required a factory to build them and just random processes. But you can find instances where the shortest path isn’t taken for an individual object, individual function. And people go, “Ah, that means the shortest path isn’t right.” And then I say, “Well, I don’t know. I think it’s right still because,” so of course, because there are other driving forces, it’s not just one molecule.
Segment 483: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1173, Text: Now you start to consider two objects, you have a joint assembly space. And it’s not now, it’s a compromise between not just making A and B in the shortest path. You want to be able to make A and B in the shortest path, which might mean that A is slightly longer, compromise. So when you see slightly more nesting in the construction, when you take a given object, that can look longer. But that’s because the overall function is the object is still trying to be efficient. And this is still very hand wavy and maybe having no leg to stand on, but we think we’re getting somewhere with that.
Segment 484: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1209, Text: And there’s probably some parallelization, right?
Segment 485: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1212, Text: Yeah.
Segment 486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1212, Text: So this is not sequential. The building is, I guess.
Segment 487: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1217, Text: No, you’re right.
Segment 488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1218, Text: When you’re talking about complex objects, you don’t have to work sequentially. You can work in parallel, you can get your friends together and they can…
Segment 489: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1225, Text: Yeah, and the thing we’re working on right now is how to understand these parallel processes. Now there’s a new thing we’ve introduced called assembly depth. And assembly depth can be lower than the assembly index for a molecule when they’re cooperating together because exactly this parallel processing is going on. And my team have been working this out in the last few weeks because we’re looking at what compromises does nature need to make when it’s making molecules in a cell? And I wonder if maybe like, well, I’m always leaping out of my competence, but in economics, I’m just wondering if you could apply this in economic processes. It seems like capitalism is very good at finding shortest path every time. And there are ludicrous things that happen because actually the cost function has been minimized.
Segment 490: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1275, Text: And so I keep seeing parallels everywhere where there are complex nested systems where if you give it enough time and you introduce a bit of heterogeneity, the system readjusts and finds a new shortest path. But the shortest path isn’t fixed on just one molecule now. It’s in the actual existence of the object over time. And that object could be a city, it could be a cell, it could be a factory, but I think we’re going way beyond molecules and my competence so probably should go back to molecules, but hey.
Segment 491: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1304, Text: All right, before we get too far, let’s talk about the assembly equation. Okay. How should we do this? Let me just even read that part of the paper. We define assembly as the total amount of selection necessary to produce an ensemble of observed objects quantified using equation one. The equation basically has A on one side, which is the assembly of the ensemble, and then a sum from one to N, where N is the total number of unique objects.
Segment 492: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1340, Text: And then there is a few variables in there that include the assembly index, the copy number which we’ll talk about. That’s an interesting, I don’t remember you talking about that. That’s an interesting addition and I think a powerful one. It has to do with what, that you can create pretty complex objects randomly, and in order to know that they’re not random, that there’s a factory involved, you need to see a bunch of them. That’s the intuition there. It’s an interesting intuition and then some normalization. What else is and-
Segment 493: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1374, Text: N minus one, just to make sure that more than one object, one object could be a one-off and random. And then you have more than one identical object. That’s interesting.
Segment 494: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1383, Text: When there’s two of a thing.
Segment 495: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1385, Text: Two of a thing is super important, especially if the index assembly index is high.
Segment 496: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1390, Text: So we could say several questions here. One, let’s talk about selection. What is this term selection? What is this term evolution that we’re referring to? Which aspect of Darwinian evolution are we referring to? That’s interesting here.
Segment 497: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1406, Text: Yeah, so this is probably what the paper, we should talk about the paper for a second. The paper, what it did is it kind of annoyed, we didn’t know it. It got intention and obviously the angry people were annoyed.
Segment 498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1419, Text: There’s angry people in the world. That’s good.
Segment 499: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1421, Text: So what happened is the evolutionary biologists got angry. We were not expecting that. We thought evolutionary biologists would be cool. I knew that some, not many, computational complexity people will get angry because I’ve kind of been poking them and maybe I deserved it, but I was trying to poke them in a productive way. And then the physicists kind of got grumpy because the initial conditions tell everything. The prebiotic chemist got slightly grumpy because there’s not enough chemistry in there. Then finally, when the creationist said it wasn’t creationist enough, I was like, “I’ve done my job.”
Segment 500: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1453, Text: You’re saying the physics, they say, because you’re basically saying that physics is not enough to tell the story of how biology emerges?
Segment 501: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1462, Text: I think so.
Segment 502: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1462, Text: And then they said a few physics is the beginning and the end of the story.
Segment 503: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1469, Text: So what happened is the reason why people put the phone down on the call of the paper, if you view reading the paper like a phone call, they got to the abstract and in the abstract-
Segment 504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1479, Text: First sentence is pretty strong.
Segment 505: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1480, Text: The first two sentences caused everybody-
Segment 506: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1482, Text: Scientists have grappled with reconciling biological evolution with the immutable laws of the universe defined by physics.
Segment 507: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1491, Text: True, right? There’s nothing wrong with that statement. Totally true.
Segment 508: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1495, Text: Yeah. These laws underpin life’s origin, evolution, and the development of human culture and technology, yet they do not predict the emergence of these phenomena. Wow. First of all, we should say the title of the paper, this paper was accepted and published in Nature. The title is Assembly Theory Explains and Quantifies Selection and Evolution, very humble title. And the entirety of the paper, I think, presents interesting ideas, but reaches high.
Segment 509: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1526, Text: I am not… I would do it all again. This paper was actually on the pre-print server for over a year.
Segment 510: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1533, Text: You regret nothing?
Segment 511: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1534, Text: Yeah.
Segment 512: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1535, Text: I think, yeah, I don’t regret anything.
Segment 513: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1537, Text: You and Frank Sinatra did it your way.
Segment 514: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1539, Text: What I love about being a scientist is sometimes because I’m a bit dim and I don’t understand what people are telling me, I want to get to the point. This paper says, “Hey, the laws of physics are really cool, the universe is great, but they don’t really, it’s not intuitive that you just run the standard model and get life out.” I think most physicists might go, “Yeah, it’s not just, we can’t just go back and say that’s what happened.” Because physics can’t explain the origin of life yet. That doesn’t mean it won’t or can’t. Okay. Just to be clear. Sorry intelligent designers, we are going to get there.
Segment 515: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1576, Text: Second point, we say that evolution works, but we don’t know how evolution got going. So biological evolution and biological selection. So for me, this seems like a simple continuum. So when I mentioned selection and evolution in the title, I think, and in the abstract, we should have maybe prefaced that and said non-biological selection and non-biological evolutions. And then that might have made it even more crystal clear. But I didn’t think that biology, evolutionary biology, should be so bold to claim ownership of selection and evolution.
Segment 516: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1609, Text: And secondly, a lot of evolutionary biologists seem to dismiss the origin of life question and just say it’s obvious. And that causes a real problem scientifically because two different, when the physicists are like, ” We own the universe. The universe is good, we explain all of it, look at us.” And even biologists say, “We can explain biology.” And the poor chemists in the middle going, “But hang on.”
Segment 517: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1632, Text: And this paper kind of says, “Hey, there is an interesting disconnect between physics and biology. And that’s at the point at which memories get made in chemistry through bonds. And hey, let’s look at this close and see if we can quantify it.” So yeah, I never expected the paper to get that much interest. And still, it’s only been published just over a month ago now.
Segment 518: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1658, Text: So just to link on the selection, what is the broader sense of what selection means?
Segment 519: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1666, Text: Yeah, that’s really good. For selection, so I think for selection, so this is where for me, the concept of an object is something that can persist in time and not die, but basically can be broken up. So if I was going to kind of bolster the definition of an object, so if something can form and persist for a long period of time under an existing environment that could destroy other, and I’m going to use anthropomorphic terms, I apologize, about weaker objects or less robust, then the environment could have selected that.
Segment 520: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1710, Text: So good chemistry examples, if you took some carbon and you made a chain of carbon atoms, whereas if you took some, I don’t know, some carbon, nitrogen and oxygen and made change from those, you’d start to get different reactions and rearrangements. So a chain of carbon atoms might be more resistant to falling apart under a acidic or basic conditions versus another set of molecules. So it survives in that environment. So the acid pond, the resistant molecule can get through. And then that molecule goes into another environment. So that environment now maybe being acid pond is a basic pond or maybe it’s an oxidizing pond. And so if you’ve got carbon and it goes an oxidizing pond, maybe the carbon starts to oxidize and break apart. So you go through all these kind of obstacle courses if you like, given by reality. So selection is the ability happens when object survives in an environment for some time.
Segment 521: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1773, Text: And this is the thing that’s super subtle. The object has to be continually being destroyed and made by process. So it’s not just about the object now, it’s about the process and time that makes it because a rock could just stand on the mountain side for 4 billion years and nothing happened to it. And that’s not necessarily really advanced selection. So for selection to get really interesting, you need to have a turnover in time. You need to be continually creating objects, producing them, what we call discovery time. So there’s a discovery time for an object.
Segment 522: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1807, Text: When that object is discovered, if it’s say a molecule that can then act on itself or the chain of events that caused itself to bolster its formation, then you go from discovery time to production time and suddenly you have more of it in the universe. So it could be a self-replicating molecule and the interaction of the molecule in the environment, in the warm little pond or in the sea or wherever in the bubble could then start to build a proto factory, the environment.
Segment 523: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1834, Text: So really to answer your question, what the factory is, the factory is the environment, but it’s not very autonomous, it’s not very redundant. There’s lots of things that could go wrong. So once you get high enough up the hierarchy of networks, of interactions, something needs to happen that needs to be compressed into a smaller volume and made resistant robust because in biology, selection and evolution is robust that you have error correction built in. You have really, there’s good ways of basically making sure propagation goes on.
Segment 524: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1867, Text: So really the difference between inorganic, antibiotic selection and evolution and evolution and stuff in biology is robustness the ability to propagate, the ability to survive in lots of different environments. Whereas our poor little inorganic sole molecule, whatever, just dies in lots of different environments. So there’s something super special that happens from the inorganic molecule in the environment that kills it to where you’ve got evolution and cells can survive everywhere.
Segment 525: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1904, Text: How special is that? How do you know those kinds of evolution factors aren’t everywhere in the universe?
Segment 526: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1911, Text: I don’t, and I’m excited because I think selection isn’t special at all. I think what is special is the history of the environments on earth that gave rise to the first cell that now has taken all those environments and is now more autonomous. And I would like to think that, you know this paper could be very wrong, but I don’t think it’s very wrong. I mean it’s certainly wrong, but it’s less wrong than some other ideas, I hope, right? And if this inspires us to go and look for selection in the universe because we now have an equation where we can say, we can look for selection going on and say, “Oh, that’s interesting. We seem to have a process. It’s giving us high copy number objects that also are highly complex, but that doesn’t look like life as we know it.”
Segment 527: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=1966, Text: And we use that and say, “Oh, there’s a hydrothermal vent. Oh, there’s a process going on. There’s molecular networks,” because the assembly equation is not only meant to identify at the higher end advanced selection, what you get, I would call in biology super advanced selection. And even, you could use the assembly equation to look for technology and God forbid we could talk about consciousness and abstraction, but let’s keep it primitive, molecules and biology. So I think the real power of the assembly equation is to say how much selection is going on in this space.
Segment 528: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2000, Text: And there’s a really simple thought experiment I could do is you have a little Petri dish and on that Petri dish you put some simple food. So the assembly index of all the sugars and everything is quite low. So then, and you put a single cell of E. coli cell and then you say, “I’m going to measure the assembly in this, amount of assembly in the box.” So it’s quite low, but the rate of change of assembly, DADT will go [inaudible 00:33:47] sigmoidal as it eats all the food and the number of coli cells will replicate because they take all the food, they copy themselves, the assembly index of all the molecules goes up, up and up until the food is exhausted in the box. So now the E. coli’s stopped-
Segment 529: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2040, Text: … in the box. So now the E. coli’s stopped… I mean, die is probably a strong word. They stopped respiring because all the food is gone. But suddenly, the amount of assembly in the box has gone up gigantically because of that one E. coli factory has just eaten through, milled lots of other E. coli factories run out of food and stopped. And so that, looking at that… So in the initial box, although the amount of assembly was really small, it was able to replicate and use all the food and go up. And that’s what we’re trying to do in the lab, actually, is make those experiments and see if we can spot the emergence of molecular networks that are producing complexity, as we feed in raw materials and we feed a challenge, an environment. We try and kill the molecules. And really, that’s the main idea for the entire paper.
Segment 530: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2092, Text: Yeah, and see if you can measure the changes in the assembly index throughout the whole system.
Segment 531: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2096, Text: Yeah.
Segment 532: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2097, Text: Okay. What about, if I show up to a new planet, we’ll go to Mars or some other planet from a different solar system, how do we use assembly index there to discover alien life?
Segment 533: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2111, Text: Very simply, actually. Let’s say we’ll go to Mars with a mass spectrometer, with a sufficiently high resolution, so what you have to be able to do, so a good thing about mass spec is that you can select the molecule from the mass, and then if it’s high enough resolution, you can be more and more sure that you’re just seeing identical copies. You can count them. And then you fragment them and you count the number of fragments, and look at the molecular weight. And the higher the molecular weight and the higher the number of the fragments, the higher the assembly index.
Segment 534: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2143, Text: So if you go to Mars and you take a mass spec, with high enough resolution, and you can find molecules, a guide on earth, if you could find molecules, say, greater than 350 molecular weight, with more than 15 fragments, you have found artifacts that can only be produced, at least on earth, by life. And now you would say, “Oh, well, maybe the geological process.” I would argue very virulently that that is not the case.
Segment 535: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2170, Text: But we can say, “Look, if you don’t like the cutoff on earth, go up higher, 30, 100, because there’s going to be a point where you can find a molecule with so many different parts, the chances of you getting a molecule that has a hundred different parts and finding a million identical copies, that’s just impossible. That could never happen in an infinite set of universes.
Segment 536: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2197, Text: Can you just linger on this copy number thing? A million different copies, what do you mean by copies and why is the number of copies important?
Segment 537: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2209, Text: Yeah, that was so interesting. I always understood the copy number is really important, but I never explained it properly, for ages. And I kept having this, it goes back to this, if I give you a, I don’t know, a really complicated molecule, and I say it’s complicated, you could say, “Hey, that’s really complicated.” But is it just really random?
Segment 538: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2232, Text: Mm-hmm.
Segment 539: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2234, Text: So I realized that ultimate randomness and ultimate complexity are indistinguishable until you can see a structure in the randomness, so you can see copies.
Segment 540: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2246, Text: So copies implies structure.
Segment 541: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2251, Text: Yeah. The factory-
Segment 542: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2254, Text: I mean, there’s a deep profound thing in there. Because if you just have a random process, you’re going to get a lot of complex, beautiful, sophisticated things.
Segment 543: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2266, Text: Mm-hmm.
Segment 544: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2267, Text: What makes them complex in the way we think life is complex or, yeah, something like a factory that’s operating under a selection processes, there should be copies. Is there some looseness about copies? What does it mean for two objects to be equal?
Segment 545: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2286, Text: It’s all to do with the telescope or the microscope you’re using. And so, at the maximum resolution… The nice thing about chemists is they have this concept of the molecule and they’re all familiar with the molecule. And molecules, you can hold on your hand, lots of them, identical copies. A molecule is actually a super important thing in chemistry, to say, look, you can have a mole of a molecules, an Avogadro’s number of molecules, and they’re identical. What does that mean? That means that the molecular composition, the bonding and so on, the configuration is indistinguishable. You can hold them together. You can overlay them.
Segment 546: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2323, Text: So the way I do it is if I say, “Here’s a bag of 10 identical molecules, let’s prove they’re identical.” You pick one out of the bag and you basically observe it, using some technique, and then you take it away and then you take another one out. If you observe it using technique, you see no differences. They’re identical. It’s really interesting to get right. Because if you take, say, two molecules, molecules can be in different vibrational rotational states. They’re moving all the time.
Segment 547: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2349, Text: So in this respect, identical molecules have identical bonding. In this case, we don’t even talk about chirality, because we don’t have a chirality detector. So two identical molecules in one conception, assembly theory, basically considers both hands as being the same. But, of course, they’re not, they’re different. As soon as you have a chiral distinguisher to detect the left and the right hand, they become different. And so, it’s to do with the detection system that you have and the resolution.
Segment 548: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2379, Text: So I wonder if there’s an art and science to the, which detection system is used when you show up to a new planet.
Segment 549: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2389, Text: Yeah. Yeah, yeah.
Segment 550: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2389, Text: So you’re talking about chemistry a lot today. We have standardized detection systems of how to compare molecules. So when you start to talk about emojis and language and mathematical theorems and, I don’t know, more sophisticated things at different scale, at a smaller scale than molecules, at a larger scale than molecules, what detection… If we look at the difference between you and me, Lex and Lee, are we the same? Are we different?
Segment 551: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2424, Text: Sure. I mean, of course we’re different close up, but if you zoom out a little bit, we will morphologically look the same. High in characteristics, hair length, stuff like that.
Segment 552: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2435, Text: Well, also, the species and-
Segment 553: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2437, Text: Yeah, yeah, yeah.
Segment 554: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2438, Text: … and also there’s a sense why we’re both from earth.
Segment 555: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2442, Text: Yeah, I agree. I mean, this is the power of assembly theory in that regard. So if everything… So the way to look at it, if you have a box of objects, if they’re all indistinguishable, then using your technique, what you then do is you then look at the assembly index. Now, if the assembly index of them is really low and they’re all indistinguishable, then they’re telling you that you have to go to another resolution. So that would be, it is a sliding scale. It’s nice.
Segment 556: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2475, Text: Got it. So those two are attentional with each other.
Segment 557: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2478, Text: Yeah.
Segment 558: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2478, Text: The number of copies and the assembly index.
Segment 559: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2480, Text: Yeah.
Segment 560: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2482, Text: That’s really, really interesting. So, okay. So you show up to a new planet, you’ll be doing what?
Segment 561: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2488, Text: I would do mass spec. I would bring-
Segment 562: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2490, Text: On a sample of what? First of all, how big of a scoop do you take? Do you just take a scoop? What… So we’re looking for primitive life.
Segment 563: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2502, Text: I would look… Yeah, so if you’re just going to Mars or Titan or Enceladus, or somewhere, so a number of ways of doing it. So you could take a large scoop or you go through the atmosphere and detect stuff. You could make a life meter, right? One of Sarah’s colleagues at ASU, Paul Davies, keeps calling it a life meter, which is quite a nice idea. Because you think about it, if you’ve got a living system that’s producing these highly complex molecules and they drift away, and they’re in a highly demanding environment, they could be burnt, right? So they could just be falling apart. So you want to sniff a little bit of complexity and say warmer, warmer, warmer. Oh, we’ve found life, we found the alien. We’ve found the alien Elon Musk, smoking a joint in the bottom of the cave on Mars, or Elon himself, whatever, right?
Segment 564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2502, Text: Yeah. Mm-hmm.
Segment 565: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2554, Text: You say, “Okay, found it.” So what you can do is a mass spectrometer, you could just look for things in the gas phase or you go on the surface, drill down, because you want to find molecules that are… Well, you’ve either got to find the source, living system, because the problem with just looking for complexity is it gets burnt away. So in a harsh environment on, say, on the surface of Mars, there’s a very low probability that you’re going to find really complex molecules because of all the radiation and so on.
Segment 566: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2585, Text: If you drill down a little bit, you could drill down a bit into soil that’s billions of years old. Then I would put in some solvent, water, alcohol, or something, or take a scoop, make it volatile, put it into the mass spectrometer and just try and detect high complexity, high abundant molecules. And if you get them, hey, presto, you can have evidence of life. Wouldn’t that then be great if you could say, “Okay, we’ve found evidence of life, now we want to keep the life meter, keep searching for more and more complexity,” until you actually find living cells. And you can get those new living cells and then you could bring them back to earth or you could try and sequence them. You could see that they have different DNA and proteins.
Segment 567: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2628, Text: Go along the gradient of the life meter.
Segment 568: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2630, Text: Exactly.
Segment 569: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2630, Text: How would you build a life meter? Let’s say we’re together, starting new-
Segment 570: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2630, Text: Just a mass spectrometer.
Segment 571: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2636, Text: … new company, launching a life-
Segment 572: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2636, Text: Mass spectrometer would be the first way of doing it. Just take-
Segment 573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2639, Text: No, no, no, but that’s one of the major components of it. But I’m talking about-
Segment 574: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2643, Text: I would-
Segment 575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2644, Text: … if it’s a device and branding, logo we got to talk about-
Segment 576: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2644, Text: All right.
Segment 577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2648, Text: … that’s later. But what’s the input and what’s the… How do you get to the metered output?
Segment 578: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2655, Text: So I would take a… So my life meter, our life meter. There you go.
Segment 579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2661, Text: Oh, thank you.
Segment 580: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2661, Text: Yeah, you’re welcome, would have both infrared and mass spec. It would have two ports so it could shine a light. And so, what it would do is you would have a vacuum chamber and you would have an electrostatic analyzer, and you’d have a monochromator to producing infrared. You’d add the sum. So you’d take a scoop of the sample, put it in the life meter, it would then add a solvent or heat up the sample so some volatiles come off. The volatiles would then be put into the mass… into electrostatic trap, and you’d weigh the molecules and fragment them. Alternatively, you’d shine infrared light on them and you count number of bands. But you’d have to, in that case, do some separation, because you want to separate… And so, in mass spec, it’s really nice and convenient, because you can separate electrostatically, but you need to have that.
Segment 581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2712, Text: Can you do it in real time?
Segment 582: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2713, Text: Yeah, pretty much. Pretty much, yeah. So let’s go all the way back. Okay, we’re really going to get this-
Segment 583: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2713, Text: Let’s go.
Segment 584: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2718, Text: … Lex’s life… Lex and Lee’s life meter.
Segment 585: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2720, Text: No, I like Lex and Lee. It’s a good ring to it.
Segment 586: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2725, Text: All right. So you have a vacuum chamber, you have a little nose. The nose would have some, a packing material. So you would take your sample, add it onto the nose, add a solvent or a gas. It would then be sucked up the nose and that would be separated, using what we call chromatography. And then as each band comes off the nose, we’ll then do mass spec and infrared. And in the case of the infrared, count the number of bands, in the case of mass spec, count the number of fragments and weigh it.
Segment 587: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2756, Text: And then the further up in molecular weight range for the mass spec, and the number of bands, you go up and up and up from the dead, interesting, interesting, over the threshold, oh my gosh, earth life, and then right up to the batshit crazy, this is definitely alien intelligence that’s made this life, right? You could almost go all the way there. Same in the infrared. And pretty simple.
Segment 588: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2778, Text: The thing that is really problematical is that for many years, decades, what people have done, and I can’t blame them, is they’ve rather, they’ve been obsessing about small biomarkers that we find on earth, amino acids, like single amino acids or evidence of small molecules and these things, and looking for those while I’m looking for complexity. The beautiful thing about this is you can look for complexity without earth chemistry bias or earth biology bias. So assembly theory is just a way of saying, hey, complexity in abundance is evidence of selection. That’s how our universal life meter will work.
Segment 589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2819, Text: Complexity in abundance is evidence of selection. Okay. So let’s apply our life meter to earth. If we were just to apply assembly index measurements to earth, what kind of stuff are going to get? What’s impressive about-
Segment 590: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2819, Text: So-
Segment 591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2846, Text: … some of the complexity on earth?
Segment 592: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2848, Text: … So we did this a few years ago when I was trying to convince NASA and colleagues that this technique could work. And honestly, it’s so funny, because everyone’s like, “No, it ain’t going to work.” And it was just like, because the chemists were saying, “Of course there are complicated molecules out there you can detect that just form randomly.” And I was like, “Really?” That was like, it’s a bit like, I don’t know, someone saying, “Of course, Darwin’s textbook was just written randomly by some monkeys and a typewriter.” Just for me, it was like, “Really?” And I’ve pushed a lot on the chemists now. And I think most of them are on board, but not totally. I really had some big arguments, but the copy number caught there. Because I think I confused the chemists by saying one-off. And then when I made clear about the copy number, I think that made it a little bit easier.
Segment 593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2896, Text: Just to clarify, a chemist might say that, of course out there, outside of earth there’s complex molecules?
Segment 594: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2904, Text: Yes.
Segment 595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2904, Text: Okay. And then you’re saying, “Wait a minute, that’s like saying, ‘Of course there’s aliens out there.'” Like you-
Segment 596: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2911, Text: Yeah, exactly that.
Segment 597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2912, Text: Okay.
Segment 598: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2912, Text: Exactly.
Segment 599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2914, Text: You clarify that, that’s actually a very interesting question and we should be looking for complex molecules of which the copy number is two or greater.
Segment 600: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2925, Text: Yeah, exactly. So on earth, so coming back to earth, what we did is we took a whole bunch of samples and we were running prebiotic chemistry experiments in the lab. We took various inorganic minerals and extracted them, look at the volatile. Because there’s a special way of treating minerals and polymers in assembly theory. In this, in our life machine, we’re looking at molecules. We don’t care about polymers, because they don’t, they’re not volatile. You can’t hold them. How can you make… If you can’t discern that they’re identical, then it’s very difficult for you to work out if this, undergone selection or they’re just a random mess.
Segment 601: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2966, Text: Same with some minerals, but we can come back to that. So basically what you do, we’ve got a whole loads of samples, inorganic ones, we got a load of, we got Scotch whiskey and also got-
Segment 602: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2976, Text: Nice.
Segment 603: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2976, Text: … took a odd bag, which is one of my favorite whiskeys, which is very peaty. And another-
Segment 604: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2981, Text: What’s peaty mean?
Segment 605: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=2982, Text: It is like… So the way that in Scotland, in Isla, which is a little island, the scotch, the whiskey is let to mature in barrels. It’s said that the peat, the complex molecules in the peat find their way through into the whiskey, and that’s what gives it this intense brown color and really complex flavor. It’s literally molecular complexity that does that. And so, vodka’s the complete opposite. It’s just pure, right?-
Segment 606: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3016, Text: So the better the whiskey, the higher the assembly index, the higher the assembly index, the better the whiskey.
Segment 607: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3020, Text: I mean, I really love deep, peaty Scottish whiskeys. Near my house, there is one of the lowland distilleries, called Glengoyne. It’s still beautiful whiskey but not as complex. So for fun, I took some Glengoyne whiskey in our bag and put them into the mass spec and measured the assembly index. I also got E. coli. So the way we do it, take the E. coli, break the cell apart, take it all apart. And also got some beer. And people were ridiculing us saying, “Oh, beer is evidence of complexity.”
Segment 608: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3053, Text: And one of the computational complexity people, it was just throwing, yeah… He’s very vigorous in his disagreement of assembly theory, was just saying, “You don’t know what you’re doing. Even beer is more complicated than human.” What he didn’t realize is that it’s not beer, per se, it’s taking the yeast extract, taking the extract, breaking the cells, extracting the molecules, and just looking at the profile of the molecules, see if there’s anything over the threshold. And we also put in a really complex molecule, Taxol.
Segment 609: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3084, Text: So we took all of these, but also NASA gave us, I think, five samples, and they wouldn’t tell us what they are. They said, “No, we don’t believe you’re going to get this to work.” And they really gave us some super complex samples. And they gave us two fossils, one that was a million years old and one was at 10,000 years old, something from Antarctica, seabed. They gave us some Murchison and meteorite, and a few others. Put them through the system. So we took all the samples, treat them all identically, put them into mass spec, fragmented them, counted.
Segment 610: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3116, Text: And in this case, implicit in the measurement was we, in mass spec, you only detect peaks when you’ve got more than, say, let’s say 10,000 identical molecules. So the copy number’s already baked in, but wasn’t quantified, which is super important there. This was in the first paper. Because I was like, it’s abundant, of course.
Segment 611: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3137, Text: And when you then took it all out, we found that the biological samples gave you molecules that had an assembly index greater than 15. And all the abiotic samples were less than 15. And then we took the NASA samples and we looked at the ones that were more than 15, less than 15, and we gave them back to NASA, and they’re like, “Oh, gosh. Yep, dead, living, dead, living. You got it.” And that’s what we found on earth.
Segment 612: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3164, Text: That’s a success.
Segment 613: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3165, Text: Yeah. Oh yeah, resounding success.
Segment 614: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3168, Text: Can you just go back to the beer and the E. coli? So what’s the assembly index on those?
Segment 615: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3174, Text: So what you were able to do is, the assembly index of… We found high assembly index molecules originating from the beer sample and the E. coli sample.
Segment 616: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3188, Text: Yeast in the beer.
Segment 617: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3190, Text: I didn’t know which one was higher. We didn’t really do any detail there. Because now we are doing that. Because one of the things we’ve done, it’s a secret, but I can tell you. I think it’s-
Segment 618: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3203, Text: Nobody’s listening.
Segment 619: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3205, Text: … well, is that we’ve just mapped the tree of life using assembly theory, because everyone said, ” Oh, you can’t do anything from biology.” And what we’re able to do is, so I think there’s three, well, two ways of doing tree of life… Well, three ways actually.
Segment 620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3218, Text: What’s the tree of life?
Segment 621: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3219, Text: So the tree of life is basically tracing back the history of life on earth, all the different species, going back who evolved from what. And it all goes all the way back to the first life forms, and they branch off. And you have plant kingdom, the animal kingdom, the fungi kingdom, and different branches all the way up. And the way this was classically done, and I’m no evolutionary biologist. The evolutionary biologists tell me every day, at least 10 times… I want to be one though. I like biology, it’s cool.
Segment 622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3252, Text: Yeah, it’s very cool.
Segment 623: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3253, Text: But basically-
Segment 624: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3254, Text: Evolutionary.
Segment 625: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3256, Text: … What Darwin and Mendeleev, and all these people do is just, they draw pictures and they [inaudible 00:54:20] taxa. They were able to draw pictures and say, “Oh, these look like common classes.”
Segment 626: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3266, Text: Yeah.
Segment 627: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3266, Text: Then…
Segment 628: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3269, Text: They’re artists really. They’re just…
Segment 629: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3272, Text: They were able to find out a lot, right? And looking at vertebrates and vertebrates, Cambrian explosion and all this stuff. And then came the genomic revolution and suddenly, everyone used gene sequencing. And Craig Venter’s a good example. I think he’s gone around the world in his yacht, just picking up samples, looking for new species. Where he’s just found new species of life just from sequencing. It’s amazing. So you have taxonomy, you have sequencing, and then you can also do a little bit of molecular archeology, like measure the samples and form some inference.
Segment 630: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3308, Text: What we did is we were able to fingerprint… So we took a load of random samples from all of biology and we used mass spectrometry. And what we did now is not just look for individual molecules, but we looked for coexisting molecules where they had to look at their joint assembly space. And we were able to cut them apart and undergo recursion in the mass spec and infer some relationships. And we’re able to recapitulate the tree of life using mass spectroscopy, no sequencing and no drawing.
Segment 631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3341, Text: All right. Can you try to say that again, with a little more detail? So recreating, what does it take to recreate the tree of life? What does the reverse engineering process look like here?
Segment 632: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3352, Text: So what you do is you take an unknown sample, you bung it into the mass spec, you get… Because this comes from what you’re asking, what do you see in E. coli?
Segment 633: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3360, Text: Mm-hmm.
Segment 634: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3360, Text: And so, in E. coli, you don’t just see, it’s not the most sophisticated cells on earth make the most sophisticated molecules. It is the coexistence of lots of complex molecules above a threshold. And so, what we realized is you could fingerprint different life forms. So fungi make really complicated molecules. Why? Because they can’t move. They have to make everything onsite.
Segment 635: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3384, Text: Whereas, some animals are lazy, they can just go eat the fungi, and they don’t need to make very much. And so, what you do is you look at the, so you take, I don’t know, the fingerprint, maybe the top number of high molecular weight molecules you find in the sample, you fragment them to get their assembly indices, and then what you can do is you can infer common origins of molecules. You can do a molecular… When the reverse engineering of the assembly space, you can infer common roots and look at what’s called the joint assembly space.
Segment 636: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3422, Text: But let’s translate that into the experiment. Take a sample, bung it in the mass spec, take the top, say, 10 molecules, fragment them, and that gives you one fingerprint. Then you do it for another sample, you get another fingerprint. Now the question is you say, “Hey, are these samples the same or different?” And that’s what we’ve been able to do and by basically looking at the assembly space that these molecules create. Without any knowledge of assembly theory, you are unable to do it. With a knowledge of assembly theory, you can reconstruct the tree.
Segment 637: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3455, Text: How does knowing if they’re the same or different give you the tree?
Segment 638: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3458, Text: Let’s go to two leaves on different branches on the tree, right? What you can do, by counting the number of differences, you can estimate how far away their origin was.
Segment 639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3468, Text: Got it.
Segment 640: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3469, Text: And that’s what we do, and it just works. But when we realized you could even use assembly theory to recapitulate the tree of life with no gene sequencing, we were like, “Huh.”
Segment 641: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3478, Text: So this is looking at samples that exist today in the world.
Segment 642: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3481, Text: Yeah.
Segment 643: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3481, Text: What about things that are no longer exist? I mean, the tree contains information about the past-
Segment 644: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3488, Text: I would-
Segment 645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3489, Text: … some of it is gone.
Segment 646: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3491, Text: Yeah, absolutely. I would love to get old fossil samples and apply assembly theory, mass spec, and see if we can find new forms of life that have, that are no longer amenable to gene sequencing, because the DNA is all gone. Because DNA and RNA’s quite unstable, but some of the more complex molecules might be there. They might give you a hint something new, or wouldn’t it be great if you-
Segment 647: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3491, Text: I understand.
Segment 648: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3513, Text: … if you find a sample that’s worth really persevering and doing the proper extraction to PCR and so on and then sequence it, and then put it together-
Segment 649: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3526, Text: So when a thing dies, you can still get some information about its complexity.
Segment 650: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3530, Text: Yeah. And it appears that you can do some dating. Now there are really good techniques. There’s radiocarbon dating, there is longer dating, going looking at radioactive minerals and so on. And you can also, in bone, you can look at… What happens after something dies, is you get what’s called racemization, where the chirality in the polymers basically changes and you get decomposition, and the deviation from the pure enantiomer to the mixture, you can have, it gives you a timescale on it, half-life, so you can date when it died. I want to use assembly theory to see if I can use it and date death and things, and trace the tree of life and also decomposition of molecules.
Segment 651: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3585, Text: Do you think it’s possible?
Segment 652: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3586, Text: Oh yeah, without a doubt. It may not be better than what… I was just at conference where there’s some brilliant people, looking isotope enrichment and looking at how life enriches isotopes, and they’re really sophisticated stuff that they’re doing. But I think there’s some fun to be had there, because it gives you another dimension of dating. How old is this molecule in terms of, or more importantly, how long ago was this molecule produced by life? More complex the molecule, the more prospect for decomposition, oxidation, reorganization, loss of chirality, and all that jazz.
Segment 653: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3621, Text: But what life also does is it enriches. As you get older, the amount of carbon-13 in you goes up, because of the way the bonding is in carbon-13. So it has a slightly different strength, bond strength, than you. It’s called a kinetic isotope effect. So you can literally date how old you are or when you stop metabolizing. So you could date someone’s… how old they are, I think. I’m making this up, this might be right, but I think it’s roughly right. The amount of carbon-13 you have in you, you can estimate how old you are.
Segment 654: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3656, Text: How old living humans are, or living organism?
Segment 655: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3660, Text: Yeah, yeah. You could say, “Oh, this person is 10 years old and this person is 30 years old, because they’ve been metabolizing more carbon and they’ve accumulated it.” That’s the basic idea. It’s probably completely wrong timescale-
Segment 656: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3670, Text: Signatures of chemistry are fascinating. So you’ve been saying a lot of chemistry examples for assembly theory. What if we zoom out and look at a bigger scale of an object, like really complex objects, like humans or living organisms that are made up of millions or billions of other organisms, how do you try to apply assembly theory to that?
Segment 657: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3698, Text: At the moment, we should be able to do this to morphology in cells. So we’re looking at cell surfaces, and really, I’m to trying to extend further. It’s just that we work so hard to get this paper out and people to start discussing the ideas, but it’s kind of funny, because I think the penny is falling on this. So yeah-
Segment 658: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3723, Text: What does that even… What’s it mean for a penny to be-
Segment 659: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3726, Text: I mean, no, the penny’s dropped, right? A lot of people were like, “It’s rubbish, it’s rubbish. You’ve insulted me. It’s wrong.” I mean, the paper got published on the 4th of October. It had 2.3 million engagements on Twitter and it’s been downloaded over a few hundred thousand times. And someone actually said to me, wrote to me and said, “This is an example of really bad writing and what not to do.” And I was like, if all of my papers got read this much, because that’s the objective, if I have a publishing a paper, I want people to read it. I want to write that badly again.
Segment 660: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3757, Text: Yeah. I don’t know, what’s the deep insight here about the negativity in the space. I think it’s probably the immune system of the scientific community, making sure that there’s no bullshit that gets published and that it can overfy, it can do a lot of damage. It can shut down conversations in a way that’s not productive.
Segment 661: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3774, Text: And I go back, I mean, I’ll answer your question about the hierarchy in assembly, but let’s go back to the perception people saying the paper was badly written. I mean, of course we could improve it. We could always improve the clarity.
Segment 662: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3784, Text: Let’s go there before we go to the hierarchy.
Segment 663: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3788, Text: Yeah.
Segment 664: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3788, Text: It has been criticized quite a bit, the paper. What has been some criticism that you’ve found most powerful, that you can understand and can you explain it?
Segment 665: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3803, Text: Yes. The most exciting criticism came from the evolutionary biologist telling me that he thought that origin of life was a solved problem. And I was like, “Whoa, we’re really onto something, because it’s clearly not.” And when you poked them on that they just said, “No. You you don’t understand evolution.” And I said, “No, no, I don’t think you understand that evolution had to occur before biology and there’s a gap.” That was really for me, that misunderstanding, and that did cause an immune response, which was really interesting.
Segment 666: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3836, Text: The second thing was the fact that physicists, the physicists were actually really polite, really nice about it. But they just said, “Huh, we’re not really sure about the initial conditions thing. But this is a really big debate that we should certainly get into, because the emergence of life was not encoded in the initial conditions of the universe.” And I think assembly theory shows why it can’t be. I’ll say that-
Segment 667: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3863, Text: Okay. Sure. If you could say that again.
Segment 668: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3867, Text: The origin of, the emergence of life was not and cannot, in principle, be encoded in the initial conditions of the universe.
Segment 669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3875, Text: Just to clarify what you mean by life is what, high assembly index objects?
Segment 670: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3879, Text: Yeah. And this goes back to your favorite subject.
Segment 671: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3883, Text: What’s that?
Segment 672: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3883, Text: Time.
Segment 673: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3887, Text: Right. So why? What does time have to do with it?
Segment 674: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3890, Text: I mean, probably we can come back to it later, but I think it might be, if we have time.
Segment 675: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3896, Text: Yeah.
Segment 676: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3896, Text: But I think that, I think I now understand how to explain how… Lots of people got angry with the assembly paper, but also, the ramifications of this is how time is fundamental in the universe and this notion of commentorial spaces. And there are so many layers on this, but you have to become an… I think you have to become an intuitionist mathematician and you have to abandon Platonic mathematics. And also, Platonic mathematics is left physics astray, but there’s a lot to unpack there. So we can go to the-
Segment 677: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3934, Text: Platonic mathematic, okay. It’s okay, the evolutionary biologists criticized, because the origin of life is understood and not, it doesn’t require an explanation that involves physics.
Segment 678: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3951, Text: Yeah. It-
Segment 679: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3951, Text: That’s their statement.
Segment 680: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3954, Text: Well, I mean, they said lots of confusing statements. Basically, I realized the evolutionary biology community that were vocal, and some of them were really rude, really spiteful, and needlessly so, right? Because look, I didn’t, people misunderstand publication as well. Some of the peoples have said, “How dare this be published in Nature. What a terrible journal.” And it really, and I watched, said to people, “Look, this is a brand new idea that’s not only potentially going to change the way we look at biology, it’s going to change the way we look at the universe.”
Segment 681: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=3996, Text: And everyone’s saying, “How dare, how dare you be so grandiose?” I’m like, “No, no, no. This is not hype. We’re not saying we’ve invented some, I don’t know, we’ve discovered a alien in a closet somewhere, just for hype. We genuinely mean this to genuinely have the impact or asked the question. And the way people jumped on that was a really bad precedent for young people who want to actually do something new.
Segment 682: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4022, Text: Because this makes a bold claim, and the chances are that it’s not correct. But what I wanted to do is a couple of things. Is I wanted to make a bold claim that was precise and testable and correctable. Not another wooly information-in-biology argument, information-churring machine, blah, blah, blah, blah, blah. A concrete series of statements that can be falsified and explored, and either the theory could be destroyed or built upon.
Segment 683: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4052, Text: Well, what about the criticism of you’re just putting a bunch of sexy names on something that’s already obvious?
Segment 684: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4062, Text: Yeah, that’s really good. So the assembly index of a molecule is not obvious. No one had measure it before. And no one has thought to quantify selection, complexity, and copy number before, in such a primitive, quantifiable way. I think the nice thing about this paper-
Segment 685: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4080, Text: … quantifiable way. I think the nice thing about this paper, this paper is a tribute to all the people that understand that biology does something very interesting. Some people call it negentropy. Some people call it, think about organizational principles that lots of people were not shocked by the paper because they’d done it before. A lot of the arguments we got, some people said, “Oh, it’s rubbish. Oh, by the way, I had this idea 20 years before.” I was like, ” Which one?” Is it the rubbish part or the really revolutionary part.
Segment 686: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4115, Text: So this kind of plucked two strings at once. It plucked the there is something interesting that biology are, we can see around this, but we haven’t quantified yet. And what this is, is the first stab at quantifying that, so the fact that people said “This is obvious.” But if it’s obvious, why have you not done it?
Segment 687: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4138, Text: Sure. But there’s a few things to say there. One is, this is in part of philosophical framework because it’s not like you can apply this generally to any object in the universe. It’s very chemistry focused.
Segment 688: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4155, Text: Yeah, well, I think you will be able to, we just haven’t got there robustly. So if we can say how can we… Let’s go up a level. So if we go up from level, let’s go up from molecules to cells because you would jump to people and I jump to emoticons and both are good and they will be assembly…
Segment 689: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4170, Text: Lets stick with cells, yeah. Good point.
Segment 690: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4174, Text: If we go from molecules to assemblies and let’s take acellular assembly. A nice thing about a cell is you can tell the difference between a eukaryote and a prokaryote, right? The organalles are specialized differently when then look at the cell surface and the cell surface has different glycosylation patterns and these cells will stick together. Now let’s go up a level in multicellular creatures you have cellular differentiation.
Segment 691: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4197, Text: Now if you think about how embryos develop, you go all the way back, those cells undergo differentiation on a causal way that’s biomechanically a feedback between the genetics and biomechanics. I think we can use assembly theory to apply to tissue types. We can even apply it to different cell disease types. So that’s what we’re doing next. But we are trying to walk… The thing is, I’m trying to, I want a leap ahead to go, whoa, we apply it to culture. Clearly you can apply it to memes and culture. And we’ve also applied to assembly theory to CA’s and not as you think…
Segment 692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4197, Text: Cellular automaton, by the way.
Segment 693: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4234, Text: Yeah, yeah. Cellular automaton, not just as you think. Different CA rules were invented by different people at different times. And one of my coworkers, very talented chap basically was like, “Oh, I can realize that different people had different ideas with different rules and they copied each other and made slightly different cellular automaton rules and looked at them online.” And so he was able to refer an assembly index and copy number of rule, whatever, doing this thing. But I digress.
Segment 694: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4264, Text: But it does show you can apply it at a higher scale. So what do we need to do to apply assembly theory to things? We need to agree, there’s a common set of building blocks. So in a cell, well, in a multicellular creature, you need to look back in time. So there is the initial cell, which the creature is fertilized and then starts to grow and then there is cell differentiation. And you have to then make that causal chain both on those. So that requires development of the organism in time. Or if you look at the cell surfaces and the cell types, they’ve got different features on the cell walls and inside the cell. So we’re building up, but obviously I want a leap to things like emoticons, language, mathematical theorems.
Segment 695: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4314, Text: But that’s a very large number of steps to get from a molecule to the human brain.
Segment 696: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4321, Text: Yeah, and I think they are related, but in hierarchies of emergence. So you shouldn’t compare them. I mean the assembly index of a human brain, what does that even mean? Well, maybe we can look at the morphology of the human brain, say all human brains have these number of features in common. If they have those number… And then let’s look at a brain in a whale or a dolphin or a chimpanzee or a bird and say, “Okay, let’s look at the assembly indices and number of features in these.” And now the copy number is just the number of how many birds are there, how many chimpanzees are there, how many humans are there?
Segment 697: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4355, Text: But then you have to discover for that the features that you would be looking for.
Segment 698: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4359, Text: Yeah, and that means you need to have some idea of the anatomy.
Segment 699: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4363, Text: But is there an automated way to discover features?
Segment 700: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4366, Text: I guess so. And I think this is a good way to apply machine learning and image recognition just to basically characterize things.
Segment 701: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4375, Text: To apply compression to it, to see what emerges, and then use the features used as part of the compression, as the measurement of… As the thing that is searched for when you’re measuring assembly index and copy number.
Segment 702: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4389, Text: And the compression has to be, remember the assembly universe, which is you have to go from assembly possible to assembly contingent and that jump from… Because assembly possible all possible brains, all possible features all the time. But we know that on the tree of life and also on the lineage of life, going back to Luca, the human brain just didn’t spring into existence yesterday, it’s a long lineage of brains going all the way back. And so if we could do assembly theory to understand the development, not just in evolutionary history, but in biological development, as you grow, we are going to learn something more.
Segment 703: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4425, Text: What would be amazing is if you can use assembly theory, this framework to show the increase in the assembly index associated with, I don’t know, cultures or pieces of text like language or images and so on and illustrate without knowing the data ahead of time, just kind like you did with NASA that you were able to demonstrate that it applies in those other contexts. I mean, and that probably wouldn’t at first, and you have to evolve the theory somehow. You have to change it, you have to expand it.
Segment 704: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4461, Text: I think so.
Segment 705: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4464, Text: I guess this is as a paper, a first step in saying, okay, “Can we create a general framework for measuring complexity of objects. For measuring life, the complexity of living organisms.”
Segment 706: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4479, Text: Yeah.
Segment 707: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4479, Text: That’s what this is reaching for.
Segment 708: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4481, Text: That is the first step. And also to say, look, we have a way of quantifying selection and evolution in a fairly, not mundane, but a fairly mechanical way because before now… The ground truth for it was very subjective. Whereas here we’re talking about clean observables and there’s going to be layers on that. I mean, with collaborators right now, we already think we can do assembly theory on language. And not only that, wouldn’t it be great if we can figure out how under pressure language is going to involve and be more efficient? Because you’re going to want to transmit things.
Segment 709: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4520, Text: And again, it’s not just about compression, it is about understanding how you can make the most of the architecture you’ve already built. And I think this is something beautiful that evolution does. We are reusing those architectures. We can’t just abandon our evolutionary history. And if you don’t want to abandon your evolutionary history and you know that evolution has been happening, then assembly theory works.
Segment 710: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4544, Text: And I think that’s a key comment I want to make is that assembly theory is great for understanding when evolution has been used. The next jump is when we go to technology, because of course, if you take the M3 processor… I want to buy, I haven’t bought one yet. I can’t justify it, but I want it at some point. The M3 processor arguably is there’s quite a lot of features, a quite large number. The M2 came before it, then the M1 all the way back, you can apply assembly theory to microprocessor architecture. It doesn’t take a huge leap to see that.
Segment 711: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4575, Text: I’m a Linux guy, by the way. So your examples go way over my head.
Segment 712: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4578, Text: Yeah, well, whatever…
Segment 713: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4579, Text: Is that a fruit company of some sort? I don’t even know. Yeah, there’s a lot of interesting stuff to ask about language. Like you could look at… How would that work? You could look at GPT-1, GPT-2, GPT-3, 3, 5, 4, and try to analyze the kind of language it produces. I mean, that’s almost trying to look at assembly index of intelligence systems.
Segment 714: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4605, Text: Yeah, I mean I think the thing about large language models, and this is a whole hobbyhorse I have at the moment, is that obviously they’re all about… The evidence of evolution in the large language model comes from all the people that produced all the language. And that’s really interesting. And all the corrections in the Mechanical Turk, right?
Segment 715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4635, Text: Sure. But that’s part of the history, part of the memory of the system.
Segment 716: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4640, Text: Exactly. So it would be really interesting to basically use an assembly based approach to making language in a hierarchy. My guess is that we might be able to build a new type of large language model that uses assembly theory, that it has more understanding of the past and how things were created. Basically the thing with LLMs is like, everything everywhere, all at once, splat and make the user happy. So there’s not much intelligence in the model. The model is how the human interacts with the model. But wouldn’t it be great if we could understand how to embed more intelligence in the system?
Segment 717: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4683, Text: What do you mean by intelligence there? You seem to associate intelligence with history or memory?
Segment 718: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4691, Text: Yeah. I think selection produces intelligence.
Segment 719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4696, Text: You’re almost implying that selection is intelligence. No.
Segment 720: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4701, Text: Kind of, I would go out in limb and say that, but I think it’s a little bit more, human beings have the ability to abstract and they can break beyond selection. And this is… Darwinian selection, because a human being doesn’t have to basically do trial and error, but they can think about it and say, “Oh, that’s a bad idea, won’t do that.” And then technologies and so on.
Segment 721: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4719, Text: So we escaped Darwinian evolution and now we’re onto some other kind of evolution, I guess? Higher level.
Segment 722: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4726, Text: And assembly theory will measure that as well, right? Because it’s all a lineage.
Segment 723: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4730, Text: Okay. Another piece of criticism or by way of question is how is assembly theory or maybe assembly index different from Kolmogorov complexity? So for people who don’t know, a Kolmogorov complexity of an object is the length of a shortest computer program that produces the object as output.
Segment 724: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4750, Text: Yeah, there seems to be a disconnect between the computational approach. So Kolmogorov measure requires a Turing machine, requires a computer, and that’s one thing. And the other thing is assembly theory is supposed to trace the process by which life evolution emerged, right? There’s a main thing there. There are lots of other layers.
Segment 725: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4782, Text: So Kolmogorov complexity, you can approximate Kolmogorov complexity, but it’s not really telling you very much about the actual… It’s really telling you about your dataset, compression of your dataset.
Segment 726: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4800, Text: Sure.
Segment 727: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4800, Text: And so that doesn’t really help you identify… The turtle in this case is the computer. And so what assembly theory does is, I’m going to say, it’s a trigger warning for anyone listening who loves complexity theory. I think that we’re going to show that AIT is a very important subset of assembly theory because here’s what happens. I think that assembly theory allows us to go understand when were selections occurring. Selection produces factories and things, factories in the end produce computers, and then algorithmic information theory comes out of that. The frustration I’ve had with looking at life through this kind of information theory is it doesn’t take into account causation. So the main difference between assembly theory and all these complexity measures is there’s no causal chain. And I think that’s the main…
Segment 728: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4860, Text: That’s the causal chain is at the core of assembly theory.
Segment 729: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4866, Text: Exactly. And if you’ve got all your data in a computer memory, all the data’s the same. You can access it in the same way. You don’t care. You just compress it. And you either look at the program runtime or the shortest program. And that for me is absolutely not capturing what it is. What selection does.
Segment 730: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4888, Text: But assembly theory looks at objects. It doesn’t have information about the object history. It’s going to try to infer that history by looking for the shortest history, right? The object doesn’t have a Wikipedia page that goes with it about its history.
Segment 731: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4909, Text: I would say it does in a way, and it is fascinating to look at. So you’ve just got the object and you have no other information about the object. What assembly theory allows you to do with just with the object is to, and the word infer is correct, I agree with infer. You say, well, that’s not the history. But something really interesting comes from this.
Segment 732: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4930, Text: The shortest path is inferred from the object. That is the worst case scenario if you have no machine to make it. So that tells you about the depth of that object in time. And so what assembly theory allows you to do is without considering any other circumstances, to say from this object, how deep is this object in time if we just treat the object as itself without any other constraints? And that’s super powerful because the shortest path then allows you to say, “Oh, this object wasn’t just created randomly. There was a process.” And so assembly theory is not meant to one up AIT or to ignore the factory. It’s just to say, “Hey, there was a factory and how big was that factory? And how deep in time is it?”
Segment 733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4981, Text: But it’s still computationally very difficult to compute that history, right? For complex objects?
Segment 734: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4991, Text: It is. It becomes harder. But one of the thing that’s super nice is that it constrains your initial conditions, right?
Segment 735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4998, Text: Sure.
Segment 736: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=4998, Text: It constrains where you’re going to be. So if you take, say, imagine… So one of the things we’re doing right now is applying assembly theory to drug discovery. Now, what everyone’s doing right now is taking all the proteins and looking at the proteins and looking at molecules, doppler proteins, why not instead, look at the molecules that are involved in interacting with the receptors over time, rather than thinking about and use the molecules, evolve over time as a proxy for how the proteins evolved over time. And then use that to constrain your drug discovery process.
Segment 737: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5031, Text: You flip the problem 180 and focus on the molecule evolution rather than the protein. And so you can guess in the future what might happen. So you rather than having to consider all possible molecules, you know where to focus. And that’s the same thing if you’re looking at in assembly spaces for an object where you don’t know the entire history, but you know that in the history of this object, it’s not going to have some other motif there that it doesn’t apply. It doesn’t appear in the past.
Segment 738: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5062, Text: But just even for the drug discovery point you made, don’t you have to simulate all of chemistry to figure out how to come up with constraints?
Segment 739: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5072, Text: No.
Segment 740: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5072, Text: And the molecules and the…
Segment 741: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5074, Text: No.
Segment 742: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5075, Text: I don’t know enough about protein.
Segment 743: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5076, Text: Well, this is another thing that I think causes… Because this paper goes across so many boundaries. So chemists have looked at this and said, “This is not correct reaction.” It’s like, no, it’s a graph.
Segment 744: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5092, Text: Sure, there’s assembly index and shortest path examples here on chemistry.
Segment 745: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5098, Text: Yeah, and what you do is you look at the minimal constraints on that graph. Of course it has some mapping to the synthesis, but actually you don’t have to know all of chemistry. You can build up the constraints space rather nicely. But this is just at the beginning, right? There are so many directions this could go in and as I said, it could all be wrong, but hopefully it’s less wrong.
Segment 746: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5122, Text: What about the little criticism I saw of… By way of question, do you consider the different probabilities of each reaction in the chain so that there could be different… When you look at a chain of events that led up to the creation of an object, doesn’t it matter that some parts in the chain are less likely than others?
Segment 747: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5146, Text: No.
Segment 748: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5148, Text: It doesn’t matter?
Segment 749: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5148, Text: No, no. Well, let’s go back. So no, not less likely, but react… So, no. So let’s go back to what we’re looking at here. So the assembly index is the minimal path that could have created that object probabilistically. So imagine you have all your atoms in a plasma, you’ve got enough energy, there’s collisions. What is the quickest way you could zip out that molecule with no reaction constraints?
Segment 750: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5172, Text: How do you define quickest there then?
Segment 751: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5174, Text: It’s just basically walk on a random graph. So we make an assumption that basically the timescale for forming the bonds. So no, I don’t want to say that because then it’s going to have people getting obsessing about this point. And your criticism is a really good one. What we’re trying to say is this puts a lower bound on something. Of course, some reactions are less possible than others, but actually I don’t think chemical reactions exist.
Segment 752: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5199, Text: Oh, boy. What does that mean? Why don’t chemical reactions exist?
Segment 753: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5204, Text: I’m writing a paper right now that I keep being told I have to finish, and it’s called ‘The Origin of Chemical Reactions.’ And it merely says that reactivity exists as controlled by the laws of quantum mechanics. And reactions, chemists put names on reactions. So you can have, I don’t know, the Wittig reaction, which is by Wittig. You could have the Suzuki reaction, which is by Suzuki.
Segment 754: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5229, Text: Now what are these reactions? So these reactions are constrained by the following. They’re constrained by the fact they’re on planet Earth, 1G, 298 Kelvin, 1 Bar. So these are constraints. They’re also constrained by the chemical composition of earth, oxygen availability, all this stuff. And that then allows us to focus in our chemistry. So when a chemist does a reaction, that’s a really nice compressed shorthand for constraint application, glass flask, pure reagent, temperature, pressure, boom, boom, boom, control, control control, control control.
Segment 755: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5264, Text: So of course we have bond energies. So the bond energies are kind of intrinsic in a vacuum. So the bond energy, you have to have a bond. And so for assembly theory to work, you have to have a bond, which means that bond has to give the molecule a half life. So you’re probably going to find later on that some bonds are weaker and that you are going to miss in mass spectrum, when you look at the assembly of some molecules, you’re going to miscount the assembly of the molecule. It falls apart too quickly because the bonds just form. But you can solve that with looking at infrared.
Segment 756: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5301, Text: So when people think about the probability, they’re kind of misunderstanding. Assembly theory says nothing about the chemistry because chemistry is chemistry and their constraints are put in by biology. There was no chemist on the origin of life unless you believe in the chemist in the sky… And it’s like Santa Claus, they had a lot of work to do, but chemical reactions do not exist and the constraints that allow chemical transformations to occur do exist.
Segment 757: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5332, Text: Okay, okay. So it’s constraint. So there’s no chemical reactions. It’s all constraint application, which enables the emergence of… What’s a different word for chemical reaction?
Segment 758: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5350, Text: Transformation?
Segment 759: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5351, Text: Transformation.
Segment 760: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5351, Text: Yeah, like a function. It’s a function, but no, but I love chemical reactions as a shorthand. And so the chemists don’t all go mad. I mean, of course chemical reactions exist on earth.
Segment 761: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5360, Text: It’s a shorthand.
Segment 762: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5361, Text: It’s a shorthand for these constraints.
Segment 763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5364, Text: So assuming all these constraints that we’ve been using for so long that we just assume that that’s what was the case in natural language conversation.
Segment 764: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5370, Text: Exactly. The grammar of chemistry of course emerges in reactions and we can use them reliably, but I do not think the Wittig reaction is accessible on Venus.
Segment 765: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5381, Text: Right, and this is useful to remember to frame it as constraint application is useful for when you zoom out to the bigger picture of the universe and looking at the chemistry of the universe and then starting to apply assembly theory. That’s interesting. That’s really interesting. But we’ve also pissed off the chemists now.
Segment 766: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5401, Text: Oh, they’re pretty happy, but well, most of them.
Segment 767: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5404, Text: No. Everybody deep down is happy, I think. They’re just sometimes feisty, that’s how they have fun.
Segment 768: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5413, Text: Everyone is grumpy on some days when you challenge… The problem with this paper is… It’s almost like I went to a park, it’s like I used to do this occasionally when I was young. Go to a meeting and just find a way to offend everyone at the meeting simultaneously. Even the factions that don’t like each other, they’re all unified in the hatred of you just offending them. This paper, it feels like the person that went to the party and offended everyone simultaneously. So stop fighting with themselves and just focused on this paper.
Segment 769: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5441, Text: Maybe just a little insider interesting information. What were the editors of Nature, what the reviews and so on, how difficult was that process because this is a pretty big paper.
Segment 770: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5455, Text: So when we originally sent the paper, we sent the paper and the editor said that… This is quite a long process. We sent the paper and the editor gave us some feedback and said, “I don’t think it’s that interesting.” Or “It’s hard. It’s hard concept.” And the editor gave us some feedback and Sarah and I took a year to rewrite the paper.
Segment 771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5486, Text: Was the Nature of the feedback very specific on this part? This part? Or was it like, “What are you guys smoking? What kind of crack are you taking?”
Segment 772: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5494, Text: Yeah, it was kind of the latter. What are you smoking.
Segment 773: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5495, Text: Okay. But polite and there’s promise.
Segment 774: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5501, Text: Yeah. Well the thing is the editor was really critical, but in a really professional way. And I mean for me, this was the way science should happen. So when it came back, we had too many equations in the paper. If you look at the pre-print, there’s just equations everywhere, like 23 equations. And when I said to Abhishek, who was the first author, we’ve got to remove all the equations, but my assembly equations staying in Abhishek was like, “No, we can’t.”
Segment 775: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5525, Text: I said, “Well look, if we want to explain this to people, there’s a real challenge.” And so Sarah and I went through the, I think it was actually 160 versions of the paper, but basically we got to version 40 or something. We said, “Right, zero it start again.” So we wrote the whole paper again. We knew the entire…
Segment 776: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5541, Text: Amazing.
Segment 777: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5542, Text: And we just went bit by bit by bit and said, “What is it we want to say?” And then we sent the paper in and we expected it to be rejected and not even go to review. And then we got notification back, it had gone to review and we were like, “Oh my God, it’s so going to get rejected. How’s it going to get rejected?” Because the first assembly paper on the mass spec we sent to Nature went through six rounds of review and rejected. And by a chemist that just said, “I don’t believe you. You must be committing fraud.”
Segment 778: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5574, Text: And long story, probably a boring story, but in this case it went out to review, the comments came back and the comments were incredibly, they were very deep comments from all the reviewers. But the nice thing was the reviewers were kind of very critical, but not dismissive. They were like, “Oh, really? Explain this, explain this, explain this, explain this.”
Segment 779: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5574, Text: That’s great.
Segment 780: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5606, Text: Are you sure it’s not Kolmogorov? Are you sure it’s not this? And we went through I think three rounds of review pretty quick and the editor went, yeah, it’s in.
Segment 781: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5619, Text: But maybe you could just comment on the whole process. You’ve published some pretty huge papers on all kinds of topics within chemistry and beyond. Some of them have some little spice in them, a little spice of crazy like Tom Waits, says, “I like my Tom with a little drop of poison.” It’s not a mundane paper. So what’s it like psychologically to go through all this process to keep getting rejected, to get reviews from people that don’t get the paper or all that kind of stuff? Just from a question of a scientist, what is that like?
Segment 782: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5659, Text: I mean this paper for me kind of, because this wasn’t the first time we tried to publish assembly theory at the highest level. The Nature communications paper on the mass spec, the idea went to Nature and got rejected, went through six rounds of review and got rejected. And I just was so confused when the chemist said, this can’t be possible. I do not believe you can measure complexity using mass spec. And also by the way, complex molecules can randomly form. And we’re like, “But look at the data. The data says…” And they said, “No, no. We don’t believe you.” And we went and I just wouldn’t give up. And the editor in the end was just like… Different editors actually. Right?
Segment 783: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5710, Text: What’s behind that never giving up? When you’re sitting there 10 o’clock in the evening, there’s a melancholy feeling that comes over you and you’re like, “Okay, this is rejection number five.” Or it’s not rejection, but maybe it feels like a rejection because the comments are that you totally don’t get it. What gives you strength to keep going there?
Segment 784: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5731, Text: I don’t know. I don’t normally get emotional about papers, but it is not about giving up because we want to get it published because we want the glory or anything. It’s just like, why don’t you understand? And so what I would just… Is try to be as rational as possible and say, yeah, you didn’t like it. Tell me why. And then…
Segment 785: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5786, Text: Sorry, give me a second. Silly, never get emotional about papers normally, but I think what we do, you just compressed five years of angst from this.
Segment 786: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5798, Text: So it’s been rough?
Segment 787: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5800, Text: It’s not just rough. It’s like, it happened… I came up with the assembly equation remote from Sarah in Arizona and the people at SFI. I felt like I was a mad person. The guy depicted in A Beautiful Mind who was just like… Not the actual genius part, but just the gibberish, gibberish, gibberish.
Segment 788: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5819, Text: Just the crazy part.
Segment 789: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5822, Text: Because I kept writing expanded and I have no mathematical ability at all. And I was making these mathematical expansions where I kept seeing the same motif again. I was like, I think this is a copy number. The same string is coming again and again and again, I couldn’t do the math. And then I realized the copy number fell out of the equation and everything collapsed down. I was like, oh, that works kind of.
Segment 790: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5843, Text: So we submitted the paper and then when it was almost accepted, the mass spec one and it was astrobiologists said, great, a mass spectroscopist said great. And the chemist went nonsense, biggest pile of nonsense ever. Fraud. And I was like, “But why fraud?” And they just said, “Just because.” I was like well… I could not convince the editor in this case. The editor was just so pissed off. They see it as a, you’re wasting my time. And I would not give up. I wrote, I went and dissected all the parts. And I think, although, I mean I got upset about, it was kind of embarrassing actually, but I guess…
Segment 791: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5885, Text: I bet it was beautiful.
Segment 792: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5888, Text: But it was just trying to understand why they didn’t like it. So part of me was really devastated and a part of me was super excited because I’m like, “Huh, they can’t tell me why I’m wrong.” And this kind of goes back to when I was at school, I was in a kind of learning difficulties class, and I kept going to the teacher and saying, “What do I do today to prove I’m smart?” And they were like, “Nothing, you can’t.” I was like, “Give me a job, give me something to do, give me a job to do. Something to do.” And I kind of felt like that a bit when I was arguing with the, and not arguing. There was no ad hominem. I wasn’t telling the editor they were idiots or anything like this or the reviewers. I kept it strictly factual.
Segment 793: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5931, Text: And all I did is I just kept knocking it down bit by bit, by bit, by bit by bit. It was ultimately rejected and it got published elsewhere. And then the actual experimental data, so in this paper, the experimental justification was already published. So when we did this one and we went through the versions and then we sent it in and in the end it just got accepted. We were like, well, that’s kind of cool, right? This is kind of like some days…
Segment 794: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5961, Text: Sorry, the first author was like, “I can’t believe it got accepted.” I was like, “Nor am I, but it’s great. It’s good.” And then when the paper was published, I was not expecting the backlash. I was expecting computational. Well, no, actually I was just expecting one person who’d been trolling me for a while about it just to carry on trolling, but I didn’t expect the backlash. And then I wrote to the editor and apologized and the editor was like, “What are you apologizing for? It was a great paper. Of course it’s going to get backlash. You said some controversial stuff, but it’s awesome.”
Segment 795: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=5996, Text: Well, I think it’s a beautiful story of perseverance and the backlash is just a negative word for discourse, which I think is beautiful. That’s the science.
Segment 796: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6008, Text: I think, as I said when it got accepted and people were saying, we’re kind of hacking on it. And I was like, papers are not gold medals. The reason I wanted to publish that paper in Nature is because it says, “Hey, there’s something before biological evolution.” You have to have that, if you’re not a creationist, by the way, this is an approach. First time someone has put a concrete mechanism, or sorry, a concrete quantification and what comes next you are pushing on is a mechanism. And that’s what we need to get to is an auto catalytic sets, self-replicating molecules, some other features that come in.
Segment 797: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6048, Text: And the fact that this paper has been so discussed, for me is a dream come true, it doesn’t get better than that. If you can’t accept a few people hating it… And the nice thing is, the thing that really makes me happy is that no one has attacked the actual physical content.
Segment 798: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6070, Text: You can measure the assembly index, you can measure selection now. So either that’s right or it’s… Well, either that’s helpful or unhelpful. If it’s unhelpful, this paper will sink down and no one will use it again. If it’s helpful, it’ll help people scaffold on it and we’ll start to converge for a new paradigm. So I think that that’s the thing that I wanted to see my colleagues, authors, collaborators and people were like, you’ve just published this paper. You’re a chemist. Why have you done this? Who are you to be doing evolutionary theory? Well, I don’t know. I mean, sorry, did I need to…
Segment 799: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6108, Text: Who is anyone to do anything? Well, I’m glad you did. Let me just before coming back to Origin of Life and these kinds of questions, you mentioned learning difficulties. I didn’t know about this. So what was it like?
Segment 800: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6120, Text: I wasn’t very good at school, right.
Segment 801: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6120, Text: I wasn’t very good at school, right?
Segment 802: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6124, Text: This is when you were very young?
Segment 803: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6126, Text: Yeah. But in primary school, my handwriting was really poor and apparently I couldn’t read and my mathematics was very poor. So they just said, “This is a problem.” They identified it. My parents at the time, were confused because I was busy taking things apart, buying electronic junk from the shop, trying to build computers and things. And then once I got out of… when I think, about the major transition in my stupidity, everyone thought I wasn’t that stupid when I was… Basically, everyone thought I was faking. I liked stuff and I was faking wanting to be it. So I always want to be a scientist. So five, six, seven years old, I’d be a scientist, take things apart, and everyone’s like, “Yeah, this guy wants to be a scientist, but he’s an idiot.” So everyone was really confused, I think, at first, that I wasn’t smarter than I was claiming to be.
Segment 804: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6178, Text: And then I just basically didn’t do well in any of the tests, and I went down and down and down and down and then I was like, “Huh, this is really embarrassing. I really like maths and everyone says I can’t do it. I really like physics and chemistry and science and people say you can’t read and write.” And so I found myself in a learning difficulties class at the end of primary school and the beginning of secondary school. In the UK, secondary school is 11, 12 years old. And I remember being put in the remedial class. And the remedial class was basically full of three types of people. There were people quite violent and there were people who couldn’t speak English and there were people that really had learning difficulties. So the one thing I can objectively remember was… I could read. I liked reading. I read a lot. But something in me, I’m a bit of a rebel. I refused to read what I was told to read and I found it difficult to read individual words in the way they were told.
Segment 805: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6264, Text: But anyway, I got caught one day teaching someone else to read and they said, “Okay, we don’t understand this.” I’d always known I wanted to be a scientist, but I didn’t really know what that meant and I realized you had to go to university and I thought, “I can just go to university. They take curious people.” “No, no, no need to have these. You have to be able to enter these exams to get this grade point average, and the fact is, the exams you’ve been entered into, you are just going to get C, D or E.” You can’t even get A, B or C. These are the UK GCSEs. I was like, ” Oh, shit,” and I said, “Can you just put me into the higher exams?” They said, “No, no, you’re going to fail. There’s no chance.” So my father intervened and said, “Just let him go in the exams,” and they said, “He’s definitely going to fail. It’s a waste of time, waste of money,” and he said, “What if we paid?” So they said, “Okay,” so you didn’t actually have to pay. You only had to pay if I failed.
Segment 806: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6323, Text: So I took the exams and passed them, fortunately. I didn’t get the top grades, but I got into A Levels. But then that also limited what I could do at A Levels. I wasn’t allowed to do A Level maths.
Segment 807: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6335, Text: What do you mean you weren’t allowed to?
Segment 808: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6336, Text: Because I had such a bad math grade from my GCSE, I only had a C. But they wouldn’t let me go into the ABC for maths because of some coursework requirement back then so the top grade I could have got was a C. So C, D or E. So I got a C and they let me do AS Level maths, which is this half intermediate and get to go to university. But I liked chemistry. I had a good chemistry teacher so in the end I got to university to do chemistry.
Segment 809: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6361, Text: So through that process, I think for kids in that situation, it’s easy to start believing that you’re not… How do I put it… That you’re stupid, and basically give up, that you’re just not good at math, you’re not good at school. So this is, by way of advice for people, for interesting people, for interesting young kids right now, experiencing the same thing. Where was the place? What was the source of you not giving up there?
Segment 810: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6393, Text: I have no idea. Other than… I really liked not understanding stuff. For me, when I not understand something… I feel like I don’t understand anything. But now, but back then, I remember when I was like… I don’t know, I tried to build a laser when I was eight and I thought, “How hard could it be?” And basically, I was going to build a CO2 laser and I was like, “Right, I think I need some partially coated mirrors. I need some carbon dioxide and I need a high voltage.” And I was so stupid. I was so embarrassed. T make enough CO2, I actually set a fire and tried to filter the flame.
Segment 811: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6450, Text: Oh, nice. That’s an idea.
Segment 812: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6450, Text: Just to collect enough CO2 and it completely failed. And I burnt half the garage down. So my parents were not very happy about that. So that was one thing. I really liked first principle thinking. So I remember being super curious and being determined to find answers. And so when people do give advice about this, why ask for advice about this? I don’t really have that much advice other than don’t give up. And one of the things I try to do as a chemistry professor in my group is I hire people that I think, if they’re persistent enough, who am I to deny them the chance? Because people gave me a chance and I was able to do stuff.
Segment 813: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6498, Text: Do you believe in yourself essentially?
Segment 814: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6502, Text: So I love being around smart people and I love confusing smart people. And when I’m confusing smart people, not by stealing their wallets and hiding it somewhere, but if I can confuse smart people, that is the one piece of hope that I might be doing something interesting.
Segment 815: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6517, Text: Wow, that’s quite brilliant. As a gradient to optimize. Hang out with smart people and confuse them. And the more confusing it is, the more there’s something there.
Segment 816: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6527, Text: And as long as they’re not telling you just a complete idiot and they give you different reasons. And everyone, because with assembly theory and people said, “Oh, it’s wrong.” And I was like, “Why?” And no one could give me a consistent reason. They said, “Oh, because it’s been done before or it’s just [inaudible 01:49:04] or it’s just there, that and the other. So I think the thing that I like to do is, and in academia it’s hard because people are critical. But the criticism, although I got upset about it earlier, which is silly, but not silly because obviously it’s hard work being on your own or with a team spatially separated during lockdown and try to keep everyone on board and have some faith. I always wanted to have a new idea. And so I like a new idea and I want to nurture it as long as possible. And if someone can give me actionable criticism, that’s why I think I was trying to say earlier when I was stuck for words, give me actionable criticism.
Segment 817: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6591, Text: “It’s wrong.” “Okay, why is it wrong?” Say, “Oh, your equation’s incorrect for this or your method is wrong.” So what I try and do is get enough criticism from people to then triangulate and go back. And I’ve been very fortunate in my life that I’ve got great colleagues, great collaborators, funders, mentors, and people that will take the time to say, “You are wrong because.” And then what I have to do is integrate the wrongness and go, “Oh, cool, maybe I can fix that.” And I think criticism is really good. People have a go at me because I’m really critical. But I’m not criticizing you as a person. I’m just criticizing the idea and trying to make it better and say, “What about this?”
Segment 818: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6634, Text: And sometimes my filters are truncated in some ways. I’m just like, “That’s wrong, that’s wrong, that’s wrong. Why’d you do this?” And people are like, “Oh my God, you just told me, you destroyed my life’s work.” I’m like, “Relax. No.” I’m just like, “Let’s make it better.” And I think that we don’t do that enough because we are either personally critical, which isn’t helpful or we don’t give any criticism at all because we’re too scared.
Segment 819: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6663, Text: Yeah, I’ve seen you be pretty aggressively critical but every time I’ve seen, it’s the idea, not the person.
Segment 820: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6675, Text: I’m sure I make mistakes on that.I argue lots with Sara and she’s shocked. I’ve argued with Joscha, Joscha Bach, in the past and he is like, “You’re just making that up.” And I’m like, “No, not quite. But kind of.” But I had a big argument with Sara about time and she’s like, “No, time doesn’t exist.” I’m like, “No, no, time does exist.” And as she realized that her conception of assembly theory and my conception of assembly theory was the same thing, necessitated us to abandon the fact that time is eternal, to actually really fundamentally question how the universe produces combinatorial novelty.
Segment 821: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6719, Text: So time is fundamental for assembly theory? I’m just trying to figure out where you and Sara converged.
Segment 822: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6726, Text: I think assembly theory is fine in this time right now but I think it helps us understand that something interesting is going on. I’ve been really inspired by a guy called Nick Gisin. I’m going to butcher his argument but I love his argument a lot. So I hope he forgives me if he hears about it. But basically if you want free will, time has to be fundamental. And if you want time to be fundamental, you have to give up on platonic mathematics and you have to use intuition. By the way, and again I’m going to butcher this, but basically Hilbert said that infinite numbers are allowed. And I think it was Brouwer who said, “No, you can’t. All numbers are finite.” So let’s go back a step because it was like people going to say, assembly theory seems to explain that large combinatorial space allows you to produce things like life and technology. And that large combinatorial space is so big it’s not even accessible to a Sean Carroll, David Deutsch multiverse that physicists saying that all of the universe already exists in time is probably, provably, that’s a strong word, not correct.
Segment 823: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6823, Text: That we are going to know that the universe as it stands, the present, the way the present builds the future is so big, the universe can’t ever contain the future. And this is a really interesting thing. I think Max Tegmark has this mathematical universe. He says the universe is like a block universe, and I apologize to Max if I’m getting it wrong, but people think you can just move. You have the stat, you have the initial conditions, and you can run the universe right to the end and go backwards and forwards in that universe. That is not correct.
Segment 824: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6857, Text: Let me load that in. The universe is not big enough to contain the future.
Segment 825: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6861, Text: Yeah. That’s why. That’s it.
Segment 826: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6864, Text: That’s a beautiful way of saying that time is fundamental.
Segment 827: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6866, Text: Yes. And this is why the law of the excluded middle, something is true or false, only works in the past. Is it going to snow in New York next week or in Austin? You might, in Austin, say probably not. In New York, you might say, yeah. If you go forward to next week and say, “Did it snow in New York last week? True or false?” You can answer that question. The fact that the law of the excluded middle cannot apply to the future explains why time is fundamental.
Segment 828: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6901, Text: That’s a good example, intuitive example, but it’s possible that we might be able to predict whether it’s going to snow if we had the perfect information.
Segment 829: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6910, Text: I think…
Segment 830: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6911, Text: You’re saying it not.
Segment 831: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6913, Text: Impossible. Impossible. So here’s why. I’ll make a really quick argument and this argument isn’t mine. It’s Nick’s and a few other people.
Segment 832: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6923, Text: Can you explain his view on time being fundamental?
Segment 833: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6928, Text: Yeah. So I’ll give my view, which resonates with his, but basically it’s very simple actually. It would say your ability to design and do an experiment is exercising free will. So he used that thought process. I never really thought about it that way, and that you actively make decisions. I used to think that free will was a consequence of just selection but I’m understanding that human free will is something really interesting. And he very much inspired me. But I think that what Sara Walker said that inspired me as well, these will converge, is that I think that the universe, and the universe is very big, huge, but actually the place that is largest in the universe right now, the largest place in the universe, is earth.
Segment 834: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6980, Text: Yeah, I’ve seen you say that. And boy, does that… That’s an interesting one to process. What do you mean by that earth is the biggest place in the universe?
Segment 835: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=6991, Text: Because we have this combinatorial scaffolding going all the way back from LUCA. So you’ve got cells that can self-replicate and then you go all the way to terraforming the earth. You’ve got all these architectures, the amount of selection that’s going on, biological selection, just to be clear, biological evolution, and then have multicellularity then animals and abstraction. And with abstraction, there was another kick because you can then build architectures and computers and cultures and language and these things are the biggest things that exist in the universe because we can just build architectures that could naturally arise anywhere and the further that distance goes in time, and it’s gigantic.
Segment 836: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7035, Text: From a complexity perspective.
Segment 837: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7037, Text: Yeah.
Segment 838: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7037, Text: Okay, wait a minute. But I know you’re being poetic, but how do you know there’s not other earth-like… How do you know? You’re basically saying earth is really special. It’s awesome stuff as far as we look out, there’s nothing like it going on. But how do you know there’s not nearly infinite number of places where cool stuff like this is going on?
Segment 839: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7060, Text: I agree and I would say, I’ll say again, that earth is the most gigantic thing we know in the universe combinatorially we know.
Segment 840: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7069, Text: We know. Yeah.
Segment 841: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7070, Text: Now, I guess this is just purely a guess. I have no data other than hope. Maybe not hope, maybe… No, I have some data. That every star in the sky probably has planets and life is probably emerging on these planets. But the amount of contingency that is associated with life, is I think the combinatorial space associated with these planets is so different. Our causal cones are never going to overlap or not easily. And this is the thing that makes me sad about alien life. It’s why we have to create alien life in the lab as quickly as possible because I don’t know if we are going to be able to be able to build architectures that will intersect with alien intelligence architectures.
Segment 842: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7122, Text: Intersect, you don’t mean in time or space?
Segment 843: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7126, Text: Time and the ability to communicate.
Segment 844: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7128, Text: The ability to communicate.
Segment 845: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7129, Text: Yeah. My biggest fear in a way is that life is everywhere but we become infinitely more lonely because of our scaffolding in that combinatorial space. Because it’s so big.
Segment 846: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7140, Text: So you’re saying the constraints created by the environment that led to the factory of Darwinian evolution are just this little tiny cone in a nearly infinite combinatorial space.
Segment 847: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7154, Text: Exactly.
Segment 848: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7154, Text: So there’s other cones like it. Why can’t we communicate with other… Just because we can’t create it doesn’t mean we can’t appreciate the creation, right? Sorry, detect the creation.
Segment 849: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7170, Text: I truly don’t know but it’s an excuse for me to ask for people to give me money to make a planet simulator.
Segment 850: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7176, Text: Yeah, right.
Segment 851: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7176, Text: If I can make…
Segment 852: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7178, Text: With a different [crosstalk 01:59:40]
Segment 853: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7179, Text: It’s like another shameless say, it’s like, “Give me money. I need money.”
Segment 854: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7182, Text: This was all long plug for a planet simulator. Hey, I won’t be the first in line to do that.
Segment 855: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7190, Text: My rick garage has run out of room.
Segment 856: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7193, Text: Yeah.
Segment 857: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7194, Text: No.
Segment 858: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7194, Text: And this planet simulator, you mean a different planet or different sets of environments and pressures?
Segment 859: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7201, Text: Exactly. If we could basically recreate the selection before biology as we know it, that gives rise to a different biology, we should be able to put the constraints on where to look in the universe. So here’s the thing. Here’s my dream. My dream is that by creating life in the lab based upon constraints we understand, let’s go for Venus type life or earth type life or something again, do an Earth 2.0. Screw it, let’s do an Earth 2.0. An Earth 2.0 has a different genetic alphabet. Fine, that’s fine. Different protein alphabet, fine. Have cells and evolution, all that stuff. We will then be able to say, “Okay, life is a more general phenomena. Selection is more general than what we think is the chemical constraints on life.” And we can point at James Webb and other telescopes at other planets that we are in that zone we are most likely to combinatorially overlap with because, so there’s chemistry…
Segment 860: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7261, Text: You’re looking for some overlap.
Segment 861: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7262, Text: And then we can then basically shine light on them literally and look at light coming back and apply advanced assembly theory to general theory of language that we’ll get and say, “Huh, in that signal, it looks random but there’s a copy number. Oh, this random set of things that shouldn’t be that looks like a true random number generator has structure as not [inaudible 02:01:32], an IT type structure, but evolutionary structure given by assembly theory,” and we start to… But I would say that because I’m a shameless assembly theorist.
Segment 862: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7302, Text: Yeah, it just feels like the cone, I might be misusing the word cone here but the width of the cone is growing faster, is growing really fast to where eventually all the cones overlap even in a very, very, very large combinatorial space. But then again, if you’re saying the universe is also growing very quickly in terms of possibilities…
Segment 863: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7334, Text: I hope that as we build abstractions, one idea is that as we go to intelligence, intelligence allows us to look at the regularities around us in the universe. And that gives us some common grounding to discuss with aliens. And you might be right that we will overlap there. Even though we have completely different chemistry, literally completely different chemistry, that we will be able to pass information from one another. But it’s not a given. And I have to try and divorce hope and emotion away from what I can logically justify.
Segment 864: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7382, Text: But it’s just hard to intuit a world, a universe where there’s nearly infinite complexity objects and they somehow can’t detect each other.
Segment 865: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7393, Text: The universe is expanding. But the nice thing is I would say, I would look, you see, I think Carl Sagan did the wrong thing. Not the wrong thing. He flicked the Voyager program and the Pale Blue Dot and said, “Look how big the universe is.” I would’ve done it the other way around and said, “Look at the Voyager probe that came from the planet earth that came from LUCA. Look at how big earth is.”
Segment 866: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7411, Text: Then it produced that.
Segment 867: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7412, Text: It produced that.
Segment 868: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7414, Text: Yeah.
Segment 869: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7415, Text: And that I think is completely amazing. And then that should allow people on earth to think about, “Probably we should try and get causal chains off Earth onto Mars, onto the moon, wherever. Whether it’s human life or martian life that we create, it doesn’t matter. But I think this combinatorial space tells us something very important about the universe and that I realized in assembly theory that the universe is too big to contain itself. Now coming back, I want to change your mind about time because I’m guessing that your time is just a coordinate. So I’m going to change…
Segment 870: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7415, Text: I’m guessing you’re one of those.
Segment 871: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7460, Text: One of those. I’m change my mind in real time or at least attempt.
Segment 872: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7462, Text: Oh, in real time. There you go. I already got the tattoo. So this is going to be embarrassing if you change my mind.
Segment 873: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7467, Text: But you can just add an arrow of time onto it, right?
Segment 874: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7467, Text: Yeah, true. Just modify it.
Segment 875: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7472, Text: Or raise it a bit. And the argument that I think that is really most interesting is people say the initial conditions specify the future of the universe. Okay, fine. Let’s say that’s the case for a moment. Now let’s go back to Newtonian mechanics. Now, the uncertainty principle in Newtonian mechanics is this. If I give you the coordinates of an object moving in space and the coordinates of another object and they collide in space. And those initial conditions, you should know exactly what’s going to happen. However, you cannot specify these coordinates to infinite precision. Now everyone says, “Oh, this is like the chaos theory argument.” No, no, it’s deeper than that. Here’s a problem with numbers. This is where Hilbert and Brouwer fell out. To have the coordinates of this object, a given object that’s colliding, you have to have them to infinite precision. That’s what Hilbert says. There’s no problem. Infinite precision is fine. Let’s just take that for granted.
Segment 876: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7538, Text: But when the object is finite and it can’t store its own coordinates, what do you do? So in principle, if a finite object cannot be specified to infinite precision, in principle, the initial conditions don’t apply.
Segment 877: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7558, Text: How do you know it can’t store its…
Segment 878: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7561, Text: How do you store an in long number in a finite size?
Segment 879: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7569, Text: We’re using infinity very loosely here.
Segment 880: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7571, Text: No, no. We’re using…
Segment 881: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7572, Text: Infinite precision. Not loosely, but…
Segment 882: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7574, Text: Very precisely.
Segment 883: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7575, Text: So you think infinite precision is required?
Segment 884: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7578, Text: Let’s take the object. Let’s say the object is a golf ball. A golf ball is a few centimeters in diameter. We can work out how many atoms are in the golf ball. And let’s say we can store numbers down to atomic dislocations. So we can work out how many atoms there are in the golf ball and we can store the coordinates in that golf ball down to that number. But beyond that, we can’t. Let’s make the golf ball smaller. And this is where I think that we think that we get randomness in quantum mechanics and some people say you can’t get randomness, quantum mechanic’s deterministic, but aha, this is where we realize that classical mechanics and quantum mechanics suffer from the same uncertainty principle. And that is the inability to specify the initial conditions to a precise enough degree to give you determinism.
Segment 885: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7629, Text: The universe is intrinsically too big and that’s why time exists. It’s non-deterministic. Looking back into the past, you can use logical arguments because you can say, “Was it true or false?” You already know. But this is the fact we are unable to predict the future with the precision is not evidence of lack of knowledge. It’s evidence the universe is generating new things.
Segment 886: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7658, Text: Okay, first of all, quantum mechanics, you could just say statistically what’s going to happen when two golf balls hit each other.
Segment 887: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7664, Text: Statistically. But sure, I can say statistically what’s going to happen. But then when they do happen and then you keep nesting it together, it goes almost back to, look, let’s think about entropy in the universe. So how do we understand entropy change or process? We can use the ergodic hypothesis. We can also have have the counterfactuals where we have all the different states and we can even put that in the multiverse. But both those, they’re nonphysical. The multiverse collapses back to the same problem about the precision. So if you accept, you don’t have to have true and false going forward into the future. The real numbers are real. They’re observables.
Segment 888: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7727, Text: We’re trying to see exactly where time being fundamental sneaks in. And this difference between the golf ball can’t contain its own position perfectly precisely. How that leads to time needing to be fundamental.
Segment 889: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7747, Text: Do you believe or do you accept you have free will?
Segment 890: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7752, Text: Yeah, I think at this moment in time, I believe that I have free will.
Segment 891: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7757, Text: So then you have to believe that time is fundamental.
Segment 892: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7763, Text: I understand that’s a statement you’ve made.
Segment 893: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7765, Text: No, that we can logically follow because if you don’t have free will, so if you’re in a universe that has no time, universe is deterministic. If it’s deterministic, then you have no free will.
Segment 894: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7777, Text: I think the space of how much we don’t know is so vast that saying the universe is deterministic and from that jumping into there’s no free will is just too difficult of a leap.
Segment 895: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7788, Text: No, I logically follow. No, no, I don’t disagree. It’s deep and it’s important. All I’m saying, and it’s actually different to what I’ve said before, is that if you don’t require platonistic mathematics and accepts that non-determinism is how the universe looks and that gives us our creativity and the way the universe is getting novelty, it’s really deeply important in assembly theory because assembly theory starts to actually give you a mechanism where you go from boring time, which is basically initial conditions specify everything, to a mismatch in creative time. And I hope we’ll do experiments. I would love to do an experiment that prove that time is fundamental and the universe is generating novelty. I don’t know all the features of that experiment yet, but by having these conversations openly and getting people to think about the problems in a new way, better people, more intelligent people with good mathematical backgrounds can say, “Oh, hey, I’ve got an idea. I would love to do an experiment that shows that the universe is too big for itself going forward in time.”
Segment 896: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7864, Text: And this is why I really hate the idea of the Boltzmann brain. The Boltzmann brain makes me super, like everyone’s having a free lunch. It’s like saying, “Let’s break all the laws of physics.” So a Boltzmann brain is this idea that in a long enough universe, a brain will just emerge in the universe as conscious. And that neglects the causal chain of evolution that required to produce that brain. And this is where the computational argument really falls down because a computationalist could say,” I can calculate probability of a Boltzmann brain.” And they’ll give you a probability. But I can calculate probability of a Boltzmann brain. Zero.
Segment 897: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7900, Text: Just because the space of possibilities is so large?
Segment 898: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7903, Text: Yeah. When we start falling ourselves with numbers that we can’t actually measure and we can’t ever conceive of, I think it doesn’t give us a good explanation. And I want to explain why life is in the universe. I think life is actually novelty minor. Life basically mines novelty almost from the future and actualizes in the present.
Segment 899: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7931, Text: Okay. Life is a novelty minor from the future that is actualized in the present.
Segment 900: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7940, Text: Yep. I think so.
Segment 901: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7944, Text: Novelty minor. First of all, novelty. What’s the origin of novelty when you go from boring time to creative time? Where is that? Is it as simple as randomness like you’re referring to?
Segment 902: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=7959, Text: I am really struggling with randomness because I had a really good argument with Joscha Bach about randomness, and he just said, “Randomness doesn’t give you free will. That’s insane because you’d just be random.” And I think he’s right at that level but I don’t think he is right on another level. And it’s not about randomness, it’s about constrained, I’m making this up as I go along, so making this up, constrained opportunity. So the novelty. What is novelty? This is what I think is a funny thing if you ever want to discuss AI. Why I think everyone’s gone AI mad is that they’re misunderstanding novelty. But let’s think about novelty. Yes. What is novelty? So I think novelty is a genuinely new configuration that is not predicted by the past and that you discover in the present. And that is truly different. Now, everyone says that. Some people say that novelty doesn’t exist. It’s always with precedent. I want to do experiments that show that that is not the case. And it goes back to a question you asked me a few moments ago, which is where is the factory?
Segment 903: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8038, Text: Because I think the same mechanism that gives us a factory gives us novelty. And I think that is why I’m so deeply hung up on time. Of course I’m wrong, but how wrong? And I think that life opens up that combinatorial space in a way that our current laws of physics, although as contrived in a deterministic initial condition universe even with the get out of the multiverse, David Deutsch style, which I love by the way, but I don’t think is correct, but it’s really beautiful.
Segment 904: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8077, Text: Multiverse.
Segment 905: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8078, Text: David Deutsche’s conception of the multiverse is given. But I think that the problem with wave particle duality in quantum mechanics is not about the multiverse. It’s about understanding how determined the past is. I don’t just think that actually, this is a discussion I was having with Sara about that, where she was like, “Oh, I think we’ve been debating this for a long time now, about how do we reconcile novelty determinism in determinism.”
Segment 906: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8113, Text: Okay. Just to clarify, both you and Sara think the universe is not deterministic?
Segment 907: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8119, Text: I won’t speak for Sara but roughly. I think the universe is deterministic looking back in the past but undetermined going forward in the future. So I’m having my cake and eating it here. This is because I fundamentally don’t understand randomness, as Joscha told me or other people told me. But if I adopt a new view now which the new view is the universe is just non-deterministic, but I’d like to refine that and say the universe appears deterministic going back in the past but it’s undetermined going forward in the future. So how can we have a universe that has deterministically looking rules that’s non-determined
Segment 908: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8160, Text: … universe that has deterministically-looking rules that is non-determined going into the future. It’s this breakdown in precision in the initial conditions, and we have to just stop using initial conditions and start looking at trajectories, and how the combinatorial space behaves in an expanding universe in time and space. And assembly theory helps us quantify the transition to biology, and biology appears to be novelty-mining, because it’s making crazy stuff that are unique to Earth. Right? There are objects on Earth that are unique to Earth that will not be found anywhere else, because you can do the combinatorial math.
Segment 909: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8201, Text: What was that statement you made about “life is novelty-mining from the future”? What’s the little element of time that you’re introducing there?
Segment 910: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8211, Text: What I’m kind of meaning is because the future is bigger than the present, in a deterministic universe, how do the states go from one to another? There’s a mismatch, right?
Segment 911: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8222, Text: Yeah.
Segment 912: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8223, Text: So, that must mean that you have a little bit of indeterminism. Whether that’s randomness or something else, I don’t understand. I want to do experiments to formulate a theory to refine that as we go forward that might help us explain that. And I think that’s why I’m so determined to try and crack the “non-life to life” transition looking at networks and molecules, and that might help us think about the mechanism. But certainly the future is bigger than the past in my conception of the universe and some conception of the universe. And-
Segment 913: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8255, Text: By the way, that’s not obvious, right? The future being bigger than the past, well, that’s one statement, and the statement that the universe is not big enough to contain the future is another statement. That one is a big one. That one’s a really big one.
Segment 914: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8273, Text: I think so, but I think it’s entirely … Because look, we have the second law, and right now we don’t need the second law if the future’s bigger than the past. It follows naturally. So, why are we retrofitting all these sticking plasters onto our reality to hold onto a timeless universe?
Segment 915: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8293, Text: Yeah, but that’s because it’s kind of difficult to imagine the universe that can’t contain the future.
Segment 916: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8301, Text: But isn’t that really exciting?
Segment 917: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8303, Text: It’s very exciting, but it’s hard. We are humans on Earth, and we have a very kind of four-dimensional conception of the world, of 3D plus time. It’s just hard to intuit a world where, what does that even mean, a universe that can’t contain the future?
Segment 918: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8327, Text: Yeah. It’s kind of crazy but obvious.
Segment 919: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8330, Text: It’s weird, it’s weird. I suppose it sounds obvious, yeah, if it’s true.
Segment 920: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8336, Text: So, the reason why assembly theory turned me onto that was that, let’s just start in the present, and look at all the complex molecules, and go backwards in time, and understand how evolutionary processes gave rise to them. It’s not at all obvious that taxol, which is one of the most complex natural products produced by biology, was going to be invented by biology. It’s an accident.
Segment 921: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8364, Text: Taxol is unique to Earth. There’s no taxol elsewhere in the universe, and taxol was not decided by the initial conditions. It was decided by this interplay between the … So, the past simply is embedded in the present. It gives some features. But why the past doesn’t map to the future one-to-one is because the universe is too big to contain itself. That gives space for creativity, and novelty, and some things which are unpredictable.
Segment 922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8397, Text: Well, okay. So, given that you’re disrespecting the power of the initial conditions, let me ask you about, how do you explain that cellular automata are able to produce such incredible complexity given just basic rules and basic initial conditions?
Segment 923: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8412, Text: I think that this falls into the Brouwer-Hilbert trap. So, how do you get cellular automata to produce complexity? You have a computer, you generate a display, and you map the change of that in time. There are some CAs that repeat like functions.
Segment 924: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8432, Text: It’s fascinating to me that for pi, there is a formula where you can go to the millionth decimal place of pi and read out the number without having to go there. But there are some numbers where you can’t do that, and you have to just crank through. Whether it’s Wolframian computational irreducibility or some other thing, well, it doesn’t matter. But these CAs, that complexity, is that just complexity, or a number that is basically you’re mining that number in time? Is that just a display screen for that number, that function?
Segment 925: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8470, Text: Well, can’t you say the same thing about the complexity on Earth then?
Segment 926: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8472, Text: No. Because the complexity on Earth has a copy number and an assembly index associated with it. That CA is just a number running.
Segment 927: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8480, Text: You don’t think it has a copy number? Wait a minute …
Segment 928: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8483, Text: Well, it does where we’re looking at humans producing different rules, but then it’s nested on selection. So, those CAs are produced by selection. The CA is such a fascinating pseudo-complexity generator. What I would love to do is understand, quantify the degree of surprise in a CA and run it long enough. But what I guess that means is we have to instantiate, we have to have a number of experiments where we’re generating different rules and running them time steps, but … Oh, I got it.
Segment 929: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8513, Text: CAs are mining novelty in the future by iteration, right? And you’re like, ” Oh, that’s great. That’s great.” You didn’t predict it. Some rules you can predict what’s going to happen, and other rules you can’t. So for me, if anything, CAs are evidence that the universe is too big to contain itself, because otherwise you’d know what the rules are going to do forevermore.
Segment 930: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8534, Text: Right. I guess you were saying that the physicist saying that all you need is the initial conditions and the rules of physics is somehow missing the bigger picture.
Segment 931: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8546, Text: Yeah.
Segment 932: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8547, Text: And if you look at CAs, all you need is the initial condition and the rules, and then run the thing.
Segment 933: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8553, Text: You need three things; You need the initial conditions, you need the rules, and you need time iteration to mine it out. Without the coordinate, you can’t get it out.
Segment 934: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8565, Text: Sure, and that to you is fundamental?
Segment 935: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8567, Text: And you can’t predict it from the initial conditions. If you could, then it could be fine.
Segment 936: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8571, Text: And that time is-
Segment 937: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8573, Text: A resource.
Segment 938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8574, Text: … like the foundation of the history, the memory of each of the things it created. It has to have that memory of all the things that led up to it.
Segment 939: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8585, Text: Yeah, you have to have the resource. Because time is a fundamental resource. Yeah, I think I had a major epiphany about randomness, but I keep doing that every two days and then it goes away again. It’s random.
Segment 940: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8604, Text: You’re a time fundamentalist.
Segment 941: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8606, Text: And you should be as well. If you believe in free will, then the only conclusion is that time is fundamental. Otherwise you cannot have free will. It logically follows.
Segment 942: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8617, Text: Well, the foundation of my belief in free will is observation-driven.
Segment 943: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8628, Text: But that’s-
Segment 944: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8628, Text: I think if you use logic, logically it seems like the universe is deterministic.
Segment 945: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8635, Text: Looking backwards in time then that’s correct, the universe is.
Segment 946: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8639, Text: And then everything else is a kind of leap. It requires a leap.
Segment 947: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8651, Text: This is why I think machine learning is going to provide a chunk of that, right? To help us explain this. So, the way I’d say it, if you take …
Segment 948: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8659, Text: That’s interesting. Why?
Segment 949: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8661, Text: Well, my favorite one is … Because AI doomers are driving me mad, and in fact we don’t have any intelligence yet. I call AI “autonomous informatics” just to make people grumpy.
Segment 950: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8674, Text: Yeah. You’re saying we’re quite far away from AGI.
Segment 951: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8679, Text: I think that we have no conception of intelligence, and I think that we don’t understand how the human brain does what it does. I think that neuroscience is making great advances, but I think that we have no idea about AGI. So, I am a technological, I guess optimist. I believe we should do everything. The whole regulation of AI is nonsensical. Why would you regulate Excel, other than the fact that Clippy should come back and I love Excel ’97 because we can do the flight simulator.
Segment 952: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8711, Text: Sorry, in Excel?
Segment 953: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8712, Text: Yeah, have you not played the flight simulator in-
Segment 954: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8714, Text: In Excel ’97?
Segment 955: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8716, Text: Yeah.
Segment 956: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8718, Text: What does that look like?
Segment 957: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8719, Text: It’s like wireframe, very basic. But basically I think it’s X zero, Y zero, shift, and it opens up and you can play the flight simulator.
Segment 958: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8729, Text: Oh, wow. Wait, wait, is it using Excel?
Segment 959: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8732, Text: Excel ’97.
Segment 960: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8733, Text: Okay.
Segment 961: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8734, Text: I resurrected it the other day and saw Clippy again for the first time in a long time.
Segment 962: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8737, Text: Well, Clippy is definitely coming back. But you’re saying we don’t have a great understanding of what is intelligence, what is the intelligence underpinning the human mind.
Segment 963: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8750, Text: I’m very frustrated by the way that we’re AI dooming right now, and people are bestowing some kind of magic. Now, let’s go back a bit. So, you said about AGI, are we far away from AGI? Yes. I do not think we’re going to get to AGI anytime soon. I’ve seen no evidence of it, and the AI doom scenario is nonsensical in the extreme.
Segment 964: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8772, Text: The reason why I think it’s nonsensical … And I don’t think there isn’t things we should do and be very worried about. There are things we need to worry about right now, what AI are doing. Whether it’s fake data, fake users. I want authentic people, authentic data. I don’t want everything to be faked, and I think it’s a really big problem, and I absolutely want to go on the record to say I really worry about that. What I’m not worried about is that some fictitious entity is going to turn us all to paperclips or detonate nuclear bombs, or maybe, I don’t know, anything you can think of.
Segment 965: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8809, Text: Why is this? I’ll take a very simple series of logical arguments, and the AI doomers do not have the correct epistemology. They do not understand what knowledge is. And until we understand what knowledge is, they’re not going to get anywhere because they’re applying things falsely. So, let me give you a very simple argument.
Segment 966: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8838, Text: People talk about the probability, “P(doom)”, of AI. We can work out the probability of an asteroid hitting the planet. Why? Because it’s happened before. We know the mechanism. We know that there’s a gravity well, or that spacetime is bent and stuff falls in. We don’t know the probability of AGI because we have no mechanism. So, let me give you another one, which is like, “I’m really worried about AG.” What’s AG? AG is anti-gravity. “One day we could wake up and anti-gravity is discovered, we’re all going to die, the atmosphere is going to float away, we’re going to float away, we’re all doomed.”
Segment 967: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8872, Text: What is the probability of AG? We don’t know because there’s no mechanism for AG. Do we worry about it? No, and I don’t understand the current reason for certain people in certain areas to be generating this nonsense. I think they’re not doing it maliciously. I think we’re observing the emergence of new religions, how religions come, because religions are about some controls.
Segment 968: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8900, Text: You’ve got the optimist saying, “AI is going to cure us all,” and, “AI is going to kill us all.” What’s the reality? Well, we don’t have AI. We have really powerful machine learning tools and they will allow us to do interesting things, and we need to be careful about how we use those tools in terms of manipulating human beings and faking stuff. Right?
Segment 969: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8918, Text: Right. Well, let me try to steel man the AI doomers’ argument. And actually, I don’t know, are AI doomers in the Yudkowsky camp saying it’s definitely going to kill us? Because there’s a spectrum.
Segment 970: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8918, Text: 95% I think is the limit.
Segment 971: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8934, Text: Plus? 95%-plus, that’s the-
Segment 972: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8935, Text: No, not plus. I don’t know. I was seeing on Twitter today various things. But I think Yudkowsky is at 95%.
Segment 973: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8942, Text: But to belong to the AI doomer club, is there a threshold? I don’t know what the membership …
Segment 974: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8946, Text: Maybe.
Segment 975: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8947, Text: And what are the fees?
Segment 976: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8949, Text: Well, I think Scott Aronson, I was quite surprised, had put two … I saw this online, so I could be wrong. So, sorry if it’s wrong. He says 2%. But the thing is, if someone said there’s a 2% chance that you’re going to die going into the lift, would you go into the lift?
Segment 977: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8964, Text: In the elevator, for the American English-speaking audience. Well, no, not for the elevator.
Segment 978: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8970, Text: So, I would say anyone higher than 2% … I think there’s a 0% chance of AGI doom. Zero.
Segment 979: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=8977, Text: Just to push back on the argument where N of zero on the AGI … We could see on Earth that there’s increasing levels of intelligence of organisms. We can see what humans with extra intelligence were able to do to the other species. So, that is a lot of samples of data, what a delta in intelligence gives you. When you have an increase in intelligence, how you’re able to dominate a species on Earth.
Segment 980: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9008, Text: So, the idea there is that if you have a being that’s 10x smarter than humans, we’re not going to be able to predict what that being is going to be able to do, especially if it has the power to hurt humans. Which, you can imagine a lot of trajectories in which the more benefit AI systems give, the more control we give to those AI systems over our power grid, over our nuclear weapons, or weapons of any sort. And then it’s hard to know what an ultra-intelligence system would be able to do in that case. You don’t find that convincing?
Segment 981: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9050, Text: I think I would fail that argument 100%. Here’s a number of reasons to fail it on. First of all, we don’t know where the intention comes from. The problem is that people keep … I’ve been watching all the hucksters online with the prompt engineering and all this stuff. When I talk to a typical AI computer scientist, they keep talking about the AIs having some kind of decision-making ability. That is a category error.
Segment 982: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9077, Text: The decision-making ability comes from human beings. We have no understanding of how humans make decisions. We’ve just been discussing free will for the last half an hour, right? We don’t even know what that is. So, the intention, I totally agree with you, people who intend to do bad things can do bad things and we should not let that risk go. That’s totally here and now. I do not want that to happen, and I’m happy to be regulated to make sure that systems I generate, whether they’re computer systems, or … I’m working on a new project called “Chem Machina”.
Segment 983: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9113, Text: Nice. Well done.
Segment 984: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9114, Text: Yeah, yeah. Which is basically a …
Segment 985: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9119, Text: For people who don’t understand the pun, the Ex Machina is a great film about I guess AGI embodied, and “chem” is the chemistry version of that.
Segment 986: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9127, Text: And I only know one way to embody intelligence, and that’s in chemistry and human brains. So, category error number one is that they have agency. Category error number two is assuming that anything we make is going to be more intelligent. Now, you didn’t say super-intelligent. I’ll put the words into our mouths here, super-intelligent. I think that there is no reason to expect that we are going to make systems that are more intelligent. More capable …
Segment 987: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9158, Text: When people play chess computers, they don’t expect to win now, right? The chess computer is very good at chess. That doesn’t mean it’s super-intelligent. So, I think that super-intelligence, and I think even Nick Bostrom is pulling back on this now, because he invented this … So, I see this a lot. When did I see it first happen? Eric Drexler, nanotechnology. Atomically precise machines. He came up with a world where we had these atom cogs everywhere and we were going to make self-replicating nanobots.
Segment 988: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9186, Text: Not possible. Why? Because there’s no resources to build these self-replicating nanobots. You can’t get the precision. It doesn’t work. It was a major category error in taking engineering principles down to the molecular level. The only functioning nanomolecular technology we know is produced by evolution. There.
Segment 989: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9207, Text: So, now let’s go forward to AGI. What is AGI? We don’t know. It’s super, it can do this, or humans can’t think. I would argue the only AGIs that exist in the universe are produced by evolution. And sure, we may be able to make our working memory better. We might be able to do more things. The human brain is the most compact computing unit in the universe. It uses 20 watts, uses a really limited volume. It’s not like a ChatGPT cluster which has to have thousands of watts, and a model that’s generated, and it has to be corrected by human beings. You are autonomous and embodied intelligence.
Segment 990: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9244, Text: So, I think that there are so many levels that we’re missing out, we’ve just kind of went, “Oh, we’ve discovered fire. Oh gosh, the planet’s just going to burn one day randomly.” I just don’t understand that leap. There are bigger problems we need to worry about. So, what is the motivation? Why are these people, and let’s assume they’re earnest, have this conviction? Well, I think they’re making leaps and they’re trapped in a virtual reality that isn’t reality.
Segment 991: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9274, Text: Well, I can continue a set of arguments here, but also it is true that ideologies that fearmonger are dangerous. Because you can then use it to control, to regulate in a way that halts progress, to control people, and to cancel people, all that kind of stuff. So, you have to be careful, because reason ultimately wins. Right?
Segment 992: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9303, Text: But there is a lot of concerns with super-intelligent systems, very capable systems. I think when you hear the word “super-intelligent”, you’re hearing, “It’s smarter than humans in every way that humans are smart.” But the paperclip manufacturing system doesn’t need to be smart in every way. It just needs to be smart in a set of specific ways. And the more capable the AI systems become, the more you could see us giving them control over, like I said, our power grid, a lot of aspects of human life. And then that means they’ll be able to do more and more damage when there’s unintended consequences that come to life.
Segment 993: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9346, Text: I think that that’s right. The unintended consequences we have to think about, and that I fully agree with. But let’s go back a bit. Sentience … Again, I’m far away from my comfort zone and all this stuff, but hey, let’s talk about it. Because I give myself a qualification.
Segment 994: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9362, Text: Yeah, we’re both qualified in sentience, I think, as much as anyone else.
Segment 995: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9367, Text: I think the paperclip scenario is just such a poor one, because let’s think about how that would happen. And also, let’s think about, we are being so unrealistic about how much of the Earth’s surface we have commandeered. For paperclip manufacturing to really happen, do the math. It’s not going to happen. There’s not enough energy, there’s not enough resource. Where is it all going to come from?
Segment 996: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9392, Text: I think that what happens in evolution, it’s really: Why has a killer virus not killed all life on Earth? Well, what happens is, sure, superkiller viruses that kill the ribosome have emerged. But you know what happens? They nuke a small space because they can’t propagate. They all die. So, there’s this interplay between evolution and propagation, right? And death. So …
Segment 997: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9416, Text: In evolution. You don’t think it’s possible to engineer, for example, and sorry to interrupt, but a perfect virus?
Segment 998: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9422, Text: No.
Segment 999: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9422, Text: That’s deadly enough?
Segment 1000: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9424, Text: No. Nonsensical. I think again, it wouldn’t work. Because if it was too deadly, it would just kill the radius and not replicate.
Segment 1001: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9431, Text: Yeah. But you don’t think it’s possible to get a …
Segment 1002: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9436, Text: If you were …
Segment 1003: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9437, Text: Not kill all of life on Earth, but kill all humans. There’s not many of us. There’s only like 8 billion. There’s so much more ants. So many more ants, and they’re pretty smart.
Segment 1004: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9452, Text: I think the nice thing about where we are, I would love for the AI crowd to take a leaf out of the book of the bio-warfare, chemical warfare crowd. I mean, not love, because actually people have been killed with chemical weapons in the first and second World War, and bio-weapons have been made, and we can argue about COVID-19 and all this stuff. Let’s not go there just now. But I think there is a consensus that some certain things are bad and we shouldn’t do them, right? And sure, it would be possible for a bad actor to engineer something bad, but we would see it coming and we would be able to do something about it.
Segment 1005: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9496, Text: Now, I guess what I’m trying to say is when people talk about doom, and when you ask them for the mechanism, they just make something up. In this case, I’m with Yann LeCun. I think you put out a very good point about trying to regulate jet engines before we’ve even invented them. And I think that’s what I’m saying.
Segment 1006: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9519, Text: I’m not saying we should … I just don’t understand why these guys are going around literally making stuff up about us all dying, when basically we need to actually really focus on … Now, let’s say there’s some actors that are earnest. Let’s say Yudkowsky is being earnest and he really cares. But he loves it. He goes, “Da, da, da, and then you’re all going to die.” It’s like, why don’t we try and do the same thing and say, “You could do this, and then you’re all going to be happy forever after”?
Segment 1007: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9547, Text: Well, I think there’s several things to say there. One, I think there is a role in society for people that say we’re all going to die. Because I think it filters through as a message, as a viral message that gives us the proper amount of concern. Meaning it’s not 95%, but when you say 95% and it filters through society, it’ll give an average of like a 0.03%. An average. So, it’s nice to have people that are like, “We’re all going to die,” and then we’ll have a proper concern.
Segment 1008: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9581, Text: For example, I do believe we’re not properly concerned about the threat of nuclear weapons currently. It just seems like people have forgotten that that’s a thing, and there’s a war in Ukraine with a nuclear power involved. There’s nuclear powers throughout the world, and it just feels like war in the brink of a potential world war to a percentage that I don’t think people are properly calibrating in their head. We’re all thinking it’s a Twitter battle as opposed to actual threat.
Segment 1009: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9612, Text: So, it’s nice to have that kind of level of concern. But to me, when I hear AI doomers, what I’m imagining is with unintended consequences a potential situation where let’s say 5% of the world suffers deeply because of a mistake made, of unintended consequences. I don’t want to imagine the entirety of human civilization dying, but there could be a lot of suffering if this is done poorly.
Segment 1010: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9639, Text: I understand that, and I guess I’m involved in the whole hype cycle. So, let’s say having some people saying AI doom is a worry, fine. Let’s give them that. But what seems to be happening is there seems to be people who don’t think AI is doing that, and they’re trying to use that to control regulation and to push people to regulate, which stops humans generating knowledge. And I am an advocate for generating as much knowledge as possible.
Segment 1011: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9675, Text: When it comes to nuclear weapons, I grew up in the ’70s and ’80s where there was nuclear doom and a lot of adults really had existential threat, almost as bad as now with AI doom. They were really worried. There were some great … Well, not great. There were some horrific documentaries. I think there was one called Threads that was generated in the UK, which, it was terrible. It was so scary.
Segment 1012: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9700, Text: And I think that the correct thing to do is obviously get rid of nuclear weapons, but let’s think about unintended consequences. We’ve got rid of … This is going to be such a non sequitur. We got rid of all the sulfur particles in the atmosphere, right? All the soot. And what’s happened in the last couple of years is global warming has accelerated because we’ve cleaned up the atmosphere too much. So …
Segment 1013: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9722, Text: Sure. The same thing if you get rid of nuclear weapons. You’ll get [inaudible 02:42:05]-
Segment 1014: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9725, Text: Exactly, that’s my point. So, what we could do is if we actually started to put the AI in charge … Which I’d really like an AI to be in charge of all world politics, and this will sound ridiculous for a second. Hang on. But if we could all agree on the-
Segment 1015: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9739, Text: The AI doomers just woke up on that statement.
Segment 1016: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9742, Text: Yeah, yeah, yeah. But I really don’t like politicians who are basically just looking at local sampling. But if you could say globally, “Look, here’s some game theory here. What is the minimum number of nuclear weapons we need to distribute around the world to everybody to basically reduce war to zero?”
Segment 1017: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9760, Text: Just the thought experiment of, the United States and China and Russia and major nuclear powers get together and say, “All right, we’re going to distribute nuclear weapons to every single nation on Earth.” Oh, boy. That has a probably greater than 50% chance of eliminating major military conflict, but it’s not a hundred percent.
Segment 1018: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9787, Text: But I don’t think anyone will use them, because … And look, what you’ve got to try and do is to qualify for these nuclear weapons … This is a great idea. The game theorists could do this, right?
Segment 1019: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9799, Text: Uh-huh.
Segment 1020: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9800, Text: I think the question is this … I really buy your question. We have too many nukes. Just from a feeling point of view, that we’ve got too many of them. So, let’s reduce the number, but not get rid of them because we’ll have too much conventional warfare. So then, what is the minimum number of nuclear weapons we can distribute around to remove … Humans hurting each other is something we should stop doing. It’s not out with our conceptual capability …
Segment 1021: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9826, Text: But right now, what about certain nations that are being exploited for their natural resources in the future for a short-term gain because we don’t want to generate knowledge? So, if everybody had an equal doomsday switch, I predict the quality of life of the average human will go up faster. I am an optimist, and I believe that humanity is going to get better and better and better, that we’re going to eliminate more problems. But I think, yeah, let’s-
Segment 1022: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9853, Text: But the probability of a bad actor, of one of the nations setting off a nuclear weapon, you have to integrate that into the calculus here.
Segment 1023: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9866, Text: But we just give you [inaudible 02:44:28] nukes population. Right? What we do is we … I can’t believe this. But anyway, let’s just go there. So, if a small nation with a couple of nukes uses one because they’re a bit bored or annoyed, the likelihood that they are going to be pummeled out of existence immediately is 100%. And yet they’ve only nuked one other city. I know this is crazy, and I apologize for …
Segment 1024: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9891, Text: Well, no, no. Just to be clear, we’re just having a thought experiment that’s interesting. But there’s terrorist organizations that would take that trade. We have to ask ourselves a question of: Which percentage of humans would be suicide bombers, essentially? Where they would sacrifice their own life because they hate another group of people. I believe it’s a very small fraction, but is it large enough to, if you give out nuclear weapons …
Segment 1025: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9925, Text: I can predict a future where we take all nuclear material and we burn it for energy, right? Because we’re getting there. And the other thing you could do is say, “Look, there’s a gap.” So, if we get all the countries to sign up to the virtual agreement where we have a simulation where we can nuke each other in the simulation and the economic consequences are catastrophic …
Segment 1026: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9943, Text: Sure. In the simulation, I love it. It’s not going to kill all humans, it’s just going to have economic consequences.
Segment 1027: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9949, Text: Yeah, yeah. I don’t know, I just made it up. It seems like a cool idea.
Segment 1028: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9951, Text: No, it’s interesting. But it’s interesting whether that would have as much power on human psychology as actual physical nuclear explosion.
Segment 1029: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9959, Text: I think so.
Segment 1030: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9960, Text: It’s possible, but people don’t take economic consequences as seriously I think as actual nuclear weapons exploding.
Segment 1031: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9967, Text: I think they do in Argentina, and they do in Somalia. And they do in a lot of these places where … No, I think this is a great idea. I’m a strong advocate now for … So, what have we come up with? Burning all the nuclear material to have energy. And before we do that, because MAD is good, mutually assured destruction is very powerful, let’s take it into the metaverse and then get people to kind of subscribe to that. And if they actually nuke each other even for fun in the metaverse, there are dire consequences.
Segment 1032: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=9996, Text: Yeah, yeah. So, it’s like a video game. We all have to join this metaverse video game …
Segment 1033: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10001, Text: Yeah. I can’t believe we just …
Segment 1034: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10003, Text: And then there’s dire economic consequences. And it’s all run by AI, as you mentioned, so the AI doomers are really terrified at this point.
Segment 1035: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10012, Text: No, they’re happy. They have a job for another 20 years, right?
Segment 1036: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10015, Text: Oh, fear-mongering.
Segment 1037: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10016, Text: Yeah, yeah, yeah. I’m a believer in equal employment.
Segment 1038: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10020, Text: You’ve mentioned that, what’d you call it … Chem Machina?
Segment 1039: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10026, Text: Yeah.
Segment 1040: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10027, Text: Yeah. So, you’ve mentioned that a chemical brain is something you’re interested in creating, and that’s the way to get conscious AI soon. Can you explain what a chemical brain is?
Segment 1041: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10042, Text: I want to understand the mechanism of intelligence that’s gone through evolution, right? Because the way that intelligence was produced by evolution appears to be the following: origin of life, multi-cellularity, locomotion, senses. Once you can start to see things coming towards you, and you can remember the past and interrogate the present and imagine the future, you can do something amazing, right? And I think only in recent years did humans become Turing-complete, right?
Segment 1042: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10077, Text: Yeah.
Segment 1043: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10078, Text: Right? So, that Turing completeness kind of gave us another kick up. But our ability to process that information was produced in a wet brain. And I think that we do not have the correct hardware architectures to have the domain flexibility and the ability to integrate information, and I think intelligence also comes at a massive compromise of data. Right now we’re obsessing about getting more and more data, more and more processing, more and more tricks to get dopamine hits. So, when we look back on this going, “Oh yeah, that was really cool, because when I asked ChatGPT, it made me feel really happy and I got a hit from it.” But actually it just exposed how little intelligence I use in every moment, because I’m easily fooled.
Segment 1044: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10138, Text: So, what I would like to do is to say, “Well, hey, hang on. What is it about the brain?” So, the brain has this incredible connectivity, and it has the ability to … As I said earlier about my nephew, I went from “Bill” to “Billy” and he went, “All right, Leroy.” How did he make that leap? That he was able to basically without any training … I extended his name in a way that he doesn’t like. He wants to be called Bill. He went back and said, “You like to be called Lee? I’m going to call you Leroy.”
Segment 1045: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10169, Text: So, human beings have a brilliant ability, or intelligent beings appear to have a brilliant ability to integrate across all domains all at once, and to synthesize something which allows us to generate knowledge. And becoming Turing-complete on our own, although AIs are built and Turing-complete things, their thinking is not Turing-complete in that they are not able to build universal explanations. And that lack of universal explanation means that they’re just-
Segment 1046: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10200, Text: Lack of universal explanation means that they’re just inductivists. Inductivism doesn’t get you anywhere. It’s just basically a party trick. I think it’s in The Fabric Of Reality from David Deutsch where basically the farmer is feeding the chicken every day and the chicken’s getting fat and happy. And the chicken’s like, “I’m really happy every time the farmer comes in and feeds me.” And then one day the farmer comes in and instead of feeding the chicken, just rings its neck. And had the chicken had an alternative understanding of why the farmer was feeding it.
Segment 1047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10237, Text: It’s interesting though, because we don’t know what’s special about the human mind that’s able to come up with these kind of generalities. This universal theories of things. And we’ll come up with novelty. I can imagine… Because you gave an example about William and Leroy. I feel like an example like that we’ll be able to see in future versions of large language models. We’ll be really, really, really impressed by the humor, the insights, all of it. Because it’s fundamentally trained on all the incredible humor and insights that’s available out there on the internet. So we’ll be impressed. I think we’ll be impressed.
Segment 1048: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10282, Text: Oh, I’m impressed. I’m impressed.
Segment 1049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10285, Text: Increasingly so.
Segment 1050: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10286, Text: But we are mining the past.
Segment 1051: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10288, Text: Yes.
Segment 1052: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10288, Text: And what the human brain appears to be able to do is mine the future.
Segment 1053: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10291, Text: Yes. So novelty, it is interesting whether these large language models will ever be able to come up with something truly novel.
Segment 1054: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10301, Text: I can show on the back of a piece of paper why that’s impossible. And it’s like the problem is that… And again these are domain experts kind of bullshitting each other. The term generative, right. Average person say, oh, it’s no, no, no. Look, if I take the numbers between zero and 1000 and I train a model to pick out the prime numbers by giving all the prime numbers between zero and a thousand, it doesn’t know what prime number is. Occasionally if I can cheat a bit, it will start to guess.
Segment 1055: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10332, Text: It never will produce anything out with the dataset because you mine the past. The thing that I’m getting to is I think that actually current machine learning technologies might actually help reveal why time is fundamental. It’s like kind of insane. Because they tell you about what’s happened in the past, but they can never help you understand what’s happening in the future without training examples. Sure, if that thing happens again. So let’s think about what large language models are doing. We have all the internet as we know it, language, but also they’re doing something else. We having human beings correcting it all the time. Those models are being corrected,
Segment 1056: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10374, Text: Steered.
Segment 1057: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10376, Text: Corrected, modified, tweaked.
Segment 1058: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10381, Text: Well, yeah, but-
Segment 1059: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10382, Text: Cheating.
Segment 1060: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10384, Text: Well you could say the training on human data in the first place is cheating.
Segment 1061: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10388, Text: Well, human is in the loop. Sorry to interrupt.
Segment 1062: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10390, Text: Yes. So human is definitely in the loop, but it’s not just human is in the loop. A very large collection of humans is in the loop.
Segment 1063: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10390, Text: Look I totally-
Segment 1064: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10401, Text: And that could be… I mean to me it’s not intuitive that you said prime numbers, that the system can’t generate an algorithm. That the algorithm that can generate prime numbers or the algorithm that can tell you if a number is prime and so on. And generate algorithms that generate algorithms, that generate algorithms that start to look a lot like human reasoning.
Segment 1065: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10426, Text: I think again, we can show that on a piece of paper, that sure. I think you have to have… So this is the failure in epidemiology. I’m glad I even can say that word, let know what it means.
Segment 1066: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10439, Text: You said it multiple times.
Segment 1067: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10440, Text: I know. It’s like three times now.
Segment 1068: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10441, Text: Without failure. Quit while you’re ahead. Just don’t say it again because you did really well.
Segment 1069: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10447, Text: Thanks. But I think, so what is reasoning? So coming back to the chemical brain. If I could show the inner… Because I mean I’m never going to make an intelligence in ca machina. Because if you don’t have brain cells, they don’t have glial cells, they don’t have neurons. But if I can take a gel and engineer the gel to have it be a hybrid hardware for reprogramming, which I think I know how to do, I will able to process a lot more information and train models billions of times cheaper and use cross domain knowledge. And there’s certain techniques I think we can do. But there’s still missing, though the abilities that human beings have had to become true and complete. And so I guess the question to give back at you is like how do you tell the difference between trial and error and the generation of new knowledge?
Segment 1070: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10506, Text: I think the way you can do it is this, is that you come up with a theory, an explanation, inspiration comes from out, and then you then test that, and then you see that’s going towards the truth. And human beings are very good at doing that. And the transition between philosophy, mathematics, physics and natural sciences. And I think that we can see that. Where I get confused is why people misappropriate the term artificial intelligence to say, “Hey, there’s something else going on here.” Because I think you and I both agree, machine learning’s really good, it’s only going to get better. We’re going to get happier with the outcome. But why would you ever think the model is thinking or reasoning? Reasoning requires intention. And the intention, if the model isn’t reasoning, the intentions come from the prompter. And the intention has come from the person who programmed it to do it.
Segment 1071: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10568, Text: But don’t you think you can prompt it to have intention?Basically start with the initial conditions and get it going? Where currently large language models, ChatGPT only talks to you when you talk to it. There’s no reason why you can’t just start it talking.
Segment 1072: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10591, Text: But those initial conditions came from someone starting it.
Segment 1073: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10595, Text: Yes.
Segment 1074: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10595, Text: And that causal chain in there. So that intention comes from the outside. I think that there is something in that causal chain of intention that’s super important. I don’t disagree, we’re going to get to AGI. It’s a matter of when and what hardware. I think we’re not going to do it in this hardware and I think we’re unnecessarily fetishizing really cool outputs and dopamine hits. Because obviously that’s what people want to sell us.
Segment 1075: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10617, Text: Well, but there could be AGI is a loaded term. But there could be incredibly super impressive intelligence systems on the way to AGI. So these large language models, I mean if it appears conscious, if it appears super intelligent, who are we to say it’s not.
Segment 1076: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10641, Text: I agree, but the super intelligence I want, I want to be able to have a discussion with it about coming up with fundamental new ideas that generate knowledge. And if the superintelligent we generate can mine novel even from the future that I didn’t see in its training set in the past, I would agree that something really interesting is coming on. I’ll say that again. If the intelligence system, be it a human being, a Chatbot, something else, is able to produce something truly novel that I could not predict ,even having full audit trail from the past, then I’ll be sold.
Segment 1077: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10678, Text: Well, so we should be clear that it can currently produce things that are in a shallow sense novel. That are not in the training set. But you’re saying truly novel.
Segment 1078: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10691, Text: I think they are in the training set. I think everything it produces comes from a training set. There’s a difference between novelty and interpolation. We do not understand where these leaps come from yet. That is what intelligence is I would argue. Those leaps and some people say no, it’s actually just what will happen if you just do cross domain training and all that stuff. And that may be true. And I may be completely wrong. But right now the human mind is able to mine novelty in a way that artificial intelligence systems cannot. And this is why we still all have a job. And we’re still doing staff. And I used ChatGPT for a few weeks. Oh this is cool. And then what happened is it took me too much time to correct it. Then it got really good. And now they’ve done something to it. It’s not actually that good.
Segment 1079: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10738, Text: Yeah, right.
Segment 1080: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10739, Text: I don’t know what’s going on.
Segment 1081: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10740, Text: Censorship. Yeah, I mean that’s interesting. But it will push us humans to characterize novelty better. Characterize the novel, what is novel, what is truly novel, what’s the difference between novelty and interpolation.
Segment 1082: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10750, Text: I think that this is the thing that makes me most excited about these technologies, is they’re going to help me demonstrate to you that time is fundamental. And the unit future is bigger than the present. Which is why human beings are quite good at generating novelty because we have to expand our dataset. And to cope with unexpected things in our environment. Our environment throws them all at us. Again, we have to survive in that environment. And I mean, I never say never. I would be very interested in how we can get cross domain training cheaply in chemical systems. Because I’m a chemist and bray, the only sim thing I know of is a human brain. But maybe that’s just me being boring and predictable and not novel.
Segment 1083: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10794, Text: Yeah. You mentioned GPT for electron density. So a GPT like system for generating molecules that can bind to host automatically. I mean that’s interesting. I’s really interesting. Applying this same kind of transform mechanism.
Segment 1084: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10811, Text: I mean, my team, I try and do things that are non obvious but non obvious in certain areas. And one of the things I was always asking about in chemistry, people like to represent molecules as graphs and it’s quite difficult. It’s really hard if you’re doing AI and chemistry, you really want to basically have good representations. You can generate new molecules are interesting. And I was thinking, well molecules aren’t really graphs and they’re not continuously differentiable. Could I do something that was continuously differentiable? I was like, well, molecules are actually made up of electron density. So I got thinking and say, well, okay, could there be a way where we could just basically take a database of readily solved electron densities for millions of molecules? So we took the electron density for millions of molecules and just train the model to learn what electron density is.
Segment 1085: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10866, Text: And so what we built was a system that you literally could give it a, let’s say you could take a protein that has a particular active site or a cup with a certain hole in it. You pour noise into it and with A GPT you turn the noise into electron density. And then in this case it hallucinates, like all of them do. But then hallucinations are good because it means I don’t have to train on such a huge dataset, because these data sets are very expensive. How do you produce it? So go back a step. So you’ve got all these molecules in this dataset, but what you’ve literally done is a quantum mechanical calculation. We produce electron densities for each molecule. So you say, oh, this representation of this molecule has these electron densities associated with it, so you know what the representation is and you train the neural network to know what electron density is.
Segment 1086: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10914, Text: So then you give it an unknown pocket. You pour in noise and you say, right, produce me electron density, it produces electron density that doesn’t look ridiculous. And what we did in this case is we produce electron density that maximizes the electrostatic potential, so the stickiness, but minimizes what we call the steric hindrance. So the overlaps, so it’s repulsive. So make the perfect fit. And then we then use kind of like a ChatGPT type thing to turn that electron density into what’s called a smile. A smile string is a way of representing a molecule in letters. And then we can then-
Segment 1087: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10952, Text: So it just generates them then.
Segment 1088: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10954, Text: Just generates them. And then the other thing is then we bung that into the computer and then it just makes it.
Segment 1089: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10959, Text: Yeah, the computer being the thing that right… To generate-
Segment 1090: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10960, Text: The robot we’ve got that can basically just do chemistry. So we’ve kind of got this end-to-end drug discovery machine where you can say, “Oh, you want to bind to this active site, here you go.” I mean it is a bit leaky and things kind of break, but it is the proof of principle.
Segment 1091: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10976, Text: But were the hallucinations, are those still accurate?
Segment 1092: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=10981, Text: Well the hallucinations are really great in this case, because in the case of a large language model, the hallucinations just make everything up. It doesn’t just make everything up, but it gives you an output that you are plausibly comfortable with and thinks you’re doing probabilistically. The problem on these tron density models is it’s very expensive to solve a shredding equation going up to many heavy atoms and large molecules. And so we wondered if we trained the system on up to nine heavy atoms, whether it would go beyond nine and it did, It started to generate molecules for 12. No problem. They look pretty good. And I was like, well this hallucination I will take for free. Thank you very much.
Segment 1093: Speaker: , Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11022, Text: Because it just basically… This is a case where interpolation extrapolation worked relatively well. And we were able to generate the really good molecules. And then what we were able to do here is, and this is a really good point and what I was trying to say earlier, that we were able to generate new molecules, from the known set, that would bind to the host. So a new guest would bind. Were these truly novel? Not really because they were constrained by the host. Were they new to us? Yes. So I do, well understand… I can concede that machine learning systems, artificial intelligence systems can generate new entities, but how novel are they? It remains to be seen.
Segment 1094: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11072, Text: And how novel the things that humans generate is also difficult to quantify. They seem novel.
Segment 1095: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11080, Text: That’s what a lot of people say. So the way to really get to genuine novelty, and assembly theory shows you the way, is to have different causal chains overlap. And this really, really resonates with the time is fundamental argument. And if you are bringing together a couple of objects with different initial conditions coming together, when they interact, the more different their histories, the more novelty they generate in time going forward. And so it could be that genuine novelty is basically about mix it up a little. And the human brain is able to mix it up a little little, and all that stimulus comes from the environment. But all I think I’m saying is the universe is deterministic going back in time. Non-deterministic going forward in time. Because the universe is too big in the future to contain in the present. Therefore these collisions of known things generate unknown things, that then become part of your data set and don’t appear weird. That’s how we give ourselves comfort. The past looks consistent with this initial condition hypothesis, but actually we’re generating more and more novelty. And that’s how it works. Simple.
Segment 1096: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11158, Text: So it’s hard to quantify novelty looking backwards. I mean the present and the future at the novelty generators.
Segment 1097: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11165, Text: But I like this whole idea of mining novelty. I think it is going to reveal why the limitations of current AI is a bit like a printing press. Everyone thought that when the printing press came that writing books is going to be terrible, that you had evil spirits and all this. They were just books.
Segment 1098: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11186, Text: And same with AI. But I think just the scale you can achieve in terms of impact with AI systems is pretty nerve wracking.
Segment 1099: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11195, Text: But that’s what the big companies want you to think.
Segment 1100: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11199, Text: But not in terms of destroy all humans. But you can have major consequences in the way social media has had major consequences, both positive and negative. And so you have to think about it and worry about it. But yeah, people that fear monger…
Segment 1101: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11215, Text: My pet theory for this, you want to know?
Segment 1102: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11218, Text: Yeah.
Segment 1103: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11219, Text: Is I think that a lot… And maybe I’m being… And I really do respect a lot of the people out there who are trying to have discourse about the positive future. So open AI guys, meta guys and all this. What I wonder if they’re trying to cover up for the fact that social media has had a pretty disastrous effect at some level, and they’re just trying to say, “Oh yeah, we should do this.” Covering up for the fact that we have got some problems with teenagers, and Instagram, and Snapchat, and all this stuff, and maybe they’re just overreacting now. It’s like, “Oh yeah, sorry, we made the bubonic plate and gave it to you all and you’re all dying.” And “Oh yeah, but look at this over here it’s even worse.”
Segment 1104: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11260, Text: Yeah, there’s a little bit of that. But there’s also not enough celebration of the positive impact that all of these technologies have had. We tend to focus on the negative and tend to forget that. In part because it’s hard to measure. It is very hard to measure the positive impact social media had on the world.
Segment 1105: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11278, Text: Yeah, I agree. But what I worry about right now is I do care about the ethics of what we’re doing. And one of the reasons why I’m so open about the things we’re trying to do in the lab, make life look at intelligence, all this, so people say, what are the consequences of this? And you say, what are the consequences of not doing it? And I think that what worries me right now in the present is lack of authenticated users and authenticated data and-
Segment 1106: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11305, Text: Human users.
Segment 1107: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11306, Text: Yeah, human.
Segment 1108: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11308, Text: I still think that there will be AI agents that appear to be conscious, but they would have to be also authenticated and labeled as such. There’s too much value in that. Like friendships with AI systems. There’s too much meaningful human experiences to have with the AI systems that I just…
Segment 1109: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11328, Text: But that’s like a tool, right? It’s a bit like a meditation tool, right?
Segment 1110: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11330, Text: Sure.
Segment 1111: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11330, Text: Some people have a meditation tool, it makes them feel better. But I’m not sure you can ascribe sentience and legal rights to a chatbot that makes you feel less lonely.
Segment 1112: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11340, Text: Sentience, yes. I think legal rights, no. I think it’s the same. You can have a really deep, meaningful relationship with a dog.
Segment 1113: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11348, Text: Well the dog is sentient.
Segment 1114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11350, Text: Yes.
Segment 1115: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11352, Text: The chatbots right now, using the technology we use, it’s not going to be sentient.
Segment 1116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11356, Text: This is going to be a fun continued conversation on Twitter that I look forward to. Since you’ve had also from another place some debates that were inspired by the assembly theory paper, let me ask you about God. Is there any room for notions of God in assembly theory? Of God.
Segment 1117: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11382, Text: Yeah. I don’t know what God is a… I mean, so God exists in our mind created by selection. So the human beings have created the concept of God in the same way that human beings have created the concept of super intelligence.
Segment 1118: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11397, Text: Sure, but does it mean, does it not… It still could mean that that’s a projection from the real world where we’re just assigning words and concepts to a thing that is fundamental to the real world. That there is something out there that is a creative force underlying the universe.
Segment 1119: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11422, Text: I think the universe… There is a creative force in the universe, but I don’t think it’s sentient. So I do not understand the universe. So who am I to say that God doesn’t exist? I am an atheist, but I’m not an angry atheist. There’s some people I know that are angry atheists and say-
Segment 1120: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11449, Text: Cranky.
Segment 1121: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11450, Text: Say that religious people are stupid. I don’t think that’s the case. I have faith in some things. I mean when I was a kid I was like, I need to know what the charge of electron is. And I was like, I can’t measure the charge on electron. I just gave up and had faith. Okay, you know, resistors worked. So when it comes to… I want to know why the universe is growing in the future and what humanity is going to become. And I’ve seen that the acquisition of knowledge via the generation of novelty to produce technology has uniformly made humans’ lives better. I would love to continue that tradition.
Segment 1122: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11491, Text: You said that there’s that creative force. Do you think, just to think on that point, do you think there’s a creative force? Is there like a thing, like a driver that’s creating stuff?
Segment 1123: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11505, Text: Yeah, so I think that…
Segment 1124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11508, Text: And where? What is it? Can you describe it mathematically?
Segment 1125: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11511, Text: Well, I think selection. I think selection.
Segment 1126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11513, Text: Selection is the force.
Segment 1127: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11514, Text: Selection is the force in the universe. It creates novelty.
Segment 1128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11518, Text: So is selection somehow fundamental? Like what…
Segment 1129: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11523, Text: Yeah, I think persistence of objects that could decay into nothing through operations that maintain that structure. I mean, think about it. It’s amazing that things exist at all. That we’re just not a big commentorial mess.
Segment 1130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11537, Text: Yes.
Segment 1131: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11538, Text: So the fact that-
Segment 1132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11541, Text: And exist. A thing that exists persist in time.
Segment 1133: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11543, Text: Yeah. Let’s think, maybe the universe is actually in the present. The things… Everything that can exist in the present does exist.
Segment 1134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11559, Text: Well that would mean it’s deterministic, right?
Segment 1135: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11562, Text: I think the universes might. So the universe started super small. The past was deterministic, there wasn’t much going on. And it was able to mine mine, mine, mine, mine. And so the process is somehow generating universes basically… I’m trying to put this into words.
Segment 1136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11582, Text: Did you just say there’s no free will though?
Segment 1137: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11584, Text: No, I didn’t say that.
Segment 1138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11585, Text: As if-
Segment 1139: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11586, Text: Sorry, sorry, sorry.
Segment 1140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11586, Text: -it can exist.
Segment 1141: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11587, Text: I said there is free will. I’m saying that free will occurs at the boundary between the-
Segment 1142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11597, Text: The past and the future?
Segment 1143: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11599, Text: The past and the future.
Segment 1144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11600, Text: Yeah, I got you. But everything that can exist does exist.
Segment 1145: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11605, Text: So everything that’s possible to exist at this… So no, I’m really pulling this…
Segment 1146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11610, Text: There’s a lot of loaded words there. There’s a time element loaded into that statement.
Segment 1147: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11616, Text: I think that the universe is able to do what it can in the present, right?
Segment 1148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11620, Text: Yeah.
Segment 1149: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11620, Text: And then I think in the future there are other things that could be possible. We can imagine lots of things, but they don’t all happen.
Segment 1150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11625, Text: Sure.
Segment 1151: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11626, Text: So what-
Segment 1152: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11626, Text: So that’s where-
Segment 1153: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11627, Text: So that’s what I guess I’m getting to.
Segment 1154: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11629, Text: -you sneak in free will right there.
Segment 1155: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11630, Text: Yeah. So I guess what I’m saying is what exists is a convolution of the past with the present, and the free will going into the future.
Segment 1156: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11640, Text: Well, we could still imagine stuff. Right? We can imagine stuff that will never happen.
Segment 1157: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11644, Text: And it’s amazing force. Because this is the most important thing that we don’t understand. Is our imaginations can actually change the future in a tangible way. Which is what the initial conditions and physics cannot predict. Your imagination has a causal consequence in the future.
Segment 1158: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11665, Text: Isn’t that weird to you?
Segment 1159: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11666, Text: Yeah. It breaks the laws of physics as we know them right now.
Segment 1160: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11677, Text: So you think the imagination has a causal effect on the future?
Segment 1161: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11681, Text: Yeah.
Segment 1162: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11682, Text: But it does exist in there in the head.
Segment 1163: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11685, Text: It does, but-
Segment 1164: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11685, Text: There must be a lot of power in whatever’s going on. There could be a lot of power, whatever’s going on in there.
Segment 1165: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11690, Text: If we then go back to the initial conditions, and that is simply not possible that can happen. But if we go into a universe where we accept that there is a finite ability to represent numbers. And you have rounding… Well not rounding errors, you have sum… What happens, your ability to make decisions, imagine and do stuff is that that interface between the certain and the uncertain. It’s not as Yashar was saying to me, “Randomness goes and you just randomly do random stuff.” It is that you are set free a little on your trajectory. Free will is about being able to explore on this narrow trajectory, that allows you to build… You have a choice about what you build. Or that choice is you interacting with a future in the present.
Segment 1166: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11739, Text: What to you is most beautiful about this whole thing? The universe?
Segment 1167: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11746, Text: The fact it seems to be very undecided, very open. The fact that every time I think I’m getting towards an answer to a question, there are so many more questions that make the chase.
Segment 1168: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11763, Text: Do you hate that it’s going to be over at some point for you?
Segment 1169: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11766, Text: No. Well for me. I think if you think about it, is it over for Newton now? Newton has had causal consequences in the future. We discuss him all the time,
Segment 1170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11778, Text: His ideas, but not the person.
Segment 1171: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11781, Text: The person just had a lot of causal power when he was alive. But oh my God, one of the things I want to do is leave as many Easter eggs in the future when I’m gone to go, “Oh, that’s cool.”
Segment 1172: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11790, Text: Would you be very upset if somebody made a good large language model that’s fine tuned to Lee Cronin?
Segment 1173: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11797, Text: It would be quite boring. Because I mean, I…
Segment 1174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11800, Text: No novelty generation?
Segment 1175: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11802, Text: I mean if it’s a faithful representation of what I’ve done in my life, that’s great. That’s an interesting artifact. But I think the most interesting thing about knowing each other is we don’t know what we’re going to do next.
Segment 1176: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11814, Text: Sure. Sure.
Segment 1177: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11817, Text: I mean within some constraints I’ve got, I can predict some things about you. You can predict some things about me. But we can’t predict everything.
Segment 1178: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11824, Text: Everything.
Segment 1179: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11825, Text: And it’s because we can’t predict everything is why we’re exciting to come back and discuss and see. So yeah, I’m happy that it’ll be interesting that some things that I’ve done can be captured, but I’m pretty sure that my angle on mining novelty for the future will not be captured.
Segment 1180: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11848, Text: Yeah. Yeah. So that’s what life is, is just some novelty generation and then you’re done. Each one of us just generally a little bit. Or have the capacity to at least.
Segment 1181: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11863, Text: I think life is a selection produces life. And life affects a universe. Universes with life in them are materially, physically, fundamentally different than universes without life. And that’s super interesting. And I have no beginnings of understanding. I think maybe this is in a thousand years, there’ll be a new discipline. And the humans will be like, “Yeah, of course. This is how it all works.” Right?
Segment 1182: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11890, Text: In retrospect, it’ll all be obvious I think.
Segment 1183: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11893, Text: I think assembly theory is obvious, that’s why a lot of people got angry. They were like, “Oh my God, this is such nonsense.” And like, “Oh, actually it’s not quite.” But the writing’s really bad.
Segment 1184: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11905, Text: Well, I can’t wait to see where it evolves, Lee. And I am glad I get to exist in this universe with you. You’re a fascinating human. This is always a pleasure. I hope to talk to you many more times. And I’m a huge fan of just watching you create stuff in this world. And thank you for talking today.
Segment 1185: Speaker: Lee Cronin, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11924, Text: It’s a pleasure as always, Lex. Thanks for having me on.
Segment 1186: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=CGiDqhSdLHk&t=11927, Text: Thanks for listening to this conversation with Lee Cronin. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Carl Sagan. We can judge our progress by the courage of our questions, and the depth of our answers. Our willingness to embrace what is true rather than what feels good. Thank you for listening. And hope to see you next time.
Segment 1187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=0, Text: The following is a conversation with Lisa Randall, a theoretical physicist and cosmologist at Harvard. Her work involves improving our understanding of particle physics, supersymmetry, baryogenesis, cosmological inflation, and dark matter.
Segment 1188: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=15, Text: This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Lisa Randall.
Segment 1189: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=24, Text: One of the things you work on and write about is dark matter. We can’t see it, but there’s a lot of it in the universe. You also end one of your books with a Beatles song quote, “‘Got to be good-looking because he’s so hard to see.” What is dark matter? How should we think about it given that we can’t see it? How should we visualize it in our mind’s eye?
Segment 1190: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=47, Text: I think one of the really important things that physics teaches you is just our limitations, but also our abilities. The fact that we can deduce the existence of something that we don’t directly see is really a tribute to people that we can do that. It’s also something that tells you, you can’t overly rely on your direct senses. If you just relied on just what you see directly, you would miss so much of what’s happening in the world.
Segment 1191: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=75, Text: We can generalize this, but just for now to focus on dark matter, it’s something we know is there, and it’s not just one way we know it’s there. In my book, Dark Matter and the Dinosaurs, I talk about the many different ways. There’s eight or nine that we deduce not just the existence of dark matter, but how much is there, and they all agree.
Segment 1192: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=96, Text: Now, how do we know it’s there? Because of its gravitational force. Individually, a particle doesn’t have such a big gravitational force. In fact, gravity is an extremely weak force compared to other forces we know about in nature, but there’s a lot of dark matter out there. It carries a lot of energy. Five times the amount of energy as the matter. We know that’s in atoms, et cetera.
Segment 1193: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=120, Text: You can ask, how should we think about it? It’s just another form of matter that doesn’t interact with light, or at least as far as we know. It interacts gravitationally, it clumps, it forms galaxies, but it doesn’t interact with light, which means we just don’t see it. Most of our detection, before gravitational wave detectors, we only saw things because of their interactions with light in some sense.
Segment 1194: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=145, Text: In theory, it behaves just like any other matter, it just doesn’t interact with light.
Segment 1195: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=150, Text: When we say it interacts just like any other form of matter, we have to be careful because gravitationally, it interacts like other forms of matter, but it doesn’t experience electromagnetism, which is why it has a different distribution.
Segment 1196: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=164, Text: In our galaxy, it’s roughly spherical unless it has its own interactions, that’s another story. We know that it’s roughly spherical, whereas ordinary matter can radiate and clumps into a disk. That’s why we see the Milky Way disk. On large scales, in some sense, yes, all the matter is similar in some sense.
Segment 1197: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=186, Text: In fact, dark matter is in some sense more important because it can collapse more readily than ordinary matter because ordinary matter has radiative forces, which makes it hard to collapse on small scales. Actually it’s dark matter that drives galaxy formation and then ordinary matter comes along with it.
Segment 1198: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=210, Text: There’s also just more of it, and because there’s more of it can start collapsing sooner. That is to say the energy density in dark matter dominates over radiation earlier than you would if you just had an ordinary matter.
Segment 1199: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=223, Text: It’s part of the story of the origin of the galaxy, part of the story of the end of the galaxy, and part of the story of all the various interactions throughout.
Segment 1200: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=230, Text: Exactly. In my book, I make jokes about, it’s like when we think about a building, we think about the architect, we think about the high level, but we forget about all the workers that did all the grunt work. In fact, dark matter was really important in the formation of our universe, and we forget that sometimes.
Segment 1201: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=247, Text: That’s a metaphor on top of a metaphor. Okay. The unheard voices that do the actual work.
Segment 1202: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=256, Text: Exactly. No, but it is a metaphor, but it also captures something because the fact is we don’t directly see it, so we forget it’s there or we don’t understand it’s there, or we think it’s not. The fact that we don’t see it makes it no less legitimate, it just means that we have challenges in order to find out exactly what it is.
Segment 1203: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=275, Text: Yeah, but the things we cannot see that nevertheless have a gravitational interaction with the things we can’t see is at the layman level, it’s just mind-blowing.
Segment 1204: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=289, Text: It is and it isn’t because I think what it’s teaching us is that we’re human, the universe is what it is, and we’re trying to interact with that universe and discover what it is. We’ve discovered, amazing things.
Segment 1205: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=303, Text: In fact, I would say it’s more surprising that the matter that we know about is constitutes as big a fraction of the universe as it does. We’re limited, we’re human. The fact that we see 5% of the energy density of the universe, about one sixth of the energy density in matter, that’s remarkable. Why should that be? Anything could be out there, yet the universe that we see is a significant fraction.
Segment 1206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=330, Text: Yeah, but a lot of our intuition, I think operates using visualizations in the mind.
Segment 1207: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=336, Text: That’s absolutely true. Certainly writing books, I realized also how many of our words are based on how we see the world, and that’s true. That’s actually one of the fantastic things about physics is that it teaches you how to go beyond your immediate intuition to develop intuitions that apply at different distances, different scales, different ways of thinking about things.
Segment 1208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=357, Text: Yeah. How do you anthropomorphize dark matter?
Segment 1209: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=361, Text: I just did, I think. I made it the grunt workers.
Segment 1210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=364, Text: Oh yeah, that’s good. You did. That’s why you get paid the big bucks and write the great books. Okay, you also write in that book about dark matter, having to do something with the extinction events, the extinction of the dinosaurs, which is a fascinating presentation of how everything is connected.
Segment 1211: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=388, Text: I guess the disturbances from the dark matter, they create gravitational disturbances in the Oort Cloud at the edge of our solar system, and then that increases the rate of asteroids hitting earth.
Segment 1212: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=402, Text: I want to be really clear, this was a speculative theory.
Segment 1213: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=404, Text: I love it, though.
Segment 1214: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=408, Text: I liked it too. We still don’t know for sure, but what we liked about it… Let me take a step back. We usually assume that dark matter, we being physicists, that it’s just one thing. It’s just basically non-interacting aside from gravity or very weakly interacting matter.
Segment 1215: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=431, Text: Again, we have to get outside this mindset of just humans and ask what else could be there. What we suggested is that there’s a fraction of dark matter, not all the dark matter, but some of the dark matter, maybe it has interactions of its own just the same way in our universe, we have lots of different types of matter. We have nuclei, we have electrons, we have neutrons, we have forces.
Segment 1216: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=455, Text: It’s not a simple model, the standard model, but it does have some basic ingredients, so maybe dark matter also has some interesting structure to it. Maybe there’s some small fraction. The interesting thing is that if some of the dark matter does radiate, and I like to call it dark light because it’s light that we don’t see, but dark matter would see. It could radiate that and then it could perhaps collapse into a disk the same way ordinary matter collapsed into the Milky Way disk.
Segment 1217: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=486, Text: It’s not all the dark matter, it’s a fraction, but it could conceivably be a very thin disk of dark matter, thin, dense disk of dark matter. The question is do these exist? People have done studies now to think about whether they can find them. It’s an interesting target, it’s something you can measure. By measuring the positions and velocities of stars, you can find out what the structure of the Milky Way is, but the fun proposal was that the solar system orbits around the galaxy.
Segment 1218: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=516, Text: As it does so, it goes a little bit up and down kind of horses on a carousel. The suggestion was every time it goes through, you have an enhanced probability that you would dislodge something from the edge of the solar system in something called the Oort Cloud. The idea was that at those times, you’re more likely to have these cataclysmic events such as the amazing one that actually caused the last extinction that we know of for sure.
Segment 1219: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=541, Text: It wasn’t so amazing for the dinosaurs.
Segment 1220: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=544, Text: Or for two thirds of the species on the planet.
Segment 1221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=546, Text: But it gets amazing for humans. It wouldn’t be-
Segment 1222: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=548, Text: What really is amazing… I talk about this in Dark Matter and the Dinosaurs. It is just an amazing scientific story because it really is one of the real stories that combine together different fields of science. Geologists at the time or people thought that things happen slowly and this would be a cataclysmic event.
Segment 1223: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=567, Text: Also, I have to say if you think about it, it sounds like a story a five-year-old would make up. Maybe the dinosaurs were killed by some big rock that came and hit the earth, but then there really was a scientific story behind it. That’s also why I like the dark disk because there’s a scientific story behind it. As far-fetched as it might sound, you could actually go and look for the experimental consequences, for the observational consequences to test whether it’s true.
Segment 1224: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=591, Text: I wish you could know high-resolution details of where that asteroid came from, where in the Oort Cloud, why it happened, is it in fact because of dark matter? Just the full tracing back to the origin of the universe because humans seem to be somewhat special. It seems like so many fascinating events at all scales of physics had to happen for [inaudible 00:10:17].
Segment 1225: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=616, Text: I’m really, really glad you mentioned that because actually that was one of the main points of my book, Dark Matter and the Dinosaurs. One of the reasons I wrote it was because I really think we are abusing the planet, we’re changing the planet way too quickly. Just like anything else, when you alter things, it’s good to think about the history of what it took to get here.
Segment 1226: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=634, Text: As you point out, it took many operations on many different scales. We had to have the formation of structure, the formation of galaxies, the formation of the solar system, the formation of our planet, the formation of humans. There’s so many steps that go into this. Humans in some part were the result of the fact that this big object hit the earth, made the dinosaurs go extinct, and mammals developed. It is an incredible story and yes, something else might come of it, but it won’t be us if we mess with it too much.
Segment 1227: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=665, Text: But it is on a grand scale, earth is a pretty resilient system. Can you just clarify, just fascinating, the shape of things. The shape of the Milky Way’s… Of the observable stuff is mostly flat. You said dark matter tends to be spherical, but a subset of that might be a flat disk.
Segment 1228: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=691, Text: You want to hear about the shape of things.
Segment 1229: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=694, Text: Yes, please.
Segment 1230: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=696, Text: Structure formed early on, and now our structure that we live in is… We know about the Milky Way galaxy. The Milky Way galaxy has the disk you can see in a dry dark place, that’s where stars and light is, but you can also measure in some ways the dark matter. We believe that dark matter is more or less spherically distributed. Like we said, there’s a lot of it, not necessarily in the disk, but just because it’s a sphere, there’s a lot of it sitting there.
Segment 1231: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=731, Text: The reason it doesn’t collapse as far as we know is that it can’t radiate the same way. Because it can radiate ordinary matter collapses, and this actually, because of conservation of angular momentum, it stays a disk and it doesn’t just collapse to the center. Our suggestion was that maybe there are some components of dark matter that also radiate.
Segment 1232: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=751, Text: Like I said, that’s far from proven. People have looked for a disk, they see some evidence of some disks of certain densities, but these are all questions that are worth asking. Basically if we can figure it out from existing measurements, why not try?
Segment 1233: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=764, Text: Okay, so not all dark matter is made the same.
Segment 1234: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=768, Text: That’s a possibility. We actually don’t know what dark matter is in the first place, we don’t know what most of it is, we don’t know what a fraction is. It’s hard to measure. Why is it hard to measure for exactly the reason you said earlier, we don’t see it. We want to think of possibilities for what it can be, especially if those give rise to some observational consequences. It’s a tough game because it’s not something that’s just there for the taking. You have to think about what it could be and how you might find it.
Segment 1235: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=796, Text: The way you detect it is gravitational effects on things we can see.
Segment 1236: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=802, Text: That would be the way you detect the type of dark matter. I’ve been talking about people have suggestions for other forms of dark matter. They could be particles called axions, they could be other types of particles, and then there are different ways of detecting it.
Segment 1237: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=814, Text: The most popular candidate for dark matter probably until pretty recently because they haven’t found it, is something called WIMPs, Weakly Interacting Massive Particles, particles that have mass about the same as the Higgs boson mass, and it turns out then you would get about the right density of dark matter.
Segment 1238: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=832, Text: People really like that, of course, because it is connected to the standard model, the particles that we know about, and if it’s connected to that, we have a better chance of actually seeing it. Fortunately or unfortunately, it’s also a better chance that you can rule it out because you can look for it. So far, no one has found it. We’re still looking for
Segment 1239: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=848, Text: Is that one of the hopes of the Large Hadron Collider?
Segment 1240: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=851, Text: That was originally one of the hopes of Large Hadron Collider. I’d say at this point, it would be very unlikely given what they’ve already accomplished, but there are these underground detectors, xenon detectors that look for dark matter coming in, and they are going to try to achieve a much stronger bound than exists today.
Segment 1241: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=875, Text: Just to take that tangent, looking back now, what’s the biggest, to you, insight to humanity that the LHC has been able to provide?
Segment 1242: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=887, Text: It’s interesting. It’s both a major victory. The Higgs boson was proposed 50 years ago, and it was discovered. The Higgs mechanism seemed to be the only way to explain elementary particle masses and it was right so on the one hand, it was a major victory. On the other hand, I’ve been in physics long enough to know it was also a cautionary tale in some sense because at the time I started out in physics, we had proposed something in the United States called the Superconducting Supercollider.
Segment 1243: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=915, Text: A lot of physicists, I’ll say particularly in Europe, but I’d say a lot of physicists were saying when that the Large Hadron Collider would have the energy reach necessary to discover what underlies the standard model. We don’t want to just discover the standard model, we want to know what the next step is.
Segment 1244: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=931, Text: I think here people were more cautious about that. They want to have a more comprehensive search that could get to higher energies, more events so that we could really more definitively rule it out. In that case, many people thought they knew what would be there. It happened to be a theory called supersymmetry. A lot of physicists thought it would be supersymmetry.
Segment 1245: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=951, Text: It’s one of the many factors I think that went into the fact that the Large Hadron Collider became the only machine in town, and the Superconducting Supercollider would’ve just been a much… If it had really had achieved what it was supposed to, would’ve been a much more robust test of the space.
Segment 1246: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=967, Text: I’d say for humanity, it’s both a tribute to the ability of discovery and the ability of really believing in things so that you have the confidence to go look for them, but it’s also a cautionary tale that you don’t want to assume things before they’ve been actually found. You want to believe in your theories, but you also want to question them at the same time in ways that you’re more likely to discover the truth.
Segment 1247: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=992, Text: It’s also an illustration of grand engineering efforts that humanity can take on and maybe a lesson that you could go even bigger.
Segment 1248: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1003, Text: I’m really glad you said that though too, because that’s absolutely true. It really is an impressive… It’s impressive in so many ways. It’s impressive technologically, it’s impressive at engineering level.
Segment 1249: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1015, Text: It’s also impressive that so many countries work together to do this. It wasn’t just one country. It was also impressive in that it was a long-term project that people committed to and made it happen. It is a demonstration that when people set their minds to things and they commit to it, that they can do something amazing.
Segment 1250: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1038, Text: Also in the United States, maybe a lesson that bureaucracy can slow things down to [inaudible 00:17:24].
Segment 1251: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1044, Text: Bureaucracy and politics.
Segment 1252: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1046, Text: Politics.
Segment 1253: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1047, Text: And economics. Many things can make them faster and make them slower.
Segment 1254: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1052, Text: Science is the way to make progress, politics is the way to slow that progress down. And here we are.
Segment 1255: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1059, Text: I don’t want to overstate that because without politics, the [inaudible 00:17:42] wouldn’t happen either.
Segment 1256: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1063, Text: You need broccoli.
Segment 1257: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1069, Text: Sometimes I do think… You’re not asking this question, but sometimes I do think when I think about some of these conflicts, sometimes it’s just good to have a project that people work on together. There were some efforts to do that in science too, to have Palestinians and Israelis work together, a project called Sesame. I think it’s not a bad idea when you can do that, when you can get… Forget the politics and just focus on some particular project. Sometimes that can work.
Segment 1258: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1105, Text: Some kind of forcing function, some kind of deadline that gets people to sit in a room together and you’re working on a thing. As part of that, you realize the common humanity, that you all have the same concerns, the same hopes, the same fears, that you are all human. That’s an accidental side effect of working together on a thing.
Segment 1259: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1125, Text: That’s absolutely true. It’s one of the reasons CERN was formed actually. It was post-World War II, and a lot of European physicists had actually left Europe and they wanted to see Europeans work together and rebuild, and it worked. They did. It’s true, I often think that, that one of the major problems is we just don’t meet enough people so that everyone… When they seem like the other, it’s more easy to forget their humanity. I think it is important to have these connections.
Segment 1260: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1156, Text: Given the complexity, all cosmological scales involved here that led to the extinction of the dinosaurs, when you look out at the future of earth, do you worry about future extinction events?
Segment 1261: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1169, Text: I do think that we might be in the middle of an extinction right now if you define it by the number of species that are getting killed off. It’s subtle, but it’s a complex system. The way things respond to events is sometimes things evolve, sometimes animals just move to another place. The way we’ve developed the earth, it’s very hard for species just to move somewhere else.
Segment 1262: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1194, Text: We’re seeing that with people now, too. I know people are worried just about AI taking over, and that’s a totally different story. We just don’t think about the future very much. We think about what we’re doing now, and we certainly don’t think enough about all the animals that we’re destroying, all the things that are precursors to humans that we rely on.
Segment 1263: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1214, Text: It’s interesting to think whether the things that threaten us is the stuff we see that’s happening gradually or the stuff we don’t really see that’s going to happen all of a sudden. I sometimes think about what should we be worried about? It seems like with the asteroids or nuclear war, it could be stuff that just happens one day. When I say one day meaning over a span of a few days or a few months, but not on a scale of decades and centuries. We sometimes mostly talk about stuff that’s happening gradually, but we can be really surprised.
Segment 1264: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1257, Text: It’s actually really interesting. That was actually one of the reasons it took a while to determine what it was that it caused the last extinction because people did think at the time, many people thought that things were more gradual, and the idea of extinction was actually a novel concept at some point.
Segment 1265: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1274, Text: These aren’t predictable events necessarily. They’re only predictable on a grand scale, but sometimes they are. I think people were pretty aware that nuclear weapons were dangerous. I’m not sure people are as aware now as they were say, 20 or 30 years ago, and that certainly worries me. I have to say I was not as worried about AI as other people, but now I understand. It’s more that as soon as you create things that we lose control over, it’s scary.
Segment 1266: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1310, Text: The other thing that we’re learning from the events today is that it takes a few bad actors. It takes everyone to make things work well, it takes not that many things to make things go wrong. The issue with disease, we can find out what causes a disease, but to make things better is not necessarily that simple. Sometimes it is. But for things to be healthy, a lot of things have to work. For things to go wrong, only one thing has to go wrong. It’s amazing that we do it.
Segment 1267: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1339, Text: The same is true for democracy. For democracy to work, a lot of people have to believe in it. A few bad actors can destroy things sometimes. A lot of the things that we really rely on are delicate equilibrium situations. There is some robustness in the systems, we try to build in robustness, but a few extreme events can sometimes alter things. I think that’s what people are scared of today in many ways. They’re scared of it for democracy, they’re scared of it for peace, they’re scared of it for AI.
Segment 1268: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1371, Text: I think they’re not as scared as they should be about nuclear weapons, to be honest. I think that’s more serious danger than people realize. I think people are a little bit more scared about pandemics than they were before, but I still say they’re not super scared about it. So you’re right, there are these major events that can happen and we are setting things up so that they might happen, and we should be thinking about them. The question is who should be thinking about them? How should we be thinking about them? How do you make things happen on a global scale, because that’s really what we need.
Segment 1269: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1403, Text: It certainly shouldn’t be a source of division, it should be a source of grand collaboration probably.
Segment 1270: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1409, Text: Wouldn’t that be nice?
Segment 1271: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1410, Text: Yeah. I just wonder what it’d be like to be a dinosaur. It must have been beautiful to look at that asteroid enter the atmosphere. Until everything…. Man, that would be one of the things I would travel back in time to just to watch it.
Segment 1272: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1430, Text: That’s also one of the things that I think you probably could do with virtual reality. I don’t think you have to be there and get extinct.
Segment 1273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1434, Text: To just experience it.
Segment 1274: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1435, Text: I think there’s something… It’s an event. You’re just watching. You’re not doing anything, you’re just looking at it, so maybe you could just recreate it.
Segment 1275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1441, Text: I actually heard that there’s a nuclear weapon explosion experience in virtual reality that’s good to remind you about what it would feel like.
Segment 1276: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1454, Text: I have to say, I got an award from the Museum of Nuclear History and Technology in the Southwest, and I went to visit the museum, which turned out to be mostly a museum of nuclear weapons. The scary thing is that they look really cool.
Segment 1277: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1470, Text: It’s true that you have that, yes, this is scary, but you also have, this is cool feeling and I think we have to get around that because I think that yes, you can be in that, but I’m not sure that’s going to make people scared. Have they actually asked afterwards, are you more or less scared?
Segment 1278: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1490, Text: That’s a really good point. That’s a good summary of just humanity in general. We’re attracted to creating cool stuff, even though it can be dangerous.
Segment 1279: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1501, Text: Actually, that was the really interesting thing about visiting that museum, actually. It was very nice because I had a tour from people who had been working there in the Cold War and actually one or two people from the Manhattan Project. It was a very cool tour. You just realize just how just the thing itself gets you so excited.
Segment 1280: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1516, Text: I think that’s something sometimes these movies miss, just the thing itself. You’re not thinking about the overall consequences. In some ways it was like the early Silicon Valley. People were just thinking what if we did this? What if we did that? Not keeping track of what the peripheral consequences are. You definitely see that happening with AI now. I think that was the moral of the battle that just happened, that it’s just full speed ahead.
Segment 1281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1543, Text: Which gives me a really great transition to another quote in your book. You write about the experience of facing the sublime in physics, and you quote Rainer Rilke. “For beauty is nothing but the beginning of terror, which we are still just able to endure, and we’re so odd because it’s serenely disdains to annihilate us.” It’s pretty intense. It I think applies to nuclear weapons.
Segment 1282: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1574, Text: At a more mundane, perhaps level, I think it applies… It’s really interesting. One of the things that I found when I wrote these books is some people love certainty. Scientists, many revel in uncertainty. It’s not that you want to be uncertain, you want to solve it, but you’re at this edge where it’s really frustrating because you don’t really want to not know the answer, but of course, if you knew the answer, it would be done.
Segment 1283: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1601, Text: You’re always at this edge where you’re trying to sort things out and there is something scary. You don’t know if there’s going to be a solution, you don’t know if you’re going to find it. It’s not something that can destroy the earth, it’s just something that you do on your individual level. But then of course there are much bigger things like the ones you’re talking about where they could actually be dangerous. The stuff I do, I just want to be clear, I’m doing theoretical physics. Not very dangerous, but sometimes things end up having bigger consequences than you think.
Segment 1284: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1633, Text: Dangerous in a very pragmatic sense. Isn’t it still in part terrifying when you think of just the size of things like the size of dark matter, the power of this thing in terms of its potential gravitational effects, just cosmological objects of a black hole at the center of our galaxy.
Segment 1285: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1656, Text: This might be why I’m a physicist or why I differ from other people because I’m not such a big fan of humanity in some ways. Some ways I am, but the idea that we were everything would be really boring to me. I love the idea that there’s so much more out there, that there’s a bigger universe and there’s lots to discover and that we’re not all there is. Wouldn’t it be disappointing if we were all there is?
Segment 1286: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1677, Text: Yeah, and the full diversity of other stuff is pretty interesting.
Segment 1287: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1684, Text: We have no idea how much there is. We know what we can observe so far, so the idea that there’s other stuff out there that we yet have to figure out, it’s exciting.
Segment 1288: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1693, Text: Let me ask you an out there question. If you think of humans on earth, life on earth as this pocket of complexity that emerged and there’s a bunch of conditions that came to be, and there’s Darwinian evolution and however life originated, do you think it’s possible there’s some pockets of complexity of that sort inside dark matter that we can’t see?
Segment 1289: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1722, Text: That’s possible.
Segment 1290: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1727, Text: Chemistry and biology evolving in different ways.
Segment 1291: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1729, Text: That’s one of the reasons we suggest… It’s not the reason, but it would be true if there were the type of interactions we’d suggest, it would need more complex ones. We don’t know. I will say that the conditions that give rise to life and complexity, they’re complex, they’re unlikely. It’s not like there’s great odds that would happen, but there’s no reason to know that it doesn’t happen. It’s worth investigating are there other forces that exist in the dark matter sector? That’s exactly-
Segment 1292: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1760, Text: So the dark matter sector doesn’t have all the forces of the standard model of physics?
Segment 1293: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1766, Text: Right. As far as we know, it doesn’t have any. It might have it at some low level, but it could have its own forces, just like the dark matter might not experience our light. Maybe it has its light that we don’t experience.
Segment 1294: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1778, Text: So there could be other kinds of forces.
Segment 1295: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1781, Text: There could be other kinds of forces even within our sector that are too weak for us to have discovered so far or that exist at different scales than we know about. We detect what interacts strongly enough with our detectors to detect. It’s worth asking, and that’s one of the reasons we build big colliders to see are there other forces, other particles that exist say, at higher energies, at shorter distance scales than we’ve explored so far. It’s not just in the dark matter sector. Even in our sector, there could be a whole bunch of stuff we don’t yet know.
Segment 1296: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1817, Text: Maybe let’s zoom out and look at the standard model of particle physics. How does dark matter fit into it? First of all, what is it? Can you explain what the standard model is?
Segment 1297: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1828, Text: The standard model of particle physics is basically it tells us about nature’s most basic elements and their interactions. It’s the substructure as far as we understand it. If you look at atoms, we know they have nuclei and electrons, nuclei have protons and neutrons in them, protons and neutrons have particles called quarks that are held together by something called the strong force.
Segment 1298: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1854, Text: They interact through the strong force, the strong nuclear force. There’s something called the weak nuclear force and electromagnetism. Basically, all those particles and their interactions describe many, many things we understand. That’s the standard model. We now know about the Higgs boson, which is associated with how elementary particles get their mass. That piece of the puzzle has also been completed.
Segment 1299: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1880, Text: We also know that there are a weird array of masses of elementary particles. There’s not just the up and down quark, but there are heavier versions of the up and down quark. Charm and strange, top and bottom. There’s not just the electron, there’s a muon and a tau. There are particles called neutrinos, which are under intense study now, which are partnered with the leptons through the weak interactions.
Segment 1300: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1902, Text: We really do know these basic elements and we know the forces. When we’re doing particle physics experiments, we can usually even ignore gravity except in exceptional cases that we can talk about. Those are the basic elements in their interactions.
Segment 1301: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1918, Text: Dark matter stands outside that, it’s not interacting through those forces. When we look at the world around us, we don’t usually see the effects of dark matter. It’s because there’s so much of it that we do and it doesn’t have those forces that we know about. The standard model has worked spectacularly well. It’s been tested to a high degree of precision. People are still testing it.
Segment 1302: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1940, Text: One of the things we do as physicists is we actually want it to break down at some level, we’re looking for the precision measurement or the energy or whatever it will take where the standard model is no longer working. Not that it’s not working approximately, but we’re looking for the deviations. Those deviations are critical because they can tell us what underlies the standard model, which is what we really want to see next.
Segment 1303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1965, Text: Where can you find the places where the standard model breaks down? What are the places you can see those tiny little deviations?
Segment 1304: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1973, Text: We don’t know yet, but we know the kinds of things you wouldn’t want to look for. One obvious place to look is at higher energy. We’re looking at the Large Hadron Collider, but we’d love to go beyond that. Higher energy means shorter distances and it means things that we just couldn’t produce before. E=mc², so if you have a heavy particle and you don’t have enough energy to make it, you’ll never see it. That’s one place.
Segment 1305: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=1997, Text: The other place is precision measurements. The standard model has been tested exquisitely, so if it’s been tested 1%, you want to look at a 10th of a percent. There are some processes that we know shouldn’t even happen at all in the standard model or happen at very suppressed level, and those are other things that we look for. All of those things could indicate there’s something beyond what we know about, which of course would be very exciting.
Segment 1306: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2022, Text: When you just step back and look at the standard model, the quarks and all the different particles and neutrinos, isn’t it wild how this little system came to be and underpins everything we see?
Segment 1307: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2039, Text: Absolutely. That’s why we’d like to understand it better. We want to know is it part of some bigger sector? Why are these particles… Why do they have the masses they do? Why is the Higgs boson so light compared to the mass that could have had, which we might’ve even expected based on the principles of special relativity and quantum mechanics. That’s a really big question. Why are they what they are?
Segment 1308: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2061, Text: And they originate, there’s some mechanism that created the whole thing?
Segment 1309: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2064, Text: That’s one of the things we’re trying to study. Why is it what it is?
Segment 1310: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2069, Text: Even just the mechanism that creates stuff, the way a human being is created from a single cell. It’s like embryogenesis, the whole thing, you build up this thing. All of it, this whole thing comes to be from just like a [inaudible 00:34:47].
Segment 1311: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2086, Text: Don’t forget it is interacting with the environment.
Segment 1312: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2089, Text: For sure. Okay, right, right, right.
Segment 1313: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2091, Text: It’s important.
Segment 1314: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2093, Text: That’s a really good question is how much of it is the environment? Is it just the environment acting on a set of constraints? How much of it is just the information in the DNA or any information? How much is it in the initial conditions of the universe versus some other thing acting on it?
Segment 1315: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2114, Text: These are big questions. These are big questions in pretty much every field. For the universe, we do consider it… It’s everything there is by definition. But people now think about it. Is it one of many universes? Of course it’s a misnomer, but could there be other places where there are self-contained gravitational systems that we don’t even interact with? Those are really important questions, and the only way we’re going to answer them is we go back as far as we can. We try to think theoretically, and we try to think about observational consequences. That’s all we can do.
Segment 1316: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2149, Text: One interesting way to explore the standard model is to look at your fun, nuanced disagreement with Carlo Rovelli. When you talked about him writing in his book, “Electrons don’t always exist. They exist when they interact. They materialize in a place when they collide with something else.” You wrote that… I’ll just read the whole thing because it’s interesting.
Segment 1317: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2172, Text: “Stocks may not achieve a precise value until they’re traded, but that doesn’t mean we can’t approximate their worth until they change hands. Similarly, electrons might not have definite properties, but they do exist. It’s true that the electron doesn’t exist as a classical object with definite position until the position is measured. But something was there – which physicists use a wave function to describe.” It’s a fascinating nuanced disagreement. Do electrons always exist or not? Does a tree fall in the forest if nobody’s there to see it?
Segment 1318: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2208, Text: I like to think of the universe as being out there, whether or not… It would be really weird if the only time things came into existence was when I saw them or I measured them.
Segment 1319: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2217, Text: There’s a lot of weird stuff in the works.
Segment 1320: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2218, Text: I could believe that the Middle East doesn’t exist because I’m not there now. That would be kind of ridiculous, I think we would all agree on that. I think there’s only so much that we can attribute to our own powers of seeing. The whole system doesn’t come into being because I’m measuring it. What is weird, and this isn’t even a disagreement about the standard model, this is a disagreement about how you interpret quantum mechanics.
Segment 1321: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2242, Text: I would say that those wave functions are real. One of the things that don’t forget that particle physics does that quantum field theory says is that electrons can be created and destroyed. It’s not that every electron has to be in the universe. That’s what happens at colliders, particles get created and destroyed, but that doesn’t mean that if I have electron in an atom, it’s not there. It’s certainly there, and we know about it. Its charge is there.
Segment 1322: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2267, Text: Physics is a kind of way to see the world. At the bottom, what’s the bottom turtle? Do you have a sense that there’s a bottom reality that we’re trying to approximate with physics?
Segment 1323: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2281, Text: I think we always have in our head maybe that we’d like to find that, but I have to… I might not seem so, but I think I’m more humble than a lot of physicists. I’m not sure that we’re ever going to get to that bottom level, but I do think we’re going to keep penetrating different layers and get further.
Segment 1324: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2296, Text: I just wonder how far away we are.
Segment 1325: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2300, Text: We all wonder that. What’s even the measure of how far away we are. One way you can measure it is just by our everyday lives. In terms of our everyday lives, we’ve measured everything. In terms of what underlies it. There’s a lot more to see. Part of it has to do with how far we think we can go. It might be that the nature of reality changes so much that even these terms are different. Maybe the notion of distance itself might break down at some point.
Segment 1326: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2329, Text: Also to push back on the we’ve measured everything, maybe there’s stuff we haven’t even considered is measurable. For example, consciousness. There might be stuff, just like you said, forces unseen, undetected.
Segment 1327: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2343, Text: It’s an interesting thing, and this is often a confusion that happens. There’s the fundamental stuff underlying it, and then there’s the higher levels, what we’ll call an effective theory at some level. We’re not always working… When I throw a ball, I don’t tell you where every atom is. I tell you there’s a ball.
Segment 1328: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2362, Text: There might be different layers of reality that are built in terms of the matter that we know about in terms of the stuff we know about that. When I say we’ve measured everything, I say that with a grain of salt. I mean we’ve measured everything about the standard model. There’s lots of phenomena that we don’t understand, but often there are complex phenomena that will be given in terms of the fundamental ingredients that we know about.
Segment 1329: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2387, Text: That is an interesting question because yes, there’s phenomena that are at the higher level of abstractions that emerge, but maybe with consciousness, there is far out people that think that consciousness is panpsychus, that there’s going to be almost like a fundamental force of physics. That’s consciousness that permeates all that matter.
Segment 1330: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2410, Text: Usually when you have a crazy… Sorry, when you have a far out theory, the thing you do is you test all the possibilities within the constructs that exist. You don’t just jump to the most far out possibility. You can do that, but then to see if it’s true, you either have to find evidence of it or you have to show that it’s not possible without that, and we’re very far from that.
Segment 1331: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2432, Text: I think one of the criticisms of your theory on the dinosaurs was that it requires, if I remember correctly, for dark matter to be weirder than it already is. I think you had a clever response to that. Can you remind…
Segment 1332: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2446, Text: I’m not sure I remember what I said then, but we have no idea how weird dark matter is. It’s based on everyone thinking they know what dark matter is. Weirder than it already is, it’s not already anything. We don’t know what it is, so there’s no normalization here.
Segment 1333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2459, Text: Do we know if dark matter varies in density?
Segment 1334: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2465, Text: It just certainly does in the universe, just like… For example, there’s more dark matter in galaxies than there’s between galaxies. It clumps. It’s matter, so it’s distributed like matter. It is matter.
Segment 1335: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2478, Text: It does clump, but the full details of how it clumps and the complexity of the clumping…
Segment 1336: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2485, Text: It’s understood pretty well. People do simulations… Where people are always looking for things, including us as particle physics, it’s at small scales, are the deviations on small scales so that indicating other interactions or other processes or interactions with baryons. That is to say normal matter that we don’t understand. But on large scales, we have a pretty good understanding of dark matter distribution.
Segment 1337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2510, Text: You were part of a recent debate on can science uncover reality. Let me ask you this question then, what do you think is the limits of science?
Segment 1338: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2520, Text: I’m smart enough to know that I have no idea. Also it’s not even clear what science means because there’s the science that we do, which is particle physics. We try to find fundamental things and figure out what their effects are. There’s science like biology where at a higher level, the kind of questions you ask are different, the kind of measurements are different.
Segment 1339: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2541, Text: The kind of science that’s going to happen in the more numerical age or even AI, what does it mean to answer a question? Does it mean that we can predict it? Does it mean that we can reproduce it? I think we’re coming up against the definition of what we mean by science as human beings. In terms of the science that we can do, I don’t think we’ll know it until we get there. We’re trying to solve hard problems and we’ve made progress.
Segment 1340: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2570, Text: If you think of how much science has advanced in the last century or century and a half, it’s incredible. We didn’t even know the universe was expanding at the beginning of the 20th century. We didn’t know about quantum mechanics at the beginning of the century, we didn’t know about special relativity. That’s a lot in a relatively short time, depending on how you think of time. I think it would be premature to say we know limitations.
Segment 1341: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2594, Text: At various points throughout the history, we thought we solved everything or at least various people declared-
Segment 1342: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2600, Text: [inaudible 00:43:20] various people. Exactly.
Segment 1343: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2601, Text: Declared that we’ve solved everything. This also a good place to… Maybe could you describe the difference between top-down and bottom-up approaches to theoretical physics that you talked about in the book?
Segment 1344: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2613, Text: You could try to jump in and say I have a theory that I think is so perfect that I can predict everything from it or at least predict some salient features from it.
Segment 1345: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2626, Text: Mm-hmm. That’s top-down.
Segment 1346: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2627, Text: That would be a top-down. Bottom-up is more like the questions we just asked. Why are masses what they are? We measure things. We want to put them together. Usually a good approach is to combine the two. If you ask a very specific question but combine it with the methods of knowing that there could be a fundamental theory underlying it, sometimes you make progress.
Segment 1347: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2649, Text: The community tends to get segmented or fragmented into people who do one or the other, but there are definitely times… Some of my best collaborations with people who are more top-down than I am, so that we come up with interesting ideas that we wouldn’t have thought of if either one of us was working individually.
Segment 1348: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2665, Text: Would you say the truly big leaps happened top-down? Like Einstein?
Segment 1349: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2670, Text: Einstein was not a top-down person in the beginning. Special relativity was very much him thinking about… They were thought experiments, but he was very much… The original theory about relativity is something like on the nature of electromagnetism. He was trying to understand how Maxwell’s laws could make sense when they seemed to have different symmetries than what we had thought they were.
Segment 1350: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2694, Text: He was very much a bottom-up person, and in fact, he resisted top-down for a long time. Then when he tried to do the theory of general relativity or the general theory of relativity, whichever you want to call it, incorporating gravity into the system when you need some feedback, then he was helped by a mathematician who had developed some differential geometry and helped him figure out how to write down that.
Segment 1351: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2716, Text: After that, he thought top-down was the way to go, but he actually didn’t make that much progress. I think it’s naive to think it was just one or the other. In fact, a lot of people who made real progress were rooted in actual measurements.
Segment 1352: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2731, Text: Speaking of mathematicians, what do you is the difference, you’ve had a bit of foot in both, between physics and mathematics in the way it helps us understand the world?
Segment 1353: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2741, Text: To be frank, there’s a lot more overlap in physics and math. I think that has been… Maybe not more, but there’s certainly a lot. I think, again, the kinds of questions you’re asking are usually different. Mathematicians like the structure itself, physicists are trying to concentrate on, to some extent, on the consequences for the world. But there is a lot of overlap.
Segment 1354: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2764, Text: The string theory is an example. There’s certain theories where there’s a certain mathematical beauty to it.
Segment 1355: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2772, Text: There’s also some really cool ideas that you get in particle physics where you can describe what’s going on and connect it to other ideas. That’s also really beautiful. I think basically insights can be beautiful. They might seem simple, and sometimes they genuinely are, and sometimes they’re built on a whole system that you have to understand before. If you actually saw Einstein’s equations written out in components, if you wouldn’t think it’s so beautiful. If you write in a compact way, it looks nice.
Segment 1356: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2803, Text: What do you think about the successes and the failures of string theory? To what degree do you think it succeeded, to what degrees it not succeeded yet or has failed?
Segment 1357: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2814, Text: I think to talk about any science in terms of success and failure often misses the point because there’s not some absolute thing. I do think that string theorists were a bit overly ambitious… Not overly ambitious, but a little bit overly arrogant in the beginning, thinking they could solve many problems that they weren’t going to solve.
Segment 1358: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2834, Text: That’s not to say the methods and advances in strength theory don’t exist, but they certainly weren’t able to immediately solve all the problems they thought they could solve. It has given us tools, it has given us some insights, but it becomes almost a sociological question of how much it should be one or the other.
Segment 1359: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2855, Text: I do think that you can get caught up in the problems themselves, and sometimes you can get caught up in the methods and just do other examples. The real physics insights often come from people who are thinking about physics as well as math.
Segment 1360: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2869, Text: Because you mentioned AI, is there hope that AI might be able to help find some interesting insights? Another way to ask this question is how special are humans that we’re able to discover novel insights about the world?
Segment 1361: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2889, Text: That’s a great question, and it depends on what kind of insights and what we’re going to find that out. Because it’s hard to think about something that doesn’t quite exist yet, I could just think about something, take a step back. It’s a little bit like I’m trying understand four dimensions so you go back to three dimensions. Go to something you can imagine.
Segment 1362: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2911, Text: You can say a lot of the things in a very different level about the internet. You could say has the internet helped do things? It definitely took on a life of its own in some sense, but it’s also something that we’re able to tame. I know that I, myself wouldn’t have been able to write books if the internet didn’t exist because I wouldn’t have had the time to go to the library and look everything up. It helped me enormously.
Segment 1363: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2937, Text: In some sense, AI could be that. In a very nice world, it could be a tool that helps us go a step further than we would and a lot more efficiently. It’s already done that to some extent. Or it could be like the parts of the internet that we can control that are ruining politics or whatever. There’s certainly a lot of indications that can do that. Then there are even bigger things that people speculate about AI being able to do its own things, but in terms of actually figuring things out, we’re in the early stages.
Segment 1364: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2973, Text: Yeah, there’s several directions here. One is on the theorem prover side, Wolfram Alpha where everything’s much more precise, and we have large language model type of stuff. One of the limitations of those is it seems to come up with convincing looking things, which we don’t know if it’s true or not, and that’s a big problem for physics.
Segment 1365: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=2994, Text: Large language models are more or less generalizations of stuff that we have. There’s still breakthroughs in AI waiting to happen, and maybe they are happening and maybe they’ll be good, maybe not, but that’s not quite the same. Maybe in some cases, it’s just pattern recognition that leads to important things, but sometimes it could be something more insightful than that that I can’t even put my finger on.
Segment 1366: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3021, Text: It forces us to… We don’t really understand how smart we are. We don’t understand how we think about things all that well, actually. But one thing is true though, we are a lot more efficient right now than computers and coming up with things, we require a lot less energy to do that. If computers figure out how to do that, then it’s going to be at a totally different ball game.
Segment 1367: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3042, Text: Here are clearly kinds of connections that we don’t know how we’re making, but we are making them. That’s going to be interesting. I say we’re in early stages, but this is changing very rapidly. Right now, I don’t think that it’s actually discovered new laws of physics, but could it in the future? Maybe it can.
Segment 1368: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3066, Text: It will raise big questions about what is special about humans that we don’t quite appreciate. There could be things that are like that leap of insight that happens, truly novel ideas, that could potentially be very difficult to do.
Segment 1369: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3086, Text: There are abstract questions like that. There’s also questions of how is it that we can address to some extent, how will AI be used in the context of the world we live in? Which is based on at least our country’s based on capitalism in a certain political system. How will global politics deal with it? How will our capitalist system deal with it? What will be the things that we focus on doing with it? How much will researchers get control of it to be able to ask different sorts of questions?
Segment 1370: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3118, Text: While it was starting out, people were doing these kinds of toy problems, but what will it actually be applied to and what will it be optimized to do? There’s a lot of questions out there that it’s really important we start addressing.
Segment 1371: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3131, Text: What to you is the most beautiful unsolved problem in physics and cosmology, which is really exciting if we can unlock the mystery of in the next few decades?
Segment 1372: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3150, Text: Is it what’s the most beautiful unsolved problem, or what is the most beautiful unsolved problem I think we can make progress on?
Segment 1373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3155, Text: Oh boy, we make progress on in the next few centuries.
Segment 1374: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3163, Text: Most of the big questions have to do with what underlies things, how things started, what’s at the base of it. There’s also just basic questions like that you asked earlier, how far will science take us? How much can we understand? There are questions like how we got here, what underlies it, are there.
Segment 1375: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3182, Text: Also, there’s really deep questions like what fraction are we actually seeing? If there are these other forces, if there is another way of seeing the world, are there universes beyond their own? If they’re so totally different, how do we even comprehend them? What would we even think about them? There’s a lot about trying to get beyond… It’s always just getting beyond our limited vision and limited experience and trying to see what underlies it, both at small scales and at large scales.
Segment 1376: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3215, Text: We just don’t know the answers. I’d like to think that we understand more about dark matter, about dark energy, about are there extra dimensions, things that we actually work on, but there’s probably a lot beyond what we work on that’s yet to be discovered.
Segment 1377: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3230, Text: Yeah, understanding the extra dimensions piece will be really interesting.
Segment 1378: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3235, Text: Totally. If it is how the universe went from higher dimensions to what we see, are the extra dimensions present everywhere? One of the really interesting pieces of physics we did that I talk about in my first book, Warped Passages, is finding out that there can be a higher dimension, but only locally. Do you think there’s a gravity of a lower dimension? It could be like only locally do we think we live in three dimensions. It could be higher dimensions is different.
Segment 1379: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3265, Text: That’s not actually the gravity we have, but there’s all sorts of phenomena that might be out there that we don’t know about. All sorts of evolution things, time dependence that we don’t know about. Of course, that’s from the point of view of particle physics, from the point of view of other kinds of physics, we’re just beginning, so who knows?
Segment 1380: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3280, Text: Yeah, if the physics changes throughout is not homogeneous throughout the universe, that’ll be weird.
Segment 1381: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3288, Text: I mean, for the observable universe, it’s the same. But beyond the observable universe, who knows?
Segment 1382: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3298, Text: You’ve had an exceptional career. What advice would you give to young people, maybe high school, college, on how to have a career they can be proud of and a life they can be proud of?
Segment 1383: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3310, Text: I think the weird thing about being a scientist or an academic in general is you have to believe really strongly what you do while questioning it all the time. That’s a hard balance to have. Sometimes it helps to collaborate with people, but to really believe that you could have good ideas at the same time, knowing they could all be wrong. That’s a tough tightrope to walk sometimes, but to really test them out.
Segment 1384: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3334, Text: The other thing is sometimes if you get too far buried, you look out and you think there’s so much out there. Sometimes it’s just good to bring it back home and just think okay, can I have as good idea as the person next to me rather than the greatest physicist who ever lived? Right now, like you said, I think there’s lots of big issues out there, and it’s hard to balance that.
Segment 1385: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3355, Text: Sometimes it’s hard to forget the role of physics, but I think Wilson said it really well when he said when they were building Fermilab, it was like this won’t defend the country, but it’ll make it worth defending. It’s just the idea that in all this chaos, it’s still important that we still make progress in these things. Sometimes when major world events are happening, it’s easy to forget that. I think those are important too. You don’t want to forget those, but to try to keep that balance because we don’t want to lose what it is that makes humans special.
Segment 1386: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3384, Text: That’s the big picture. Do you also lose yourself in the simple joy of puzzle solving?
Segment 1387: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3389, Text: Yeah. We all like solving puzzles. Actually one of the things that drives me in my research is the inconsistencies. When things don’t make sense, it really bugs me and it just will go into different directions to see how could these things fit together.
Segment 1388: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3406, Text: It bugs you, but that motivates you?
Segment 1389: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3408, Text: Yeah, totally.
Segment 1390: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3409, Text: Until it doesn’t. You have to resolve it.
Segment 1391: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3412, Text: I think I have this underlying belief that it should make sense, even though the world comes at you in many ways and tells you nothing should make sense, but if you believe that it makes sense and you look for underlying logic. I think that’s just good advice for everything to try to find why is it the way.
Segment 1392: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3428, Text: I talk about effective theory in my second book, Knocking On Heaven’s Door, a lot. It’s rather than ask the big questions, sometimes we just ask the questions about the immediate things that we can measure and like I said, we can sometimes tell one that we’ll fail, but we can have these effective theories. Sometimes I think when we approach these big questions, it’s good to do it from an effective theory point. Why do I find this satisfying? Why is the world we have the way it is?
Segment 1393: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3451, Text: We think things are beautiful that we live in. I’m not sure if we had different senses or different ways of looking at things, we wouldn’t necessarily find it beautiful. But I have to say, it is fantastic that no matter how many times I see a sunset, I will always find it beautiful. I don’t think I ever see a sunset as say whatever. It’s just always beautiful.
Segment 1394: Speaker: , Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3474, Text: There are things that as humans, clearly resonate with us, but we were maybe evolved that way. But that’s about us. In terms of figuring out the universe, it’s amazing how far we’ve gotten. We have discovered many, many wonderful things, but there’s a lot more out there and I hope we have the opportunity to keep going.
Segment 1395: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3494, Text: With effective theories, one small step at a time, just keep unraveling the mystery.
Segment 1396: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3499, Text: Also having in mind the big questions, but doing one small step at a time. Exactly.
Segment 1397: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3503, Text: Yeah, looking out to the stars. You said the sunset. For me, it’s the sunset, the sunrise, and just looking at the stars. It’s wondering what’s all out there and having a lot of hope that humans will figure it out.
Segment 1398: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3519, Text: Right. I like it.
Segment 1399: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3522, Text: Lisa, thank you for being one of the humans in the world for having me here for that are pushing it forward and figuring out this beautiful puzzle of ours. Thank you for talking today. This was amazing.
Segment 1400: Speaker: Lisa Randall, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3533, Text: Thank you for having me here.
Segment 1401: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=VPaOy3G1-2A&t=3535, Text: Thanks for listening to this conversation with Lisa Randall. To support this podcast, please check out our sponsors in the description. Now, let me leave you with some words from Albert Einstein. The important thing is to not stop questioning. Curiosity has its own reason for existence. Thank you for listening, and hope to see you next time.
Segment 1402: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=0, Text: What’s your opinion on my bird here, Mr. Parrot?
Segment 1403: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4, Text: It’s a Macaw. Scarlet Macaw.
Segment 1404: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=7, Text: What?
Segment 1405: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=8, Text: It is a Scarlet Macaw.
Segment 1406: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=10, Text: Oh, you know birds?
Segment 1407: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=11, Text: Yeah. And that’s actually not life-sized.
Segment 1408: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=15, Text: Are you saying he’s not real?
Segment 1409: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=17, Text: I’m saying it’s not to scale.
Segment 1410: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=19, Text: Okay. But he’s real.
Segment 1411: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=21, Text: Are we doing that Monty Python sketch?
Segment 1412: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=25, Text: Everything is a Monty Python sketch.
Segment 1413: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=26, Text: I don’t think Monty Python’s funny.
Segment 1414: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=28, Text: You don’t?
Segment 1415: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=29, Text: At all. Not once.
Segment 1416: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=29, Text: That explains so much.
Segment 1417: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=31, Text: Does it? What does it explain?
Segment 1418: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=32, Text: What do you think is funny?
Segment 1419: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=35, Text: You not answering that question is pretty funny.
Segment 1420: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=38, Text: Yeah. What do you think is funny, having a mantis shrimp?
Segment 1421: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=41, Text: No.
Segment 1422: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=42, Text: You think Big Lebowski is funny?
Segment 1423: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=44, Text: Oh God, no.
Segment 1424: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=46, Text: This is getting worse and worse. The following is a conversation with Michael Malice, anarchist and author of Dear Reader, The New Right, The Anarchist Handbook, The White Pill, and he is the host of the podcast, YOUR WELCOME. This is a Thanksgiving special of the pirate and oceangoing variety. So once again, let me say thank you for listening today and for being part of this wild journey with me. This is a Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Michael Malice.
Segment 1425: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=94, Text: The box?
Segment 1426: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=95, Text: Yeah.
Segment 1427: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=95, Text: The mystery box.
Segment 1428: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=96, Text: I’m wondering what’s in it.
Segment 1429: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=96, Text: There’s something in that box of exquisite beauty, both literally and in what it symbolizes and why it is here.
Segment 1430: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=106, Text: Given the kind of human being you are, I’m terrified at what you find beautiful.
Segment 1431: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=112, Text: That’s a good point. You kind of hit me with a curve ball. For me, the most beautiful wildlife are what I call God’s mistakes. Because my friend came up with that term where she’s like, “God made these disgusting animals, just threw in the bottom of the ocean.” He’s like, “No one’s ever going to see this.”
Segment 1432: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=132, Text: Yeah. You commented on Twitter about some creature, a rainbow type creature.
Segment 1433: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=137, Text: The peacock mantis shrimp.
Segment 1434: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=138, Text: Yeah, it’s beautiful.
Segment 1435: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=140, Text: It’s horrific though. So it has, I think eight legs, six arms, two punching claws or spearing claws depending on the genus. Two eyes, two antennae, two ear flaps. I don’t know what they do. And its punch can be as strong as a bullet. And the other type with the spears, divers call them thumb splitters because if you stick your finger near it’ll cut your thumb down to the bone. So I had one as a pet. All night I would hear banging on the PVC pipe. And I’ve got to tell you, if they have the best eyesight of any animal because they see in seven different ways. And when you make eye contact with this thing, it’s just absolutely terrifying. But you can eat them as sushi. They call them sea centipedes.
Segment 1436: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=181, Text: But they’re colorful and beautiful.
Segment 1437: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=183, Text: That’s species is, yeah.
Segment 1438: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=184, Text: What was it like having one as a pet, and why did you do it?
Segment 1439: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=189, Text: Well, when you have a species that’s that unique and that much of an outlier, growing up, reading these books, watching these shows, I found this stuff so much more fascinating than space, which is dead. So to be able to have this specimen in your house and just observe its behavior is just an amazing thing.
Segment 1440: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=212, Text: Why’d you get rid of it?
Segment 1441: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=214, Text: I didn’t have, I guess, the right minerals in the mix because-
Segment 1442: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=216, Text: It died?
Segment 1443: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=217, Text: … it had a problem moulting once. Yeah, it couldn’t moult correctly.
Segment 1444: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=220, Text: Wow. Do you miss it? Think about it still?
Segment 1445: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=223, Text: I do think about it, to be honest. I still have a pair of it’s punching appendages from when it moulted.
Segment 1446: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=231, Text: What pet animal in your life do you miss the most, that has been in your life that you think about?
Segment 1447: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=239, Text: I’ve never had cats or dogs growing up or anything like that, which I… Oh God. My problem is-
Segment 1448: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=247, Text: Here we go.
Segment 1449: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=248, Text: … if I like something, I will go down a rabbit hole. So I know if I got one tattoo, I already know my first five are going to be. Okay? So I can’t do it because then once I get those five, it’s going to be a hundred and I’m already too old to be the tattoo guy.
Segment 1450: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=265, Text: What would be the first tattoo? My face? Would it go on your ass cheeks or where would you put them if it was my face?
Segment 1451: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=276, Text: If I got your face, it would definitely be on my arm right here.
Segment 1452: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=279, Text: If you had multiple faces, would you put like?
Segment 1453: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=282, Text: I think delts, right? Shoulders, different faces on different shoulders.
Segment 1454: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=284, Text: And when you flex?
Segment 1455: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=285, Text: I’d want some symmetry.
Segment 1456: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=286, Text: Yeah. Would you get a dictator? If you had to get a dictator, who would you get?
Segment 1457: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=291, Text: Would have to be Kim Jong-il. Right? Because I wrote the book on him.
Segment 1458: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=294, Text: Oh, it’s like the plugging your book in the tattoo?
Segment 1459: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=297, Text: I don’t think plugging, it’s just I have a personal connection to this stuff.
Segment 1460: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=300, Text: Good opener, the conversation. People would be asking why him and he’d be like, “Well, I wrote a book about it.” And I’d be like, “Oh, okay.”
Segment 1461: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=307, Text: Okay. Here’s why-
Segment 1462: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=308, Text: “Let me check it out.”
Segment 1463: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=308, Text: That would be a bad. No, that’s not what happens.
Segment 1464: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=310, Text: Okay.
Segment 1465: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=311, Text: Here’s the thing.
Segment 1466: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=312, Text: What happens?
Segment 1467: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=312, Text: When you write a book about North, “Hey, nice to meet you. What is it you do?’ “I’m an author.” “What kind of books do you write?” “Well, my last book was on North Korea,” 90% of the time, 90, they will then start telling me everything they know about North Korea. And it’s like, “I don’t need, this isn’t a quiz, and it’s a very poorly understood country. I don’t expect you to know anything. You’re not on the spot. And half of what you’re saying is not accurate either. It’s fine.”
Segment 1468: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=336, Text: How often did they bring up Dennis Rodman?
Segment 1469: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=338, Text: A hundred percent.
Segment 1470: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=339, Text: A hundred percent of the time.
Segment 1471: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=340, Text: “Oh, so do you know Dennis Rodman?”
Segment 1472: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=342, Text: Yeah.
Segment 1473: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=342, Text: But I don’t understand why. I guess, people feel the need to, “All right, now we’re talking about this subject. I just got to drop whatever I can talk about.” It’s usually a small amount. And there’s this thing in the culture, which I hate that everyone have to have an opinion on everything. And it’s like it’s okay to be like, “Yeah, I don’t know anything about that. Tell me more.” There’s lots of things I don’t know anything about.
Segment 1474: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=362, Text: What’s your opinion on my bird here, Mr. Parrot?
Segment 1475: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=367, Text: It’s Macaw, Scarlet Macaw.
Segment 1476: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=370, Text: What?
Segment 1477: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=371, Text: It is a Scarlet Macaw.
Segment 1478: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=373, Text: Oh, you know birds?
Segment 1479: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=374, Text: Yeah. And that’s actually not life-sized.
Segment 1480: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=378, Text: Are you saying he’s not real?
Segment 1481: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=380, Text: I’m saying it’s not to scale.
Segment 1482: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=382, Text: Okay. But he’s real.
Segment 1483: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=384, Text: Are we doing that Monty Python sketch?
Segment 1484: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=387, Text: Everything is a Monty Python sketch.
Segment 1485: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=389, Text: I don’t think Monty Python’s funny.
Segment 1486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=391, Text: You don’t?
Segment 1487: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=391, Text: At all. Not that once.
Segment 1488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=392, Text: That explains so much.
Segment 1489: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=393, Text: Does it? What does it explain?
Segment 1490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=395, Text: What do you think is funny?
Segment 1491: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=398, Text: You not answering that question is pretty funny.
Segment 1492: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=399, Text: Yeah. What do you think is funny, having a mantis shrimp?
Segment 1493: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=404, Text: No.
Segment 1494: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=405, Text: Do you think big Big Lebowski is funny?
Segment 1495: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=406, Text: Oh God, no. Although…
Segment 1496: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=409, Text: This is getting worse and worse.
Segment 1497: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=410, Text: To be fair, I only tried to watch Big Lebowski after it’s been part of the culture for many years.
Segment 1498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=417, Text: Right.
Segment 1499: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=418, Text: To the point where every single line has been quoted incessantly by the most annoying frat bros ever. So I kind of have been poisoned to be able to appreciate it.
Segment 1500: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=430, Text: Right.
Segment 1501: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=430, Text: So maybe if I’d seen it when it came out, before it became a thing, I would’ve enjoyed it. I couldn’t get through it. I couldn’t get through 20 minutes.
Segment 1502: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=437, Text: Is that how you feel about Schindler’s List?
Segment 1503: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=441, Text: Well…
Segment 1504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=441, Text: It’s so much easier for me to stare at you when you have sunglasses on.
Segment 1505: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=444, Text: I didn’t think you’d be the one making Holocaust jokes today. And yet, here we are.
Segment 1506: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=448, Text: And cut scene. I actually have no trouble making eye contact with you when you’re wearing shades.
Segment 1507: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=455, Text: Yes, because you’re a robot.
Segment 1508: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=456, Text: Two copies of myself.
Segment 1509: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=458, Text: Yeah. Oh, you’re seeing yourself in them?
Segment 1510: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=459, Text: Mm-hmm.
Segment 1511: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=460, Text: Okay, cool.
Segment 1512: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=460, Text: Yeah, I’m having a conversation with myself. It’s not your fault, Lex.
Segment 1513: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=466, Text: They made you like this. You were just a good little Roman in Saint Petersburg.
Segment 1514: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=471, Text: I could see Mr. Parrot a little bit too.
Segment 1515: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=474, Text: But what do you find funny? Come on. This is an interesting subject.
Segment 1516: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=477, Text: Well, I find Monty Python. I find absurdity funny.
Segment 1517: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=480, Text: Yes. I find absurdity funny. I think that’s the thing. When people come at me, and maybe this is an Eastern European thing, when they’re like, “How can you find this very dark subject funny?” It’s like, well, the humor. First of all, the humor is that you’re making fun of something that’s dark. So already it’s absurd. It’s completely inappropriate. Second, just psychologically, Joan Rivers said that Winston Churchill said, I don’t know if it’s true, that when you make people laugh, you’re giving them a little vacation. And I was just thinking about this the other day, how when I die, if, I want my funeral to be a roast. It doesn’t help me that everyone’s sad. If I brought people happiness or joy in life, whatever, I want to keep doing that in death. Your sadness doesn’t help me. I know you can’t help it, but tell stories of how I made you laugh. Make fun of me. Make me the punching bag. Even literally, take me out of that coffin and beat the-.
Segment 1518: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=535, Text: Make me a pinata. I don’t care. I don’t understand, well, I do understand, but it’s sad for me when people are like, “This isn’t funny. That isn’t funny.” The way I look at humor is the way it’s like a chef, right? It’s pretty easy to make bacon taste good, but some of these really obscure ingredients to make it palatable, that’s takes skill. So if you’re dealing with a subject that is very emotional or intense and you can make people laugh, then that takes skill and that’s the relief for them.
Segment 1519: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=569, Text: Yeah. It’s all about timing.
Segment 1520: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=573, Text: Yeah.
Segment 1521: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=574, Text: Yeah.
Segment 1522: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=578, Text: What’s the difference? You want to hear one of my jokes?
Segment 1523: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=581, Text: Is it a pirate joke? Because that’s the only kind I accept today.
Segment 1524: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=585, Text: Okay.
Segment 1525: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=585, Text: But no, go ahead. It doesn’t have to be a pirate joke this one time.
Segment 1526: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=588, Text: Do you know who Lia Thomas is?
Segment 1527: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=590, Text: Yeah.
Segment 1528: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=591, Text: What’s difference between Lia Thomas and Hitler?
Segment 1529: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=593, Text: What?
Segment 1530: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=594, Text: Lia Thomas knows how to finish a race.
Segment 1531: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=598, Text: Very nice. Very nice.
Segment 1532: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=599, Text: Did I just get the gold medal?
Segment 1533: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=600, Text: Good job. Why does it take pirates forever to get through the alphabet?
Segment 1534: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=609, Text: Why?
Segment 1535: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=611, Text: Because they spent years at sea.
Segment 1536: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=613, Text: Oh, I thought it was going to be an [inaudible 00:10:15] joke.
Segment 1537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=615, Text: Nope. No.
Segment 1538: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=616, Text: That’s a good one. I like that.
Segment 1539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=617, Text: Yeah.
Segment 1540: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=618, Text: When I was in North Korea.
Segment 1541: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=621, Text: Oh, you know Dennis Rodman? It’s a callback.
Segment 1542: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=623, Text: By the way, the thing that is very heartbreaking about the North Korean situation is that they have a great sense of humor. It would be a lot easier if these were robots or drones. They have big personalities, big senses of humor, and that made it much harder to leave and interact with these people because I mean, there’s nothing more human and universal than laughter and laughter’s free.
Segment 1543: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=647, Text: Are you saying there’s humor even amongst the people that have most of their freedoms taken away?
Segment 1544: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=652, Text: Especially. I mean, again, we’re from the Soviet Union, there’s [inaudible 00:10:57] I mean, Russian humor is a thing because there’s nothing you can, if you can’t have food or nice things, at least you can have joy and make each other laugh. I think about it all the time, and I think about my guide all the time. It’s been, what, 2012? So it’s been 11 years since I’ve been there, and she’s still there. And everyone I’ve seen is still there. They just recently electrified the border. So you can’t even, even the few people who are escaping can’t do it anymore.
Segment 1545: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=679, Text: Well, that’s interesting that they still have a sense of humor. I attribute the Soviet Union for having that because of the really deep education system. You got to read a lot of literature.
Segment 1546: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=689, Text: Okay.
Segment 1547: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=690, Text: And because of that, you get to kind of learn about the cruelty, the injustices, the absurdity of the world.
Segment 1548: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=700, Text: Right.
Segment 1549: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=700, Text: As long as the writing is not about the current regime.
Segment 1550: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=703, Text: Yeah. But I think if you look at African Americans, Jewish Americans, gay Americans, they are all disproportionate in terms of attributing to comedy. It’s not because these groups have some kind of magic to them., It’s that when you are on the outside looking in, A, you’re going to have different perspective than the people who are in the middle of the bell curve. But also, when you don’t have anything to lose, at the very least, you can make each other laugh and find happiness that way. So that is something that I think is an important thing to recognize.
Segment 1551: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=734, Text: So what do you find funny? What makes you giggle in the most joyful of ways? The suffering of others?
Segment 1552: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=744, Text: I mean, there are YouTube videos of fat people falling down and they’re really funny.
Segment 1553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=756, Text: There’s two kinds of people in this world, those that laugh at those videos and those that don’t.
Segment 1554: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=762, Text: No. And those that are in them. My friend Jesse just told me a great Norm Macdonald joke, and this is a good litmus test joke because he says, “A certain group of people lose their minds and a certain group of people just stare at you.” And he goes, “This kind of…” and so I’ll tell you the joke. This is Norm McDonald. A guy walks into a bar and he sees someone at the bar who has a big pumpkin for a head.
Segment 1555: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=787, Text: And the guy’s like, “Dude, what happened to you?” He goes, “Ugh, you never believe this. I got one of those genie lamps and this genie.” He’s like, “Well, what happened?” He goes, “Well, the first wish, I wished for a hundred million dollars.” He’s like, “Yeah, did you get it?” He goes, “Yeah.” He goes, “In my bank account. Feels fine.” He goes, “All right. Well, the second wish, I wished to have sex with as many beautiful women as I want.” He goes, “Did that happen?” He goes, “Yeah, it was amazing.” He goes, “Then what?” “Well, I wished for a giant pumpkin head.”
Segment 1556: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=814, Text: Yeah.
Segment 1557: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=815, Text: So there’s a certain mindset that will just be staring at the screen. And that is, I mean, there’s so many levels why that’s funny, at least to me. And I just love that kind of humor.
Segment 1558: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=825, Text: Well, Norm McDonald is just, I watch his videos all the time. He’s a guy that definitely makes me giggle. And he’s one of the people that makes me giggle for reasons I don’t quite understand.
Segment 1559: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=838, Text: Did you ever see him with Carrot Top on Conan O’Brien?
Segment 1560: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=841, Text: No.
Segment 1561: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=842, Text: Making fun of Carrot Top?
Segment 1562: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=843, Text: No.
Segment 1563: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=845, Text: This is probably the best talk show clip of all time. He’s on with Courtney Thorne-Smith. She was on Melrose’s Place and Conan O’Brien’s the host, and Courtney’s talking about how she’s going to be an upcoming movie with Carrot Top. And Conan is like, “Oh, what’s it going to be called?” And she’s like, “Doesn’t have a title yet.” And Norm goes, “Oh, I know what should be called, Box Office Poison.” And they’re all laughing. And she’s like, “No, no, no, the working title is Chairman of the Board. And Conan goes, “Do something with that smart ass.” And Norm goes, “Yeah, bored is spelled B-O-R-E-D.” And they all just completely lost it.
Segment 1564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=879, Text: There’s something about him with words spoken out of his mouth with the way he turns his head and looks at the camera.
Segment 1565: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=886, Text: I think he is one of those rare comedians who you really feel like he’s talking to you directly. He feels like he’s winking at you in the audience. And he’s like, “Can you believe I’m doing this?” It’s like almost he feels like he’s, I don’t want to say imposter, but he’s more a member of the audience than he is a member of the people on the stage.
Segment 1566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=906, Text: Yeah, it feels like he’s on our side.
Segment 1567: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=908, Text: Yes. Yeah.
Segment 1568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=909, Text: Whatever the hell “Our” means.
Segment 1569: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=911, Text: Roseanne got him his first job.
Segment 1570: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=914, Text: Man. Roseanne, you and her have been hanging out.
Segment 1571: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=917, Text: I got it. Oh my God. Talk about Thanksgiving. When you are talking to Roseanne Barr and making eye contact with this person, it is, I can’t even describe it. It’s just like, “Holy crap, Roseanne Barr’s talking to me.” She is, I’ve said this to her face, pathologically funny. It does not turn off. And you’re sitting there and you’re like, “Holy crap.”
Segment 1572: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=940, Text: And when you make her laugh, which is that laugh that’s in the theme song of her show, you feel like, “Okay, I did a mitzvah. I did something good and right in the world that I made Roseanne Barr laugh.” And it’s also really funny because, and she’s going to hate this, because I tell her, she’s adorable. She doesn’t like that. She’s little. You think of Roseanne Barr as this force of nature, like a tsunami.
Segment 1573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=961, Text: Big, yeah.
Segment 1574: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=961, Text: She’s five three, I’d say maybe 130. And she puts on the sunglasses, you think this little old Jewish lady. You’d never know this is one of the most epic performers of all time. She lives near here now. So it’s just so much fun talking to her. There was an old satirical magazine in the, I think early two thousands called Heeb, written by Jews, and she dressed up as Hitler for one of the photo shoots, and she was baking little men in the oven. I found it on eBay, I wanted her to sign it to, “Michael, it should have been you.” But she signed it to, “Michael, you’re one smart cookie.” And now it hangs, “Love, mom, Roseanne Barr.” And I call her mom and it hangs over my desk because I have her good domestic goddess energy flowing at me. What?
Segment 1575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1012, Text: What do you find? What else? So Norm McDonald. I guess, we’ve landed on that.
Segment 1576: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1016, Text: No. My favorite comedian is-
Segment 1577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1016, Text: We agree on something.
Segment 1578: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1017, Text: My favorite comedian of all time is Neil Hamburger. So Neil Hamburger, I don’t know if I’m ruining the bit, he’s a character performed by this guy named Gregg Turkington. So he comes out in a tuxedo, big eyeglasses, holding three glasses of water, coughing into the mic. And I remember I saw him once in LA and the girl ahead of me, at the table ahead of me was with her boyfriend, this basic chick, pumpkin spice. She turns to him and she goes, “What is this?” And I remember the first time he was on Jimmy Kimmel, and he tells one of his jokes and it was like, “Why does ET Reese’s Pieces so much? Well, that’s what sperm tastes like on his home planet.” And no one laughs. And he goes, “Oh, come on guys. I have cancer.” And it just cuts to this Marine in the audience with his arms crossed. So if you know what he’s doing, it’s just absolutely amazing.
Segment 1579: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1078, Text: He opened for Tenacious D once in somewhere, I think in Ireland or the UK, one of those. And they’re booing him because his jokes are often not funny. He’s like, “Hey, where did my whore ex-wife run off to with that dentist she’s shacking up with? I don’t know. But when I see her in court next month, Alaska.”
Segment 1580: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1100, Text: So they’re booing and he goes, “All right, do you guys want me to bring out Tenacious D?” They’re like, “Yeah.” “Do you want to see your heroes of my Tenacious D?” “Yeah.” “Come on, let me hear it. Do you want to see Tenacious D?” “Yeah.” He goes, “All right, if I tell this next joke and you don’t boo me, I’ll bring out Tenacious D.” And it’s like, I’m trying to think of one that’s not too…
Segment 1581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1124, Text: Self censorship is never good.
Segment 1582: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1125, Text: Okay. He goes, “Can we agree that George Bush is the worst President America’s ever had?” Everyone claps. He goes, “Which makes it all the stranger that his son, George W. Bush was in fact the best.”
Segment 1583: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1138, Text: I take it back on the self-censorship.
Segment 1584: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1141, Text: So two people laugh and he goes, “Oh, that’s amazing. I guess I’ll do an encore.” And he did 10 more minutes. It was just, I love him so much.
Segment 1585: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1149, Text: It’s interesting. They opened for Tenacious D. Jack Black, that’s a comedic genius of a different kind.
Segment 1586: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1156, Text: Oh, yeah. And he was in one of my favorite movies, Jesus’ Son. It’s this little Indie movie. He did a great turn in that. He’s really underrated as an actor. He’s got a lot of range. I know he kind of get types cast as this one specific type, but he’s really, really talented.
Segment 1587: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1170, Text: But also just the pure joy.
Segment 1588: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1172, Text: Yes. He’s clearly having fun.
Segment 1589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1175, Text: Okay. It is Thanksgiving. So in the tradition, following tradition, what are you thankful for, Michael, in this world?
Segment 1590: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1185, Text: Do you have a list too?
Segment 1591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1186, Text: No, not really.
Segment 1592: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1187, Text: Really?
Segment 1593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1188, Text: It’s up in here.
Segment 1594: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1189, Text: Oh, I mean, but you have several things you’re thankful for.
Segment 1595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1191, Text: Yes.
Segment 1596: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1192, Text: Okay.
Segment 1597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1192, Text: Yes.
Segment 1598: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1193, Text: One of the things I’m-
Segment 1599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1194, Text: My list comes from the heart. I don’t have to write anything down.
Segment 1600: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1196, Text: Well, I don’t have written down.
Segment 1601: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1197, Text: Okay.
Segment 1602: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1198, Text: One of the things that I’m most thankful for, this is a common answer, but I can back it up, is my family. Because my nephew, Lucas, is now six years old. And when kids have a sense of humor, it’s like just miraculous. So he stole my sister’s phone, his mom. Figured out that grandma is listed as mom in the phone, and he calls her up and he’s like, “Michael’s in the hospital. He’s really sick.
Segment 1603: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1227, Text: He didn’t want to tell you.” And she’s freaking out. He goes, “Prank.” So I took him, Dinesh D’Souza just released a movie called Police State, which was actually really good, highly recommend it. I was surprised how much I liked it because he wasn’t going Republicans good, Democrats bad.
Segment 1604: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1241, Text: It was just about authoritarianism. And he had a movie premier at Mar-a-Lago. So I’m like, I got to bring Lucas to Mar-a-Lago. So Lucas is, I’m like, “We’re going to the President’s house.” He’s like, “Oh, the White House?” And I’m like, “No, no, a former president.” He goes, “Oh, Abe Lincoln?” And I’m like, “Okay, kid logic.” He’s giving logical answers. This is kind of like AI, you have to program it. It’s using logic correctly.
Segment 1605: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1264, Text: You should have told him it’s a president that’s second to only Ab Lincoln in terms of greatness.
Segment 1606: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1271, Text: Accomplishments, yeah. He went up to all the women in their ball gown, evening gowns, and he goes, “You’re so beautiful. Were you born as a girl?” So when you have this six year old asking you this, it was really, really fun. So that is a great joy to have a nephew. And I have another one, Zach, who’s coming up in age, and he’s starting to talk now. That is really, really fun for me.
Segment 1607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1299, Text: Getting to watch them find out about the world for the first time.
Segment 1608: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1303, Text: And also training them, that he loves being funny and having fun.
Segment 1609: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1309, Text: You’re his audience in a sense?
Segment 1610: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1311, Text: Yeah, but.
Segment 1611: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1312, Text: Because you giggle and?
Segment 1612: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1314, Text: I give him, “We’re prank bros.” He gives me a high five. My family, and this is one, you talk about what I find funny, this is things that actually enraged me. When people, and this is such a wasp thing, don’t just go with the joke or they’re like, “I don’t get it,” or they don’t understand to just go with it.
Segment 1613: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1330, Text: I was in the car with my sister when she was 10, 12, whatever. She’s much younger than me. She’s 12 years younger. And there’s this species of squid, by the way, which is asymmetric. One of its eyes is very much bigger than the other because it swims horizontally. And so one’s looking up, one’s looking down where there’s more light. Shout out. If you want to learn more about squids, go to octonation.com.
Segment 1614: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1352, Text: OctoNation. Shout out.
Segment 1615: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1354, Text: Shout out to Warren.
Segment 1616: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1354, Text: There’s a lot of fascinating stuff. OctoNation on Instagram.
Segment 1617: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1357, Text: Yes. I was in the car with my sister. She’s 10 or 20.
Segment 1618: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1360, Text: Me as a pirate, I’m sorry for the rude interruptions. I appreciate that comment, especially.
Segment 1619: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1365, Text: Yeah, it’s a great. Yeah.
Segment 1620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1366, Text: These jokes and thoughts are coming to me at a ten-second delay, so I apologize. Anyway, you were telling about the asymmetrical.
Segment 1621: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1374, Text: I know where I was, don’t worry. I got it.
Segment 1622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1374, Text: All right.
Segment 1623: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1376, Text: So I tell my-
Segment 1624: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1376, Text: Sometimes you need help.
Segment 1625: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1377, Text: No.
Segment 1626: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1377, Text: The age is getting to you.
Segment 1627: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1377, Text: I was…
Segment 1628: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1382, Text: Your skin is showing it. It’s getting dark.
Segment 1629: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1386, Text: I told my sister, I go, “When you were born, one of your eyes was bigger than the other, and you had to have surgery to fix it.” So she turns, she’s like, “Mom.” And my mom goes, “Honey, the important things that you’re beautiful now. It’s like, what’s the big deal? It was just a little surgery.” And I says like, “All right.” Calls grandma. And grandma goes, she goes, “Michael said that I was born one of the eyes.” She goes, “Why is he telling you this now? It’s not a big deal.” So the fact that everyone went with this…
Segment 1630: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1415, Text: Oh, nice.
Segment 1631: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1416, Text: I was so impressed. I was like, “This is a quality family in this very specific regard.”
Segment 1632: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1421, Text: Yeah.
Segment 1633: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1421, Text: Does your family have a sense of humor?
Segment 1634: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1423, Text: Yeah. Yeah. Yeah. Yeah. Yeah. Yeah.
Segment 1635: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1423, Text: Yeah.
Segment 1636: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1427, Text: Soviet culture, there’s a dark sense of humor.
Segment 1637: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1430, Text: Very much so.
Segment 1638: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1431, Text: There’s…
Segment 1639: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1432, Text: Wordplay.
Segment 1640: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1432, Text: Wordplay. Yeah. Yeah. And especially the Russian language allows for some-
Segment 1641: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1438, Text: Yes.
Segment 1642: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1439, Text: Hilarity to it. There’s also culture of poetry and my dad, my mom too, but they remember a lot of lines from books and poems. So you can do a lot of fascinating references that add to the humor and the richness of the conversation.
Segment 1643: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1458, Text: I feel like that’s a very Russian thing. At a party or maybe at a bar or something, I don’t know where you’d meet people, these are such great ice-
Segment 1644: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1458, Text: I never go out.
Segment 1645: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1465, Text: I meant in Russia.
Segment 1646: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1467, Text: Oh.
Segment 1647: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1467, Text: I meant these would be such good icebreakers, right? You go up to someone and goes, “Hey, did you hear this one?” [foreign language 00:24:32] And you just tell him some little story.
Segment 1648: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1474, Text: Did you say icebreakers because it’s cold in Russia? I’m here all night.
Segment 1649: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1482, Text: That’s true. You never leave the house.
Segment 1650: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1482, Text: Literally.
Segment 1651: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1486, Text: I feel like that’s a thing.
Segment 1652: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1487, Text: Yeah.
Segment 1653: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1488, Text: And that’s not a thing in America.
Segment 1654: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1491, Text: You mean like witty banter?
Segment 1655: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1493, Text: No. Meaning you go up to stranger and that’s your icebreaker. You tell them this little joke, and since everyone kind of has the same sensibilities, right away, you guys are chatting. I don’t think that’s a thing here.
Segment 1656: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1502, Text: Yeah.
Segment 1657: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1502, Text: I think here it’s more small talk, which.
Segment 1658: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1500, Text: … We’re chatting. I don’t think that’s a thing here. The thing here, it’s more small talk, which drives me crazy.
Segment 1659: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1505, Text: So what else are you thankful for?
Segment 1660: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1506, Text: Well, what’s something you’re thankful for?
Segment 1661: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1509, Text: Well, you went with family. I’m definitely thankful for family.
Segment 1662: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1512, Text: Okay.
Segment 1663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1512, Text: Yeah.
Segment 1664: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1514, Text: If I may ask, how do they react to you? You’re sitting down with Elon, you’re sitting out Netanyahu, sitting down with Kanye, all these big names. Are they expressing that they’re proud of you or is it more like, why haven’t you talked to this person?
Segment 1665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1530, Text: Yeah, more Michael Malice, please.
Segment 1666: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1534, Text: The people’s choice.
Segment 1667: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1536, Text: Yeah, They’re very proud. But they get argumentative and they’re just like a regular human being with whom I’m close and we just argue about stuff. They’re maybe not enough show the being proud of, but that part is just the nature of our relationship. It’s also the same with your parents?
Segment 1668: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1556, Text: Yeah. I don’t talk to my dad. That’s one of the reasons because there’s never ever any good job. And at a certain point it’s like, why am I trying to search for approval from someone I’m never getting it for? And from whom it wouldn’t mean anything at this point anyway.
Segment 1669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1574, Text: Well, that’s interesting. There’s a journey like that for a lot of people with their father or their mother. They’re always trying to find approval, and that’s life for a lot of people. That’s a really big part of the human condition is that relationship you have with your father, with your mother. I don’t know. It’s a beautiful thing whether it’s been a rough childhood or a beautiful one, all of it. That’s who you are. The relationship, especially early on in your life with your father or with your mother, is extremely formative.
Segment 1670: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1608, Text: Yeah. My dad taught me a lot of things at a young age that I’m very, very grateful for. He’s extremely intelligent, very flawed, and that’s fine. We all are, except for me. And it’s the kind of things that when you learn things at a right age, and this is one of the things I like about being older, is that when I’m friends with people-
Segment 1671: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1608, Text: Much older.
Segment 1672: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1629, Text: Much older, much older. When I have friends who are younger, it’s very easy for me to keep them from making the mistakes I did. So at least this is something I’m getting out of it is that, okay, I can’t fix these mistakes, but it just takes me 30 seconds and I can pull you back from making the mistake. So he’s taught me a lot as a kid, he really encouraged me very much to… He has a very good sense of humor and also very bad in some ways. Dad jokes, but also really funny jokes, but also this love of learning that I got that from him. And I have got literally right now, 98 books on my shelf to read. I remember I had a friend and she ran into someone she went to high school with and he stopped me on the train and he’s like, “Yo, you’re not in college. You don’t need to read books anymore.” And I was just horrified to hear this.
Segment 1673: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1680, Text: Yeah, yeah. Boy, don’t I know it.
Segment 1674: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1687, Text: You do laugh, but there’s a lot of things I don’t understand. When you got heat for, I want to read the Western Classics. To me, that might’ve been the internet at its absolute worst.
Segment 1675: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1701, Text: I think there’s just a cynical perspective you can take that this is such a simple celebration of a thing, that there must be something behind it. I think the internet for good and bad, is just skeptical. What’s behind this?
Segment 1676: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1716, Text: My hero, Albert Camus. And if there’s one thing I would want to fight, it’s cynicism because it’s such a giving up. It’s such, everything sucks, this sucks, this sucks. Most things suck. Most stand up comedians suck. Most movies suck. All podcasts suck. But it doesn’t matter.
Segment 1677: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1734, Text: Especially yours.
Segment 1678: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1735, Text: Especially mine. It’s unwatchable.
Segment 1679: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1738, Text: You’re welcome. You can’t even spell it correctly.
Segment 1680: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1743, Text: But the stuff that’s good is what matters. Who cares if 90% of movies are terrible? They’re the ones that change your life, the books, the people, the comedians, the shows, the music.
Segment 1681: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1757, Text: And even the terrible things have good moments, beautiful moments.
Segment 1682: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1762, Text: Some, not all.
Segment 1683: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1763, Text: Your podcast being an example of not all. I keep listening for something good, something good.
Segment 1684: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1771, Text: In all fairness, none of my guests have anything to offer.so that’s not on me. I try.
Segment 1685: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1777, Text: Yeah. Well, I wish you’d talk a little less in your podcast. It’s a little excessive. I only listen for the underwear commercials.
Segment 1686: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1786, Text: Sheathunderwear.com. Promo code Malice.
Segment 1687: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1788, Text: I haven’t seen you do it in a while, but this kind of commentary on a debate or I think it was with Rand, like an Ayn Rand debate or something.
Segment 1688: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1800, Text: Oh yeah. Malice at the Movies. I watched the video and I broke it down.
Segment 1689: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1803, Text: That was really great. I wish you did that more.
Segment 1690: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1805, Text: I haven’t done livestreaming in a long time. It was something I was doing a lot in New York, especially during COVID. I feel that I don’t know, I got so many projects on the plate. Oh, this is something else I’m thankful for. This is something I’m very, very thankful for and I’m going to announce it here.
Segment 1691: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1826, Text: Coming out of the closet, finally. Go ahead. Who’s the lucky guy?
Segment 1692: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1838, Text: You’re the one in drag.
Segment 1693: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1842, Text: Guns out. Guns out.
Segment 1694: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1845, Text: He makes me call him Sex Friedman.
Segment 1695: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1848, Text: You like it.
Segment 1696: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1850, Text: I didn’t say I did.
Segment 1697: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1852, Text: All right.
Segment 1698: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1852, Text: Didn’t even imply that. When I in, as you probably know as you know, but as many people watching this also know, Harvey Pekar who had the comic book series, American Splendor was the subject of the movie, American Splendor. He wrote a graphic novel about me in 2006 called Ego and Hubris, which goes for like $150 on eBay. It’s not worth it, just downloaded it. And I met Harvey because I wrote this screenplay about this band from the 80s called Rubber Rodeo. It’s a real band. And the keyboardist, Gary Leib, who passed away. Rest in peace, Gary. Introduced me to Harvey because he did the animation for the movie. And this script’s been in my desk for over 20 years, and I realized thanks to my buddy Eric July, who has some huge success with his comics, I could just produce this as a graphic novel.
Segment 1699: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1903, Text: So I’ve got an artist, we’re getting it together, so I’m going to make it happen finally. And it’s some of the best writing I’ve ever done. I’m really proud of the story. It’s ironic reading it now, because when you’re a writer, obviously different books, you put different aspects of yourself into them, and this story is very, very dark because basically they did all the right things and they went nowhere. What I realized was reading it now, that all these fears I had over 20 years ago about what if I’m not going to make it? What if I’m doing all the hard work and it’s still not enough? Now it’s been disproven because I can at least pay my rent.
Segment 1700: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1942, Text: Do you feel like you’ve made it because you said you could pay your rent.
Segment 1701: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1946, Text: I feel that to make it is if you don’t have to have a boss, and you know how I really felt like I made it?
Segment 1702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1956, Text: Mm-hmm.
Segment 1703: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1957, Text: This is going to sound like a joke, and it’s not. This is being an immigrant, I own as you know, Margaret Thatcher’s bookcases.
Segment 1704: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1965, Text: Yes.
Segment 1705: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1965, Text: So to me as an immigrant, to have her bookcases in my house, I’ve made it.
Segment 1706: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1971, Text: You’re right. It’s not a joke.
Segment 1707: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1973, Text: There’s nothing funny about it at all.
Segment 1708: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1975, Text: Not laughing.
Segment 1709: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1975, Text: It’s time to get serious.
Segment 1710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1979, Text: Oh, nice. Oh, now I’m more nervous and aroused. So what else are you thankful for? So we’re both thankful for family.
Segment 1711: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1990, Text: the fact that I can-
Segment 1712: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1991, Text: Still get it up?
Segment 1713: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1992, Text: What’s that?
Segment 1714: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1993, Text: Nothing, go ahead.
Segment 1715: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=1994, Text: I think as an author, to be able to write what you want and have of enough an audience that it covers your living, that’s as good as it gets as an author almost. You don’t need to be Stephen King or some legend. There’s lots of stand-ups who aren’t world famous, but they have perfectly good living. They do their gig, they do what they love. I feel very, very blessed. You must be thankful for your career?
Segment 1716: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2023, Text: Yeah, yeah. Career wise. But I think the best part about it’s just making friends with people I admire.
Segment 1717: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2032, Text: Okay.
Segment 1718: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2033, Text: Quite honestly, just friends. The people that have gotten to know me, I hide from the world sometimes, I hit some low points, especially with all the new experiences and just the people that have been there for me and haven’t given up on me.
Segment 1719: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2046, Text: There’s days, and I’m sure you’ve had this also where I literally don’t speak to someone the whole day. And in certain times in my life, I remember very vividly, I was in DC in ’97, I was an intern, and that summer, DC closes down on the weekends. And I remember those weekends when I got off the phone with the third person. I knew there was no possibility anyone was going to call and what that felt like, and it was dark and it was bad. So I remember those feelings of loneliness a lot.
Segment 1720: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2084, Text: I still feel alone like that sometimes. You don’t feel alone?
Segment 1721: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2091, Text: Not anymore.
Segment 1722: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2093, Text: What’s the reason, you think?
Segment 1723: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2097, Text: Because I have a lot of people who I care about and who care about me. The thing about moving to Austin is I forgot how lonely New York got because it was like one after another, I lost everybody. And then you start losing the places you go to, and then it was just like, “Holy crap. I’m very isolated.” And here in Austin, there’s not as much to do, obviously as in New York, but there’s a lot of people here. More people are coming all the time. So if I ever want to hang out with someone, I’ve got a long list. And these are people who I’ve known for a very long time, people who know me quite well, so I could be myself. My awful, awful, awful, awful self. And that is something I don’t take lightly.
Segment 1724: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2142, Text: Now you moved to Texas, it’s going to secede.
Segment 1725: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2144, Text: Yeah.
Segment 1726: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2144, Text: It’s just a very-
Segment 1727: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2146, Text: Do you know what happened with that?
Segment 1728: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2147, Text: No.
Segment 1729: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2148, Text: I forget the guy’s name, and it’s probably for the best. On Monday, a guy in the Texas legislature introduces a bill to have it on the referendum to have a referendum for Texas to declare its independence. Tuesday, I’m on Rogan. Me and him discuss it. I give it national attention. It was also really funny because a lot of people are like, “These people have been in Texas, five minutes, blah, blah.” I go to the Texas legislature, meet with the guy, have a nice conversation. A month or two later, unanimous, I think, he gets voted kicked out of Congress because he got an intern drunk and was inappropriate with her. At least it was a girl in this case. But yeah, so that was my little Texas independence moment.
Segment 1730: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2196, Text: Oh, it didn’t go anywhere?
Segment 1731: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2198, Text: It did not go anywhere.
Segment 1732: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2199, Text: Wow.
Segment 1733: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2201, Text: But it’s still part of the platform of the Texas Republican Party.
Segment 1734: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2205, Text: It’s fascinating that history is probably laden with stories like this of failed revolutionaries. We celebrate the heroes, but then there’s the losers like…
Segment 1735: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2215, Text: Myself.
Segment 1736: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2216, Text: Yeah.
Segment 1737: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2216, Text: Yeah.
Segment 1738: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2218, Text: And we’re going to mark that one as a failure and edit it out and moving on. So thankful. Friendships, right? But by the way, I want to say just to you, I’m thankful in these lonely moments, for people who write books. I’ve been listening to audiobooks a lot and reading a lot. I really like audiobooks actually. I don’t know, I can just name random person, Serhii Plokhy. He’s a historian I’m reading on the-
Segment 1739: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2248, Text: Wait, I read him. What did he…
Segment 1740: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2249, Text: It’s just he’s written a book most recently about the Russia-Ukraine war.
Segment 1741: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2255, Text: He wrote another one that I read. Didn’t he write about-
Segment 1742: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2257, Text: Empires, I think.
Segment 1743: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2258, Text: The fall of the Soviet Union or something like that.
Segment 1744: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2258, Text: Yeah, yeah.
Segment 1745: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2260, Text: Yeah. It was very, very good.
Segment 1746: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2261, Text: He’s great.
Segment 1747: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2262, Text: I used him as a resource for the White Pill.
Segment 1748: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2264, Text: He’s objective while still having emotion and feeling to it. He has a bias.
Segment 1749: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2269, Text: That’s fine.
Segment 1750: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2273, Text: A lot of times when you write a story that involves Putin, people are really ideological. They don’t write with a calmness and the clarity and the rigor of history, there’s emotion in it. There’s almost a virtue signaling. And he doesn’t have that, even though he is Ukrainian and has very strong opinions on the matter. Anyway, there’s people like that and he’s done an incredible job researching a recent event. Like he says, I was looking at everything that’s been written about the war in Ukraine and realizing the old Churchill line, that historians are the worst ones to write about current events except everybody else. And so he’s like, “I might as well just write about this war.” And he does an exceptional job summarizing day by day, the details of this war. Anyway. So I’m just grateful for a guy like that.
Segment 1751: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2330, Text: For me, I’ll name some historians I love. Arthur Herman, Victor Sebastyen is probably my favorite. David Pietrusza, P-I-E-T-R- U-S-Z-A. When you are a historian, and I try to do this to some degree in the White Pill as much as I could. But when you take data and you make it read like a novel, so you’re learning about who we are as people, what had happened, but also it’s entertaining and readable. That to me is like the Acme of writing. I have so much admiration-
Segment 1752: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2365, Text: What does Acme mean?
Segment 1753: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2367, Text: Top.
Segment 1754: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2367, Text: Okay.
Segment 1755: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2368, Text: Zenith.
Segment 1756: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2369, Text: Zenith? Okay. Is this what writers do? They just come up with these incredibly sophisticated words? I’m impressed.
Segment 1757: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2375, Text: Well, Acme is-
Segment 1758: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2375, Text: Because you could have just said the best of writing.
Segment 1759: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2378, Text: Acme is also the company in Bugs Bunny and Wile E. Coyote is always Acme, like Acme bombs. When they are that good, it leaves me in awe.
Segment 1760: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2392, Text: It’s just-
Segment 1761: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2393, Text: Ron Chernow is another one.
Segment 1762: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2394, Text: Who?
Segment 1763: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2395, Text: He wrote the Hamilton biography.
Segment 1764: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2397, Text: Oh, nice. Well, I have a lot of favorite historians about the whole time period of World War II, William Shirer, people that lived during it, especially. I really like those accounts. Obviously Soldier Knudsen, he’s not a historian, but his accounts are fascinating. Actually, how much do you talk about Soldier Knudsen?
Segment 1765: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2420, Text: Never.
Segment 1766: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2421, Text: Not much, right? Why not?
Segment 1767: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2424, Text: I feel like I wanted to. There’s nothing I could add to him.
Segment 1768: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2430, Text: But he’s the Michael Malice of the previous century?
Segment 1769: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2434, Text: No, he’s talented, charismatic, and skilled. So he’s not the Michael Malice. Yeah. I feel like I didn’t read Gulag Archipelago for the White Pill.
Segment 1770: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2447, Text: You didn’t?
Segment 1771: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2448, Text: I didn’t. No. I got a lot of it from Anne Applebaum, who’s a very controversial figure. Her history books on the Soviet Union, I think are superb, but she’s also accused of being very much a NeoCon and being a warmonger in contemporary times.
Segment 1772: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2462, Text: Oh, I see.
Segment 1773: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2462, Text: And I think comparisons between Putin and Stalin, although there is a Venn diagram, I think are a bit much, because I think it’s very hard to claim that if Putin conquered Ukraine, that there’d be a genocide. I think that’s a very hard argument to make.
Segment 1774: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2479, Text: In these tense times. Even the comparisons of what’s going on in Israel on either side, comparisons to the Holocaust are also troubling in this way.
Segment 1775: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2488, Text: Yes. And I also don’t like how that… I got in trouble. There was some literal demon who works at the Atlantic.
Segment 1776: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2496, Text: As opposed to a regular demon?
Segment 1777: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2498, Text: As opposed to figurative demon.
Segment 1778: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2500, Text: I didn’t know they employed demons.
Segment 1779: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2501, Text: They exclusively employ demons at the Atlantic. And he was giving me crap this a couple of years ago on Twitter because I didn’t think it’s appropriate to refer to George Soros as a Holocaust survivor. And I’m like, “Listen, if you want to put him in the same context as Anne Frank, knock yourself out.” But I think that’s so completely disingenuous and frankly repulsive to me morally to equivocate between figures like that. And also to claim that anyone who is a billionaire who is including Elon, including Sheldon Adelson, there’s no shortage of these people. If you want to use your extreme wealth, use it to influence politics, you have to be up for criticism, Bill Gates. To protect these people from criticism just on the base of their identity is deranged to me.
Segment 1780: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2555, Text: But also, the Holocaust as a historical event and the atrocities within it are just singular in history. And so comparing them…
Segment 1781: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2567, Text: What’s the utility? You’re just basically trying to take this brand. I’m using that term in a very specific way. And when they say climate denial, no one’s denying climate exists. So you’re just trying to go off Holocaust denial. I think it’s shameless and I think it’s gross.
Segment 1782: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2584, Text: And it cheapens everything because there’s deep important lessons about the Holocaust.
Segment 1783: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2589, Text: Yes.
Segment 1784: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2590, Text: To me, the lessons are about how extreme it can get.
Segment 1785: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2595, Text: And how fast.
Segment 1786: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2597, Text: Yeah, and how fast.
Segment 1787: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2597, Text: That’s the one. So people ask, “Oh, are humans basically good? Are they basically evil?” I always say they’re basically animals. And I think most people are almost fundamentally deranged. And that there’s basically this veneer of civilization and decency. And when shit hits the fan and we see this over and over, they do things that would’ve been completely unthinkable even to themselves five years ago.
Segment 1788: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2626, Text: Most people are fundamentally deranged with a veneer of civility.
Segment 1789: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2630, Text: There’s a show called-
Segment 1790: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2631, Text: I Think I disagree with that.
Segment 1791: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2633, Text: What’s the show called? I’m having Alzheimer’s because of the advanced age.
Segment 1792: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2638, Text: The age, the skincare. It’s just working well.
Segment 1793: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2640, Text: There’s a show called, I Think You Should Leave. It’s a sketch comedy.
Segment 1794: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2640, Text: I think you should leave. Okay, sorry.
Segment 1795: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2644, Text: It’s a sketch comedy show. And he captures these great… How’s your hair, princess? He captures these great moments of just the very thin veneer of normalcy and just the craziness that’s so frequently lurking underneath. Another great example of this, when this is dealing with people who are literally crazy, have you ever seen the show, Hoarders?
Segment 1796: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2667, Text: Yeah.
Segment 1797: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2667, Text: So every episode of Hoarders, there’s usually two people in every episode, but every episode has the same plot line, veneer of normalcy, veneer of normalcy, veneer of normalcy, slight expression of concern, full-blown derangement. And it always follows that exact pattern.
Segment 1798: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2684, Text: Yeah, I don’t know. I think the deep ocean of the human mind is good. There’s a longing to be good to others.
Segment 1799: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2696, Text: I have seen literally no evidence of this. And I know everything’s a deep ocean with you people, but-
Segment 1800: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2701, Text: What do you mean you people?
Segment 1801: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2702, Text: Pirates.
Segment 1802: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2704, Text: Oh.
Segment 1803: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2705, Text: I don’t see it.
Segment 1804: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2705, Text: What’s that Mr. Parrot? He’s an antisemite/ No, that’s not nice to say in front of such a large audience. You’re embarrassing me, Mr. Parrot.
Segment 1805: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2718, Text: Lex, you have-
Segment 1806: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2719, Text: What’s that Mr. Parrot? He’s a run-of-the-mill troll and barely an intellectual. That’s not nice to say. That’s not true. We talked about this. You have to see the good in people.
Segment 1807: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2731, Text: You have seen personally, how quickly and easily it is for human beings to form outgroups and to just rid others, as I just did a minute ago with the Atlantic, completely out of the human race. And that happens constantly and very easily. Humans are tribal beings. I don’t see how that’s compatible with this essential desire to do good.
Segment 1808: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2758, Text: No, I think it’s like in 1984, the two minutes of hate. There is a part of humans that wants to be tribal and wants to get angry and hateful. And then that hate is easy to direct by, especially people as you, as an anarchist, talk about, there are people in power that direct that anger.
Segment 1809: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2780, Text: Yes.
Segment 1810: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2781, Text: But I think if you just look at recent human history, the desire for good, the communal desire for good outweighs that, I think. Most of life on earth right now, people are being good to each other in a most fundamental sense relative to how nature usually works.
Segment 1811: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2800, Text: Okay. I think you’re both wrong about people and about nature. So nature is not inherently violent in the sense, for example, if anyone has an aquarium or if you look at wildlife, yeah, you’re going to have predator or prey, but these animals are going to be coexisting and they’re going to be ignoring each other for the most part, right?
Segment 1812: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2800, Text: Mm-hmm.
Segment 1813: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2819, Text: And as for humans being essentially good, I think humans are essentially to each other, you said, I think they’re essentially civil and amiable, but that’s not really being good.
Segment 1814: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2832, Text: Good, I think is a thing that gets illustrated when you’re challenged, when there’s difficult situations.
Segment 1815: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2837, Text: Yes, exactly. Yes.
Segment 1816: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2838, Text: Civility is a good starting point. And then when there’s a big challenge that comes, people step up on average.
Segment 1817: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2846, Text: I completely agree with you that human beings are capable of such profound goodness, that it makes you extremely emotional. And I certainly think that’s that’s true, but I think that’s more unusual than it’s the norm.
Segment 1818: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2862, Text: I see beauty everywhere.
Segment 1819: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2863, Text: So do I, but that doesn’t mean it’s in every person.
Segment 1820: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2866, Text: Not in every person, but in most people. I wish there was a really good way to measure this, my general sense of the world. It’s just there’s so much incredible both in terms of economics, in terms of art, in terms of just creation as a whole, that’s happened over the past century, that it feels like the good is out powering the bad.
Segment 1821: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2889, Text: You just did the perfect segue to the box.
Segment 1822: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2896, Text: What’s in the box? Is it your fragile ego?
Segment 1823: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2901, Text: You stole my joke. You stole my joke. That was the joke I made at you before we recorded. You stole my joke.
Segment 1824: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2908, Text: No, I didn’t. I write all your material, you hack.
Segment 1825: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2913, Text: So as you know, I have a lot of beautiful stuff in my house because I think it’s something very important. Everyone listening, if you accomplish something that is great, some achievement, what I like to do is buy myself something to remember that moment. Because sometimes when it’s hard, you forget you’ve done great things in your life. You’ve made accomplishments. It doesn’t have to be some amazing factory. It could just be like my first job or I got a raise or you know what? Anything. So there’s this amazing sculptor named Jake Michael Singer, a singer who’s a sculptor, and I saw a piece of him.
Segment 1826: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2958, Text: How’s his singing voice? This joke’s not going-
Segment 1827: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2963, Text: Hold on. I could go somewhere with this.
Segment 1828: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2964, Text: Okay.
Segment 1829: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2965, Text: How’s his singing voice?
Segment 1830: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2966, Text: Do you want me to write your joke for you?
Segment 1831: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2967, Text: Yeah. What’s the punchline? Harrrd. There it is, that’s the one.
Segment 1832: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2973, Text: That’s what she said.
Segment 1833: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=2974, Text: So I followed him on Instagram, he followed me back and he says, “What’s the point of being an artist if the work I create isn’t in the spaces of people I like and admire?” He’s a big fan of yours. You’ve given him and our episodes together give him joy. So he said, “If I make Lex a sculpture, will he put it on the-“
Segment 1834: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3000, Text: He said, “If I make Lex a sculpture, will he put on the shelf behind him?” And what that reminded me of is when I was a kid, you read Batman comics and there’s the Bat Cave. And the Bat Cave has all this cool stuff in it. I didn’t realize until much later that all of those things in the bat cave had an origin story. So the giant penny, the dinosaur, there was actually a story where that came from. So if you’re a fan of a show, you can spot, oh, this is when this appeared. This is when that appeared. This is when that appeared. So he made you this sculpture. He lives in Turkey and it’s called Chance Murmur. And it is, I haven’t even seen it yet. It is absolutely beautiful.
Segment 1835: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3042, Text: So you want to do a little unboxing?
Segment 1836: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3042, Text: Yes.
Segment 1837: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3044, Text: Okay. Axe or…
Segment 1838: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3049, Text: Body spray?
Segment 1839: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3054, Text: All right.
Segment 1840: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3054, Text: Let’s do it.
Segment 1841: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3055, Text: Let’s unbox.
Segment 1842: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3059, Text: I’m so excited. He lunges out of the box.
Segment 1843: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3064, Text: You know that Steven Seagal movie where there’s a stripper that comes out of the box?
Segment 1844: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3067, Text: Is there?
Segment 1845: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3068, Text: Under Siege.
Segment 1846: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3069, Text: Okay.
Segment 1847: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3069, Text: He’s on a boat. You’re not an action film guy.
Segment 1848: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3074, Text: No.
Segment 1849: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3079, Text: One.
Segment 1850: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3081, Text: What does the pirate say when he turns 80?
Segment 1851: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3084, Text: What?
Segment 1852: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3085, Text: Aye matey.
Segment 1853: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3089, Text: Aye matey. Oh.
Segment 1854: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3092, Text: Oh.
Segment 1855: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3093, Text: See, that’s how I know you don’t like humor.
Segment 1856: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3095, Text: I just don’t like pirates.
Segment 1857: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3097, Text: Well, your mom does.
Segment 1858: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3099, Text: Do you play any musical instruments?
Segment 1859: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3100, Text: No. Neither do you. I’ve seen your guitar videos.
Segment 1860: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3106, Text: Okay.
Segment 1861: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3108, Text: Here’s a big piece of wood for you. That’s what it feels like, just so you know.
Segment 1862: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3117, Text: Oh, wow. Do you need help?
Segment 1863: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3117, Text: Oh my God.
Segment 1864: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3120, Text: This traveled across the world.
Segment 1865: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3125, Text: So here’s why his work speaks so much to me. So first of all, he’s combining so many different references. It’s Nike, the Goddess of Victory, right? It looks like an angel as well. The Italian futurist, which is my favorite art movement from the early 20th century, they tried to capture motion in 2D or 3D form.
Segment 1866: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3151, Text: Well, Jake, thank you, thank you, thank you. Thank you for creating beautiful things. Thank you for caring about somebody like me and somebody like Michael. We really feel the love.
Segment 1867: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3163, Text: That’s the other thing.
Segment 1868: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3163, Text: Thank you.
Segment 1869: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3165, Text: When you have something that matters to you in your house and you’re having a bad day, you can look at it and remember. You know what I mean? That spirit of joy. And I actually have a list here. Okay? I’ve got a little rant ready. Do you want to hear my rant?
Segment 1870: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3180, Text: Yeah. Let’s go.
Segment 1871: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3182, Text: One of the things that drives me crazy is when people, especially conservatives, think that all contemporary art is ugly or abstract or literally garbage. And there’s a lot of that, but so much of the stuff out there in galleries is not only not crazy expensive, but they’re trying to sell things for people in their house. And these are young artists. They’re trying to add beauty. I have a list, so if you don’t believe me and you think all contemporary art is garbage or terrible, go to the website or any of these places that I’m going to rattle off, look through them. And you’re telling me that it’s not about creating beauty and joy and things in people’s lives?
Segment 1872: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3220, Text: So I don’t have any relationship with any of these people, these are just some galleries I follow on Instagram. Outre Gallery, Antler Gallery, Giant Robot 2, Beinart, I don’t know how to pronounce it, I’m sorry. B-E-I-N-A-R-T. Spoke Art Gallery, Var Gallery in Milwaukee, I was there. The pieces were not expensive at all.
Segment 1873: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3238, Text: What kind of art are we talking about? Everything? Paintings?
Segment 1874: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3240, Text: Mostly paintings. Mostly paintings. Some sculptures too, like this. Corey Helford is my favorite one in LA. Night Gallery, Vertical Gallery, Avant Gallery, Hive Gallery, Haven Gallery, and Curio Art Gallery. I’m telling you, it’s not exorbitant. This is not the kind of thing where you have to go to a museum and be like, “This doesn’t make sense to me.” You look at it right away, you’re like, “Okay, I know what this is.” And it’s beautiful. It’s awesome. And you’re supporting someone who’s young and creative trying to do something and make the world a better place.
Segment 1875: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3271, Text: So I’m a big fan of the contemporary art scene. A lot of it is not great, but even the stuff that’s not great is very rarely disgusting or gross. It’s just like, okay, I’ve seen this before, or something like that.
Segment 1876: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3283, Text: Okay.
Segment 1877: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3284, Text: It’s like the difference between, there’s a standup where I’ll pay money for the ticket, and someone who’s an opener. It’s like, I wouldn’t pay to see him perform, but he sure still made me laugh. That person is still by far more good than bad. So a lot of this art isn’t stuff I would own, but it’s like, okay, I get it. I like it.
Segment 1878: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3301, Text: Well, as the analogy goes, I really like going to open mics, actually, because funny… It sounds absurd to say, but funny isn’t the only thing that’s beautiful about standup comedy, it’s the…
Segment 1879: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3314, Text: The agony.
Segment 1880: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3317, Text: It’s going for it. It’s trying to be funny. It’s taking the leap, trying the joke. And some of the best stuff is actually funny, but the audience is like three people, two of whom are drunk and bored, and you’re still going for it. And that’s the human spirit right there.
Segment 1881: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3335, Text: Roseanne was telling me how Gilbert Gottfried would go on, it was like 3:00 in the morning. And it was her and three other comics in the audience and they all were just dying.
Segment 1882: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3346, Text: Yeah.
Segment 1883: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3346, Text: He was just killing them. Who’s your favorite comedian?
Segment 1884: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3353, Text: Dave Smith.
Segment 1885: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3354, Text: Who?
Segment 1886: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3356, Text: And cut scene. Favorite comedian. First, Norm Macdonald. If you put a gun to my head and I had to answer really quickly, that would be him.
Segment 1887: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3364, Text: Okay.
Segment 1888: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3367, Text: I would also say Louis C.K.
Segment 1889: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3369, Text: Oh, wow. Yeah. Oh my God, yes.
Segment 1890: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3372, Text: But that’s almost like a vanilla answer at this moment in history because it’s like a-
Segment 1891: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3376, Text: Louis C.K.’s pretty radioactive.
Segment 1892: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3378, Text: He is. Well, yeah. He does the tough topics-
Segment 1893: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3381, Text: Sure.
Segment 1894: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3382, Text: … the best. Mitch Hedberg. The wit of a good one-liner is great. I guess that’s what Norm Macdonald was a genius at. What about you?
Segment 1895: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3393, Text: I mean, we’re so fortunate to be here in Austin because that Comedy Mothership, you go there and people are just killing it. David Lucas is amazing.
Segment 1896: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3403, Text: Yeah, he’s great.
Segment 1897: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3403, Text: Thai Rivera probably did the best set I’ve seen since I’ve been here in Austin. And I watched him and I’m like, “This guy’s even bitchier than I am.” So I reached out to him. So he’s just terrific. David Lucas is another one, a buddy of mine.
Segment 1898: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3417, Text: You just said it twice, I think. David.
Segment 1899: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3420, Text: I’m thinking of Dave Landau, excuse me.
Segment 1900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3421, Text: Yeah.
Segment 1901: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3421, Text: Dave Landau. Joe Machi is-
Segment 1902: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3424, Text: Old age catching up.
Segment 1903: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3424, Text: It’s true though.
Segment 1904: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3425, Text: It’s true.
Segment 1905: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3426, Text: It’s true.
Segment 1906: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3427, Text: It’s true.
Segment 1907: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3428, Text: Dave Lucas.
Segment 1908: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3430, Text: You ever been to the Comedy Mothership? It’s a great spot.
Segment 1909: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3433, Text: Where is that? Is that in Austin?
Segment 1910: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3435, Text: Austin? Is that where Willie Nelson is from? I haven’t really… Go ahead, I’m-
Segment 1911: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3439, Text: Oh, I heard a joke about that the other week.
Segment 1912: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3443, Text: Go ahead. Tell a joke again.
Segment 1913: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3445, Text: What’s the only thing worse than giving head to Willie Nelson?
Segment 1914: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3451, Text: What?
Segment 1915: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3452, Text: If he says, “I’m not Willie Nelson.”
Segment 1916: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3456, Text: What’s that, Mr. Parrot? I know he’s not funny. He thinks he’s better on Twitter. But that’s not nice to say, and right in front of his face. Just think how he feels.
Segment 1917: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3469, Text: The statue, Chance Murmur is judging you.
Segment 1918: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3472, Text: Chance?
Segment 1919: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3472, Text: It’s called Chance Murmur.
Segment 1920: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3474, Text: Chance Murmur.
Segment 1921: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3475, Text: God, that’s so beautiful.
Segment 1922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3476, Text: That is gorgeous.
Segment 1923: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3478, Text: This is another reason I hate cynicism, and I talk about this a lot. Even just on Etsy, there are so many small, not huge companies, individual artisans who are creating great stuff and just making it happen. And it’s really sad for me where people can’t see that. Or if they’re like, “Well, how could I be excited about a sculpture when blah, blah, blah, the Middle East?” And it’s just like, you can always look for an excuse not to look for joy, or you could look for an excuse to look for joy.
Segment 1924: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3506, Text: Yeah. Etsy is incredible. I feel the same way about-
Segment 1925: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3508, Text: OnlyFans?
Segment 1926: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3510, Text: … OnlyFans. I can’t even get that out of my mouth before laughing at my own failed joke.
Segment 1927: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3514, Text: That’s what she said.
Segment 1928: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3516, Text: Oh, all right. That might be one of the first that’s what she said from Michael Malice.
Segment 1929: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3523, Text: Yeah.
Segment 1930: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3523, Text: I’m going to count that.
Segment 1931: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3528, Text: I don’t know what I’m going to do with mine, because I got my own. Mine’s three feet tall, just like me.
Segment 1932: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3532, Text: Your box was much bigger.
Segment 1933: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3533, Text: Yeah.
Segment 1934: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3534, Text: And it was giving me an inferiority complex. I think I’m going to invade Russia. That’s a Napoleon reference for those in the audience.
Segment 1935: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3549, Text: I don’t know if I’m going to… I think I’m going to put it in my bedroom so it’s the first thing I see when I wake up.
Segment 1936: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3553, Text: Put it in the bedroom.
Segment 1937: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3553, Text: Yeah.
Segment 1938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3556, Text: Did we get through everything we’re thankful for?
Segment 1939: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3559, Text: No, I’ve got lots of things I’m thankful for.
Segment 1940: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3560, Text: What else? Friends, family. We said books.
Segment 1941: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3566, Text: I’m thankful for career. I am thankful for… And I know people are going to lose their minds and I can hear them flipping out already. I am thankful for social media.
Segment 1942: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3580, Text: Yeah.
Segment 1943: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3581, Text: I’m thankful for several reasons. First, it is a way for people to make connections that they couldn’t have made in years past. That if you’ve got some weird hobby, you can find that other person’s weird hobby and you make that connection. It’s a great way to stay in touch permanently for people otherwise you’d lose touch with, you know, at whatever venue. And it’s also a great way to expose corporate depravity. When you have these organizations that are dishonest, I think the community notes thing on Twitter is the greatest thing ever.
Segment 1944: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3609, Text: Yeah, it’s incredible. I wish they would pay attention to the Michael Malice account more often.
Segment 1945: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3615, Text: You shouldn’t be encouraging anyone to pay attention to my Twitter account.
Segment 1946: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3618, Text: Yeah.
Segment 1947: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3618, Text: It’s a dumpster fire. And I don’t mean Bridget, I mean like a literal… Bridget Phetasy.
Segment 1948: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3623, Text: Oh, Bridget, by the way, is amazing. But your Twitter account makes-
Segment 1949: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3623, Text: She lives here.
Segment 1950: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3625, Text: Yes. Not here. I wish she did.
Segment 1951: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3629, Text: She’s in Georgetown.
Segment 1952: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3630, Text: No, I mean in this, where we’re sitting.
Segment 1953: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3632, Text: Oh.
Segment 1954: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3632, Text: It’s a joke, Michael.
Segment 1955: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3633, Text: Is it?
Segment 1956: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3634, Text: Yeah.
Segment 1957: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3634, Text: But I’m just really glad about… It’s another way for people who before would’ve felt very alone. I know some people do feel alone, but for other people it makes them feel connected.
Segment 1958: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3646, Text: There’s been a lot of talk about antisemitism recently.
Segment 1959: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3649, Text: Yeah.
Segment 1960: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3649, Text: What’s your sense about this? Is antisemitism like any other brand of hate? There’s a lot of hate out there.
Segment 1961: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3657, Text: No, I don’t think it’s like any other brand of hate, because I don’t think racists or transphobes or homophobes or misogynists or xenophobes argue openly or even not so openly for the killing of black Americans, transgender people, gay people, women, or immigrants. And it’s not only something that’s talked about, it’s something that has actually happened. And not just the Holocaust, but just centuries of pilgrims, right? There’s this great book that I read many years ago called The Satanization of the Jews. Camille Paglia recommended it and I read it. And they live in this certain specific kind of antisemitism. And again, I’m not talking about people who are against Israel or something like that. I’m talking specifically about Jew hatred. They have this moral calculus that Jews are the only people who are capable of good or evil, and Jews are exclusively capable of evil.
Segment 1962: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3716, Text: For example, if you look at the George W. Bush White House, you had W, you had Cheney, Condoleezza Rice, Colin Powell, Donald Rumsfeld, a lot of these NeoCon advisors. So if there’s 10 people in a room and there’s one Jewish person, it’s his fault, and the rest are Jew controlled. So again, they only exist as a puppet of Jews in this kind of worldview. And it’s like, to me, if there were no Jews on earth, it is crazy to say that John Bolton and Liz Cheney and Lindsey Graham wouldn’t be pushing for more war. That makes no sense to me. It’s like, you blame the Jews when bad things happen, but when a Jewish person does something good, it doesn’t really matter. Or just wait, he’s going to do something bad. Well, yeah, that’s true. Human beings do good things and then they do bad things sometimes. But it only counts when that Jewish person does the bad thing.
Segment 1963: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3778, Text: I wonder what’s a way to fight antisemitism and fight hate in general?
Segment 1964: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3782, Text: I think the only or the best way, because I thought a lot about this, about how did gay Americans go from being universally hated and despised to the point that many people in the ’80s went to their graves, those who had AIDS, without even telling their parents because they were so scared, to now Times Square is just covered in pride flags. And this also works for Islamophobia and some of these other bigotry, is what I call the ambassador program. Because as soon as you know someone who is a member of a certain group, it is a lot harder to be bigoted against them because instead of this being this out group that’s somewhere out there, it’s like, wait a minute, I work with this guy. Yeah, he’s kind of a jerk and maybe he sees things a little differently than me, but this guy is not a horrible human being. So I think the only way to fight any form of bigotry is to be a good example of the counter to whatever archetype or stereotype is in the culture.
Segment 1965: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3853, Text: Karl Marx wrote that, “Religion is the sigh of the oppressed creature, the heart of a heartless world, and the soul of a soulless condition. It is the opium of the people.” As the famous phrase goes. Do you think he has a point?
Segment 1966: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3866, Text: No. I hate that quote. I absolutely hate it. I despise this sort of Reddit internet atheist activism for the simple reason that I know many people who in finding faith have become objectively better human beings.
Segment 1967: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3886, Text: Yeah.
Segment 1968: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3886, Text: They start living consciously. They take morality seriously. They try, we all fail, to be moral good people. So this sneering that these midwits, these marginally intelligent people have towards religious people. Now, lots of religious people use religion to rationalize their bad behavior or sinful or big ego, so on and so forth. That exists, that’s true. But to say that it never helps anyone and it’s universally the… See, Marx was talking about a period, I mean, I’ll defend his quote, when his argument was the masses are being starved and oppressed, but they’re promised, don’t worry, you’ll have riches in heaven. So you should kind of let yourself be pushed around now, and this is kind of this BS bargain that the people are being given. So that was, I think, the point he was making. It certainly doesn’t apply nowadays. I’m close to the family in the Midwest. They’re good Christian people. I remember very specifically this guy, shout out to him, Sean Sherrod. I went to college with him. David Lucas.
Segment 1969: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3961, Text: Have you checked out the Comedy Mothership? Great club.
Segment 1970: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3963, Text: Where is it? Is it in Austin?
Segment 1971: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3965, Text: Willie Nelson.
Segment 1972: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=3967, Text: I was 17, 18, freshman year, and I was reading all this criticism of the Bible and I was like, “Look, this is in there. Look at this in there.” And he put his hand on my shoulder and he says, “Michael, there’s nothing you’re going to tell me that’s going to make me lose my faith.” And that was a very self-aware and profound thing to say. As I’ve gotten older, I know lots of religious people. There’s no part of me that thinks they’re wrong or they should be mocked. It also reminds me of when people sneer at addicts in recovery, they’re like, “Alcoholism isn’t a disease, it’s a choice.” It’s like, wait a minute. You don’t know what it’s like to have your entire life ruined by drugs or alcohol.
Segment 1973: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4008, Text: Yes.
Segment 1974: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4009, Text: And if you have to tell yourself, “I have this disease and blah, blah, blah,” and that keeps you from drinking and now you’re a moral upstanding person who’s reliable and takes responsibility for their actions, I don’t see the harm at all. So I think this kind of activist atheism is cheap. I don’t agree with it whatsoever. And I do not like that quote at all.
Segment 1975: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4032, Text: But otherwise, big fan of Marx?
Segment 1976: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4034, Text: I mean, I think there’s a fan of mine, I forget who it was, apologies. He had this great quote, and this is me talking. He goes, “The games people play to feel smarter than others is depressing and annoying.” And I think this kind of fedora internet atheism is a good example, because here’s the other thing. If you’ve proven that someone else is stupid, that doesn’t mean you’re smart. You could both be stupid. So congrats, you proved someone else is stupid. Who cares?
Segment 1977: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4063, Text: Yeah. And sneering of all forms in general is just not great.
Segment 1978: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4068, Text: That’s one of the things I block out people on social media instantly. You’re not going to sneer at me in my space. You could sneer at me all you want in your space, but I’m not putting up with your crap. I don’t know you.
Segment 1979: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4077, Text: MySpace, great social network.
Segment 1980: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4080, Text: Is that on Sixth Street?
Segment 1981: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4084, Text: AOL.com.
Segment 1982: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4087, Text: Clang, clang, clang. That’s how Lex comes.
Segment 1983: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4092, Text: Like a Pavlov’s dog. That was the sound before you get to see… Spend 10 minutes waiting for an image of a lady load one line at a time.
Segment 1984: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4104, Text: Yeah.
Segment 1985: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4109, Text: I recently talked to John Mearsheimer, I don’t know if you know him at all. So he has this idea about offensive realism. It’s a way to analyze the world into national relations. And the basic idea, and I’ll run it by you and see what you think, is that states, nations want to survive and they try to do so by maximizing power, military power. And he talks about anarchy quite a bit, in that one of these underlying assumptions of this way of viewing the world is that states are anarchic towards each other.
Segment 1986: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4150, Text: Yes, that’s true.
Segment 1987: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4151, Text: And they operate under a lot of uncertainty. States cannot be sure that other states will not use military capabilities against them.
Segment 1988: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4158, Text: Right.
Segment 1989: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4159, Text: They want to survive and they want to use military power to control the uncertainty to protect themselves.
Segment 1990: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4169, Text: So I disagree in that regard. And I see on your bookshelf, I think the world is a lot closer to Brave New World than it is to 1984. And I think if you look at, let’s suppose China’s influence in America. The influence is far more through soft power than military power. China doesn’t threaten America through “we’re going to kill you.” It’s more like the infiltration of universities, TikTok, things of that nature. Maybe this would’ve worked before the pop culture era, but I think one of the reasons we have this kind of American hegemony isn’t just a function of American military. I think it’s much more a function of American popular culture. When you’re exporting ideas and culture, it makes other people in other countries feel closer to you and also regard you as a friend, and also to adopt your value. It’s a great way to spread propaganda.
Segment 1991: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4228, Text: It seems to correlate though, right? It’s interesting. It’s an interesting idea. What has more power, the viral spread of ideas or the power of the military? It seems that the United States is at the top of the world on both.
Segment 1992: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4244, Text: That’s true.
Segment 1993: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4245, Text: And so it’s hard to disentangle the two.
Segment 1994: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4248, Text: Let’s look at Europe. American culture is very popular in Europe in many ways, right? The best music comes out of Sweden, Swedish indie pop. They’re singing in English, even though… So on and so forth. None of this is a function, maybe it’s a function of post World War II to some extent, but I don’t think it’s a function of American bases there. I think it’s a function of we’re exporting our music, our TV shows, and our movies.
Segment 1995: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4274, Text: Yeah. It’s interesting, if the battleground will be Brave New World, the battle of ideas.
Segment 1996: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4278, Text: I think it’s clearly Brave New World. It’s so much cheaper, and again, this is one of the dark sides of social media, to use influence than it is to use threats. I think Covid is a good example of this. So much of the pressure, yes, there was authoritarianism, but it was the fact that everyone bought into it, rightly or wrongly. But the vast majority of the population wars behind all of these things, and that was through persuasion. And because people are begging for it to come back in many cases.
Segment 1997: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4307, Text: So who’s funding you? Which intelligence agency?
Segment 1998: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4310, Text: Mossad.
Segment 1999: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4311, Text: Mossad. Mossad. This is how you do great interviewing. See, he didn’t even expect that. Okay.
Segment 2000: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4321, Text: What’s that, Mr. Parrot?
Segment 2001: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4322, Text: What was that, Mr. Parrot? You knew it? But you didn’t have any documentation, did you?
Segment 2002: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4330, Text: I think Mr. Parrot is threatened by the better wings on Chance Murmur.
Segment 2003: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4335, Text: He gets like that when he’s turned on, he’s not threatened.
Segment 2004: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4338, Text: Oh, okay.
Segment 2005: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4338, Text: You can’t wait until all three of us are alone together. It’s going to be one hell of a party.
Segment 2006: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4345, Text: Beaks and feathers everywhere.
Segment 2007: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4347, Text: And metal. Yeah, this thing is beautiful.
Segment 2008: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4352, Text: It’s ridiculous.
Segment 2009: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4354, Text: You have actually a lot of really cool stuff at your place.
Segment 2010: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4357, Text: It’s so fun.
Segment 2011: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4359, Text: What’s a cool thing that stands out to you? Maybe a recent addition.
Segment 2012: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4364, Text: So I went to the Dallas Museum of Art last year for my birthday and there was a painting I liked, and I Googled it and I saw the auction for that exact painting. And it was, I think three grand, which is not cheap, but not something you think… You think in a museum, “I could never afford something like this,” right? So when I went to Houston with some friends… The Sideserfs, Natalie, who made the cake of you.
Segment 2013: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4394, Text: Oh, yeah, the cake. Terrified my mom.
Segment 2014: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4397, Text: Did it?
Segment 2015: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4398, Text: Yeah.
Segment 2016: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4398, Text: Aww.
Segment 2017: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4399, Text: No, it’s not the cake that terrified my mom. It’s you, Michael Malice, cutting it off, cutting the face off and laughing maniacally.
Segment 2018: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4410, Text: Well, Natalie’s pregnant. She’s going to have a daughter named Daisy. So congrats to Natalie.
Segment 2019: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4410, Text: Congrats to Natalie.
Segment 2020: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4415, Text: But I was in the museum with them and there was a statue of Thoth, who’s the Egyptian god whose head is an ibis. It’s a bird with a long beak. And Thoth is the god of the moon, god of knowledge, and supposedly he invented writing. So I thought, you know what? I’ve always loved Ancient Egypt. I know a lot about it and especially the mythology. It’d be really cool as an aspiring author to have an ancient Egyptian Thoth statue in my house. Well, it turned out that the Egyptians also killed and mummified ibises and buried them with scribes. And a week after I went to the museum, there was an auction for an ibis mummy. And I have it now in my house, still in its bandages, overlooking my desk. And we all know it’s going to come to life and peck out my eyes and write with my blood. But that is one of the recent cool additions.
Segment 2021: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4471, Text: Another thing I have, which is like, in terms of holy crap I’ve made it. I have an original Patrick Nagel painting, and if people don’t know the name, he’s like the ’80s artist. He did the Duran Duran cover. Whenever you see him in nail salons. I have a male, which were very rare for him to do. So that’s two of my kind of favorite pieces.
Segment 2022: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4489, Text: You have what?
Segment 2023: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4489, Text: He only drew women predominantly. I have one where we drew a male. It was a guy in a jean ad or something. And now I’m looking forward to, so Jake made me a three-foot tall sculpture called Future Murmur, which I am ecstatic-
Segment 2024: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4500, Text: … sculpture called Future Murmur, which I am ecstatic to get.
Segment 2025: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4506, Text: Just remind yourself how many fascinating, beautiful people that are out there.
Segment 2026: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4514, Text: And just the victory and holiness and technology and speed, and how many people have fought so that I could do what I do.
Segment 2027: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4526, Text: Yeah. That’s another thing I’m grateful for. Just like the 100 billion or so people that came before us, and also the trillions of lifeforms that came before that.
Segment 2028: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4538, Text: Oh God, I’ve gone down this trilobite rabbit hole, buying fossils because as a kid I thought trilobites were the coolest thing, and now I’ve got like 15. And what’s interesting is when you buy trilobite fossils on eBay, they’re listed as used, because it’s got to be new or used according to the programming. So it’s used.
Segment 2029: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4557, Text: Yeah. But just thinking about all that history, just all the lifeforms that came before. It seems like a really special thing we have going on earth here.
Segment 2030: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4570, Text: Oh yeah. I think that’s very fair to say, but also think this kind of is like live life to the fullest. Camus talked about living to the point of tears, especially on behalf of people who didn’t have that privilege. So I dedicated the white pill to my parents who got me out of the Soviet Union and all the kids who never could. And it’s like when I die, I want everyone else to not only, they’re obviously going to be happy, but yeah… I’m not here. Live for me, I can’t have that privilege anymore.
Segment 2031: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4604, Text: What do you think about Camus as a writer?
Segment 2032: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4607, Text: I don’t like his novels at all.
Segment 2033: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4609, Text: Oh, you don’t?
Segment 2034: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4609, Text: At all.
Segment 2035: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4610, Text: Yeah. You’ve talked about The Plague to me, a little bit.
Segment 2036: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4612, Text: Yeah. I think the book is pointless.
Segment 2037: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4615, Text: It’s fascinating.
Segment 2038: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4616, Text: Because all you need to do is read the synopsis and then you get it. I don’t think his book-
Segment 2039: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4620, Text: Isn’t that true for most books?
Segment 2040: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4621, Text: No.
Segment 2041: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4622, Text: I mean, you could take, I don’t know… I just don’t agree at all. I mean, it’s Catcher in the Rye. There’s a lot of books that are seem trivial.
Segment 2042: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4631, Text: I don’t think it seems trivial, but I think-
Segment 2043: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4633, Text: Animal Farm.
Segment 2044: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4635, Text: Animal Farm is a methodical step-by-step examination of a transformation from one thing to another. The Plague is not that.
Segment 2045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4643, Text: It’s a methodical examination of what a society is like under the plague, which could symbolize a lot of things, including the plague directly or Nazi Germany or ideological movements, or… It’s similar to Animal Farm. Maybe not as effective in terms of using this kind of symbology-
Segment 2046: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4664, Text: I think Animal Farm has a narrative and… I’m going to spoil the whole Plague. The book, The Plague. There’s a town, I believe in Oman, a plague descends, people struggle to deal with it, and the plague vanishes as quickly as it came. The end.
Segment 2047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4682, Text: But there’s the victims, the people that take advantage of it. There’s the doctor that, amidst the absurdity and the evil of the plague, is fighting to do good.
Segment 2048: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4691, Text: Nothing for me. Does nothing for me.
Segment 2049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4693, Text: Okay, well I can spoil the Animal Farm. There’s animals at a farm and the humans are abusing them, and then the animals overthrow the humans, but then the pigs become just like the humans. The lesson, kids, is that power corrupts, no matter whether you walk on four or on two.
Segment 2050: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4720, Text: I thought the lesson was that pigs are the most human-like animals on the farm.
Segment 2051: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4727, Text: I thought the lesson was that there’s no sugar candy mountain.
Segment 2052: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4730, Text: That’s right. Yeah.
Segment 2053: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4733, Text: You’ve interviewed a lot of people. What have you learned about getting to the soul of a person, the soul of an idea from interviewing? Just how to do a good interview?
Segment 2054: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4744, Text: First off, I’m not interviewing just random people. I’m interviewing people who are accomplished. It’s not a random group. That’s self-selecting for something different. But I think that people love to, and this is very understandable, love to feel seen. So if you’re someone who’s done something, even if you’re like the best Guinea pig breeder in America, to have someone interested in your work and listen to what you’re saying… because I remember every book I’ve written, I have friends, and I wouldn’t stop talking about the person I’m writing with or the North Korea. And a certain point, I’m sure they’re like, “All right, I don’t care about this anymore.”But it takes over your brain. You know what I mean?
Segment 2055: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4783, Text: So if you someone who has an interest or a hobby, I’m sure to some extent, maybe your friends or family are sick of talking about it or you don’t want to talk about it with them. That’s the private life where you could just be yourself. So I try to, and this comes from my co-authoring background. When I’m talking to people to ask the questions that they haven’t heard before. There’s a possibility that this actor I’m a huge fan of is going to be on my show. I don’t want to spoil everything. And he’s got a very specific role that he’s known for. And I’m like, “Okay, I know it’s going to be annoying for you talking about this one role, but my goal is to ask questions that you aren’t sick of asking, haven’t been asked.”
Segment 2056: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4828, Text: Porn star or…
Segment 2057: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4829, Text: No, not a porn star.
Segment 2058: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4832, Text: That joke failed. Also edit out. What do you know about breeding Guinea pigs? You mentioned it. I’d love to hear-
Segment 2059: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4832, Text: I don’t know anything.
Segment 2060: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4842, Text: I would love to hear more about it.
Segment 2061: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4844, Text: I always use this as an example. You meet someone at a party who breeds Guinea pigs, right? There’s two approaches. Either you’re weird, okay. Or, “Sit down and tell me everything.” And I’m very much, and all the people I like are the second group. When you meet someone who’s doing something unusual and are passionate about it and are good at it, that to me is the mother load.
Segment 2062: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4869, Text: Yeah. That to me also is the thing I enjoy the most, is people-
Segment 2063: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4873, Text: And then it’s like-
Segment 2064: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4875, Text: … that are passionate about a thing.
Segment 2065: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4876, Text: … who do you guys hate? Do you guys hate the hamster people? Do you hate the rabid people? There’s got to be someone that you guys look down on, because the marine aquarium people look down on the freshwater aquarium people.
Segment 2066: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4885, Text: Yeah. It’s a hierarchy.
Segment 2067: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4886, Text: Yes. There’s always going to be a hierarchy. This is where the left anarchists and I disagree, because they think you can have egalitarianism. There’s going to be a hierarchy.
Segment 2068: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4893, Text: Hierarchies emerge.
Segment 2069: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4894, Text: Yes.
Segment 2070: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4895, Text: There’s no anarchy in the Guinea pig world.
Segment 2071: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4899, Text: No. It’s just a different kind of anarchy.
Segment 2072: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4901, Text: Somebody’s always breeding somebody else.
Segment 2073: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4903, Text: Yes.
Segment 2074: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4904, Text: And looking down on the others.
Segment 2075: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4907, Text: Yeah, someone’s the other. Whether it’s the hamster people, the rat people.
Segment 2076: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4910, Text: And everybody’s breeding. By the way, are you an anarcho-capitalist? What flavor of anarchist are you?
Segment 2077: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4919, Text: I’m an anarchist without adjectives. I like them all. The black flag comes in many colors.
Segment 2078: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4924, Text: All right. All right. You’re quoting your… No, I understand. It’s a beautiful line in the book.
Segment 2079: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4929, Text: Thank you. I think the anarcho-capitalists don’t give the left anarchist enough credit, especially for their courage. And I do whatever I can in my power to talk about people like Emma Goldman, whenever possible.
Segment 2080: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4944, Text: Do you still think that “are some people better than others” is a good litmus test?
Segment 2081: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4949, Text: Yes. It’s worked 100% of the time.
Segment 2082: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4952, Text: And for you, the answer is yes?
Segment 2083: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4955, Text: I never answer.
Segment 2084: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4959, Text: There’s two of them.
Segment 2085: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4963, Text: What are you all Hitchcock up in here?
Segment 2086: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4966, Text: Oh, hey, careful. I always got your back. What little habits in your life make you happy now that you’re in Austin?
Segment 2087: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=4979, Text: Oh my god. I was prepping for this interview, and I imagined this coming up, and I knew that as I explained this, you know how sometimes when someone tells a story, at first it’s amusing, then it’s amusing and concerned, and then you’re like, “Holy shit, where’s the exit?”
Segment 2088: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5007, Text: Yeah. I’m getting nervous already.
Segment 2089: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5010, Text: You should. So I’m going to tell you something I’ve told only a couple of people. This is my absolutely off the charts, autistic approach to shaving. So I have this insane system. You asked about habits that give me joy. I used to hate shaving. I used to hate it. There’s something called wet shaving. So wet shaving is you get the brush, you get the soap that’s in a canister, you stirred up, you paint your face, and then you shave. The thing is, there are dozens of these shaving soap companies, okay? So I tried a couple of hundred of these soaps, because you’re testing for scent, you’re testing for, with the lather, thickness, and also how smooth of a shave it gives you. I have it down… I’m not making this up. I’m not this creative. I have it down to a cycle of 67 soaps. Okay?
Segment 2090: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5080, Text: A cycle.
Segment 2091: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5081, Text: A cycle. So 67. When I use up one soap, that is a slot that I will have to try new ones, and I will try new ones in that slot until I get one that I like, and then that slot is filled. So right now, I have 67 that I use, and I have 86 candidates.
Segment 2092: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5105, Text: Like in the queue?
Segment 2093: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5107, Text: In the queue.
Segment 2094: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5107, Text: Do you label them? Do you remember which one is which?
Segment 2095: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5109, Text: Well, they all have beautiful labels. I mean, these are artisans who are creating these a amazing things. I would encourage everyone to try this hobby, who’s a guy. It’s so much fun. I will give a shout-out to the companies that are the best. So the best company, in my opinion, is a company called… they just changed the name because… You know what they’re originally called? I’m not joking. Grooming Department. And now it’s like-
Segment 2096: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5137, Text: Not a bad name.
Segment 2097: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5138, Text: Yeah, but it has certain connotations in contemporary discourse.
Segment 2098: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5142, Text: Yeah, I understand. Contemporary discourse, yeah.
Segment 2099: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5143, Text: So now he changed his name to Aion Skincare, A-I-O-N. That’s the sense of the most sophisticated, the most diverse, and the soap is just really high quality. Another amazing company is Barrister and Man. And if I’m going to tell you to try one, it’s called Cheshire. He comes out with new ones every month or so. A lot of it’s miss. A lot of it’s hit. Just great, great quality stuff. Another great company is Chiseled Face. They make something called Midnight Stag, which basically smells like a garage. It’s one of my favorite soaps of all time.
Segment 2100: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5176, Text: What makes for a good smell for Michael Malice?
Segment 2101: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5179, Text: I have 67 answers. So some of them smell-
Segment 2102: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5182, Text: So you can’t convert it into words?
Segment 2103: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5184, Text: Some are citrusy, some are industrial, some-
Segment 2104: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5187, Text: So garage is more industrial.
Segment 2105: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5188, Text: It smells like a garage. Yeah. Midnight Stag. It smells like a garage. Some are fun. There smells that smell like other things. For example, there’s a scent in my queue called Finding Scotty. It smells like Swedish Fish. Another great company is Phoenix Shaving, and they have one called Aloha Smackdown. It smells like Hawaiian Punch. They had one called Yule Ham that they made for me special. Smells like a ham. They had a ramen one, Rock and Ramen. Smells a cup of noodles. And every year they do an advent calendar where for 12 days you have a little sample of a soap and a sample of the aftershave.
Segment 2106: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5224, Text: Nice.
Segment 2107: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5226, Text: I’m forgetting someone and I’m feeling angry that I’m doing it. But those are some of the… Oh, and Catie’s Bubbles is great. They’re vegan, out of New Jersey. They’ve got one called a Knee High to a Grape. It smells like grape soda. I think those are the biggest names off the top of my head.
Segment 2108: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5245, Text: Will that list converge down to a small set eventually, or no? 67 down to-
Segment 2109: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5251, Text: Well, no, it’s 67.
Segment 2110: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5253, Text: Oh, so it always keeps [inaudible 01:27:35]-
Segment 2111: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5255, Text: So if there’s a slot, then, you know what I mean? I’ll fill that. You see what I’m saying?
Segment 2112: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5259, Text: Oh, so you will forever have the variety of 67?
Segment 2113: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5261, Text: Yes.
Segment 2114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5266, Text: You know how sad my brain is? When you were telling me this, I was like, “I wonder how many soaps are left in Michael Malice’s life.” You can count your life by days, by month, by years, or by soaps.
Segment 2115: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5281, Text: That is depressing. That is very dark.
Segment 2116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5283, Text: Because each experience of shaving is a little beautiful experience.
Segment 2117: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5287, Text: Yes, it is. It’s so much fun.
Segment 2118: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5289, Text: How many do you have left in your life, right?
Segment 2119: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5290, Text: That’s true.
Segment 2120: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5291, Text: Yeah.
Segment 2121: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5292, Text: I got to tell you, there’s something else. There’s a term my friend Jackie taught me called Touching Pan. It’s a makeup term. So basically when you use it and you could see the bottom, that’s like a big moment.
Segment 2122: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5304, Text: Oh, it’s a great thing.
Segment 2123: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5304, Text: Yeah. Well, it’s kind of fun. I’m telling you, people can scoff. It is such a fun… and there’s a lot of us online who are into this whole space. It’s really, really fun.
Segment 2124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5314, Text: When did you first discover this?
Segment 2125: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5316, Text: Can I curse?
Segment 2126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5317, Text: Yeah.
Segment 2127: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5318, Text: Fuck you, Cole Stryker. Because I was staying at my friend Cole’s house in LA. Fuck you Cole.
Segment 2128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5325, Text: Fuck you, Cole.
Segment 2129: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5326, Text: Cole is one of the biggest hipsters I know. He’s got the shirts with the pearl snaps and everything. And I’m staying at his house because I was doing Rogan, and he goes, “Oh, have you heard of this wet shaving thing?” And he goes, “Look, this one’s Proraso. That’s the Italian grandpa soap, which is also a great one. And I went down this rabbit hole, and now I’m like… I don’t even know how much money I spent on this. And it’s all because of him.
Segment 2130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5349, Text: Oh. But it’s like a happy fuck you. Like, fuck you, Cole.
Segment 2131: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5349, Text: Yeah.
Segment 2132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5352, Text: I love you, Cole. Fuck you.
Segment 2133: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5353, Text: Yeah, it’s just-
Segment 2134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5354, Text: Thank you.
Segment 2135: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5355, Text: Yes, yes.
Segment 2136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5356, Text: That’s a good idea for a tattoo. Fuck you, Cole. Do you have advice on how to be happy?
Segment 2137: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5365, Text: Yes.
Segment 2138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5366, Text: There’s a lot of loneliness and sadness in the world.
Segment 2139: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5371, Text: I can give a very easy piece of advice that worked a lot for me. Instead of telling yourself that you have these ridiculous standards, tell yourself, “I can be better. I don’t have to be a great writer. I could be a better writer. I don’t have to be a great podcaster. That will never happen. I could be a better podcaster. I could be a better person. I could be better at the gym. I could be better with my time.” And when you regard things in… and especially if you have metrics that you can go by. “I’ll run this many miles a day.” Things you have control over. Especially as males, when you have this chart and the data is telling you you’re improving, right away, it’s like you have this sense of accomplishment. So I think that is a really great way to…
Segment 2140: Speaker: , Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5425, Text: And if something is not working in your life… Let’s suppose you don’t have friends. Right? There’s the internet. How do people make friends? Try things out? What’s the worst that’s going to happen? Things will blow up in your face. Well, you’ll learn something at least. Don’t be afraid of making mistakes. When I was a kid, I was so scared of having things under control, so like I would never have to get hit in the face metaphorically. And then I realized, and you realized this as well, everyone who’s important gets hit in the face. Look at the president, whoever the president is. It becomes a matter of being strong enough that you could take getting hit in the face. So that is a big important switch in your thinking.
Segment 2141: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5465, Text: Yeah. There’s a Bukowski quote I wrote down. “Sometimes you climb out of bed in the morning and you think, I’m not going to make it. But you laugh inside, remembering all the times you felt that way.”
Segment 2142: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5476, Text: Yeah, yeah.
Segment 2143: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5477, Text: There’s a part of me that’s like that. There’s some days where I feel like this is the worst day of my life. And then shortly after, I chuckle at that.
Segment 2144: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5486, Text: Yes.
Segment 2145: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5486, Text: Just knowing the ups and downs of the brain and the mind and life and all that. You ever been depressed?
Segment 2146: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5492, Text: Yeah, of course. I’m more anxious than depressed. I don’t really get depressed, but I’ve been depressed.
Segment 2147: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5498, Text: Like low points.
Segment 2148: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5499, Text: Yeah. But I think I distinguish depression between low points, right? If things are going bad and you feel bad, that makes sense. But when I think of depression, I think of someone who feels bad when things aren’t bad. To me, it’s almost by definition irrational.
Segment 2149: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5515, Text: Well, yeah. And there’s different kinds of… There’s a exhausted kind of depression where it’s not so much sad as you don’t want to do anything. You don’t want to live. You don’t want to-
Segment 2150: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5529, Text: Yeah. What’s the point? It’s a wrap, yeah.
Segment 2151: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5530, Text: What’s the point? What’s the point? And an extreme self-critical negativity, which I’m also scared of because my brain is generally very self-critical.
Segment 2152: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5539, Text: Because you’re not taking enough magnesium.
Segment 2153: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5541, Text: Do you take a rectally or in the mouth?
Segment 2154: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5543, Text: You take a rectally.
Segment 2155: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5544, Text: Okay.
Segment 2156: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5545, Text: But as for the magnesium, you should take it as a pill.
Segment 2157: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5548, Text: Okay. Well, the way your mom explained it then is way different. What are you most afraid of?
Segment 2158: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5567, Text: Holy crap. I am trying to think of anything I’m afraid of.
Segment 2159: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5571, Text: In 1984-
Segment 2160: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5574, Text: I thought even just-
Segment 2161: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5575, Text: Look, if I wanted to torture you, hypothetically…
Segment 2162: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5579, Text: Well, the mission accomplished. I mean, I’m scared of increasing authoritarianism, but that’s not personal. And that’s something that I don’t think is as much of an imminent concern as let’s say in Canada.
Segment 2163: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5595, Text: Are you scared of death?
Segment 2164: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5597, Text: No.
Segment 2165: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5597, Text: You think Camus was scared of death?
Segment 2166: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5600, Text: No.
Segment 2167: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5602, Text: He just accepted it as-
Segment 2168: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5604, Text: Look, I honestly feel like if I died tomorrow, I did pretty good with what I had. I think I did things that matter to me. I think I moved the needle on things that matter to me. I think I’ve been a good friend to the people I care about. I’ve saved a couple of lives. So I think it’s a very low bar for someone to be able to grow their grave and say, “I left the world a better place than I found it.” I don’t think it’s that hard.
Segment 2169: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5641, Text: You ever been betrayed?
Segment 2170: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5643, Text: Oh god, yes. Of course. Haven’t you?
Segment 2171: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5647, Text: Not as often as I would’ve predicted.
Segment 2172: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5649, Text: Yeah. The Russian upbringing expects everyone to be like… it’s a time bomb before they betray you. I have been betrayed. Of course. Yeah.
Segment 2173: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5656, Text: Yeah. You value loyalty?
Segment 2174: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5660, Text: I do. And I also made it a point to not let that betrayal color my future interactions and regard that as the universal or the norm. I think that’s very important.
Segment 2175: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5672, Text: Me too.
Segment 2176: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5674, Text: And also, I feel bad. I’ve gotten, Lex, enough that I feel bad for the person who betrayed me, because it’s just like they didn’t need to do this. And at some point, if you betray someone, you know, and you know you’re not a good person. I believe that. Like even if you tell yourself, “This is something I had to do,” you still know you had to do a bad thing to someone who didn’t deserve it. And that’s a really hard pill to swallow.
Segment 2177: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5702, Text: In my situation, I still think good thoughts and empathize with the people that have done me wrong.
Segment 2178: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5711, Text: I don’t empathize with them, but I sympathize with them.
Segment 2179: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5714, Text: My English is not good enough to know the difference.
Segment 2180: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5716, Text: Empathizing means you’re putting yourself in their shoes. Sympathizing means you feel bad for them and wish them well.
Segment 2181: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5725, Text: Yeah, I wish them well.
Segment 2182: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5727, Text: Yeah, but I don’t put myself… it’s very hard for me to empathize with someone who betrays someone that they care about. It’s not that just I think I’m such a great person. It’s that I feel guilt very strongly. So if I did that to someone who trusted me, it would up my head for a long time.
Segment 2183: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5746, Text: Yeah, but maybe they were in pain. Maybe they were desperate. Maybe their back’s to the wall.
Segment 2184: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5753, Text: Sure.
Segment 2185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5753, Text: They felt that way.
Segment 2186: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5754, Text: Sure. Well, that’s a sympathy thing. Not really an empathy thing.
Segment 2187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5756, Text: Yeah. Yeah. Loyalty is a fascinating thing.
Segment 2188: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5763, Text: Yes.
Segment 2189: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5764, Text: I value trust a lot.
Segment 2190: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5765, Text: I know you do. Especially because you’re in such a public… Both of us, we’re in very public positions. You have to be very careful who you surround yourself with.
Segment 2191: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5773, Text: It sucks.
Segment 2192: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5774, Text: Does it? Well, it’s-
Segment 2193: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5776, Text: Well, it sucks because it’s hard to… I usually just trust everybody.
Segment 2194: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5785, Text: Okay, that’s crazy.
Segment 2195: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5789, Text: But what’s the alternative?
Segment 2196: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5790, Text: To have a filter?
Segment 2197: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5793, Text: Well, I have a filter in terms of who I interact with, but within the… I see the good in people, but then in the very rare instances that might turn. Yeah. It just sucks. It breaks my heart.
Segment 2198: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5808, Text: Yeah, I hear you. I completely agree.
Segment 2199: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5812, Text: Has your heart ever been broken?
Segment 2200: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5814, Text: Yes.
Segment 2201: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5815, Text: Love?
Segment 2202: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5816, Text: Yes.
Segment 2203: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5821, Text: I’m just so relaxed right now, and happy.
Segment 2204: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5823, Text: Good.
Segment 2205: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5824, Text: Relaxed sand happy.
Segment 2206: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5825, Text: Good.
Segment 2207: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5826, Text: This is making me really happy.
Segment 2208: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5829, Text: Again, it’s beautiful on like eight different levels.
Segment 2209: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5831, Text: I think that’s the deepest thing I’m thankful for, is just how beautiful people are and how beautiful the world is.
Segment 2210: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5841, Text: People are going to laugh, and I welcome it. That’s fine. I really sometimes feel like the guy in American Beauty looking at the plastic bag dancing in the wind, and he’s brought to tears because of how much beautiful life is. And a lot of people feel the need to sneer at that scene and Ricky Pitts, whatever, and I think he’s got it exactly right.
Segment 2211: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5865, Text: I think he does too. Well, in the end, you and I will be both laughing,
Segment 2212: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5873, Text: Right. And also seeing beauty where other people see garbage. And I’d rather be the person who sees beauty than the person who sees garbage.
Segment 2213: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5882, Text: Yep. Well, when I look at you, I see beauty when most people see garbage. And it’s really unfair, Mr. Parrot, that you keep saying that. But all jokes aside, man, I’m really grateful for your friendship. I’m really grateful for who you are as a person. Thank you so much for talking today. Thank you so much for talking to me throughout all these years. Thank you for being who you are.
Segment 2214: Speaker: Michael Malice, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5908, Text: You are welcome.
Segment 2215: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=2yHr9DPnSzk&t=5911, Text: Thanks for listening to this conversation with Michael Malice. To support this podcast. Please check out our sponsors in the description. And now, let me leave you with some words from Andre Gide. Man cannot discover new oceans unless he has the courage to lose sight of the shore. Thank you for listening and hope to see you next time.
Segment 2216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=0, Text: The following is a conversation with John Mearsheimer, a professor at University of Chicago and one of the most influential and controversial thinkers in the world. He teaches, speaks and writes about the nature of power and war on the global stage, in history and today.
Segment 2217: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=19, Text: Please allow me to say, once again, my hope for this little journey I’m on. I will speak to everyone on all sides with compassion, with empathy, and with backbone. I’ll speak with Vladimir Putin and with Volodymyr Zelenskyy, with Russians and with Ukrainians, with Israelis and with Palestinians, with everyone. My goal is to do whatever small part I can to decrease the amount of suffering in the world by trying to reveal our common humanity. I believe that in the end, truth and love wins. I will get attacked for being naive, for being a shill, for being weak. I’m none of those things, but I do make mistakes and I will get better. I love you all.
Segment 2218: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=79, Text: This is a Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s John Mearsheimer.
Segment 2219: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=89, Text: Can you explain your view on power in international politics as outlined in your book, The Tragedy of Great Power Politics and in your writing since then?
Segment 2220: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=99, Text: Yeah, I make two sets of points there. First of all, I believe that power is the currency of international relations, and by that I mean that states are deeply interested in the balance of power and they’re interested in maximizing how much power they control. And the question is why do states care so much about power. In the international system, there’s no higher authority, so if you get into trouble and you dial 911, there’s nobody at the other end. In a system like that, you have no choice but to figure out for yourself how best to protect yourself. And the best way to protect yourself is to be powerful, to have as much power as you can possibly gain over all the other states in the system. Therefore, states care about power because it enhances or maximizes their prospects for survival.
Segment 2221: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=159, Text: Second point I would make is that in the realist story or in my story, power is largely a function of material factors. The two key building blocks of power are population size and wealth. You want to have a lot of people and you want to be really wealthy. Of course, this is why the United States is so powerful. It has lots of people and it has lots of wealth. China was not considered a great power until recently because it didn’t have a lot of wealth. It certainly had population size, but it didn’t have wealth. And without both a large population and much wealth, you’re usually not considered a great power. So I think power matters, but when we talk about power, it’s important to understand that it’s population size and wealth that are underpinning it.
Segment 2222: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=218, Text: So there’s a lot of interesting things there. First you said nations in relation to each other is essentially in a state of anarchism.
Segment 2223: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=228, Text: Yeah, well, anarchy basically means the opposite of hierarchy. Sometimes people think when you’re talking about anarchy, you’re talking about murder and mayhem, but that’s not what anarchy means in the realist context. Anarchy simply means that you don’t have hierarchy. There’s no higher authority that sits above states. States are like pool balls on a table. And in an anarchic world, there’s no higher authority that you can turn to if you get into trouble.
Segment 2224: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=262, Text: And of course the political philosopher who laid this all out was Thomas Hobbes. And Hobbes talked about life in the state of nature, and in the state of nature you have individuals and those individuals compete with each other for power. And the reason that they do is because in the state of nature, by definition, you have no higher authority. And Hobbes’s view is that the way to get out of this terrible situation where individuals are competing with each other and even killing each other is to create a state. It’s what he calls the Leviathan, and that of course is the title of his famous book.
Segment 2225: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=302, Text: So the idea is to escape anarchy, you create a state, and that means you go from anarchy to hierarchy. The problem in international politics is that there is no world state, there is no hierarchy. And if you have no hierarchy and you’re in an anarchic system, you have no choice but to try to maximize your relative power to make sure you are, as we used to say when I was a kid on New York City playgrounds, the biggest and baddest dude on the block. Not because you necessarily want to beat up on other kids or on other states, but because again, that’s the best way to survive.
Segment 2226: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=347, Text: And as I like to point out to people, the best example of what happens when you’re weak in international politics is what the Chinese call the century of national humiliation. From the late 1840s to the late 1940s the Chinese were remarkably weak, and the great powers in the system preyed upon them. And that sends a very important message to not only the Chinese, but to other states in the system. Don’t be weak, be as powerful as you can.
Segment 2227: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=378, Text: And we’ll talk about it, but humiliation can lead to resentment or resentment leads to something you’ve also studied, which is Nazi Germany in the 1930s. We’ll talk about it, but staying to the psychology and philosophy picture, what’s the connection between the will to power in the individual, as you mentioned, and the will to power in a nation?
Segment 2228: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=403, Text: The will to power in an individual has a lot to do with individual psychology. The story that I tell about the pursuit of power is a structural argument. It’s an argument that says when you are in a particular structure, when you’re in a system that has a specific architecture which is anarchy, the states have no choice but to compete for power. So structure is really driving the story here. Will to power has a lot more to do with an individual in the Nietzschen story where that concept comes from. So it’s very important to understand that I’m not arguing that states are inherently aggressive. My point is that as long as states are in anarchy, they have no choice but to behave in an aggressive fashion. But if you went to a hierarchic system, there’s no reason for those states to worry about the balance of power, because if they get into trouble there is a higher authority that they can turn to. There is in effect a leviathan.
Segment 2229: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=479, Text: So what is the role of military might in this will to power on the national level?
Segment 2230: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=486, Text: Well, military mights is what ultimately matters. As I said to you before, the two building blocks of power are population size and wealth.
Segment 2231: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=496, Text: You didn’t mention military mights.
Segment 2232: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=497, Text: I did not, no. That’s right. And it’s good that you caught that because if you have a large population and you’re a wealthy country, what you do is you build a large military, and it’s ultimately the size of your military that matters because militaries fight wars. And if states are concerned about survival, which I argue is the principle goal of every state in the international system for what I think are obvious reasons, then they’re going to care about having a powerful military that can protect them if another state comes after them.
Segment 2233: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=535, Text: Well, it’s not obvious that a large nation with a lot of people and a lot of money should necessarily build a gigantic army and seek to attain dominant soul superpower status to military might. But you’re saying, as you see the world today, it has to be that way.
Segment 2234: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=556, Text: Yeah, I’m arguing it is obvious. If you’re a state in the international system, do you want to be weak? If you live next door to Nazi Germany or Imperial Germany or Napoleonic France or even the United States… The United States is a ruthless great power, you surely recognize that. And if you’re dealing with the United States of America and you’re Vladimir Putin, you want to make sure you’re as powerful as possible so that the United States doesn’t put its gun sights on you and come after you. Same thing is true with China. You want to be powerful in the international system.
Segment 2235: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=590, Text: States understand that, and they go to great lengths to become powerful. Just take the United States of America. When it started in 1783, it was comprised of 13 measly colonies strung out along the Atlantic seaboard. Over time, the various leaders of the United States went to great lengths to turn that country into the dominant power in the Western Hemisphere. And then once that was achieved in 1900, we’ve gone to great lengths to make sure that there’s no pier competitor in the system. We just want to make sure that we’re number one.
Segment 2236: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=633, Text: And my argument is that this is not peculiar to the United States. If I’m China, for example, today, I would want to dominate Asia the way the United States dominates the Western Hemisphere. They’d be fools not to. If I were imperial Germany, I’d want to dominate all of Europe the way the United States dominates the Western Hemisphere. Why? Because if you dominate all of Europe, assuming you’re Imperial Germany or Napoleonic France, then no other state in the area or in the region can threaten you because you’re simply so powerful.
Segment 2237: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=672, Text: And again, what I’m saying here is that the structure of the international system really matters. It’s the fact that you’re in this anarchic system where survival is your principle goal and where I can’t know your intentions, right? You’re another state. I can’t know that at some point you might not come after me. You might. And if you’re really powerful and I’m not, I’m in deep trouble.
Segment 2238: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=697, Text: Yeah. So some of the ideas underlying what you’ve said, offensive realism, which I would love to talk to you about sort of the history of realism versus liberalism, but some of the ideas you already mentioned, anarchy between states, everybody’s trying to develop military capabilities, uncertainty, such an interesting concept. States cannot be sure that other states will not use military capabilities against them, which is one-
Segment 2239: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=727, Text: That’s of enormous importance to the story,
Segment 2240: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=729, Text: …really important, and so interesting because you also say that this makes realists more cautious and more peaceful, the uncertainty because of all the uncertainty involved here, it’s better to approach international politics with caution, which is really interesting to think about. Again, survival, most states interested in survival. And the other interesting thing is you assume all the states are rational, which-
Segment 2241: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=760, Text: Most of the time.
Segment 2242: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=761, Text: Most of the time. You call this framework offensive realism. Can you just give an overview of the history of the realism versus liberalism debate as worldviews?
Segment 2243: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=776, Text: Well, I think for many centuries now, the big divide within the world of international relations theory is between realism and liberalism. These are time honored bodies of theory. And before I tell you what I think the differences are between those two bodies of theory, it is important to emphasize that there are differences among realists and differences among liberals. And so when you talk about me as an offensive realist, you should understand that there are also defensive realists out there, and there are a panoply of liberal theories as well.
Segment 2244: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=822, Text: But basically realists believe that power matters, that states compete for power, and that war is an instrument of statecraft. And liberals, on the other hand, have what I would say is a more idealistic view of the world. This is not to say that they’re naive or foolish, but they believe there are aspects of international politics that lead to a less competitive and more peaceful world than most realists say. And I’ll lay out for you very quickly, what are the three major liberal theories today that I think will give you a sense of the more optimistic perspective that is inherent in the liberal enterprise.
Segment 2245: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=880, Text: The first and most important of the liberal theories is democratic peace theory, and this is a theory that says democracies do not fight against other democracies. So the more the world is populated with democracies, the less likely it is that we will have wars. And this basic argument is inherent in Francis Fukuyama’s The End of History. He argues that democracy triumphed first over fascism in the 20th century, it then triumphed over communism, and that means that in the future we’re going to have more and more liberal democracies on the planet. And if you have more and more liberal democracies and those democracies don’t fight each other, then you have a more peaceful world. That was his argument. It’s a very liberal argument.
Segment 2246: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=936, Text: A realist like me would say that it doesn’t matter whether a state is a democracy or not, all states behave the same way because the structure of the system, getting back to our earlier discussion about international anarchy, the structure of the system leaves those states no choice, whether they’re democracies or autocracies. And again, the liberal view, this first liberal theory, is that democracies don’t fight other democracies, and therefore the more democracies you have, the more peaceful the world.
Segment 2247: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=972, Text: Can I just sort of try to unpack that a little bit? So the democratic peace theory, I guess, would say that in democracies leaders are elected, and the underlying assumption is most people want peace, and so they will elect peacemakers. So the more democracies you have, the more likely you have peace. And then the realist perspective says that it doesn’t matter if the majority of people want peace. The structure of international politics is such that superpowers want to become more super and powerful, and they do that through war.
Segment 2248: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1011, Text: You can’t make that argument that you’re making about democracies, because if you’re saying that democracies are inclined toward peace and that the electorate picks leaders who are inclined towards peace, then you have to show that democracies are, in general, more peaceful than non democracies, and you can’t support that argument. You can find lots of evidence to support the argument that democracies don’t fight other democracies.
Segment 2249: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1045, Text: So the argument I believe that you have to make, if you’re going to support democratic peace theory, the main argument you have to make is that liberal democracies have a healthy respect for each other and they can assess each other’s intentions. If you’re a liberal democracy, and I’m a liberal democracy, we know we have value systems that argue against aggression, and argue for peaceful resolution of crises. And therefore, given these norms, we can trust each other, we can know each other’s intentions. Remember, for realists like me, uncertainty about intentions really helps drive the train. But if you’re talking about two democracies, the argument there is that they know each other’s intentions.
Segment 2250: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1099, Text: And for you, sure, maybe democracies reduce uncertainty a little bit, but not enough to stop the train.
Segment 2251: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1106, Text: I think that’s right, yeah. That’s right. So that’s democratic peace theory. The second theory is economic interdependence theory, and that’s the argument that, in a globalized world like the one that we live in and have lived in for a long time, there’s a great deal of economic interdependence. And if you and I are two countries, or if you and me are two countries and we’re economically interdependent and we’re both getting prosperous as a result of this economic intercourse, the last thing that we’re going to do is start a war, either one of us, because who would kill the goose that lays the golden eggs, it’s that kind of argument. So there you have an argument that economic interdependence leads to peace.
Segment 2252: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1149, Text: And then the third liberal argument has to do with institutions, sometimes referred to as liberal institutionalism. And this is the argument that if you can get states into institutions where they become rule abiding actors, they will obey the rules that dictate that war is not acceptable. So if you get them to accept the UN rules on when you can and cannot initiate a war, then you’ll have a more peaceful world. So those are the liberal theories, and as you can tell, they’re very different from realism as articulated by somebody like me.
Segment 2253: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1197, Text: Can you maybe argue against the economic interdependence and in the institutions that institutions follow rules a little bit? So the golden goose with the golden egg, you’re saying that nations are happy to kill the goose because again, they want power.
Segment 2254: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1219, Text: If they think it’s necessary to kill the golden goose because of security concerns, they will do it. The point is that economic interdependence at its root has prosperity as the core variable. In the realest story, the core variable is survival, and survival always trumps prosperity. So if you go back to the period before World War I, we’re in Europe, it’s 1913 or early 1914, what you see is that you have an intense security competition between all of the great powers. On one side you have the Triple Alliance, and on the other side you have the Triple Entente. You have these two alliances, and you have an intense security competition between them. At the same time, you have a great deal of economic interdependence. It’s amazing how much economic intercourse is taking place in Europe among all the actors. And people are getting prosperous or countries are getting prosperous as a result. But nevertheless, in the famous July crisis of 1914, this economic prosperity is unable to prevent World War I because security concerns or survival is more important. So there are going to be lots of situations where prosperity and survival come into conflict, and in those cases, survival will win.
Segment 2255: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1319, Text: And maybe you can speak to the different camps of realists. You said offensive and defensive. Can you draw a distinction between those two?
Segment 2256: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1329, Text: Yeah. Let me just back up a bit on that one. And you were talking about will to power before. The first big divide between realists is structural realists and human nature realists, and Hans Morgenthau, who was influenced by nature and therefore had that will to power logic embedded in his thinking about how the world works, he was a human nature realist. I’m a structural realist and I believe it’s not human nature, it’s not individuals in some will to power that drives competition and war. What drives competition and war is the structure of the system. It’s anarchy.
Segment 2257: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1383, Text: So you’re not as romantic as the human nature realists.
Segment 2258: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1386, Text: Yeah. There’s just a world of difference between the two. It’s just important to understand that.
Segment 2259: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1392, Text: So within that, from the structural, there’s a subdivision also of offensive and defensive.
Segment 2260: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1397, Text: Yes. Inside the structural realist world. And you have a handful of realists who believe that the structure of the system fosters competition, for sure, security competition. But it really rules out great power war almost all the time. So it makes sense to care about the balance of power, but to focus on maintaining how much power you have. That’s the defensive realism, maintaining how much power you have. Not trying to gain more power, because the argument the defense of realists make is that if you try to gain more power, the system will punish you, the structure will punish you. I’m not a defensive realist, I’m an offensive realist. And my argument is that states look for opportunities to gain more power, and every time they see, or almost every time they see an opportunity to gain more power, and they think the likelihood of success is high and the cost will not be great, they’ll jump at that opportunity.
Segment 2261: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1479, Text: Just to linger on the human nature perspective, how do you explain Hitler and Nazi Germany, just one of the more recent aggressive expansions through military might? How do you explain that in the framework of offensive realism?
Segment 2262: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1504, Text: Well, I think that Nazi Germany was driven in large part by structural considerations. And I think if you look at Imperial Germany, which was largely responsible for starting World War I, and of course Nazi Germany’s largely responsible for starting World War II, what that tells you is you didn’t need Adolf Hitler to start World War I. And I believe that there is a good chance you would’ve had World War II in the absence of Hitler. I believe that Germany was very powerful, it was deeply worried about the balance of power in Europe, and it had strong incentives to behave aggressively in the late 1930s, early 1940s. So I believe that structure mattered.
Segment 2263: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1554, Text: However, I want to qualify that in the case of Adolf Hitler, because I do think he had what you would call a will to power. I’ve never used that word to describe him before, but it’s consistent with my point that I often make, that there are two leaders, or there have been two leaders in modern history who are congenital aggressors, and one was Napoleon and the other was Hitler. Now, if you want to call that a will to power, you can do that. I’m more comfortable referring to Hitler as a congenital aggressor and referring to Napoleon as a congenital aggressor, although there were important differences between the two, because Hitler was probably the most murderous leader in recorded history, and Napoleon was not in that category at all. But both of them were driven by what you would call a will to power, and that has to be married to the structural argument in Hitler’s case, and also in Napoleon’s case.
Segment 2264: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1622, Text: Is there some degree on the human psychology side that resentment, because of what happened after World War I, led to Hitler willing so much power, and then Hitler starting World War II? So this is the human side. Perhaps the reason I asked that question is also because you mentioned the century of humiliation on the China side. So to which degree does humiliation lead to Hitler and lead to World War II?
Segment 2265: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1653, Text: Well, the question of what led to Hitler is a very different question than the question of what led to World War II once Hitler was in power. I mean, after January 30th, 1933, he’s in power. And then the question of what is driving him comes racing to the fore. Is there resentment over the Versailles treaty and what happened to Germany? Yes. Did that matter? Yes. But my argument is that structure was the principle factor driving the train in Hitler’s case. But what I’m saying here is that there were other factors that as well, resentment being one of them. Will to power or the fact that he was a congenital aggressor in my lexicon certainly mattered as well, so I don’t want to dismiss your point about resentment.
Segment 2266: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1709, Text: So Hitler in particular, the way he wielded, the way he gained so much power, might have been the general resentment of the populace or the German populace.
Segment 2267: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1721, Text: I think that as a result of defeat in World War I and all the trials and tribulations associated with Weimar Germany, and then the coming of the Great Depression, all of those factors definitely account for his coming to power. I think that one of the reasons that he was so successful at winning over the German people once he came to power was because there was a great deal of resentment in the German body politic. And he played on that resentment, that surely helped him get elected too. But I think having studied the case, it was even more important once he took over.
Segment 2268: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1772, Text: I also believe that one of the principal reasons that he was so popular and he was wildly popular inside Nazi Germany is because he was the only leader of an industrialized country who pulled his country out of the depression. And that really mattered, and it made him very effective. It’s also worth noting that he was a remarkably charismatic individual. I find that hard to believe because every time I look at him or listen to his speeches, he does not appear to be charismatic to me. But I’ve talked to a number of people who are experts on this subject who assure me that he was very charismatic. And I would note to you, if you look at public opinion polls in Germany, West Germany, in the late 1940s, this is the late 1940s after the Third Reich is destroyed in 1945, he is still remarkably popular in the polls.
Segment 2269: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1831, Text: Stalin is still popular in many parts of Eastern Europe.
Segment 2270: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1836, Text: Yeah, yeah. And Stalin’s popular in many quarters inside Russia, and Stalin murdered more of his own people than he murdered people outside of the Soviet Union.
Segment 2271: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1850, Text: And still to you, the tides of history turned not on individuals, but on structural considerations. So Hitler may be a surface-layer characteristics of how Germany started war, but not really the reason.
Segment 2272: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1869, Text: Well, history is a multidimensional phenomenon-
Segment 2273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1874, Text: So I hear.
Segment 2274: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1875, Text: … and we’re talking about interstate relations here, and realism is a theory about how states interact with each other, and there are many other dimensions to international politics. And if you’re talking about someone like Adolf Hitler, why did he start World War II is a very different question than why did he start the Holocaust or why did he push forward a holocaust? I mean, that’s a different question, and realism doesn’t answer that question. So I want to be very clear that I’m not someone who argues that realism answers every question about international politics, but it does answer what is one of the big, if not the biggest, questions that IR scholars care about, which is what causes security competition and what causes great power war.
Segment 2275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1930, Text: Does offensive realism answer the question why Hitler attacked the Soviet Union?
Segment 2276: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1937, Text: Yes.
Segment 2277: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1938, Text: Because from a military strategy perspective, there’s pros and cons to that decision.
Segment 2278: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1945, Text: Pros and cons to every decision. The question is, did he think that he could win a quick and decisive victory. And he did, as did his generals. It’s very interesting, I’ve spent a lot of time studying German decision making in World War II. If you look at the German decision to invade Poland on September 1st, 1939, and you look at the German decision to invade France on May 10th, 1940, and then the Soviet Union on June 22nd, 1941, what you see is there was actually quite a bit of resistance to Hitler in 1938 at the time of Czechoslovakia, Munich, and there was also quite a bit of resistance in September, 1939.
Segment 2279: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1993, Text: Internally? Or you mean…
Segment 2280: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=1994, Text: Internally, internally. For sure. Yeah. People had doubts. They didn’t think the Wehrmacht was ready, and given the fact that World War I had just ended about 20 years before, the thought of starting another European war was not especially attractive to lots of German policy makers, including military leaders. And then came France 1940. In the run-up to May 10th, 1940, there was huge resistance in the German army to attacking France. But that was eventually eliminated because they came up with a clever plan, the Manstein Plan. If you look at the decision to invade the Soviet Union on June 22nd, 1941, which is the only case where they fail… They succeeded in France, they succeeded in Poland, they succeeded at Munich in 1938. Soviet Union is where they fail. There’s hardly any resistance at all, right?
Segment 2281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2060, Text: Yeah. Well, and to say that they failed the Soviet Union, my grandfather fought for the Soviet Union, there was a lot of successes early on. So there’s poor military, I would say, strategic decisions along the way, but it caught Stalin off guard. Maybe you can correct me, but from my perspective, terrifyingly so, they could have been successful if certain different decisions were made from a military perspective.
Segment 2282: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2094, Text: Yeah. I’ve always had the sense they came terrifyingly close to winning. You can make the opposite argument that they were doomed-
Segment 2283: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2103, Text: You can make the opposite argument that they were doomed. But I’m not terribly comfortable making that argument. I think the Wehrmacht, by the summer of 1941, was a finely tuned instrument for war, and the Red Army was in quite terrible shape. Stalin had purged the Officer Corps, they had performed poorly in Finland, and there were all sorts of reasons to think that they were no match for the Wehrmacht.
Segment 2284: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2136, Text: And if you look at what happened in the initial stages of the conflict, that proved to be the case. The Germans won a lot of significant tactical victories early on.
Segment 2285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2149, Text: And if they focused and went to Moscow as quickly as possible, again, terrifyingly, so could have been, basically topple Stalin. And one thing that’s-
Segment 2286: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2163, Text: That’s possible.
Segment 2287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2164, Text: That’s possible.
Segment 2288: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2165, Text: Fortunately, we’re not going to run the experiment again, but one could argue that, had they concentrated as the generals wanted to do, in going straight from Moscow, that they would’ve won. I mean, what Hitler wanted to do is, he wanted to go into the Ukraine. I mean, Hitler thought that the main Axis… There were three Axes. The northern Axis went towards Leningrad, the central Axis of course, went to Moscow, and then the Southern Axis, Army Group South, headed towards Ukraine and deep into the caucuses.
Segment 2289: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2199, Text: And Hitler believed that that should have been the main Axis. And in fact, in 1942, the Soviets, excuse me, the Germans go back on the offensive in 1942. This is Operation Blue, and the main Axis in ’42 is deep into the Ukraine and into the caucuses, and that fails.
Segment 2290: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2221, Text: But one could argue that, had they done that in ’41, had they not gone to Moscow, had they gone, had they concentrated on going deep into Ukraine and into the caucuses, they could have knocked the Soviets out that way. I’m not sure that in the end I believe that. I think in the end the Soviets would’ve won no matter what, but I’m not a hundred percent sure of that.
Segment 2291: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2248, Text: Sometimes, maybe you can educate me, but sometimes they say, just like with Napoleon, winter defeated Hitler in Russia. I think not often enough people tell the story of the soldiers and the motivation and how hard they fight. So it turns out that Ukrainians and Russians are not easy to conquer. They’re the kinds of people that don’t roll over and fight bravely. There seems to be a difference in certain peoples, in how they see war, how they approach war, how proud they are to fight for their country, to die for their country, these kinds of things. So I think Battle of Stalingrad tells, at least to me, a story of extremely brave fighting on the Soviet side, and that, it’s a component of war too. It’s not just structural, it’s not just military strategy, it’s also the humans involved, but maybe that’s a romantic notion of war.
Segment 2292: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2313, Text: No, I think there’s a great deal of truth in that, but let’s just unpack it a bit in the case of the Soviet Union in World War II. The counterargument to that is that in World War I, the Russian Army disintegrated. And if you look at what happened when Napoleon invaded in 1812, and you look at what happened in 1917, and then you look at what happened between ’41 and ’45, the Napoleon case looks a lot like the Hitler case, and it fits neatly with your argument.
Segment 2293: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2354, Text: But World War I does not fit neatly with your argument because the Russians lost and surrendered, and you had the infamous treaty of Brest-Litovsk, where the Soviet Union then, because it went from Russia to the Soviet Union in October 1917, the Soviet Union surrendered large amounts of Soviet territory because it had suffered a humiliating defeat.
Segment 2294: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2378, Text: My argument for why the Russians, let me take that back, why the Soviets fought like wild dogs in World War II is that they were up against a genocidal adversary. You want to understand that the Germans murdered huge numbers of Soviet POWs. The overall total was 3.7 million. And by December, December of 1941, remember the invasion is June ’41, by December of 1941, the Germans have murdered 2 million Soviet POWs. At that point in time, they had murdered many more POWs than they had murdered Jews.
Segment 2295: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2420, Text: And this is not to deny for one second that they were on a murderous rampage when it came to Jews, but they were also on a murderous rampage when it came to Soviet citizens and Soviet soldiers. So those Soviet soldiers quickly came to understand they were fighting for their lives. If they were taken prisoner, they would die. So they fought like wild dogs.
Segment 2296: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2448, Text: Yeah, the story of the Holocaust, of the 6 million Jews, is often told extensively. If Hitler won, conquered the Soviet Union, it’s terrifying to think, on a much grander scale than the Holocaust, what would’ve happened to the Slavic people, to the Soviet people.
Segment 2297: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2468, Text: Absolutely. All you have to do is read the Hunger Plan, right? And they also had a plan, what was it called? Grand Planned East, I forget the exact name of it, which made it clear that they were going to murder many tens of millions of people. And by the way, I believe that they would’ve murdered all the Poles and all the Roma. I mean, my view is that the Jews were number one on the genocidal hit list. The Roma, or the gypsies, were number two, and the Poles were number three.
Segment 2298: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2502, Text: And of course, I just explained to you how many POWs they had killed. So they would’ve ended up murdering huge numbers of Soviet citizens as well. But people quickly figured out that this was happening, that’s my point to you. And that gave them, needless to say, very powerful incentives to fight hard against the Germans, and to make sure that they did not win.
Segment 2299: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2529, Text: To fast-forward in time, but not in space, let me ask you about the war in Ukraine. Why did Russia invade Ukraine on February 24th, 2022? What are some of the explanations given? And which do you find the most convincing?
Segment 2300: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2553, Text: Well, clearly, the conventional wisdom is that Putin is principally responsible. Putin is an imperialist, he’s an expansionist.
Segment 2301: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2563, Text: That’s the conventional thinking.
Segment 2302: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2564, Text: Yeah, yeah. And the idea is that he is bent on creating a greater Russia, and even more, so he’s interested in dominating Eastern Europe, if not all of Europe, and that Ukraine was the first stop on the train line. And what he wanted to do was to conquer all of Ukraine, incorporate it into a greater Russia, and then he would move on and conquer other countries. This is the conventional wisdom. My view is there is no evidence, let me emphasize, zero evidence, to support that argument.
Segment 2303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2606, Text: Which part? That he would… The imperialist part, the sense that he sought to conquer all of Ukraine, and move on and conquer-
Segment 2304: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2616, Text: There’s no evidence he was interested in conquering all of Ukraine. There was no evidence beforehand that he was interested in conquering any of Ukraine. And there’s no way that an army that had 190,000 troops, at the most, could have conquered all of Ukraine, it’s just impossible.
Segment 2305: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2639, Text: As I like to emphasize, when the Germans went into Poland in 1939, and the Germans, you want to remember, were only intent on conquering the western half of Poland, because the Soviets, who came in later that month, were going to conquer the eastern half of Poland. So the western half of Poland is much smaller than Ukraine, and the Germans went in with 1.5 million troops. If Vladimir Putin were bent on conquering all of Ukraine, he would’ve needed at least 2 million troops. I would argue he’d need 3 million troops, because not only did he need to conquer the country, you then have to occupy it.
Segment 2306: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2684, Text: But the idea that 190,000 troops was sufficient for conquering all of Ukraine, it’s not a serious argument. Furthermore, he was not interested in conquering Ukraine, and that’s why, in March 2022, this is immediately after the war starts, he is negotiating with Zelensky to end the war. There are serious negotiations taking place in Istanbul involving the Turks. And Naftali Bennett, who was the Israeli prime minister at the time, was deeply involved in negotiating with both Putin and Zelensky to end the war.
Segment 2307: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2722, Text: Well, if he was interested, Putin, in conquering all of Ukraine, why in God’s name would he be negotiating with Zelensky to end the war? And of course, what they were negotiating about was NATO expansion into Ukraine, which was the principal cause of the war. People in the West don’t want to hear that argument because if it is true, which it is, then the West is principally responsible for this bloodbath that’s now taking place. And of course, the West doesn’t want to be principally responsible. It wants to blame Vladimir Putin.
Segment 2308: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2759, Text: So we’ve invented this story out of whole cloth that he is an aggressor, that he’s the second coming of Adolf Hitler, and that what he did in Ukraine was try to conquer all of it and he failed. But with a little bit of luck, he probably would’ve conquered all of it, and he’d now be in the Baltic States, and eventually end up dominating all of Eastern Europe. As I said, I think there’s no evidence to support this.
Segment 2309: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2788, Text: So maybe there’s a lot of things to ask there. Maybe just to linger on NATO expansion, what is NATO expansion? What is the threat of NATO expansion and why is this such a concern for Russia?
Segment 2310: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2802, Text: NATO was a mortal enemy of the Soviet Union during the Cold War. It’s a military alliance which has at its heart the United States of America, which is the most powerful state on the planet. It is perfectly understandable that Russia is not going to want that military alliance on its doorstep.
Segment 2311: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2828, Text: Here in the United States we have, as you well know, what’s called the Monroe Doctrine, and that basically says no great powers from Europe or Asia are allowed to come into our neighborhood and form a military alliance with anybody in this neighborhood. When I was young, there was this thing called the Cuban Missile Crisis. The Soviets had the audacity to put nuclear armed missiles in Cuba. We told them in no uncertain terms that that was not acceptable, and that those missiles had to be removed. This is our backyard and we do not tolerate distant great powers coming into our neighborhood.
Segment 2312: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2865, Text: Well, what’s good for the goose is good for the gander. And if we don’t like great powers coming into our neighborhood, it’s hardly surprising that the Russians did not want NATO on their doorstep. They made that manifestly clear when the Cold War ended, and they exacted a promise from us that we would not expand NATO. And then when we started expanding NATO, they made it clear, after the first tranche in 1999, that they were profoundly unhappy with that. They made it clear in 2004, after the second tranche, that they were profoundly unhappy with that expansion.
Segment 2313: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2909, Text: And then, in April 2008, when NATO announced that Ukraine and Georgia would become part of NATO, they made it unequivocally clear, not just Putin, that was not going to happen. They were drawing a red line in the sand. And it is no accident that in August 2008, remember the Bucharest Summit is April 2008? And August 2008, you had a war between Georgia and Russia, and that involved, at its core, NATO expansion.
Segment 2314: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2942, Text: So the Americans and their allies should have understood by at least August 2008 that continuing to push to bring Ukraine into NATO was going to lead to disaster. And I would note that there were all sorts of people in the 1990s like George Kennan, William Perry, who was Bill Clinton’s Secretary of Defense, the Chairman of the Joint Chiefs of Staff, Paul Nitsa, and so forth and so on, who argued that NATO expansion would end up producing a disaster, which it has.
Segment 2315: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=2978, Text: I would note that at the famous April 2008 Bucharest Summit, where NATO said that Ukraine would be brought into the alliance, Angela Merkel and Nicolas Sarkozy, the German and French leaders respectively, opposed that decision. Angela Merkel later said that the reason she opposed it was because she understood that Putin would interpret it as a declaration of war. Just think about that. Merkel is telling you that she opposed NATO expansion into Ukraine, because she understood, correctly, that Putin would see it as a declaration of war.
Segment 2316: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3022, Text: What did the United States and its friends and friends in Europe do? They continued to push and push, because we thought that we could push NATO expansion down their throat after 2008, the same way we did in 1999 and 2004, but we were wrong, and it all blew up in our face in 2014. And when it blew up in our face in 2014, what did we do? Did we back off and say, “Well, maybe the Russians have some legitimate security interest.” No, that’s not the way we operate. We continued to double down.
Segment 2317: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3057, Text: And the end result is that in 2022, you got a war. And as I’ve argued for a long time now, we, the West, are principally responsible for that, not Vladimir Putin.
Segment 2318: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3071, Text: So the expansion of NATO is primarily responsible for that.
Segment 2319: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3075, Text: Yeah. To put it in more general terms, what we were trying to do was turn Ukraine into a Western bulwark on Russia’s border, and it really wasn’t NATO expansion alone. NATO expansion was the most important element of our strategy. But the strategy had two other dimensions. One was EU expansion, and the third was the Color Revolution. We were trying to force Orange Revolution in Ukraine, and the basic goal there was to turn Ukraine into a pro-Western, liberal democracy.
Segment 2320: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3112, Text: And that meant that you’d have Ukraine, if it worked, as a pro-Western liberal democracy that was in the EU, and that was in NATO. This was our goal. And the Russians made it unequivocally clear Ukraine was not going to become a Western bulwark on their border, and most importantly, they made it clear that Ukraine in NATO was unacceptable.
Segment 2321: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3139, Text: Can we talk about the mind of Vladimir Putin? You’ve mentioned this idea that he has aspirations for imperialist conquest, that he dreams of empire, is not grounded in reality. He wrote an essay in 2021, about one people. Do you think there is some degree to which he still dreams of the former Soviet Union reuniting?
Segment 2322: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3170, Text: No, he’s made it clear that anybody with a triple digit IQ understands that it’s nuts to think about recreating the Soviet Union. He thinks it’s a tragedy that the Soviet Union fell apart, but as he made clear in that essay, the July 12th, 2021 essay, and as he made clear in speeches before, immediately before he invaded Ukraine, he accepted the breakup of the Soviet Union, and he accepted the status quo in Europe, save for the fact he did not accept the idea that Ukraine would become part of NATO.
Segment 2323: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3213, Text: He’s been in power for over two decades. Is there a degree that power can affect a leader’s ability to see the world clearly, as they say, corrupt? Do you think power has corrupted Vladimir Putin, to a degree?
Segment 2324: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3232, Text: It’s very hard for me to answer that question because I don’t know him, and I’ve not studied him carefully in terms of his overall performance over the course of the 23 years that he’s been in power. I’ve studied him as a strategist, and I’ve studied how he deals with the West, and deals with the international system more generally since 2014. And I think he is a first class strategist.
Segment 2325: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3271, Text: This is not to say he doesn’t make mistakes, and he admits he’s made some mistakes, but I think that the West is dealing with a formidable adversary here. And I don’t see any evidence that he’s either lost speed off his fastball, or that power has corrupted his thinking about strategic affairs.
Segment 2326: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3299, Text: So he has consistently put, as a primary concern, security? As does the United States, he’s put for Russia’s security, making sure that NATO doesn’t get close to its borders?
Segment 2327: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3312, Text: I think that’s clear. Yeah, I think as I emphasized early on in our conversation, that leaders privilege security or survival over everything else. And by the way, he gave a number of talks and press conferences in addition to writing that famous article that you referred to on July 12th, 2021. So we have a pretty clear record of what he was saying, and I would argue what he was thinking, in the run-up to the war in February 2022.
Segment 2328: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3350, Text: And if you read what he said, it’s quite clear that he privileged security or survival. He was deeply concerned about the security of Russia. And Russia is a quite vulnerable state in a lot of ways, especially if you think back to what it looked like in the 1990s, as you know better than I do. It was in terrible shape. The Chinese talk about the century of national humiliation. One could argue that for the Russians, that was the decade of national humiliation. And it took Putin, I think, quite a bit of time to bring the Russians back from the dead. I think he eventually succeeded, but it took a considerable amount of time, and I think he understood that he was not playing a particularly strong hand. He was playing something of a weak hand, and he had to be very careful, very cautious, and I think he was. And I think that’s very different than the United States. The United States was the Unipol. It was the most powerful state in the history of the world, the most powerful state relative to all its possible competitors. From roughly 1989, certainly after December 1991, when the Soviet Union fell apart, up until, I would argue, about 2017, we were incredibly powerful. And even after 2017, up to today, the United States remains the most powerful state in the system.
Segment 2329: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3438, Text: And because of our geographical location, we are in a terrific situation to survive in any great power competition. So you have a situation involving the United States that’s different than the situation involving Russia. They’re just much more vulnerable than we are. And therefore, I think Putin tends to be more sensitive about security than any American president in recent times.
Segment 2330: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3471, Text: Europe on one side, China on the other side. It’s a complicated situation.
Segment 2331: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3476, Text: Yeah. And we talked before about 1812, when Napoleon invaded and Moscow got burned to the ground. We talked about World War I, where the Russians were actually defeated and surrendered, and then we talked about 1941 to 1945, where, although thankfully the Soviets prevailed, it was a close call. And I mean, the casualties, the destruction that the Soviet Union had inflicted on it by the Germans is just almost hard to believe. So they are sensitive.
Segment 2332: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3518, Text: You can understand full well, or at least you should be able to understand full well, why the idea of bringing Ukraine up to their border really spooked them. I don’t understand why more Americans don’t understand that, it befuddles me. I think it has to do with the fact that Americans are not very good at putting themselves in the shoes of other countries. And you really, if you’re going to be a first class strategist in international politics, you have to be able to do that. You have to put yourself in the shoes of the other side and think about how they think, so you don’t make foolish mistakes.
Segment 2333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3556, Text: And as a starting point, Americans tend to see themselves as the good guys and a set of others as the bad guys. And you have to be able to empathize that Russians think of themselves as the good guys, the Chinese think of themselves as the good guys, and just be able to empathize. If they are the good guys… It’s like that funny skit. Are we the baddies? Consider the United States could be the bad guys.
Segment 2334: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3584, Text: First of all, see the world, if the United States is the bad guys and China is the good guys, what does that world look like? Be able to just exist with that thought, because that is what the Chinese leadership and many Chinese citizens, if not now, maybe in the future, will believe. And you have to kind of do the calculation, the simulation forward from that. And same with Russia, same with other nations.
Segment 2335: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3612, Text: Yeah, I agree with you, a hundred percent. And just, I always think of Michael McFall at Stanford, who was the American ambassador to Russia, I think between 2012 and 2014. And he told me that he told Putin that Putin didn’t have to worry about NATO expansion because the United States was a benign hegemony.
Segment 2336: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3636, Text: And I asked Mike what Putin’s response was to that. And Mike said that Putin didn’t believe it, but Mike believed that he should believe it, and that we could move NATO eastward to include Ukraine, and in the end, we’d get away with it because we are a benign hegemony, but the fact is that’s not what Putin saw. Putin saw us as a malign hegemony. And what Mike thinks, or any American thinks, doesn’t matter. What matters is what Putin thinks.
Segment 2337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3675, Text: But also, the drums of war have been beating for some reason. NATO expansion has been threatened for some reason. So you’ve talked about NATO expansion being dead, so it doesn’t make sense from a geopolitical perspective, on the Europe side, to expand NATO. But nevertheless, that threat has been echoed. So why has NATO expansion been pushed, from your perspective?
Segment 2338: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3706, Text: There are two reasons. One is, first of all, we thought it was a wonderful thing to bring more and more countries into NATO. We thought that it facilitated peace and prosperity. It was ultimately all for the good. And we also thought that countries like Ukraine had a right to join NATO.
Segment 2339: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3732, Text: These are sovereign countries that can decide for themselves, and the Russians have no say in what Ukraine wants to do. And then finally, and this is a point I emphasized before, we were very powerful, and we thought we could shove it down their throat. So it’s a combination of those factors that led us to pursue what I think was ultimately a foolish policy.
Segment 2340: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3759, Text: We’ve talked about how wars get started. How do you hope the war in Ukraine ends? What are the ways to end this war? What are the ways to achieve peace there? To end the, I would say, senseless death of young men, as always happens in war?
Segment 2341: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3784, Text: I’m sad to say I don’t have a good answer to that. I don’t think there’s any real prospect of a meaningful peace agreement. I think it’s almost impossible. I think the best you can hope for at this point is, at some point the shooting stops, you have a ceasefire, and then you have a frozen conflict. And that frozen conflict will not be highly stable.
Segment 2342: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3816, Text: And the Ukrainians in the West will do everything they can to weaken Russia’s position, and the Russians will go to great lengths to not only damage that dysfunctional rump state that Ukraine becomes, but the Russians will go to great lengths to sow dissension within the alliance. And that includes in terms of transatlantic relations.
Segment 2343: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3843, Text: So you’ll have this continuing security competition between Russia on one side, and Ukraine and the West on the other. Even when you get a frozen peace, or you get a frozen conflict, and the potential for escalation there will be great. So I think this is a disaster.
Segment 2344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3865, Text: That’s a very realist perspective. Let me ask you sort of the human side of it. Do you think there’s some power to leaders sitting down, having a conversation, man to man, leader to leader, about this? There is just a lot of death happening. It seems that, from an economic perspective, from a historic perspective, from a human perspective, both nations are losing.
Segment 2345: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3895, Text: Is it possible for Vladimir Zelensky and Vladimir Putin to sit down and talk, and to figure out a way where the security concerns are addressed, and both nations can minimize the amount of suffering that’s happening, and create a path towards future flourishing?
Segment 2346: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3921, Text: I think the answer is no.
Segment 2347: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3923, Text: Even with the United States involved, three people in the room?
Segment 2348: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3927, Text: Well, I think if the United States is involved, the answer is definitely no. You have to get the Americans out. And then, I think if you have Zelensky and Putin talking, you have a sliver of a chance there. The Americans are a real problem. Look, let’s go back to what happens right after the war starts, okay? As I said before, we’re talking March, early April of 2022. The war starts on February 24th, 2022.
Segment 2349: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=3959, Text: And as I said to you, the two sides were negotiating in Istanbul, and they were also negotiating through Naftali Bennett, and the Bennett track and the Turkish track were operating together. I mean, they were not at cross purposes at all. What happened? Bennett tells the story very clearly that they had made significant progress in reaching an agreement. This is Zelensky on one side and Putin on the other. Bennett is talking in person to both Putin and Zelensky, and what happens to produce failure?
Segment 2350: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4005, Text: The answer is, the United States and Britain get involved and tell Zelensky to walk. They tell Zelensky to walk. If they had come in and encouraged Zelensky to try to figure out a way with Putin to shut this one down, and worked with Bennett, and worked with Erdogan, we might’ve been able to shut the war down then, but it was the United States.
Segment 2351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4029, Text: Well, let me sort of push back on that. You’re correct, but the United States paints this picture that everybody’s aligned. Maybe you can correct me, but I believe in the power of individuals, especially individual leaders. Again, whether it’s Biden or Trump or whoever goes into a room and says, in a way that’s convincing, that no more NATO expansion. And actually just on a basic human level, ask the question of why are we doing all this senseless killing?
Segment 2352: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4069, Text: And look at the interest of one, Russia, look at the interest of the other, Ukraine. Their interests are pretty simple. And say, the United States is going to stay out of this. We’re not going to expand NATO, and say all that in a way that’s convincing, which is that NATO expansion is silly at this point, China’s the big threat. We’re not going to do this kind of conflict escalation with Russia. The Cold War’s over, let’s normalize relations.
Segment 2353: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4100, Text: Let me just embellish your argument, okay?
Segment 2354: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4103, Text: Thank you. I need it.
Segment 2355: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4106, Text: If we say there’s a sliver of a chance that you can do this, and I do think there is a sliver of a chance. Let me just embellish your point.
Segment 2356: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4114, Text: Thank you. I need all the help I can get.
Segment 2357: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4117, Text: Two things have to be done here, in my opinion. One is, Ukraine has to become neutral, and it has to completely sever all security ties with the West, right? It is not like you can say, “We’re not going to expand NATO to include Ukraine, but we’re going to continue to have some loose security arrangement with Ukraine.” None of that. It has to be completely severed. Ukraine has to be on its own, okay?
Segment 2358: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4153, Text: And number two, Ukraine has to accept the fact that the Russians are going to keep the four oblasts that they’ve now annexed, and Crimea. The Russians are not going to give them back. And what you really want to do, if you’re Zelensky or who’s ever running Ukraine in this scenario that we’re positing, is you want to make sure the Russians don’t take another four oblasts, to include Kharkiv and Odessa.
Segment 2359: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4185, Text: If I’m playing Putin’s hand and this war goes on, I’m thinking about taking four more oblasts. I want to take about 43% of Ukraine and annex it to Russia, and I certainly want Odessa, and I certainly want Kharkiv, and I want the two oblasts-
Segment 2360: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4203, Text: And I certainly want Harki and I want the two old boss in between as well.
Segment 2361: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4205, Text: Literally, or as leveraged in negotiation or Ukraine neutrality?
Segment 2362: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4212, Text: No, I want them literally, I want to conquer them literally. My point to you is if we can begin to talk about cutting a deal now, you may be able to head that kind of aggression off at the pass. In other words, you may be able to limit Putin and Russia to annexing the four old boss that they’ve now annexed plus Crimea. That’s the best I think you can hope for. The point is you have to get the Ukrainians to accept that. You have to get the Ukrainians to accept becoming a truly neutral state and conceding that the Russians keep a big chunk of territory. It’s about 23% of Ukrainian territory that they’ve annexed and I find it hard to imagine any Ukrainian leader agreeing to that.
Segment 2363: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4263, Text: Well, there could be more nuanced things like no military involvement between the United States and Ukraine, but economic involvement, sort of financial support, so normalizing economic relationships with Ukraine, with Russia, all being-
Segment 2364: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4281, Text: I think you could probably get away with that. I think the tricky question there that you would have to answer is what about EU expansion? And I think EU expansion is probably a no-no for the Russians because most people don’t recognize this, but there is a military dimension built into EU expansion. It’s not purely an economic alliance or relationship or institution, whatever word you want to use. There’s a military dimension to that. In the run-up to the war, actually in the run-up to the 2014 crisis, when it first broke out, the Russians made it clear they saw EU expansion as a stalking horse for NATO expansion.
Segment 2365: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4330, Text: So EU expansion is tricky, but I think your point of close economic relations between … or healthy economic relations to use a better term between Ukraine and the West is possible. I think the Russians have a vested interest and if it’s a neutral Ukraine, they have a vested interest in that Ukraine flourishing, but that then brings us back to the territorial issue, right?
Segment 2366: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4359, Text: Well, so do you believe it’s possible for individual human relations to counteract the structural forces that you talk about? So meaning the leaders being able to pick up the phone and make agreements that are good for humanity as a whole and for their individual nations in the long term?
Segment 2367: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4379, Text: I think leadership matters here. I mean, one of the real problems here is that there’s no trust on the Russian side, and that has to do with the Minsk agreements. The Minsk agreements, which were designed to shut down the Civil War in Eastern Ukraine, in the Donbas really mattered to the Russians. And there were four players involved in the Minsk process, four main players, Russia and Ukraine of course, and then Germany and France. And I believe the Russians took the Minsk Accord seriously. I believe Putin took them very seriously. He wanted to shut down that conflict.
Segment 2368: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4432, Text: And Angela Merkel, Francois Hollande, he was the French leader and Poroshenko, who was the Ukrainian leader, those were the three key players besides Putin. Again, Hollande from France, Merkel from Germany, and Poroshenko from Ukraine have all explicitly said they were not seriously interested in reaching an agreement in all of the discussions with Putin, they were bamboozling him. They were trying to trick him so that they would buy time to build up Ukraine’s military. Putin is profoundly upset about these admissions by these three leaders. He believes he was fooled into thinking that Minsk could work. He believes that he negotiated in good faith and they did not.
Segment 2369: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4489, Text: And he believes that the level of trust now between Russia and the West is virtually zero as a result of this experience over Minsk. I only bring this up because it cuts against your argument that leaders could pick up the phone and talk to each other and trust each other at least somewhat to work out a meaningful deal. If you’re Putin at this point in time, trusting the West is not an idea that’s going to be very attractive at all. In fact, you’re going to distrust anything they say.
Segment 2370: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4530, Text: Yeah, distrust anything the West say, but there is individual humans. The way human nature works is when you’re sitting across from a person, you can trust a human being while still distrusting the West. I mean, I believe in the power of that. I think with the right leaders, you could sit down and talk, like override the general structural distrust of the West and say, “You know what? I like this guy or gal, whatever.” I do hope Zelensky and Putin sit down together and talk, have multiple talks.
Segment 2371: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4568, Text: Just remember they were doing that in March and the Americans came in and the British came in and they scotched a potential deal.
Segment 2372: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4577, Text: Well, the other beautiful thing about human nature, there’s forgiveness and there’s trying again.
Segment 2373: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4585, Text: When you’re the leader of a country in an anarchic system, you have to be very careful not to let your trust in a foreign leader take you too far, because if that foreign leader betrays you or betrays your trust and stab you in the back, you could die and again, you want to remember that the principal responsibility of any leader, I don’t care what country it is, is to ensure the survival of their state. And that means that trust is only going to buy you so much, and when you’ve already betrayed the trust of a leader, you really are not going to be able to rely on trust very much to help you moving forward. Now, you disagree with that? I hope you’re right.
Segment 2374: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4637, Text: And if they can shut down the Ukraine-Russia war, it would be wonderful. If I’m proved dead wrong, that would be wonderful news. My prediction that this war is going to go on for a long time and end in an ugly way is a prediction that I don’t like at all. So I hope I’m wrong.
Segment 2375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4665, Text: You wrote that many in the West believe that the best hope for ending the Ukraine wars to remove Vladimir Putin from power, but you argue that this isn’t the case. Can you explain?
Segment 2376: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4678, Text: Well, a lot of people thought when they were having all that trouble, the Russians were having all that trouble with Prigozhin and the Wagner Group that Putin was vulnerable and was likely to be overthrown. And what would happen is a peace-loving leader would replace Putin. I made two points at the time, and I would make those same two points now. Number one, he’s not likely to be overthrown. He was not likely then to be overthrown. And I think as long as his health holds up, I think he will remain in power. My second point is if he doesn’t remain in power and he’s replaced, I would bet a lot of money that his replacement will be more hawkish and more hard line than Putin is.
Segment 2377: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4738, Text: I actually think one could argue that Putin was too trusting of the West before the war started and number two, I think one could argue that he has not waged the war against Ukraine as vigorously as one might have expected. He was slow to mobilize the nation for war, and he has pursued a limited war in all sorts of ways. The Israelis, for example, have killed more civilians in Gaza in one month than the Russians have killed over 18 months in Ukraine. The idea that Vladimir Putin is waging a punishment campaign and killing on purpose, large numbers of civilians, is simply not true.
Segment 2378: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4793, Text: All this just to say that … I would imagine that if Putin leaves office and someone else comes in to replace him, that someone else will be at least if not, more hard line than him in terms of waging the war, and certainly will not trust the West any more than he has.
Segment 2379: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4815, Text: By way of advice, let me ask you, if I were to have a conversation interview Vladimir Putin and Zelensky individually, what should I ask them? If you, me and Vladimir Putin are having a chat, what are good ideas to explore? What are good questions to ask? What are good things to say on or off the mic once again, that could potentially even slightly, lessen the amount of suffering in the world caused by this war?
Segment 2380: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4851, Text: I think if you get an interview with Vladimir Putin, there’s just all sorts of questions you could ask him. And my sense is that Putin is a straight shooter. He’s also very knowledgeable about history, and he has simple theories in his head about how the world works. I think he would level with you, and all you would’ve to do is just figure out what all the right questions are. That would not be hard to do. You could ask him why was he so foolish? For example, why was he so foolish as to trust Poroshenko, Hollande and Merkel in the Minsk Accords. Why after his famous talk at Munich in 2007 where he made it clear that he was so unhappy with the West, did he continue to, in a very important way, trust the West?
Segment 2381: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4912, Text: Why didn’t he mobilize the Russian military before late September, 2022, once the negotiations that we were talking about before involving Istanbul and Naftali Bennett. Once they broke down, why didn’t he immediately mobilize more of the Russian population to fight the war? Just all sorts of questions like that. Then, you could ask him questions about where he sees this one headed. What’s the best strategy for Russia if the Ukrainians will not agree to neutrality?People like John Mearsheimer say, “You’ll probably take close to half of Ukraine. Is that true? Does it make sense to take Odessa.”
Segment 2382: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4967, Text: And John Mearsheimer also has questions about China, your future relationships with China?
Segment 2383: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=4973, Text: Yeah, I mean, one really important question that I would ask him is if the United States had basically not driven you into the arms of the Chinese, if there had been no war over Ukraine and the United States and its European allies had gone to considerable lengths to create some sort of security architecture in Europe that resulted in you, Vladimir Putin having good relations with Ukraine, what would your relations with China be and how would you think about that? So there are just plenty of questions you could ask him.
Segment 2384: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5013, Text: Well, hope burns eternal in my heart, I think probably in Putin’s heart and Zelensky’s heart, I hope because hope is, the leap of trust that we’ve talked about, I think is necessary for deescalation and for peace.
Segment 2385: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5030, Text: Well, you realize, I have, from the beginning, argued for different policies that were all designed to prevent this war from ever happening.
Segment 2386: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5039, Text: Yes.
Segment 2387: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5040, Text: I don’t know if you know this, but in 1993, I argued that Ukraine should keep its nuclear weapons. I was probably the only person in the West who made that argument. And my argument in 1993, this is in foreign affairs, was that there may come the day when Russia thinks about invading Ukraine. And should that day come, it would be very helpful for preventing war if Ukraine had nuclear weapons.
Segment 2388: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5067, Text: So military might is essential for maintaining a balance of power and peace.
Segment 2389: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5073, Text: Well, if you’re interested in deterring an adversary, if I’m worried about you coming after me, the best way to deter you is to have military might. If you’re Russia, and I’m Ukraine, I’m far weaker than you, right?
Segment 2390: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5086, Text: Yeah.
Segment 2391: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5087, Text: And having a nuclear deterrent would be very effective at convincing you not to attack me because if you attack me, you’re threatening my survival. And that’s the one circumstance where it is likely that I would use nuclear weapons to defend myself and given the consequences of nuclear use, you would be reluctant in the extreme to attack me. So that’s why I argued in ’93 that if Ukraine kept its nuclear weapons that made war down the road much less likely. And I believe I was correct. And in fact, Bill Clinton, who played the key role in forcing Ukraine to give up its nuclear weapons now says … he has said it publicly, you can find it on YouTube that he made a mistake doing that.
Segment 2392: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5136, Text: Furthermore, I argued in 2014 that it made eminently good sense not to continue to push to bring Ukraine into NATO because the end result is that Ukraine would be destroyed and Ukraine is being destroyed. So I was deeply interested at time in making sure that that didn’t happen for the good of the Ukrainians, not to mention, because stability in Europe is a net positive for almost everybody involved, but people did not listen to me then either.
Segment 2393: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5168, Text: How did nuclear weapons change the calculus of offensive realism, because of mutually assured destruction? I mean, it’s not just military might. It’s just so destructive that you basically can’t use nuclear weapons unless you want complete destruction.
Segment 2394: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5188, Text: There’s no question that the presence of nuclear weapons makes it much less likely. I’m choosing my words carefully here, much less likely that a great power would aggress against another great power. It doesn’t take that possibility off the table, but it makes it much less likely because of the reasons that you articulated. With regard to nuclear use, it’s an interesting question how you think about nuclear use in a MAD world. I mean, your point that we’re in a MAD world is … that’s mad, MAD as well as mad, small letters, but let’s stick to the capital letters. We’re in a world of mutual assured destruction. There’s no question that in that world, it’s unlikely that nuclear weapons would be used.
Segment 2395: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5242, Text: The way you use nuclear weapons in that world is you use them for manipulation of risk purposes, demonstration effect. You put both sides out on the slippery slope. Now, what exactly am I saying here? Let me talk about NATO doctrine during the Cold War. We lived in a MAD world, United States and Soviet Union or the Warsaw Pact in NATO, both had an assured destruction capability. So you had mutual assured destruction. If the Warsaw Pact were to invade Western Europe, and here we’re talking about West Germany and NATO was losing the war, we said that we would use nuclear weapons. How would we use nuclear weapons given that we were in a MAD world? The argument was that we would use a handful of nuclear weapons against the Warsaw Pact, not necessarily against their military forces.
Segment 2396: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5305, Text: It could be in a remote area. We would use a small number of nuclear weapons to signal to the Soviets that we were deadly serious about putting an end to their offensive, and that we were throwing both sides out on the slippery slope to oblivion. In other words, we were manipulating risk and the last clear chance to avoid Armageddon rested with them. And then, we would tell them that if you retaliated with a handful of nuclear weapons and you didn’t cease your offensive against West Germany, we would launch a small, another nuclear attack. We would explode a handful more of nuclear weapons, all for the purposes of showing you our resolve.
Segment 2397: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5361, Text: So this is the manipulation of risk strategy, and a lot of the language I just used in describing it to you is language that Thomas Schelling invented. Now fast-forward to the present, if Russia were losing in Ukraine, that’s the one scenario where I think where Russia would’ve used nuclear weapons. The question is, how would Russia have used nuclear weapons? Again, we’re assuming that the Russians are losing to the Ukrainians. I believe they would’ve pursued a manipulation of risk strategy. They would’ve used four or five, three or four, who knows, nuclear weapons-
Segment 2398: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5399, Text: Maybe just one in a rural area that kills very few people.
Segment 2399: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5403, Text: Yes, exactly, and basically, that would spook everybody. The American-
Segment 2400: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5408, Text: Just the mushroom cloud.
Segment 2401: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5410, Text: Yeah. It’s because of the threat of escalation.
Segment 2402: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5414, Text: Yeah.
Segment 2403: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5414, Text: Again, your point is we’re in a MAD world. I accept that and if you have limited nuclear use, right? We understand hardly anything about nuclear escalation because thank goodness we’ve never had a nuclear war. So once you throw both sides out on the slippery slope, even if you only use one nuclear weapon in your scenario, you don’t know what the escalation dynamics look like. So everybody has a powerful incentive to put an end to the conflict right away. I might add to you that there were people who believed that we would not even initiate a manipulation of risk strategy in Europe if we were losing to the Warsaw Pact during the Cold War.
Segment 2404: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5464, Text: Both Henry Kissinger and Robert McNamara said after leaving office that they would not have done it. They would’ve not initiated nuclear use, even limited nuclear use. That’s what we’re talking about here. They would rather be red than dead, that was the argument.
Segment 2405: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5484, Text: Too risky.
Segment 2406: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5485, Text: Too risky. That’s exactly right, but if they had used one nuclear weapon in your story, or three or four in my story, everybody would’ve said, “Oh my God, we’ve got to shut this one down immediately.” I only tell you this story or lay out this scenario as an answer to your question of how you use nuclear weapons in a MAD world, and this is the answer.
Segment 2407: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5513, Text: This is all very terrifying. Perhaps in part, it’s terrifying to me because I can see in the 21st century, China, Russia, Israel, United States using a nuclear weapon in this way, blowing it up somewhere in the middle of nowhere that kills maybe nobody, but I’m terrified of seeing the mushroom cloud and not knowing, given social media, given how fast news travels, what the escalation looks like there. Just in a matter of minutes, how the news travels and how the leaders react. It’s terrifying that this little demonstration of power, the ripple effects of it, in a matter of minutes, seconds, what that leads to because it’s human emotions.
Segment 2408: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5571, Text: You see the landscape of human emotions, the leaders and the populace and the way news are reported, and then the landscape of risk, as you mentioned, shifting the world’s most intense nonlinear dynamical system, and it is just terrifying because the entirety of human civilizations hangs in the balance there. And it’s like this, hundreds of millions of people could be dead.
Segment 2409: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5601, Text: Let’s just talk about this in the context of the Ukrainian War. If the Russians were losing, as I said before, which is not the case anymore, but in 2022, it did look like that, if the Russians are losing and they turn to nuclear weapons, the question is how do they use them? And they would use them in Ukraine, and because Ukraine has no nuclear weapons of its own, Ukraine cannot retaliate. It’s not a mutual assured destruction world. It’s a case where one side has nuclear weapons and the other doesn’t. That means that the Russians are likely to think that they can get away with using nuclear weapons in ways that would not be the case if they were attacking NATO.
Segment 2410: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5657, Text: And therefore, it makes nuclear use more likely. Okay. That’s point one. Point two is let’s assume that the Russians use two or three nuclear weapons in a remote area-
Segment 2411: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5667, Text: My palms are sweating, by the way. Just as a commentary. It’s terrifying.
Segment 2412: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5672, Text: Yeah. The question then is what does the West do? Now, Macron has said and Biden has also, I think, implicitly made this clear, “We would not retaliate with nuclear weapons, if the Russians were to attack with a handful of nuclear weapons in Western Ukraine.” Then, the question is what would we do? And if you listen to David Petraeus, what David Petraeus says, is that we should attack the Russian naval assets in the Black Sea and attack Russian forces in Ukraine. Well, once you do that, you have a great power of war. You have NATO versus Russia, which is another way of saying you have the United States versus Russia. We’re now in a great power of war.
Segment 2413: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5723, Text: They have nuclear weapons, we have nuclear weapons. They’ve used nuclear weapons. What is the happy ending here? And just to take it a step further and go back to our earlier discussion about moving NATO up to Russia’s borders, the point I made, which you’ll surely agree with, is that the Russians are very fearful when they see NATO coming up to their border. Well, here’s a case where not only is NATO come up to their border, but they’re in a war with NATO right on their border. What do the escalation dynamics look like there? You know what the answer is? Who knows? That should scare the living bejesus out of you, right?
Segment 2414: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5766, Text: And some of it could be, like you mentioned, unintended. There could be unintended consequences. That could be a Russian missile misses in hits Poland. These kinds of things that just escalate misunderstandings, miscommunications, even … I mean, nuclear weapon could be … boy, it could have been planned to go location X, and it went to a location Y that ended up actually killing a very large number of people. I mean, the escalation that happens there just happens in a matter of minutes. And the only way to stop that is communication between leaders. And that to me is a big argument for ongoing communication.
Segment 2415: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5812, Text: There’s a story that during the Cuban missile crisis, Kennedy put out the word, no aircraft under any circumstances or to penetrate Soviet airspace. He then found out a few days later that some guy hadn’t gotten the message and had penetrated in an aircraft deep into Soviet airspace.
Segment 2416: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5839, Text: Yeah.
Segment 2417: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5839, Text: And this supports your basic point that bad things happen.
Segment 2418: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5845, Text: Yeah.
Segment 2419: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5846, Text: And again, the overarching point here is we’ve never done this before, thankfully. Therefore, we don’t have a lot of experience as to how it plays itself out. It’s really a theoretical enterprise because there’s no empirical basis for talking about escalation in a nuclear crisis. And that, of course, is a wonderful thing.
Segment 2420: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5870, Text: Well, and in general, the human species as a whole as a one-off, is a theoretical enterprise. The survival of the human species. We’ve seen empires rise and fall, but we haven’t seen the human species rise and fall. So far it’s been rising, but it’s not obvious that it doesn’t end. In fact, I think about aliens a lot, and the fact that we don’t see aliens makes me suspect it’s not so easy to survive in this complicated world of ours. Switching gears a little bit and going to a different part of the world, also engulfed in war. Let me ask you about the situation in Israel. Why did Hamas attack Israel on October 7th, 2023? As you understand the situation, what was the reason that attack happened?
Segment 2421: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5928, Text: Well, I think the main reason was that you had this suffocating occupation. I think as long as the occupation persists, the Palestinians are going to resist. As you well know, this is not the first time there has been a Palestinian uprising. There was the first Intifada, there was the second Intifada, now there’s October 7th, and there are uprisings besides those three, so this is not terribly surprising. A lot of people hypothesized that this attack was due to the fact that the Israelis, the Saudis and the Americans were working together to foster another Abraham Accord and that the Palestinians would in effect be sold down the river.
Segment 2422: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=5985, Text: I think given the fact that this was in the planning stages for probably about two years, and the Abraham Accords with regard to Saudi Arabia are relatively new phenomenon, I don’t think that’s the main driving force here. I think the main driving force is that the Palestinians feel oppressed as they should, and that this was a resistance move. They were resisting the Israeli occupation.
Segment 2423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6018, Text: So that resistance, the attack involved killing a large number of Israeli civilians. There’s many questions asked there, but one is, do you think Hamas fully understood what the retaliation will involve from Israel and to Gaza?
Segment 2424: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6039, Text: They had to understand. I mean, you had Operation Cast Lead in 2008, 2009. It started, I think right after Christmas 2008, and it ended right before President Obama took office in January 2009. And the Israelis periodically do what they call mowing the lawn where they go into Gaza and they pound the Palestinians to remind them that they’re not supposed to rise up and cause any problem. So there’s no question in my mind that the Hamas forces understood full well that the Israelis would retaliate and they would retaliate in force as they have done.
Segment 2425: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6095, Text: Yeah, even the metaphor of mowing the lawn is disturbing to me in many ways. I actually saw Norman Finkelstein, I think, say that, well, then if you use that metaphor, then you could say that Hamas was also mowing the lawn. It’s such a horrific image because the result on either side is just the death of civilians. I mean, let me ask you about the death of civilians. So during the attack, 1400 Israelis were killed. Over 240 were taken hostage. Then, in response, as we sit today, Israel’s military response has killed over 10,000 people in Gaza. And given the nature of the demographics, it’s a very heavily young population.
Segment 2426: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6147, Text: Over 40% of them are under the age of 18, of those killed. That’s of course, according to Ministry of Health of Palestinian Authority. So what do you think is the long-term effect on the prospect of peace when so many civilians die?
Segment 2427: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6166, Text: I mean, I think it’s disastrous. I mean, the only way you’re going to get peace here is if you have a two-state solution where the Palestinians have a sovereign state of their own, and there is a sovereign Jewish state. And these two states live side by side American presidents since Jimmy Carter have understood this full well. And this is why we have pushed very hard for two-state solution. Indeed, many American Jews and many Israelis have pushed for a two-state solution because they think that that is the only way you’re going to get peace between the two sides. What’s happened here is that in recent years, the Israelis have lost all interest in a two-state solution.
Segment 2428: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6223, Text: And it’s in large part because the political center of gravity in Israel has steadily moved to the right. When I was a young boy, the political center of gravity in Israel was much further to the left than it is today. It is in a position now, the political center of gravity where there’s hardly any support for two state solution and Netanyahu and the rest of the people in his government were in favor or are in favor of a greater Israel. There’s just no question about that. Well, on top of that, you now have had a war where, as you described, huge numbers of civilians have been killed, and you already had bad blood between the Palestinians and the Israelis before this conflict.
Segment 2429: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6281, Text: And you could imagine how people on each side now feel about people on the other side. So even if you didn’t have this opposition inside Israel to a two-state solution, how could you possibly get the Israelis now to agree to a two-state solution? I think for the foreseeable future, the animosity …
Segment 2430: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6303, Text: Solution. I think for the foreseeable future, the animosity inside Israel towards the Palestinians is so great that it is impossible to move the Israelis in that direction. And the Israelis here are the key players more so than the Palestinians because it’s the Israelis who control Greater Israel. It’s the Israelis who you have to convince. Now, I want to be clear here. You also ultimately have to get around the fact that Hamas is not committed to a two-state solution. But I think that problem could be dealt with. It’s important to understand that Arafat and the PLO was once adamantly opposed to a two-state solution. But Arafat came around to understand that that was really the only hope for settling this. And he became a proponent of a two-state solution.
Segment 2431: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6353, Text: And that’s true of Mahmoud Abbas who runs the PA in the West Bank. It’s not true of Hamas at this point in time. They want a one-state solution, they want a Palestinian state. And of course, the Israelis want a one-state solution too, which is a Jewish state that controls all of Greater Israel. So the question is, can you get some sort of agreement? And I think to get to the nub of your question, given what’s just happened, it’s almost impossible to imagine that happening anytime soon.
Segment 2432: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6387, Text: The cynical perspective here is that those in power benefit from conflict while the people on both sides suffer. Is there a degree of truth to that? Or for the people in power to maintain power conflict needs to continue?
Segment 2433: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6404, Text: No, I don’t believe that. I mean, just to take the Netanyahu government or any Israeli government that maintains the occupation, what you want is you want a Palestinian population that submits to Israeli domination of Greater Israel. You don’t want resistance, you don’t want an intifada. You don’t want what happened on October 7th. In fact, I think one of the principal reasons that the Israelis are pounding Gaza and killing huge numbers of civilians. Punishing the civilian population in ways that clearly violate the laws of war, is because they want the Palestinians to understand that they are not allowed to rise up and resist the occupation. That’s their goal.
Segment 2434: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6453, Text: So, I think the Israelis would prefer that the Palestinians roll over and accept submission. In terms of the people who live in Gaza to include the elites, and the people who live in the West Bank to include the elites. They would much prefer to move to some sort of situation where the Palestinians have a state of their own. I think in the case of the PA, under Abbas, they would accept a two-state solution. I think what, at this point in time, Hamas wants is a one-state solution, but they want peace. All of them want peace. The two different sets of leadership in Palestine and the Israelis.
Segment 2435: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6496, Text: So you think Hamas wants peace?
Segment 2436: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6499, Text: Sure. But on its own terms, that’s the point.
Segment 2437: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6501, Text: What does peace look like for Hamas?
Segment 2438: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6504, Text: At this point in time, I think peace basically means a Greater Israel controlled by Palestine or Palestinians.
Segment 2439: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6511, Text: Okay. So essentially, it’s the whole land is called Palestine and there’s no Israel?
Segment 2440: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6518, Text: I think, at this point in time, that’s their principal goal. I do believe, and there have been hints over time, Jimmy Carter has said this, that Hamas can be convinced to a two-state solution. Assuming that the Palestinians get a viable state of their own, that Hamas would buy into that. Can we say that with a high degree of certainty? No, but I think the Israelis should have pursued that possibility. They should have worked with Abbas, they should have worked with Hamas to do everything they can to facilitate a two-state solution. Because I think, ultimately, that’s in Israel’s interest. Now, the Israeli government, and most Israelis at this point in time, I believe, don’t agree with that.
Segment 2441: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6561, Text: What do you think of Israel starting the ground invasion of Gaza recently on October 27th?
Segment 2442: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6571, Text: The question is, should they continue until they have finally defeated Hamas? There are all sorts of reports in the media, including in the Israeli media, that they’re not going to be allowed by the United States to continue this offensive for much more than a few weeks. The Israelis have been saying it’s going to take, in the best of all possible worlds, a number of months, if not a year to finish off Hamas. Well, it doesn’t look like they’re going to have enough time to do that. I doubt whether they can finish off Hamas, even if they’re given the time. I think they’re going to run into fierce resistance. And when they run into fierce resistance and large numbers of Israelis going to start to die, they’ll lose their appetite for this. And they, the Israelis, surely know at this point in time that even if they finish off Hamas, even if I’m wrong and they’re able to finish off Hamas, another group is going to rise up to resist the occupation.
Segment 2443: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6648, Text: The idea that you can use with Ze’ev Jabotinsky called The Iron Wall, to beat the Palestinians into submission is delusional. It’s just not going to happen. The Palestinians want a state of their own. They don’t want to live under occupation. And there’s no military solution for Israel here. There has to be a political solution. And the only viable political solution is a two-state solution. I mean, you can’t go to democracy. You can’t go to a situation where you give the Palestinians equal rights inside of Greater Israel in large part because there are now as many Palestinians as there are Israeli Jews. And over time, the balance, the demographic balance shifts against the Israeli Jews and in favor of the Palestinians. In which case, you’ll end up with a Palestinian state in Greater Israel. So democracy for all doesn’t work. The Israelis, I believe, are quite interested in ethnic cleansing.
Segment 2444: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6716, Text: I think they saw this recent set of events as an opportunity to cleanse Gaza, but that’s not going to happen. The Jordanians and the Egyptians have made it clear that that’s not happening. The United States has now made it clear that that’s not happening. And the Palestinians will not leave. They’ll die in place. So ethnic cleansing doesn’t work. So you’re really left with two alternatives, the two-state solution or a Greater Israel that is effectively an apartheid state. I mean, that’s what the occupation has led to. And all sorts of people have been predicting this for a long, long time. And you’ve now reached the point. Here in the United States, if you say that Israel’s an apartheid state, that’s going to get you into all sorts of trouble. But the fact is that Human Rights Watch, Amnesty International, and B’Tselem, which is the leading Israeli human rights group. All three of those institutions or organizations have issued detailed reports making the case that Israel is an apartheid state.
Segment 2445: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6787, Text: Furthermore, if you read the Israeli media, all sorts of Israelis, including Israeli leaders, refer to Israel as an apartheid state. It’s not that unusual to hear that term used in Israel. This is disastrous for Israel in my opinion. And Steve Walt and I said this, by the way, when we wrote The Israel Lobby, that Israel is an apartheid state, which is equivalent to Israel as an occupier is not good for Israel. That brings us back to the two-state solution. But as you and I were talking about a few minutes ago, it’s hard to see how you get a two-state solution. And the end result of this conversation is utter despair.
Segment 2446: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6833, Text: Because the path to a two-state solution is blocked by the amount of hate that’s created by civilian deaths?
Segment 2447: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6841, Text: Well, that plus the fact that the Israeli government is filled with people who have no interest in a two-state solution. They’re ideologically deeply committed to a Greater Israel. They want all the land between the Jordan River and the Mediterranean Sea to be part of a Jewish state. They’re just ideologically committed to that. And of course, as we were talking about before with regard to Hamas, Hamas wants everything between the river and the sea to be a Palestinian state. And when you have two sides with those kinds of views, you’re in deep trouble because there’s a little room for compromise. So what you have to do to get this to work is you have to convince the Israelis that it’s in their interest to have a two-state solution. And you’ve already taken care of the PA on this front, the Palestinian Authority, but you’ve got to convince Hamas that it’s maximalist goals are not going to work. And it’s in its interest to follow in the footsteps of Arafat and accept a two-state solution.
Segment 2448: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6917, Text: But even if you do that at this point, let’s say, that there’s a lot of willingness intellectually on both sides to do that. The problem is that the hatred that has been fueled by this ongoing conflict is so great that it’s just hard to imagine how you can make a two-state solution work at this juncture. That’s why I’ve sort of taken to saying, and I hope I’m wrong here, that on the two-state solution, that boat has sailed. It’s no longer possible.
Segment 2449: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6953, Text: Well, again, I believe in leadership and there’s other parties at play here, other nations, Jordan, Saudi Arabia, other players in the Middle East that could help through a normalization of relationships and these kinds of things. There’s always hope, like you said, slither of hope.
Segment 2450: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6970, Text: Slither of hope.
Segment 2451: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6972, Text: I think human civilization progresses forward by taking advantage of all the slithers it can get. Let me ask you about, you mentioned The Israel Lobby. You wrote a book, probably your most controversial book on the topic.
Segment 2452: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6986, Text: Not probably. Clearly, the most controversial book I ever wrote.
Segment 2453: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=6990, Text: So you’ve criticized the Israel lobby in the United States for influencing US policy in the Middle East. Can you explain what the Israel lobby is, their influence, and your criticism over the past, let’s say a couple of decades?
Segment 2454: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7008, Text: Well, the argument that Steve Walt and I made, actually, we wrote an article first, which appeared in the London Review of Books, and then we wrote the book itself. Our argument is that the lobby is a loose coalition of individuals and organizations that push American policy in a pro-Israel direction. And basically, the lobby is interested in getting the United States, and here we’re talking mainly about the American government, to support Israel no matter what Israel does. And our argument is, that if you look at the relationship between the United States and Israel, it’s unprecedented in modern history. This is the closest relationship that you can find between any two countries in recorded history. It’s truly amazing the extent to which Israel and the United States are joined at the hip. And we support Israel no matter what almost all the time. And our argument is that, that is largely due to the influence of the lobby. The lobby is an extremely powerful interest group.
Segment 2455: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7095, Text: Now, it’s very important to understand that the American political system is set up in ways that allow interest groups of all sorts to wield great influence. So in the United States, you have an interest group or a lobby like the National Rifle Association that makes it, well, not impossible to get gun control. And so with the Israel lobby, you have this group of individuals and organizations that wield enormous influence on US policy toward the Middle East. And this is not surprising given the nature of the American political system. So our argument is that the lobby is not doing anything that’s illegal, or illicit, or immoral, or unethical. It’s just a good old-fashioned American interest group. And it just happens to be extremely powerful. And our argument is that this is not good for the United States because no two countries have the same interests all the time. And when our interests conflict with Israel’s interest, we should be able to do what we think is in our national interest, in America’s national interest.
Segment 2456: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7182, Text: But the lobby tends to conflate America’s national interests with Israel’s national interests and wants the United States to support Israel no matter what. We also argue, and I cannot emphasize this enough, given what’s going on in the world today, that the lobby’s effects, the lobby has not been pushing policies that are in Israel’s interest. So our argument is that the lobby pushes policies that are not in America’s interest or not in Israel’s interest. Now, you’re saying to yourself, what exactly does he mean by that? What every president since Jimmy Carter has tried to do, as I said before, is to foster a two-state solution to push Israel, which is the dominant player in Greater Israel, push Israel to accept the two-state solution. And we have run into huge resistance from the lobby whenever we try to, let’s be blunt about it, coerce Israel.
Segment 2457: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7251, Text: In a perfect world where there was no lobby and an American president was free to put pressure on Israel, to coerce Israel, I believe, we would’ve gone a long way towards getting two-state solution. And I believe, this would’ve been in Israel’s interest. But we couldn’t get a two-state solution because it was almost impossible to put meaningful pressure on Israel because of the lobby. So this was not in Israel’s interest and it was not in America’s interest. And that was the argument that we made. And we, of course, got huge pushback for making that argument.
Segment 2458: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7288, Text: What’s the underlying motivation of the lobby? Is it religious in nature? Is it similar to the way war hawks are sort of militaristic in nature? Is it nationalistic in nature? If you were describe this loose coalition of people, what would you say is their motivation?
Segment 2459: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7307, Text: Well, first of all, I think you have to distinguish between Jews and Christians. You want to remember that there are a huge number of Christian Zionists who are deeply committed to Israel no matter what, right? And then, there are a large number of Jews. The Jews are obviously the most important of those two groups in the Israel lobby. But one of the arguments that we made in the book is that you should not call it the Jewish lobby because it’s not populated just by Jews and Christian Zionists are an important part of that lobby. But furthermore, there are a good number of Jews who are opposed to the lobby and the policies that the lobby pervades. And there are a number of Jews who are prominent anti-Zionist, and they’re obviously not in the lobby. Or if you take a group like Jewish Voice for Peace, Jewish Voice for Peace is not in the lobby. So it’s wrong to call it a Jewish lobby.
Segment 2460: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7372, Text: But with regard to the American Jews who are in that lobby, I think that really, this is all about nationalism. It’s not so much religion. Many of those Jews who are influential in the lobby are not religious in any meaningful sense of that term. But they self-identify as Jewish in the sense that they feel they’re part of a Jewish nation. And that in addition to being an American, they are part of this tribe, this nation called Jews. And that they have a responsibility to push the United States in ways that support the Jewish state. So I think that’s what drives most, if not almost all the Jews. This is not to say there’s not a religious dimension for some of them, but I think that the main connection is much more tribal in nature.
Segment 2461: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7429, Text: So I had a conversation with Benjamin Netanyahu and he said, “Fundamentally, if you’re anti-Zionist, you’re antisemitic.” So the Zionist project is tied to the hip to the Jewish project, what do you have to say to that?
Segment 2462: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7448, Text: Look, you can define antisemitism any way you want. And you can define antisemitism to incorporate anti-Zionism. And I think we have reached the point where antisemitism is identified today, not just with anti-Zionism, but with criticism of Israel. If you criticize Israel, some people will say you’re an antisemite. And if that’s your definition of antisemitism, it’s taken an important term and stretched it to the point where it’s meaningless. So when Steve and I wrote the book, wrote the article and then wrote the book, all sorts of people said that we were antisemites. This is a ludicrous charge. But what they meant was, you’re criticizing the lobby, you’re criticizing Israel, and therefore, you’re an antisemite. Okay. If that’s what an antisemite is, somebody who criticizes Israel, probably half the Jewish community, if not more in the United States, is antisemitic. And of course, you get into all these crazy games where people are calling Jews, self-hating Jews and antisemites because they’re critical of Israel.
Segment 2463: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7535, Text: But even people who are anti-Zionists, I don’t think they’re antisemitic at all. You can argue they’re misguided, that’s fine. But many of these people are Jewish and proud of the fact that they’re Jewish. They just don’t believe that nationalism and Jewish nationalism is a force that should be applauded. And you want to understand that in the American context, there is a rich tradition of anti-Zionism. And these were not people who were antisemites if you go back to the thirties, forties, fifties. And the same thing was even true in Europe. There were all sorts of European Jews who were opposed to Zionism. Were they antisemites? I don’t think so. But we’ve gotten to the point now where people are so interested in stopping any criticism of Israel that they wield this weapon of calling people antisemites so loosely that the term has kind of lost meaning. So I think Netanyahu is wrongheaded to equate anti-Zionism with antisemitism.
Segment 2464: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7609, Text: Alan Dershowitz was one of the people that called you specifically antisemitic. So just looking at the space of discourse, where’s the slither of hope for healthy discourse about US relationships with Israel between you and Alan Dershowitz and others like him?
Segment 2465: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7636, Text: Well, I think until there is a settlement of the Israeli-Palestinian conflict, there’s no hope of putting an end to this nonsense. Right?
Segment 2466: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7647, Text: So these are just uses of terms to kind of cheat your way through the discourse, it’s a shortcut.
Segment 2467: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7655, Text: No, it’s to silence people. It’s very important to understand that one of the lobby’s principle goals is to make sure we don’t have an open discourse, a freewheeling discourse about Israel. Because they understand, people in the lobby understand, that if you have an open discourse, Israel will end up looking very bad. You don’t want to talk about the occupation, you don’t want to talk about how Israel was created. All these subjects are ones that will cause problems for Israel. See, just to go to the present crisis. When you have a disaster, and what happened on October 7th is a disaster. One of the first things that happens is that people begin to ask the question, how did this happen? What’s the root cause of this problem? This is a disaster. We have to understand what caused it so that we can work to make sure it doesn’t happen again. So we can work to shut it down and then make sure it doesn’t happen again.
Segment 2468: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7726, Text: But once you start talking about the root causes, you end up talking about how Israel was created. And that means telling a story that is not pretty about how the Zionists conquered Palestine. And number two, it means talking about the occupation, right? It’s not like Hamas attacked on October 7th because there were just a bunch of antisemites who hated Jews and wanted to kill Jews. This is not Nazi Germany. This is directly related to the occupation and to what was going on inside of Gaza. And it’s not in Israel’s interest or the lobby’s interest to have an open discourse about what the Israelis have been doing to the Palestinians since, I would say, roughly 1903 when the second aliyah came to Israel or came to what was then Palestine, right? We want to talk about that. And we don’t want to talk about from the lobbyist’s point of view, the influence that the lobby has, right?
Segment 2469: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7794, Text: It’s better from the lobbyist’s point of view if most Americans think that American support of Israel is just done for all the right moral and strategic reasons, not because of the lobby. And when John Mearsheimer and Steve Walt come along and say, you have to understand that this special relationship is due, in large part, to the lobby’s influence. That is not an argument that people in the lobby want to hear. So the point is, you have to go to great lengths for all these reasons. You have to go to great lengths to silence people like me and Steve Walt. And one of the ways to do that is to call us antisemites.
Segment 2470: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7832, Text: I think the chapter or the section of the book where we talk about this charge of antisemitism is called The Great Silencer. That’s what we call the charge of antisemitism, The Great Silencer. Who wants to be called an antisemite, especially in the wake of the holocaust? Do I want to be called an antisemite? Oh my God, no. And so it’s very effective. But it is important to talk about these issues, in my humble opinion. And I think if we had talked about these issues way back when, it would’ve gone a long way towards maybe getting a two-state solution, which I think was the best alternative here.
Segment 2471: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7881, Text: It’s complicated. And I wonder if you can comment on the complexity of this, because criticizing Israel and criticizing the lobby can, for a lot of people, be a dog whistle for sort of antisemitic conspiracy theories. That this idea that Jews run everything, run the world, they’re this kind of cabal. And it’s also very true that people who are legitimately antisemitic are also critics of Israel in the same kind of way. And so, it’s such a complicated landscape in which to have discussions. Because even people like David Duke who are racist, don’t sound racist on the surface. I haven’t listened to him enough. But there’s dog whistles. It’s a complicated space in which to have discussions. I wonder if you can sort of speak to that. Because there’s this silencing effect of calling everybody antisemitic. But it’s also true that there’s antisemitism in the world, there is a sizable population of people that hate Jews. There’s probably a sizable population of people who hate Muslims, too.
Segment 2472: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7971, Text: A lot of hate out there.
Segment 2473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=7973, Text: A lot of hate out there. But the hatred of Jews has a long history. And so you have, like Rolling Stones have a set of great hits. And there’s just a set of great hits of the ways, conspiracy theories, that you can make about the Jews that are used as part of the hatred. So there’s nice templates for that. And I just wonder if you can comment on operating as a historian, as an analyst, as a strategic thinker in this kind of space.
Segment 2474: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8005, Text: Obviously, when we wrote the article, which we did before the book gave this subject a great deal of thought. I mean, what you say just now is music to our ears. I’m talking about me and Steve. I think that your point about dog whistles is correct. Look, we went to great lengths to make it clear that this is not a cabal. It’s not a conspiracy. And in fact, in a very important way, the lobby operates out in the open. They brag about their power. And this was true before we wrote the article. And we said in the article, in the book, and you heard me say it here, first of all, it’s not a Jewish lobby. Secondly, it’s not a cabal. It’s an American interest group.
Segment 2475: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8069, Text: And the American system is designed such that interest groups are perfectly legal, and some of them are super effective.
Segment 2476: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8077, Text: Exactly. I mean, you hit the nail right on the head. That’s exactly right. And there was nothing that we said that was antisemitic by any reasonable definition of that term. And huge numbers of Jews have known me and Steve over the years, and nobody ever, ever said that we were antisemitic before March, 2006 when the article appeared, because we’re not antisemitic. But look, you’ve got this interest group that has a significant influence on American policy and on Israeli policy, and you want to talk about it. It’s just important to talk about it. It’s important for Jews in the United States, for Jews in Israel, to talk about this. The idea that you want to silence critics is not a smart way to go about doing business, in my opinion. If we were wrong, if Steve and I were so wrong and our arguments were so foul, they could have easily exposed those arguments. They could have gone into combat with this in terms of the marketplace of ideas and easily knocked this down.
Segment 2477: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8160, Text: The problem was that our arguments were quite powerful. And instead of engaging us and defeating our arguments, they wanted to silence us. And this is not good. It’s not good for Israel, it’s not good for the United States. And I would argue in the end, if anything, it’s going to foster antisemitism. I think you don’t want to run around telling people that they can’t talk about Israel without being called an antisemite. It’s just not healthy in terms of the issue that you’re raising. But I still agree with you that it is a tricky issue. I don’t want to make light of that. I know that there’s this piece of literature out there called the Protocols of the Elders of Zion. And I fully understand that if you’re not careful, you can come close to writing volume two of the protocol. But I don’t believe that we wrote anything that was even close to that. And again, I think that a healthy debate on the issues that we were raising would’ve been not only in America’s interest, but it would’ve been in Israel’s interest.
Segment 2478: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8235, Text: Yeah. Underneath it all is just, I wonder why there is so much hate against groups, why it’s such a sticky way of thinking. Not just tribalism, proud of your country and kind of hating another country, but really deeply hating. Hating in a way where it’s part of your identity kind of hate.
Segment 2479: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8260, Text: Well, just to make a general point on this issue in our conversation here today, you often talk about individual leaders, and the word individual often pops up in your vocabulary. I believe that we are ultimately social animals before we are individuals. I believe we’re born into tribes, we’re heavily socialized, and that we carve out space for our individualism. But we are part of tribes, or social groups, or nations. Call them what you want, ethnic groups, religious groups. But the fact is that these tribes often crash into each other. And when they crash into each other, they end up hating each other. If you go to a place like Bosnia, the Croats and the Serbs, oh, my God. And then throw in the Bosniaks, which is the term for Bosnian Muslims. And Muslims, Croats, Serbs, and the tribes hate each other. And in a funny way, that hatred almost never goes away. And I guess, there are some exceptions to that.
Segment 2480: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8339, Text: If you look at the Germans after World War II, they’ve gone a long way towards reducing, I wouldn’t want to say completely eliminating, but reducing a lot of the hatred that existed between Germans and their neighbors. But that’s really kind of an anomalous case. I mean, you go around East Asia today and the hatred of Japan in a place like China, the hatred of Japan in a place like Korea, just not to be underestimated. But I think a lot of it just has to do with the fact that you’re dealing with social groups that have crashed into each other at one point or another. And there are those lingering effects. And by the way, this gets back to our discussion a few minutes ago about trying to get a two-state solution between the Palestinians and the Israeli Jews now that you have had this horrible war, which is ongoing.
Segment 2481: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8399, Text: It’s interesting to ask, to go back to World War II-
Segment 2482: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8402, Text: … To ask to go back to World War II. Now, you said you studied Nazi Germany in the ’30s from a perspective of maybe offensive realism, but just to look at the Holocaust, it’s sometimes popular in public discourse today to compare certain things to the Holocaust. People have compared the Hamas attack on Israel to the Holocaust, saying things like, “It’s the biggest attack on Jews since the Holocaust,” which kind of implies that there’s a comparison. People have made that same comparison in the other direction. What do you make of this comparison? Is it comparable? Does the use of the Holocaust have any accuracy in comparisons of modern day international politics?
Segment 2483: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8461, Text: Is it possible that you could have another genocide? Yes, and I would argue that what you had in Rwanda was a genocide. The Holocaust is not the only genocide. I believe the word genocide is used too loosely today. And as you know, lots of people, and I mean lots of people who are pro-Palestinian accused the Israelis of engaging in genocide in Gaza. I think what the Israelis are doing in Gaza represents a massacre. I would use that term given the number of civilians that they’ve killed and the fact that they’ve been indiscriminate in terms of how they’ve been bombing Gaza. But I would not use the word genocide. For me, a genocide is where one side attempts to eliminate another group from the planet. I think that what happened with the Holocaust was clearly a genocide, and that the Germans were bent on destroying all of European Jewry.
Segment 2484: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8533, Text: And if they could have gotten their hands on Jews outside of Europe, they would’ve murdered them as well. That’s a genocide. And I think with the Hutus and the Tutsis, you had a similar situation. I think with the Turks and the Armenians during World War I, that was a genocide, but I have a rather narrow definition of what a genocide is and I don’t think there are many cases that qualify as a genocide. The Holocaust certainly does. Now, what Hamas did doesn’t even come close to what happened to European Jewry between, let’s say, 1939 and 1945, although I date the start of the Holocaust to 1941, if we were looking at it closely, but let’s just say 1939, when they invaded Poland, from 1939 to 1945. What Hamas did pales in comparison. It’s hard to believe anybody would make that argument. Yes, a lot of Jews died, but hardly any compared to the number that died at the hands of the Germans. No parallel at all. And furthermore, Hamas was in no position to kill all of the Jews in the Middle East, just not going to happen.
Segment 2485: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8623, Text: But there’s also levels of things, Germans using human skin for lamps. There’s just levels of evil in this world.
Segment 2486: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8634, Text: Yes, but that’s not what Hamas is doing. I want to be very clear here. I am not justifying the Hamas’ killing of civilians. Not for one second, but I’m just saying… And by the way, just to go to the Israelis and what they’re doing in Gaza, as I said to you before, I do believe that is a massacre and I believe that’s to be condemned, the killing of civilians. This is not legitimate collateral damage. They’re directly punishing the population. But I would not call that a genocide and I would not compare that to the Holocaust for one second. I just want to be very clear on that.
Segment 2487: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8677, Text: Do you think if Israel could, they would avoid the death of any civilians? So you’re saying there’s some degree of punishment of collective-?
Segment 2488: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8688, Text: They’re purposely killing civilians. This is the Iron Wall. They’re trying to beat the Palestinians into submission. There’s no way you kill this many civilians if you’re trying to precisely take out Hamas fighters. And by the way, the Israeli spokesmen, the IDF spokesman has explicitly said that, “We are not pursuing precision bombing. And that what we are doing is trying to maximize the amount of destruction and damage that we can inflict on the Palestinians and I think this is a major mistake on the part of Israel.” First of all, it ends up being a moral stain on your reputation, number one. And number two, it doesn’t work. It doesn’t work. The Palestinians are not going to roll over and submit to Israeli domination of their life.
Segment 2489: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8752, Text: The whole concept of the Iron Wall, Jabotinsky’s term, was misguided. And by the way, if you look at what the Israelis are doing, they’re trying to do two things. One is the Iron Wall, and that’s where you punish the civilian population in Gaza and get them to submit. The other thing that they’re trying to do is get Hamas. They want to destroy Hamas. And the belief there is that if they destroy Hamas, they’ve solved the problem. But as many Israelis know, including people on the hard right, even if you destroy Hamas, they are going to be replaced by another resistance group and that resistance group will employ terror.
Segment 2490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8796, Text: Yeah. I think you’ve said that other terrorist organizations have used the situation in Palestine as a recruitment mechanism for a long time.
Segment 2491: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8807, Text: Osama bin Laden made it clear that this was one of those principal reasons for attacking the United States.
Segment 2492: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8816, Text: And the United States attacked back and got us into a 20-year war that cost the lives of millions of people, not American, but human beings and-
Segment 2493: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8832, Text: Engaged in torture.
Segment 2494: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8834, Text: And torture. Yeah.
Segment 2495: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8836, Text: No, I think if you look at how we reacted to 9/11 and how the Israelis are reacting to what happened on October 7th, there’s quite a bit of similarity in that both sides, the Israeli side and the American side, are enraged and they lash out and they go on a rampage and the end result is not good.
Segment 2496: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8865, Text: Is there a capacity within Israel or within United States after 9/11 to do something approximating turn the other cheek of understanding the root of terror is hate and fighting that hate with, not to sound naive, but compassion?
Segment 2497: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8890, Text: Well, I don’t think in either case you’re going to turn the other cheek.
Segment 2498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8898, Text: What I mean by that is some limited powerful military response, but very limited?
Segment 2499: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8905, Text: Coupled with a smart political strategy.
Segment 2500: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8907, Text: Political strategy, diplomacy.
Segment 2501: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8909, Text: Yeah. That’s what they should have done.
Segment 2502: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8911, Text: Yeah.
Segment 2503: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8911, Text: Right.
Segment 2504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8911, Text: But is there capacity for that or from your offensive realism perspective, it’s just the odds are really low?
Segment 2505: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=8921, Text: From my offensive realist perspective or my realist perspective, that’s what you should do. My view is states are rational actors, they should be cunning. They should think about the strategic situation they’re in and choose the appropriate response. And what happens, and this is why my theory is not always correct, is that sometimes states are not rational and they misbehave. I would argue in the Israeli case that it would’ve been good after October 7th, or starting on October 7th, if the United States had tried to hold the Israelis back and countenanced a more moderate response. Take some time just to think about how to deal with this problem instead of lashing out. I think given what happened to the Israelis, given how shocked they were, given the level of fear, given the level of rage, they were going to lash out and I don’t believe that was in their interest. I think it would’ve made sense to think about it and to think about a smarter strategy than they’re now employing. And I think the Americans blew it. The Americans gave them a bear hug and a green light and said, “We’ll give you all the weaponry you need and go out and do it.” And I don’t think that was the smart thing to do. Look, in the wake of October 7th, the Israelis had no good strategy. It’s not like there’s a magic formula that they just didn’t see and we should have told them what the magic formula was. That’s not true. They were, in a sense, caught between a rock and a hard place in terms of what to do. But there are smarter things than number things and I think the Israelis lashed out in ways that are counterproductive. I think going on a rampage and killing huge numbers as civilians, it’s obviously morally wrong, but it’s also just not in their strategic interest because it’s not going to buy them anything.
Segment 2506: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9063, Text: And in fact, it’s going to cost them because people all over the planet are turning against Israel. I saw an Israeli think tank today that has been tracking protests around the world, gave some figures for what it looked like between October 7th and October 13th in terms of the number of protests around the world that were pro-Israel versus pro-Palestine. And then it looked at the numbers from October 13th up to the present and I think the numbers were 69% were pro-Palestinian in the first six days after October 7th, 69%, and I think 31%… Take these numbers with a grain of salt. 31% were pro-Israel. So I think it was 69 and 31.
Segment 2507: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9124, Text: And since then, since October 13th, if you look at the number of protests around the world, 95% have been pro-Palestinian and 5% have been pro-Israel. And what this tells you is that public opinion around the world has shifted against Israel. And if you look at some of the demonstrations in places like London and Washington, DC, it’s truly amazing the number of people who are coming out in support of the Palestinians. And all of this, again, is just to support my point that it was just not smart for Israel to launch this bombing campaign. You can make an argument for going after Hamas and doing it in a surgical way or as surgical a way as possible, but that’s not what they did. And again, my point to you is I think that this punishment campaign is not going to work strategically. In other words, they’re not going to beat the Palestinians into submission, they’re not going to finish off Hamas. And at the same time, by pursuing this strategy, they’re doing huge damage to their reputation around the world.
Segment 2508: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9196, Text: In the wake of October 7th, given the geopolitical context, I think there’s a lot of leverage to be the great ethical superpower, demonstrate power without killing any civilians, and use that leverage diplomatic leverage to push forward something like Abrahamic Accords with more nations, with Saudi Arabia, push for peace aggressively, peace agreements, this kind of stuff, economic relationships, all of this kind of stuff, and thereby pressure the Palestinian authority towards perhaps the two-state solution.
Segment 2509: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9244, Text: I think what you’re missing here, just in the Israeli case, is that the Israeli government is not interested in two-state solution. And you want to remember that Benjamin Netanyahu, who looks very hawkish when you look at him in isolation, doesn’t look so hawkish when you look at him compared to the rest of the people in his cabinet. He almost looks like a moderate. He’s got a lot of people who are way out to the right of him. And these people, and this of course includes Netanyahu, are not interested in the two-state solution. So the question you have to ask yourself is, if you’re Benjamin Netanyahu and it’s October 7th, late in the day, what do you do? You’re not thinking about a two-state solution. You’re thinking about an occupation that’s not going to end. And the question is how do you deal with the Palestinians given what’s just happened?
Segment 2510: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9305, Text: Well, there’s people in the cabinet and then there’s history. And history remembers great leaders. So Benjamin Netanyahu can look in the streets of Israel and see the protests and think of how history will remember him. I think a two-state solution is on the table for a great leader.
Segment 2511: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9324, Text: Well, it was there. Was he the person who was going to take advantage of it? I don’t think so, but we’ll see.
Segment 2512: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9335, Text: He’s a student of history. At this point, it’s very difficult. Like you said, 95% now or whatever the number is of protests, I think the window in which Israel has the ears of the world, it can do the big ethical action towards peace, I think, has closed. Or maybe there’s still a slither, but it’s just… The slippery slope of hate has taken off. It’s quite depressing to watch what’s going on.
Segment 2513: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9370, Text: Yep. I agree a hundred percent. Unequivocally depressing.
Segment 2514: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9373, Text: But of course, as you talk about the role of… The US involvement is of critical importance here for the United States and the argument you make is that we should not be involved in Ukraine, at least to the degree we are, we being the United States, and we should not be involved in Israel to the degree we are because it’s stretching us too thin when the big geopolitical contender in the 21st century with United States is China. Is that a correct summary?
Segment 2515: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9409, Text: Yeah, I think just on Ukraine, we should not have pushed Ukraine to join NATO.
Segment 2516: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9415, Text: Sure.
Segment 2517: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9416, Text: And once the war started, we should have worked overtime to shut it down immediately.
Segment 2518: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9423, Text: March.
Segment 2519: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9424, Text: March, right. And you remember, by the way, not to go back to Ukraine in great detail, in the early fall of 2022… The war starts February, 2022. There’s March, 2022, which we’ve talked about, which is the negotiations. In the fall of 2022, I think it was in September, the Ukrainians had won two major tactical victories, one in Kherson and the other in Kharkiv. And at that point in time, General Milley, who was the chairman of the Joint Chiefs of Staff, said, “Now is the time to negotiate because this is the high watermark for the Ukrainians.” Milley understood that things were only going to get worse, and the White House shut Milley down and said, “We’re not negotiating.” So we have blown a number of opportunities here to head this problem off at the pass. But that’s my view there. And with regard to the Israelis, my only point about Israel is that it would be better for Israel and better for the United States if we, the United States, was in a position to put pressure on Israel from time to time. As Steve and I say in the book, we should be able to treat Israel like a normal country. The fact is that countries sometimes do stupid things. This includes the United States and Israel. And if Israel is pursuing a policy that we think is unwise, we should be in a position where we could put pressure on Israel. That’s our argument. But anyway, we goofed both with regard to Ukraine and with regard to the Middle East and we’re now up to our eyeballs in alligators in both of those regions. And as you described my view, this is not good because the area of the most strategic importance for the United States today is East Asia and that’s because China is there and China is the most serious threat the United States faces.
Segment 2520: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9554, Text: Do you think there will be a war with China in the 21st century?
Segment 2521: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9559, Text: I don’t know. My argument is there will be. There is right now a serious security competition and at the same time, there is a real possibility of war. Whether or not we avoid it is very hard to say. I mean, we did during the Cold War. We had a serious security competition from roughly 1947 to 1989 and we thankfully avoided war, probably came the closest in 1962 at the Cuban Missile Crisis. But we avoided it and I think we can avoid it here. Is it for sure? No.
Segment 2522: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9599, Text: You’ve said that China won’t move on Taiwan militarily, in part because, as you said, amphibious operations are difficult. Why will China not move on Taiwan in your sense in the near future?
Segment 2523: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9616, Text: Well, it’s because there’s this body of water called the Taiwan Strait, which is a big body of water, and getting across water is very difficult unless you can walk on water.
Segment 2524: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9629, Text: So geography still has a role to play in the 21st century?
Segment 2525: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9632, Text: Oh, yeah. I think geography’s very important. Big bodies of water really matter. In an ideal world, you’d like to have the Pacific Ocean between you and any potential adversary. 6,000 miles of water, hard to get across. If you’re a country and I’m a country and there’s land between us, I can take my Panzer divisions and I can go right across the land and get into your country or attack your country. And you of course can take your Panzer divisions and come across that same piece of land. But if there’s a big body of water between us, your Panzer divisions can’t go across the water and then the question is how do you get them across the water? And that’s very tricky. And in a world where we have lots of submarines and you have lots of aircraft and you have missiles that are land-based that can hit those surface ships, it is very, very hard to attack across a body of water. And all you have to do is think about the American invasion of Normandy, June 6th, 1944, coming in on Omaha Beach. Oh, boy. That was really difficult.
Segment 2526: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9706, Text: But there is a growing asymmetry of military power there that even though it’s difficult-
Segment 2527: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9713, Text: That is correct.
Segment 2528: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9714, Text: So I guess-
Segment 2529: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9716, Text: That is correct.
Segment 2530: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9717, Text: So I recently had a conversation with Elon Musk and he says that China is quite serious about the One China policy, and it seems inevitable that Taiwan will have to be… If you look at this pragmatically in the 21st century, it seems inevitable that Taiwan will have to be a part of China and so we can get there either diplomatically or militarily. What do you think about the inevitability of that kind of idea? When a nation says, “This is a top priority for us,” what do you think about them meaning it, and what do we do about that?
Segment 2531: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9766, Text: There’s no question it’s a top priority for them and there’s no question they mean it, but it’s also a top priority for us not to let them take Taiwan.
Segment 2532: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9774, Text: Why exactly?
Segment 2533: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9776, Text: Because it’s an important strategic asset. Many people will say it’s because Taiwan’s a democracy, but that doesn’t matter that much. It’s because of two strategic reasons. The first is that if we were to let Taiwan go, it would have hugely negative consequences for our alliance structure in East Asia. To contain China, we need allies. We have an alliance structure, and our allies, Japanese, South Koreans, Filipinos, Australians, they’re all counting on us to be there for them. And if we say, “We’re not going to defend Taiwan, the Chinese attack,” they’re going to say, “I bet if the Chinese attack us, the Americans won’t be there for us.” So it would have a damaging effect on our alliance structure, which we cannot afford because containing China is a wicked problem. It’s a powerful state. You were getting to this before when you talked about China versus Taiwan. So that’s the first reason.
Segment 2534: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9847, Text: Second reason is you want to bottle up the Chinese Navy and the Chinese Air Force inside the first island-chain. You don’t want to let them get out into the Pacific. You don’t want them dominating the waters of East Asia. You want to bottle them up again inside the first island-chain. And you can only do that if you control Taiwan. You don’t control Taiwan, they get out into the Philippines Sea, into the Pacific, and the Western Pacific and cause all sorts of problems.
Segment 2535: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9878, Text: Well, you saying all that, you’ve also said the Century of Humiliation, Japan and the United States are a source of that humiliation for China, don’t you think they see the other side of that?
Segment 2536: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9892, Text: Absolutely.
Segment 2537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9893, Text: And in the interest of avoiding a World War… I guess the question is how do we avoid a world war? It doesn’t seem like the military involvement in the conflict between China and Taiwan is the way.
Segment 2538: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9914, Text: Well, I don’t want-
Segment 2539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9915, Text: There’s no good answers here. I’m just saying-
Segment 2540: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9917, Text: There are no-
Segment 2541: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9918, Text: Which is the less bad option?
Segment 2542: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9920, Text: Well, what you want to do is you want to make sure that you deter China from invading Taiwan. You want to avoid a war. You and I are in complete agreement on that. We don’t want a war, but we want to contain China. We do not want to let China dominate Asia. That’s what the Americans are principally concerned with here and it’s what China’s neighbors are principally concerned with. This includes the Japanese, the South Koreans, the Filipinos, Australians, and the Taiwanese. They don’t want and we don’t want China to dominate the region, so we have to contain it.
Segment 2543: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=9957, Text: But at the same time, and this should be music to your ears, we not only want to contain it, we want to make sure we don’t end up in a shooting match with the Chinese because this could be disastrous. So you have to have a very smart policy. You have to build powerful military forces, and you have to make sure you don’t do anything that’s provocative. On Taiwan, for example, the last thing you want is for the Taiwanese government to declare its independence because the Chinese have said, “If Taiwan does that, we’ll go to war.” And of course, we don’t want that. So my view is you want to smartly build up your military forces and you want to do everything you can to contain China, and at the same time, not be provocative.
Segment 2544: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10001, Text: So a big component of that is making sure the US military is bigger than the Chinese military.
Segment 2545: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10011, Text: Not necessarily. It’s an interesting question. A lot of people think that to make deterrence work, you have to be able to beat the Chinese and therefore, you need a much bigger military. And I don’t think over time that’s possible. I think it’s probably not even possible now to beat the Chinese in a war over Taiwan or in a war in the South China Sea. I think what you want to do is make it clear to the Chinese either that there will be no winner… In other words, you don’t have to win, but you want to make sure they don’t win. It’s a lose-lose proposition if they go to war over Taiwan or what have you.
Segment 2546: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10060, Text: And if you can’t do that, you think that they’re so powerful that they’re ultimately going to win, you want to convince them that victory would be a Pyrrhic victory. In other words, they would pay a godawful price to win the war. You follow what I’m saying? So the best strategy for deterrence is you win, China loses. Second best strategy is a stalemate, nobody wins. Third best strategy is they win, but they pay a godawful price. And the fourth possibility, which you don’t want, is they went quickly and decisively. If that’s the case, then you don’t have much deterrence.
Segment 2547: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10108, Text: What does a world with China as the sole dominant superpower look like? I mean, a little bit underlying our discussion is this kind of idea that US is the good guys and China is the bad guys. First of all, dividing the world into good guys and bad guys seems to somehow miss the nuance of this whole human civilization project we’re undertaking. But what does the world look like where China is the dominant sole superpower in a unipolar world?
Segment 2548: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10141, Text: Well, I don’t tend to think of the world in terms of good guys and bad guys. As a good realist, I think that states or states, they’re all black boxes. I don’t discriminate between democracies and autocracies. But having said that, I am an American and as an American, I’m interested in the security of my country, the survival of my country. So I want the United States to be the most powerful state in the world, which means I want the United States to dominate the Western hemisphere, I want us to be a regional hegemon, and I want to make sure that China does not dominate Asia the way we dominate the Western hemisphere.
Segment 2549: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10185, Text: It’s not because I think we’re the good guys and they’re the bad guys. If I were Chinese and I were in Beijing and I was Xi Jinping’s national security advisor, I’d tell him what we got to do is make sure we dominate the world or dominate our region and then do everything we can to undermine America’s position in the Western hemisphere. That’d be my view. So I guess you could say I do view the world in terms of good guys and bad guys, an American and-
Segment 2550: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10216, Text: More like us and them versus-
Segment 2551: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10218, Text: Yeah, it’s us and them. That’s a nice way to put it. Yeah, it’s us versus them. Not so much good guys versus bad guys.
Segment 2552: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10224, Text: Is it possible to have a stable, peaceful world with a good balance of power where it’s China and US as superpowers? It’s a bipolar world, no longer unipolar.
Segment 2553: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10237, Text: Yeah. Okay, so you’re hypothesizing a world where they dominate Asia and we dominate the Western hemisphere.
Segment 2554: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10243, Text: Yeah.
Segment 2555: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10244, Text: I believe there would be a great deal of intense security competition between those two superpowers.
Segment 2556: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10253, Text: The definition of intense matters here. So it could be small military conflicts or it could be extremely large unstable military conflicts, right?
Segment 2557: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10264, Text: Well, conflict… Let’s use the word war. So I distinguish between security competition and war. And what I’m telling you is you’ll have an intense security competition where there’s no shooting, or if there’s shooting, it’s mainly proxies that are doing the fighting, much like the Vietnam War. Or you could have a case where one of those superpowers was involved in a war against a proxy of the other superpower. Think the Korean War. The United States fought the Chinese who were allied with the Soviets at the time. But a war between the United States and China, just like a war between the United States and the Soviet Union during the Cold War, that’s what you really want to avoid. So I think you’d have an intense security competition. You’d have wars involving proxies of each of those two superpowers and you would probably have some wars where one of superpowers was involved in a proxy with one of the other superpower’s proxies.
Segment 2558: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10332, Text: So it seems likely then, if that’s the case, then it would be Taiwan is the proxy and US fighting China through the proxy of Taiwan?
Segment 2559: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10341, Text: Yeah. Well, that would assume the United States… But you want to remember, you’re hypothesizing a situation where China dominates Asia.
Segment 2560: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10349, Text: Oh, it already has dominated.
Segment 2561: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10351, Text: Yeah, it’s already dominated Taiwan.
Segment 2562: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10354, Text: I see. Where do you find the proxies? Australia?
Segment 2563: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10358, Text: The Middle East could be a good case.
Segment 2564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10360, Text: Oh, wow.
Segment 2565: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10361, Text: Persian Gulf.
Segment 2566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10363, Text: Oh boy. And then our discussion of Israel becomes even more dramatically-
Segment 2567: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10367, Text: Yeah, well, Israel gets involved… I think in this scenario, if you’re talking about a US China competition and you’re talking about the Middle East, I think it’s the Gulf, it’s the Saudis, the Iranians, the Iraqis. It’s the oil.
Segment 2568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10383, Text: Don’t you think it could be Israel versus Iran with some very 1984 kind of dramatic partnership of Iran, Russia, and China versus United States, Europe, and Israel?
Segment 2569: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10398, Text: I think that’s possible. Yeah.
Segment 2570: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10399, Text: Oh boy.
Segment 2571: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10400, Text: I think that’s possible. Yeah. I mean, I hadn’t thought about it until you said it, but yeah, I think that that is possible.
Segment 2572: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10408, Text: Isn’t that terrifying?
Segment 2573: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10411, Text: Yeah. Well, in your scenario, where China already dominates Asia and we dominate the Western hemisphere, I think you start talking about where the most likely places that the United States and China go head-to-head or fight through proxies. I think it is the Gulf or the Middle East and the scenario that you posit.
Segment 2574: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10436, Text: I mean, one question I have… I don’t know about you, but for me, unlike with the Soviet Union, and I know I was born there, but even outside of that, the cultural gap, the loss in translation, the communication gap between China and the United States seems to be much greater than that of what was the former Soviet Union and the United States. I see two cultures intermingling and communicating as one of the ways to deescalate future conflict.
Segment 2575: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10475, Text: It’s an interesting question. I mean, at sort of an abstract theoretical level, my argument is that great powers act according to realist dictates and they understand those realistic dictates and that could lead to cooperation or it can lead to war. It depends. I would say just in the case of the Soviets, a lot of people…
Segment 2576: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10503, Text: I would say just in the case of the Soviets, a lot of people describe the Cold War as an ideological competition above all else, it was communism versus liberal democracy or communism versus liberal capitalism, whatever. I actually don’t believe that. I believe the Soviets were realist to the core. I believe Stalin was a realist par excellence, and that ideology did not matter much in Stalin’s foreign policy. And I believe if you look at Soviet foreign policy after World War II, throughout the Cold War, they were realists to the core. And I think in those days, the Americans were realists, a lot of liberal ideology floating around out there, but the Americans were realists. And I think one of the reasons you avoided a shooting match between the United States and the Soviet Union from ’47 to ’89 was because both sides, I think understood basic balance of power logic. US China competition is somewhat different.
Segment 2577: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10574, Text: First of all, the Chinese are realists to the core. I’ve spent a lot of time in China. I basically have rock and roll. I’m basically a rock and roll star in China. The Chinese-
Segment 2578: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10587, Text: You’re kind of a big deal in China. I love it.
Segment 2579: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10589, Text: The Chinese are my kind of people. They’re realists, right? They speak my language. It’s the United States that is not very realist. American leaders have a very powerful liberal bent and tend not to see the world in realist terms. I believe, by the way, just going back to our discussion of NATO expansion, I think our inability to understand that NATO expansion was anathema to the Soviet, to the Russians, was due in large part to the fact that we just during the unipolar moment, didn’t think of international politics from a realist perspective and didn’t respect anyone who thought about international politics from a realist perspective. If those various American administrations starting with the Clinton administration had put their realist hat on, they would’ve understood that NATO expansion into Ukraine was not a good idea, but we had this thoroughly liberal view of the world that dominated our thinking, and it’s gone away somewhat since we’ve moved into Multi-polarity, but not completely.
Segment 2580: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10654, Text: And this makes me a little nervous to pick up on your point. I mean, the United States is thinking about the world in ways that are somewhat different than the Chinese who are real as par excellence.
Segment 2581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10667, Text: So that’s fascinating. So the Chinese are pragmatic about thinking of the world as a competition of military powers, all the ways in which you described the realist perspective. So that’s a hopeful thing, right? If we can achieve stability and a balance of powers through that military competition.
Segment 2582: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10691, Text: Yeah, I actually think that’s right. I think if the United States, just let me talk a little bit about the United States to get at the issue you’re raising. If the United States pursues a smart containment strategy, given what you just said, and I said about the Chinese, I think we will avoid war. The problem with the Americans is it’s not just the liberalism. It’s the possibility that we will pursue a rollback policy. In other words, during the Cold War, we pursued containment. It was whenever anybody talked about American grand strategy towards the Soviet Unions, containment, containment, containment. We now know from the historical record that the United States was not only pursuing containment, it was pursuing rollback. We were trying to roll back Soviet power to put it bluntly, we were trying to wreck the Soviet Union, and I would not be surprised moving forward with regard to China if the United States pursues a serious rollback policy and-
Segment 2583: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10757, Text: So you’re saying throughout history, United States was always doing that. Always. Where’s that from? Why can’t we respect the power of other nations?
Segment 2584: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10766, Text: Because they may be a threat to us?
Segment 2585: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10768, Text: Well, I mean-
Segment 2586: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10771, Text: Look, you don’t respect the power of other nations. You fear the power of other nations.
Segment 2587: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10777, Text: Well fear and respect are next door neighbors depending on the neighborhood you’re living in, but I just mean it could be very counterproductive to try because if you can empathize with their… If you assume they’re rational actors you trying to roll back would lean into the uncertainty of potential conflict. So you want to avoid the uncertainty of potential conflict, caution, right?
Segment 2588: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10803, Text: Well, yes and no. Look, your point is you want to empathize. You want to be able to put yourself in the shoes of the other side.
Segment 2589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10810, Text: Yes.
Segment 2590: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10810, Text: I agree 100% with that, right. It’s very important if you’re a first class strategist to be able to do that, but at the same time, there is this competition for power taking place, and what you want to do is maximize how much power you have relative to the other side, and the other side wants to maximize how much power it has relative to you. So you have this competition for power that’s taking place all the time, and that’s taking place at the same time you want to have empathy or you want to be able to put yourself in the shoes of the other side. So those two things kind of go together.
Segment 2591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10849, Text: It just feels less threatening to build up your thing versus try to hurt the other person’s thing, the other group’s thing.
Segment 2592: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10860, Text: But if you build up your own power, you are building up your capability to hurt the other side.
Segment 2593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10866, Text: Right, but I guess you don’t rattle the saber just work on manufacturing sabers.
Segment 2594: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10873, Text: Well, that I agree with. I think that the United States wants to make sure it has a big stick in East Asia for purposes of containing China and avoiding a war, right? Again, I want to be clear, I’m not advocating that we start World War III, but the point is you want to have a big stick and you want to make sure that you don’t overstep your bounds in terms of using that big stick. This is the danger with rollback that you get too aggressive and you precipitate a war, and you also just have to be very careful what you say. And to go back to your favorite argument, you want to be able to have empathy or put yourself in the shoes of the other side, because if you do something, you want to think smartly about what that other side, how that other side is going to see your action and how they’re going to react, right?
Segment 2595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10929, Text: And mostly focus on the carrots, have a giant stick laying around, but never mention it, just focus on the carrots.
Segment 2596: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10937, Text: Well, occasionally you have to mention the stick.
Segment 2597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10939, Text: Everyone knows the stick is there.
Segment 2598: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10941, Text: There is some truth in that, right?
Segment 2599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10943, Text: I mean, yeah, and words matter a lot. It feels our current President Biden is meeting with Xi Jinping, and I think the words exchanged there are really important. I have a notion that leaders can stop wars just as much as they can start wars.
Segment 2600: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=10962, Text: Well, leaders matter. There’s no question about that, no question, but just on rhetoric, you want to remember that Putin has on more than one occasion, very subtly rattled the nuclear sword, and it has been very effective because Joe Biden has paid attention, and Joe Biden wants to make sure we don’t end up in a thermonuclear war, and thank goodness he’s thinking that way. So all Putin has to do is mention the possibility of nuclear war. Just to go back to Taiwan, switch areas of the world. If you’re interested in containing China and you’re interested in deterrence, and let’s go back to those various scenarios where the Chinese win, we win, Chinese win, but they do it at great cost.
Segment 2601: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11015, Text: One could argue that, that discussion that I laid out before it didn’t take into account nuclear weapons and all President Biden or any of his successors has to do is just very subtly rattle or employ the nuclear threat and just sort of remind the Chinese that you start a war over Taiwan, it could easily escalate into a nuclear war. You want to understand we both have nuclear weapons, and if either one of us is put into a desperate situation, we may turn to those nuclear weapons and oh, by the way, Xi Jinping, you want to understand that we’re out here in the water and using nuclear weapons in the water, it’s not the same as using war nuclear weapons on lands. So we may very well use them. I’m not saying we will, but anyway, a little saber rattling. Right?
Segment 2602: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11076, Text: Let me just zoom out on human history. What makes empires collapse and what makes them last when they do when you look at human history, in your sense thinking about the United States, perhaps as an empire?
Segment 2603: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11092, Text: I don’t view the United States as an empire.
Segment 2604: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11097, Text: So to you empire as a thing that seeks expansion constantly?
Segment 2605: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11103, Text: Yeah, I think it’s a country that incorporates different regions or areas around the world into sort of a giant sphere of influence without incorporating those territories actually into the state itself. So you had this thing called the British Empire and it controlled areas like India, North America, and Kenya, just to pick a couple instances at different points. Singapore would be another example. Australia would be another example. So these were all entities that were part of the British Empire and the United States has taken a stab at empire after the Spanish American War, for example, with regard to the Philippines and Cuba and Puerto Rico, but we never got serious about it. There’s never been an American empire.
Segment 2606: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11173, Text: This is not to say the United States is not an incredibly powerful country that goes all around the world building military bases and stationing troops here, there and everywhere, but we’re not running an empire the way the British Empire was run or the French Empire. So the question for me is why did those empires go away? Why did the British Empire go away? If you ever look at a map of the world in 1922 after World War I, it’s truly amazing how much of that map is controlled by Britain. They had a huge empire and it’s disappeared.
Segment 2607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11213, Text: Probably by far the biggest in terms of area empire in human history, I think so.
Segment 2608: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11219, Text: I think that’s right. It almost has to be.
Segment 2609: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11221, Text: Yeah, right. It’s crazy.
Segment 2610: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11224, Text: Crazy, yeah.
Segment 2611: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11225, Text: And then no longer is the case.
Segment 2612: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11227, Text: Yeah. Now I want to be clear. The Americans have wielded maybe even greater influence than Britain did when it had its empire, but I don’t believe we have an empire that bears any resemblance to the British Empire. So the question is, what happened to that British empire? What happened to the French Empire? What happened to the Belgian Empire? What happened to the Dutch Empire? These were countries that had colonies all over the planet. The Dutch East Indies, Vietnam was French Indochina. Where did those empires go? Two factors finished them off. Number one, nationalism. Nationalism became a very powerful force in the 19th Century. It began to rear its head in the late 18th Century and became a very powerful force in the 19th and certainly in the 20th.
Segment 2613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11277, Text: Can you explain nationalism here?
Segment 2614: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11279, Text: Nationalism is the idea that these different nations that were part of the empire, like the Kenyans wanted their own state, nation state. This is my point about the Palestinians, right? This is Palestinian nationalism. What is Zionism? Zionism is Jewish nationalism. Jewish nationalism. Think of Theodore Herzl’s famous book. It’s called The Jewish State, Nation State. Think of the word nation state that embodies nationalism. Nation state, Jewish state. Palestinians want their own state, two state solution. Can’t beat the Palestinians into submission. The Indians wanted their own state. The Pakistanis wanted their own state. The Kenyans wanted their own state. Singapore wanted its own state. Oh, the Americans wanted their own state. This is called the American Revolution.
Segment 2615: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11331, Text: So that’s the first reason, nationalism that these empires disappeared. The second reason is that from a cost benefit analysis, they no longer made any sense, and it was the coming of the Industrial Revolution. Once the Industrial Revolution comes, an empire is basically an albatross around your neck. I would argue that the British Empire was an albatross around Britain’s neck in most of the 20th Century. Some of my friends disagree with that and think there were all sorts of benefits from the British Empire, but you want to remember that in the 20th Century, the three countries that really were powerful were the United States, Germany and the Soviet Union. Those were the big three. Did any of them have an empire? No.
Segment 2616: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11379, Text: That’s a good argument.
Segment 2617: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11380, Text: In the industrial world, you don’t need an empire, right? What you need is a powerful manufacturing base.
Segment 2618: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11390, Text: Well, the cost benefit analysis is different before the Industrial Revolution, there’s been many empires.
Segment 2619: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11396, Text: There’s no question that empires came and went, right?
Segment 2620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11400, Text: Yes.
Segment 2621: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11402, Text: All you have to do is just look at the British and the French in the Seven Years War, 1756 to 1763, the British win, they get Canada, and that’s why Quebec, Montreal, all these big French speaking areas are now part of Canada. So borders change and countries got established. The United States being one, and remember, South American, Central America were once completely dominated by the Spanish, and in the case of Brazil, the Portuguese, but they all in the 19th Century got their independence, and what I’m saying to you is in the 19th and in the 20th Century, there were two forces that were really driving the train. One is nationalism, and then the other is the industrial revolution, which changes the cost benefit analysis.
Segment 2622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11461, Text: Almost too crazy of a question, but if you look, let me calculate, let’s say 500 years from now, and you John Mearsheimer traveled through time and are at a bookstore looking at the entire history of human civilization in a single book. What role does US play? What’s the story of US over the next a hundred, 200, 300 years? Is it a big role, small role?
Segment 2623: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11492, Text: Well, that’s a long time. If you asked me, let’s just say the next hundred years.
Segment 2624: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11499, Text: Yeah, that’s still tough.
Segment 2625: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11502, Text: That’s still tough, but actually I think we’re in excellent shape and here’s the reason. Going back to the beginning of our conversation, you asked me about power and I told you the two principle building blocks of power are population size and wealth, and therefore you want to look around the world and you want to look at what you think the demographics are of countries like Britain, the United States, Iran, China, Russia, pick your country moving forward, what do the demographics look like and how wealthy are those countries likely to be? What you discover very quickly is that almost every country around the world is depopulating over time. Russia’s going to be much smaller, China’s going to be much smaller a hundred years from now than both of those countries are, as best we can tell.
Segment 2626: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11569, Text: United States, American women are not having lots of babies these days. No question about that, but we have immigration. We’re an immigrant culture. You’re a perfect manifestation of that. You’re a perfect, you’re now an American. That’s wonderful. We need more people like you. So when I hear Donald Trump and others arguing that immigration’s a terrible thing, this is ridiculous. Immigration is what made us great. It’s when my relatives came over in the middle of the 19th Century from Germany and Ireland.
Segment 2627: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11606, Text: That’s fascinating because there’s been a huge concern, America and other developed nations are not having enough children, but you just made me realize in the long arc of history, the United States has gotten really good at integrating immigrants and helping them flourish. The whole diversity of that makes up America.
Segment 2628: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11631, Text: You’re absolutely right.
Segment 2629: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11632, Text: There’s a machinery of integrating other cultures.
Segment 2630: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11636, Text: Yeah, just very quickly on this-
Segment 2631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11637, Text: That’s fascinating.
Segment 2632: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11639, Text: Sam Huntington’s book, Who Are We? Which in many ways I love that book, but it has one fundamental flaw and a number of people told him beforehand that flaw existed and he didn’t fix it, but Sam argues in the book that we have large numbers of Hispanics in this country and we’re doing a very poor job of integrating them into the mainstream and they’re not becoming Americans, and because many of them are concentrated in the Southwest of the United States, unlike other ethnic groups that were spread out all over God’s little green acre, we’re going to have this cohesive group of Spanish speaking Americans who are going to want to break away, and the United States is no longer going to be a reasonably coherent nation state. He’s wrong. All the evidence is that Hispanics are integrating into the American mainstream more quickly and more effectively than the European immigrant groups that came starting around 1835.
Segment 2633: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11712, Text: If you look at immigration from Europe into the United States, leaving aside the original wasps who came over and founded the place, the immigrants start coming in large numbers in 1835, and we really don’t shut the door until 1924, right? This is a crude overview, starting in 1835 and running up till about 1885, it’s mainly Germans and Irish. That’s why Germans are the largest ethnic group to ever come to the United States, and the Irish are right behind them. These are the European ethnic groups we’re talking about. Then starting in 1885 Pols, Jews and Italians start coming, and the Germans and Irish keep coming, and this is why Ellis Island is opened, I think it’s 1893, Ellis Island is opened because Castle Garden in New York, which had handled all the previous immigrants coming across the pond, Castle Garden, couldn’t handle them all, so they opened up Ellis Island.
Segment 2634: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11771, Text: That’s why somebody like me, I can’t find my distant relative’s records in Ellis Island because they came through Castle Garden. Whereas lots of Jews I know, lots of Italians, I know they can find their relatives records in Ellis Island because they came through Ellis Island. The point is, you had all these immigrants who came in roughly between 1835 and 1924 when we shut the gates. It was the only time we’ve ever really shut the gates in a meaningful way and this is what made America great, all these people, and they made lots of babies.
Segment 2635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11807, Text: So in some sense, make America great again, means getting more immigrants in.
Segment 2636: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11812, Text: Well, we opened the gates again in ’65, closed them in ’24, opened them in ’65. I’m oversimplifying the story here, because we didn’t completely shut them. We almost completely shut them in ’24, opened in ’65, and we’ve had huge numbers of immigrants flowing in. These immigrants who have been flowing in since ’65 are not Europeans. They’re not mainly Europeans, they’re mainly Hispanics and Asians. If you look at those Hispanics and Asians, they’re integrating into the American mainstream at a much faster and more effective clip than was the case with those immigrants who came in the 19th Century and early 20th Century.
Segment 2637: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11856, Text: The Irish, oh my God, they were treated horribly. There’s a book, a very famous book that’s been written called When The Irish Became White, just think about the title of that book. There was discrimination against all these groups, and the worst discrimination, of course was against Chinese Americans, but we’ve gotten much better and what we should do moving forward is redouble our efforts to integrate immigrants into the American mainstream, Hispanics, Asians of all sorts, because the fact is that America is rapidly reaching the point where it’s not going to be an all white country.
Segment 2638: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11904, Text: I have five children and two of my children are, I was a generation Z, Gen Z. Gen Z is the last majority white generation, subsequent generations, and not majority white. So for anybody who’s bothered by this, I’m not bothered by that, but for anybody who is bothered by this, they better good use to it because Americans aren’t making enough babies that we can continue to grow population-wise in a robust way. So we need immigration and we’re an immigrant culture, and this is a great virtue. It has been a great virtue over time.
Segment 2639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11950, Text: It should be a source of hope, not worry.
Segment 2640: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11953, Text: That’s my view. That’s my view and America when it works, is a place that is very attractive to immigrants and immigrants can do very well here and then the real key moving forward is intermarriage, and you have a huge amount of intermarriage. Somebody was telling me not too long ago that the highest inner marriage rates in the United States are among Asian women, Asian American women, Asian women and Anglos, and I say wonderful and-
Segment 2641: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11987, Text: Great.
Segment 2642: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11988, Text: Yeah. No, the more-
Segment 2643: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11989, Text: Love is the fastest way to integrate.
Segment 2644: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=11992, Text: Yeah. Well, what you want to do is you want to eliminate difference, right? You want to eliminate difference, right? It’s like people who say, “I’m an antisemite,” right? I have two grandsons who Adolf Hitler would’ve thrown into a gas chamber. One of whose first name is John, and middle name is Mearsheimer, right?
Segment 2645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12015, Text: Yeah.
Segment 2646: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12016, Text: This is what you want. Steve Watt’s wife and his two children would’ve been thrown into a gas chamber by Adolf Hitler. This is what you want. You want intermarriage. Now, there are a good number of people in some of those groups, especially among Jews who don’t like intermarriage, but they’ve lost because I haven’t looked recently at the data for intermarriage rates among basically secular Jews, but it used to be around 62% large numbers of Jews marry Guam.
Segment 2647: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12051, Text: And they’ve lost because of intermarriage. Intermarriage helps fight tribalism. Destructive kind of tribalism.
Segment 2648: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12058, Text: Exactly.
Segment 2649: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12058, Text: It’s nice
Segment 2650: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12059, Text: Calling me an antisemite, they haven’t met my grandsons, my son-in-laws, a niece that I have, nephews that I have, brother-in-laws that I have. Jewish. Come on.
Segment 2651: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12073, Text: And this gives a really nice hopeful view of America is the integration of different cultures, different kinds of peoples. That is a unique property of America.
Segment 2652: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12084, Text: Yes, but just to go back to where we started, it was not smooth in the beginning.
Segment 2653: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12089, Text: All things are rough in the beginning.
Segment 2654: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12091, Text: All things are rough in the beginning.
Segment 2655: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12094, Text: What advice would you give to a young person today about how to have a career they can be proud of or a life they can be proud of?
Segment 2656: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12102, Text: Well, I think it’s very important to make sure that you do something in life that really interests you. My mother used to use this phrase, “Floats your boat.” You want to do something that floats your boat or to use another one of my mother’s phrases, ” You want to get off. You want to do something where you get up out of bed in the morning with a bounce in your step.” So I think that if your mother and father want you to be a lawyer and they’re pushing you to be a lawyer and you don’t want to be a lawyer, you want to be a policeman, be a policeman. Don’t do what other people want you to do because it’s very important to find a job, an occupation that you really love.
Segment 2657: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12146, Text: The second thing I would say, and this has to do with your point about humility, you want to think about the humility hubris index. My friend Steve Van Everett, who teaches at MIT, he and I invented this concept. We call it the hubris humility index, and you want to have a healthy dose of humility, but you also want to have a healthy dose of hubris. You want to think you can change the world. You want to think you can make things better for yourself. You want to take chances. You want to think sometimes that you know better than other people do. Hubris is not a bad thing, but at the same time, you have to have humility. You have to understand that a man or a woman has his or her limits and you want to listen to other people. You want to be a good listener.
Segment 2658: Speaker: , Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12199, Text: So always remember the importance of the hubris humility index and the importance of having healthy doses of both hubris and humility.
Segment 2659: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12211, Text: Speaking of humility, you’re mortal, like all humans are, do you ponder your mortality? Are you afraid of it? Are you afraid of death?
Segment 2660: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12222, Text: I’m not sure I’m afraid of death. I don’t want to die because I enjoy life so much.
Segment 2661: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12230, Text: Having too much fun?
Segment 2662: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12233, Text: Given how horrible the world is today, I hate to say that I’m having too much fun, but do I find what I do interesting and gratifying? I do. I just love what I do and I love studying international politics, and I love being intellectually curious about all sorts of subjects. I love talking to you about this and that. I mean, this is really wonderful, and I often tell people thank goodness I’m only 28 years old because I do try to behave like I’m only 28 years old, but I am well aware of the fact that as my mother used to say, “Nothing is forever,” and that includes me and when you’re 75 going on 76, you understand that you have a limited number of years left and I find that depressing because I’ve been very lucky and I feel like I’ve won the lottery. I’m very thankful for that. I’d like to make it last for as long as possible, but I do understand that nothing is forever.
Segment 2663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12306, Text: Yeah, the finiteness of things.
Segment 2664: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12309, Text: Yeah. You never think that when you’re young. I mean, you think you’re going to live forever and you’re just not going to get old. I never thought this would happen that I would become 75 years old.
Segment 2665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12322, Text: Well, you got so much energy and boldness and fearlessness and excitement to you that I’m really grateful to see that, especially given how much I’m sure you’ve been attacked for having bold ideas and presenting them and not losing that youthful energy is beautiful to see.
Segment 2666: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12346, Text: Thank you.
Segment 2667: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12347, Text: Not becoming cynical. John, it’s a huge honor to speak with you that you’ve given me so much time and so much respect and so much love. This was a really incredible conversation. Thank you so much for everything you do in the world, for looking out into the world and trying to understand it and teach us, and thank you so much for talking with a silly kid like me.
Segment 2668: Speaker: John Mearsheimer, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12367, Text: It was my pleasure. Thank you very much. I thoroughly enjoyed it.
Segment 2669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=r4wLXNydzeY&t=12371, Text: Awesome. Thanks for listening to this conversation with John Mearsheimer. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Plato. “Only the dead have seen the end of war.” Thank you for listening and hope to see you next time.
Segment 2670: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=0, Text: The following is a conversation with Elon Musk, his fourth time on this, the Lex Fridman Podcast. I thought you were going to finish it. It’s one of the greatest themes in all of film history.
Segment 2671: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=31, Text: Yeah, that’s great.
Segment 2672: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=33, Text: So I was just thinking about the Roman Empire, as one does.
Segment 2673: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=38, Text: Is that whole meme where all guys are thinking about the Roman Empire at least once a day?
Segment 2674: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=44, Text: And half the population is confused whether it’s true or not. But more seriously, thinking about the wars going on in the world today, and as you know, war and military conquest has been a big part of Roman society and culture, and I think has been a big part of most empires and dynasties throughout human history.
Segment 2675: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=66, Text: Yeah, they usually came as a result of conquest. I mean, there’s some like the Hapsburg Empire where there was just a lot of clever marriages.
Segment 2676: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=76, Text: But fundamentally there’s an engine of conquest and they celebrate excellence in warfare, many of the leaders were excellent generals, that kind of thing. So a big picture question, Grok approved, I asked if this is a good question to ask.
Segment 2677: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=93, Text: Tested, Grok approved. Yeah.
Segment 2678: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=96, Text: At least on fun mode. To what degree do you think war is part of human nature versus a consequence of how human societies are structured? I ask this as you have somehow controversially been a proponent of peace.
Segment 2679: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=117, Text: I’m generally a proponent of peace. I mean, ignorance is perhaps, in my view, the real enemy to be countered. That’s the real hard part, not fighting other humans, but all creatures fight. I mean, the jungle is… People think of nature as perhaps some sort of peaceful thing, but in fact it is not. There’s some quite funny Werner Herzog thing where he is in the jungle saying that it’s basically just murder and death in every direction. The plants and animals in the jungle are constantly trying to kill each other every single day, every minute. So it’s not like we’re unusual in that respect.
Segment 2680: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=160, Text: Well, there’s a relevant question here, whether with greater intelligence comes greater control over these base instincts for violence.
Segment 2681: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=169, Text: Yes. We have much more vulnerability to control our limbic instinct for violence than say a chimpanzee. And in fact, if one looks at say, chimpanzee society, it is not friendly. I mean, the Bonobos are an exception, but chimpanzee society is filled with violence and it’s quite horrific, frankly. That’s our limbic system in action. You don’t want to be on the wrong side of a chimpanzee, it’ll eat your face off and tear your nuts off.
Segment 2682: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=202, Text: Yeah. Basically there’s no limits or ethics or they almost had just war. There’s no just war in the chimpanzee societies. Is war and dominance by any means necessary?
Segment 2683: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=213, Text: Yeah. Chimpanzee society is a permanent version of human society. They’re not like peace loving basically at all. There’s extreme violence and then once in a while, somebody who’s watched too many Disney movies decides to raise a chimpanzee as a pet, and then that eats their face or they’re nuts off or chew their fingers off and that kind of thing. It’s happened several times.
Segment 2684: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=238, Text: Ripping your nuts off is an interesting strategy for interaction.
Segment 2685: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=242, Text: It’s happened to people. It’s unfortunate. That’s, I guess, one way to ensure that the other chimp doesn’t contribute to the gene pool.
Segment 2686: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=250, Text: Well, from a martial arts perspective is the fascinating strategy.
Segment 2687: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=255, Text: The nut rougher.
Segment 2688: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=258, Text: I wonder which of the martial arts teaches that one.
Segment 2689: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=261, Text: I think it’s safe to say if somebody’s got your nuts in their hands and as the option of roughing them off, you’ll be amenable to whatever they want.
Segment 2690: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=270, Text: Yeah. Safe to say. So, like I said, somehow controversially, you’ve been a proponent of peace on Twitter on X.
Segment 2691: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=278, Text: Yeah.
Segment 2692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=279, Text: So let me ask you about the wars going on today and to see what the path to peace could be. How do you hope the current war in Israel and Gaza comes to an end? What path do you see that can minimize human suffering in the longterm in that part of the world?
Segment 2693: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=294, Text: Well, I think that part of the world is definitely, if you look up… There is no easy answer in the dictionary. It’ll be the picture of the Middle East in Israel especially. So there is no easy answer. This is strictly my opinion is that the goal of Hamas was to provoke an overreaction from Israel. They obviously did not expect to have a military victory, but they really wanted to commit the worst atrocities that they could in order to provoke the most aggressive response possible from Israel, and then leverage that aggressive response to rally Muslims worldwide for the course of Gaza and Palestine, which they have succeeded in doing. So the counterintuitive thing here, I think that the thing that I think should be done, even though it’s very difficult, is that I would recommend that Israel engage in the most conspicuous acts of kindness possible, everything, that is the actual thing that we’re taught the goal of Hamas.
Segment 2694: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=379, Text: So in some sense, the degree that makes sense in geopolitics turn the other cheek implemented.
Segment 2695: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=386, Text: It’s not exactly turn the other cheek because I do think that it is appropriate for Israel to find the Hamas members and either kill them or incarcerate them. That’s something has to be done because they’re just going to keep coming otherwise. But in addition to that, they need to do whatever they can. There’s some talk of establishing, for example, a mobile hospital. I’d recommend doing that. Just making sure that there’s food, water, medical necessities and just be over the top about it and be very transparent. So [inaudible 00:07:22] can claim it’s a trick. Just put webcam on the thing or 24, 7.
Segment 2696: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=449, Text: Deploy acts of kindness.
Segment 2697: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=451, Text: Yeah, conspicuous acts of kindness that are unequivocal, meaning they can’t be somehow because Hamas will then their response will be, “Oh, it’s a trick.” Therefore, you have to counter how it’s not a trick.
Segment 2698: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=467, Text: This ultimately fights the broader force of hatred in the region.
Segment 2699: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=471, Text: Yes. And I’m not sure who said it, it’s an [inaudible 00:07:54] saying, but an eye for an eye makes everyone blind. Now, that neck of the woods, they really believe in the whole eye for an eye thing. But you really have… If you’re not going to just outright commit genocide against an entire people, which obviously would not be acceptable to really, shouldn’t be acceptable to anyone, then you’re going to leave basically a lot of people alive who subsequently hate Israel. So really the question is like for every Hamas member that you kill, how many did you create? And if you create more than you killed, you’ve not succeeded. That’s the real situation there. And it’s safe to say that if you kill somebody’s child in Gaza, you’ve made at least a few homeless members who will die just to kill an Israeli. That’s the situation. But I mean, this is one of the most contentious subjects one could possibly discuss. But I think if the goal ultimately is some sort of long-term piece, one has to look at this from the standpoint of over time, are there more or fewer terrorists being created?
Segment 2700: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=566, Text: Let me just linger on war.
Segment 2701: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=569, Text: Yeah, war, safe to say, wars always existed and always will exist.
Segment 2702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=573, Text: Always will exist.
Segment 2703: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=574, Text: Always has existed and always will exist.
Segment 2704: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=577, Text: I hope not. You think it’ll always-
Segment 2705: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=582, Text: There will always be war. There’s a question of just how much war and there’s sort of the scope and scale of war. But to imagine that there would not be any war in the future, I think would be a very unlikely outcome.
Segment 2706: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=595, Text: Yeah. You talked about the Culture series. There’s war even there.
Segment 2707: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=598, Text: Yes. It’s a giant war. The first book starts off with a gigantic galactic war where trillions die trillions.
Segment 2708: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=607, Text: But it still nevertheless protects these pockets of flourishing. Somehow you can have galactic war and still have pockets of flourishing.
Segment 2709: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=618, Text: Yeah, I guess if we are able to one day expand to fool the galaxy or whatever, there will be a galactic war at some point.
Segment 2710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=631, Text: I mean, the scale of war has been increasing, increasing, increasing. It’s like a race between the scale of suffering and the scale of flourishing.
Segment 2711: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=638, Text: Yes.
Segment 2712: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=641, Text: A lot of people seem to be using this tragedy to beat the drums of war and feed the military industrial complex. Do you worry about this, the people who are rooting for escalation and how can it be stopped?
Segment 2713: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=656, Text: One of the things that does concern me is that there are very few people alive today who actually viscerally understand the horrors of war, at least in the US. I mean, obviously there are people on the front lines in Ukraine and Russia who understand just how terrible war is, but how many people in the West understand it? My grandfather was in World War II. He was severely traumatized. He was there I think for almost six years in Eastern North Africa and Italy. All his friends were killed in front of him, and he would’ve died too, except they randomly gave some, I guess IQ test or something, and he scored very high. He was not an officer. He was I think a corporal or a sergeant or something like that because he didn’t finish high school because he had to drop out of high school because his dad died and he had to work to support his siblings. So because he didn’t graduate high school, he was not eligible for the offset corps.
Segment 2714: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=717, Text: So he kind of got put into the cannon fodder category basically. But then randomly they gave him this test. He was transferred to British intelligence in London. That’s where we met my grandmother. But he had PTSD next level, next level. I mean, just didn’t talk, just didn’t talk. And if you tried talking to him, he’d just tell you to shut up. And he won a bunch of medals, never bragged about it once, not even hinted nothing. I found out about it because his military records were online. That’s how I know. So he would say like, “No way in hell do you want to do that again.” But how many people… Obviously, he died, he 20 years ago or longer, actually 30 years ago. How many people are alive that remember World War II? Not many.
Segment 2715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=774, Text: And the same perhaps applies to the threat of nuclear war.
Segment 2716: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=781, Text: Yeah, I mean, there are enough nuclear bombs pointed at United States to make the radioactive revel balance many times.
Segment 2717: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=790, Text: There’s two major wars going on right now. So you talked about the threat of AGI quite a bit, but now as we sit here with the intensity of conflict going on, do you worry about nuclear war?
Segment 2718: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=805, Text: I think we shouldn’t discount the possibility of nuclear war. It is a civilizational threat. Right now, I could be wrong, but I think the current probability of nuclear war is quite low. But there are a lot of nukes pointed at us, and we have a lot of nukes pointed at other people. They’re still there. Nobody’s put their guns away. The missiles are still in the silos.
Segment 2719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=837, Text: And the leaders don’t seem to be the ones with the nukes talking to each other.
Segment 2720: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=843, Text: No, there are wars which are tragic and difficult on a local basis. And then there are wars which are civilization ending or has that potential. Obviously, global thermonuclear warfare has high potential to end civilization, perhaps permanently, but certainly to severely wound and perhaps set back human progress to the Stone Age or something. I don’t know. Pretty bad. Probably scientists and engineers want to be super popular after that as well. You got us into this mess. So generally, I think we obviously want to prioritize civilizational risks over things that are painful and tragic on a local level, but not civilizational.
Segment 2721: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=900, Text: How do you hope the war in Ukraine comes to an end? And what’s the path, once again to minimizing human suffering there?
Segment 2722: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=908, Text: Well, I think that what is likely to happen, which is really pretty much the way it is, is that something very close to the current lines will be how a ceasefire or truce happens. But you just have a situation right now where whoever goes on the offensive will suffer casualties at several times the rate of whoever’s on the defense because you’ve got defense in depth, you’ve got minefields, trenches, anti-tank defenses. Nobody has air superiority because the anti-aircraft missiles are really far better than the aircraft. They’re far more of them. And so neither side has air superiority. Tanks are basically death traps, just slow moving, and they’re not immune to anti-tank weapons. So you really just have long range artillery and infantry ranges. It’s World War I all over again with drones, thrown old drones, some drones there.
Segment 2723: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=985, Text: Which makes the long range artillery just that much more accurate and better, and so more efficient at murdering people on both sides.
Segment 2724: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=994, Text: So whoever is… You don’t want to be trying to advance from either side because the probability of dying is incredibly high. So in order to overcome defense in depth, trenches and minefields, you really need a significant local superiority in numbers. Ideally combined alms where you do a fast attack with aircraft, a concentrated number of tanks, and a lot of people, that’s the only way you’re going to punch through a line and then you’re going to punch through and then not have reinforcements just kick you right out again. I mean, I really recommend people read World War I warfare in detail. That’s rough. I mean, the sheer number of people that died there was mind-boggling.
Segment 2725: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1057, Text: And it’s almost impossible to imagine the end of it that doesn’t look like almost exactly like the beginning in terms of what land belongs to who and so on. But on the other side of a lot of human suffering, death and destruction of infrastructure.
Segment 2726: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1076, Text: Yes. The thing that… The reason I proposed some sort of truce or peace a year ago was because I’ve predicted pretty much exactly what would happen, which is a lot of people dying for basically almost no changes in land and the loss of the flower of Ukrainian and Russian youth. And we should have some sympathy for the Russian boys as well as the Ukrainian boys, because Russian boys, because boys didn’t ask to be on their frontline. They have to be. So there’s a lot of sons not coming back to their parents, and I think most of them don’t hate the other side. It’s sort of like as this saying comes from World War I, it’s like young boys who don’t know each other killing each other on behalf of old men that do know each other. The hell’s the point of that.
Segment 2727: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1142, Text: So Volodymyr Zelenskyy said that he’s not, or has said in the past, he’s not interested in talking to Putin directly. Do you think he should sit down man to man, lead a leader, and negotiate peace?
Segment 2728: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1154, Text: Look, I think I would just recommend do not send the flower of Ukrainian youth to die in trenches, whether he talks to Putin or not, just don’t do that. Whoever goes on the offensive will lose massive numbers of people and history will not look kindly upon them.
Segment 2729: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1182, Text: You’ve spoken honestly about the possibility of war between US and China in the longterm if no diplomatic solution is found, for example, on the question of Taiwan and One China policy, how do we avoid the trajectory where these two superpowers clash?
Segment 2730: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1198, Text: Well, it’s worth reading that book on the, difficult to pronounce, the Thucydides Trap, I believe it’s called. I love war history. I like inside out and backwards. There’s hardly a battle I haven’t read about. And trying to figure out what really was the cause of victory in any particular case as opposed to what one side or another claim the reason.
Segment 2731: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1221, Text: Both the victory and what sparked the war and-
Segment 2732: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1224, Text: Yeah, yeah.
Segment 2733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1225, Text: The whole thing.
Segment 2734: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1226, Text: Yeah. So that Athens and Sparta is a classic case. The thing about the Greek is they really wrote down a lot of stuff. They loved writing. There are lots of interesting things that happened in many parts of the world, but people didn’t write down, so we don’t know what happened or they didn’t really write in detail. They just would say, “We had a battle and we won.” And what? Can you add a bit more? The Greeks, they really wrote a lot. They were very articulate on… They just love writing. And we have a bunch of that writing as preserved. So we know what led up to the Peloponnesian War between the Spartanand Athenian Alliance, and we know that they saw it coming.
Segment 2735: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1276, Text: Spartans didn’t write… They also weren’t very verbose by their nature, but they did write, but they weren’t very verbose. They were [inaudible 00:21:23]. But the Athenians and the other Greeks wrote a line, and Spartan was really kind of like the leader of Greece. But Athens grew stronger and stronger with each passing year. And everyone’s like, “Well, that’s inevitable that there’s going to be a clash between Athens and Sparta. Well, how do we avoid that?” And actually they saw it coming and they still could not avoid it. So at some point, if one group, one civilization or country or whatever exceeds another sort of like the United States has been the biggest kid on the block since I think around 1890 from an economic standpoint.
Segment 2736: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1334, Text: So the United States has been the most powerful economic engine in the world longer than anyone’s been alive. And the foundation of war is economics. So now we have a situation in the case of China where the economy is likely to be two, perhaps three times larger than that of the US. So imagine you’re the biggest kid on the block for as long as anyone can remember, and suddenly a kid comes along who’s twice your size.
Segment 2737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1375, Text: So we see it coming, how is it possible to stop? Let me throw something out there, just intermixing of cultures understanding there does seem to be a giant cultural gap in understanding of each other. And you’re an interesting case study because you are an American, obviously you’ve done a lot of incredible manufacture here in the United States, but you also work with China.
Segment 2738: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1400, Text: I’ve spent a lot of time in China and met with the leadership many times.
Segment 2739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1402, Text: Maybe a good question to ask is, what are some things about China that people don’t understand, positive just in the culture? What’s some interesting things that you’ve learned about the Chinese?
Segment 2740: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1416, Text: Well, the sheer number of really smart, hardworking people in China is incredible. There are really say how many smart, hardworking people are there in China? There’s far more of them there than there are here, I think, in my opinion. And they’ve got a lot of energy. So I mean, the architecture in China that’s in recent years is far more impressive than the US. I mean the train stations, the buildings, the high speed rail, everything, it’s really far more impressive than what we have in the US. I mean, I recommend somebody just go to Shanghai and Beijing, look at the buildings and go to take the train from Beijing to Xian, where you have the terracotta warriors. China’s got an incredible history, very long history, and I think arguably in terms of the use of language from a written standpoint, one of the oldest, perhaps the oldest written language, and then China, people did write things down.
Segment 2741: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1490, Text: So now China historically has always been, with rare exception, been internally focused. They have not been inquisitive. They’ve fought each other. There’ve been many, many civil wars. In the Three Kingdoms war, I believe they lost about 70% of their population. So they’ve had brutal internal wars, civil wars that make the US Civil War look small by comparison. So I think it’s important to appreciate that China is not monolithic. We sort of think of China as a sort of one entity of one mind. And this is definitely not the case. From what I’ve seen and I think most people who understand China would agree, people in China think about China 10 times more than they think about anything outside of China. So it’s like 90% of their consideration is internal.
Segment 2742: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1561, Text: Well, isn’t that a really positive thing when you’re talking about the collaboration and the future piece between superpowers when you’re inward facing, which is focusing on improving yourself versus focusing on quote, unquote improving others through military might.
Segment 2743: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1578, Text: The good news, the history of China suggests that China is not inquisitive, meaning they’re not going to go out and invade a whole bunch of countries. Now they do feel very strongly… So that’s good. I mean, because a lot of very powerful countries have been inquisitive. The US is also one of the rare cases that has not been inquisitive. After World War II, the US could have basically taken over the world in any country, we’ve got nukes, nobody else has got nukes. We don’t even have to lose soldiers. Which country do you want? And the United States could have taken over everything and it didn’t. And the United States actually helped rebuild countries. So it helped rebuild Europe, helped rebuild Japan. This is very unusual behavior, almost unprecedented.
Segment 2744: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1630, Text: The US did conspicuous acts of kindness like the Berlin Airlift. And I think it’s always like, well, America’s done bad things. Well, of course America’s done bad things, but one needs to look at the whole track record and just generally, one sort of test would be how do you treat your prisoners at war? Or let’s say, no offense to the Russians, but let’s say you’re in Germany, it’s 1945, you’ve got the Russian Army coming one side and you’ve got the French, British and American Army’s coming the other side, who would you like to be just surrendered to? No country is [inaudible 00:27:58] perfect, but I recommend being a POW with the Americans. That would be my choice very strongly.
Segment 2745: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1687, Text: In the full menu of POWs in the US.
Segment 2746: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1688, Text: Very much so. And in fact, Wernher von Braun, a smart guy, was like, “We’ve got to be captured by the Americans.” And in fact, the SS was under orders to execute von Braun and all of the German rocket conditioners, and they narrowly escaped. They said they were going out for a walk in the woods. They left in the middle of winter with no coats and then ran, but no food, no coats, no water, and just ran like hell and ran West and Vice Sherlock, I think his brother found a bicycle or something and then just cycled West as fast as he couldn’t have found a US patrol. So anyway, that’s one way you can tell morality is where do you want to be a PW? It’s not fun anywhere, but some places are much worse than others. Anyway, so America has been, while far from perfect, generally a benevolent force, and we should always be self-critical and we try to be better, but anyone with half a brain knows that.
Segment 2747: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1771, Text: So I think there are… In this way, China and the United States are similar. Neither country has been acquisitive in a significant way. So that’s a shared principle, I guess. Now, China does feel very strongly about Taiwan. They’ve been very clear about that for a long time. From this standpoint, it would be like one of the states is not there like Hawaii or something like that but more significant than Hawaii. And Hawaii is pretty significant for us. So they view it as really there’s a fundamental part of China, the island of Formosa, not Taiwan, that is not part of China, but should be. And the only reason it hasn’t been is because the US Pacific fleet.
Segment 2748: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1832, Text: And is their economic power grows and is their military power grows, the thing that they’re clearly saying is their interest will clearly be materialized.
Segment 2749: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1846, Text: Yes, China has been very clear that they’ll incorporate Taiwan peacefully or militarily, but that they will incorporate it from their standpoint is 100% likely.
Segment 2750: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1864, Text: Something you said about conspicuous acts of kindness as a geopolitical policy, it almost seems naive, but I’d venture to say that this is probably the path forward, how you avoid most wars. Just as you say it sounds naive, but it’s kind of brilliant. If you believe in the goodness of underlying most of human nature, it just seems like conspicuous acts of kindness can reverberate through the populace of the countries involved and deescalate.
Segment 2751: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1904, Text: Absolutely. So after World War I, they made a big mistake. They basically tried to lump all of blame on Germany and saddle Germany with impossible reparations. And really there was quite a bit of blame to go around for World War I, but they try to put it all in Germany and that laid the seeds for World War II. So a lot of people, were not just Hitler, a lot of people felt wronged and they wanted vengeance and they got it.
Segment 2752: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1958, Text: People don’t forget.
Segment 2753: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=1961, Text: Yeah, you kill somebody’s father, mother or son, daughter, they’re not going to forget it. They’ll want vengeance. So after World War II, they’re like, “Well, the Treaty of Versi was a huge mistake in World War I. And so this time, instead of crushing the losers, we’re actually going to help them with the module plan, and we’re going to help rebuild Germany. We’re going to help rebuild Austria and Italy and whatnot.” So that was the right move.
Segment 2754: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2006, Text: It does feel like there’s a profound truth to the conspicuous acts of kindness being an antidote to this.
Segment 2755: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2017, Text: Something must stop the cycle of reciprocal violence. Something must stop it, or it’ll never stop. Just eye for an eye, tooth for a tooth, limb for a limb, life for a life forever and ever.
Segment 2756: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2037, Text: To escape briefly the darkness, was some incredible engineering work, xAI just released Grok AI assistant that I’ve gotten a chance to play with. It’s amazing on many levels. First of all, it’s amazing that a relatively small team in a relatively short amount of time was able to develop this close to state-of-the-art system. Another incredible thing is there’s a regular mode and there’s a fun mode.
Segment 2757: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2063, Text: Yeah, I guess I’m to blame for that one.
Segment 2758: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2067, Text: First of all, I wish everything in life had a fun mode.
Segment 2759: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2069, Text: Yeah.
Segment 2760: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2070, Text: There’s something compelling beyond just fun about the fun mode interacting with a large language model. I’m not sure exactly what it is because I’ve only have had a little bit of time to play with it, but it just makes it more interesting, more vibrant to interact with the system.
Segment 2761: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2087, Text: Yeah, absolutely. Our AI, Grok, is modeled after The Hitchhiker’s Guide to the Galaxy, which is one of my favorite books, which it’s a book on philosophy. It’s-
Segment 2762: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2100, Text: My favorite books, it’s a book on philosophy, disguises book on humor. And I would say that forms the basis of my philosophy, which is that we don’t know the meaning of life, but the more we can expand the scope and scale of consciousness, digital and biological, the more we’re able to understand what questions to ask about the answer that is the universe. So I have a philosophy of curiosity.
Segment 2763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2134, Text: There is generally a feeling like this AI system has an outward looking, like the way you are sitting with a good friend looking up at the stars, asking pod head like questions about the universe, wondering what it’s all about. The curiosity that you talk about. No matter how mundane the question I ask it, there’s a sense of cosmic grandeur to the whole thing.
Segment 2764: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2159, Text: Well, we are actually working hard to have engineering math, physics answers that you can count on. So for the other AIs out there, these so-called large language models, I’ve not found the engineering to be reliable. It unfortunately hallucinates most when you at least want it to hallucinate. So when you’re asking important, difficult questions, that’s when it tends to be confidently wrong. So we’re really trying hard to say, okay, how do we be as grounded as possible? So you can count on the results, trace things back to physics first principles, mathematical logic. So underlying the humor is an aspiration to adhere to the truth of the universe as closely as possible.
Segment 2765: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2221, Text: That’s really tricky.
Segment 2766: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2222, Text: It is tricky. So that’s why there’s always going to be some amount of error. But do we want to aspire to be as truthful as possible about the answers with acknowledged error. So that there was always, you don’t want to be confidently wrong, so you’re not going to be right every time, but you want to minimize how often you’re confidently wrong. And then like I said, once you can count on the logic as being not violating physics, then you can start to bull on that to create inventions, like invent new technologies. But if you cannot count on the foundational physics being correct, obviously the inventions are simply wishful thinking, imagination land. Magic basically.
Segment 2767: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2281, Text: Well, as you said, I think one of the big goals of XAI is to understand the universe.
Segment 2768: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2286, Text: Yes, that’s how simple three word mission.
Segment 2769: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2293, Text: If you look out far into the future, do you think on this level of physics, the very edge of what we understand about physics, do you think it will make the sexiest discovery of them as we know now, unifying general relativity and quantum mechanics? So coming up with a theory of everything, do you think it could push towards that direction, almost like theoretical physics discoveries?
Segment 2770: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2318, Text: If an AI cannot figure out new physics, it’s clearly not equal to humans, nor has surpassed humans because humans have figured out new physics. Physics is just deepening what’s inside into how reality works. And then there’s engineering which is inventing things that have never existed. Now the range of possibilities for engineering is far greater than for physics because once you figure out the rules of the universe, that’s it. You’ve discovered things that already existed. But from that you can then build technologies that are really almost limitless in the variety. And it’s like once you understand the rules of the game properly, and with current physics, we do at least at a local level, understand how physics works very well. Our ability to predict things is incredibly good. Degree to which quantum mechanics can predict outcomes is incredible. That was my hardest class in college by the way. My senior quantum mechanics class was harder than all of my other classes put together.
Segment 2771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2390, Text: To get an AI system, a large language model be as reliable as quantum mechanics and physics is very difficult.
Segment 2772: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2401, Text: Yeah. You have to test any conclusions against the ground truth of reality. Reality is the ultimate judge. Like physics is the law, everything else is a recommendation. I’ve seen plenty of people break the laws made by man, but none break the laws made by physics.
Segment 2773: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2415, Text: It’s a good test actually. If this LLM understands and matches physics, then you can more reliably trust whatever it thinks about the current state of politics in some sense.
Segment 2774: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2428, Text: And it’s also not the case currently that even that its internal logic is not consistent. So especially with the approach of just predicting a token predict token, predict token, it’s like a vector sum. You’re summing up a bunch of vectors, but you can get drift. A little bit of error adds up and by the time you are many tokens down the path, it doesn’t make any sense.
Segment 2775: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2459, Text: So it has to be somehow self-aware about the drift.
Segment 2776: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2462, Text: It has to be self-aware about the drift, and then look at the thing as a gestalt as a whole and say it doesn’t have coherence as a whole. When authors write books, they will write the book and then they’ll go and revise it, take into account all the end and the beginning and the middle and rewrite it to achieve coherence so that it doesn’t end up at a nonsensical place.
Segment 2777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2493, Text: Maybe the process of revising is what reasoning is, and then the process of revising is how you get closer and closer to truth. At least I approached that way, you just say a bunch of bullshit first and then you get it better. You start a bullshit and then you-
Segment 2778: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2511, Text: Create a draft and then you iterate on that draft until it has coherence, until it all adds up basically.
Segment 2779: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2519, Text: Another question about theory of everything, but for intelligence, as you’re exploring this with XAI, creating this intelligence system? Do you think there is a theory of intelligence where you get to understand what is the I in AGI and what is the I in human intelligence?
Segment 2780: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2542, Text: No, I in team America. Wait, there is.
Segment 2781: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2544, Text: No, it’s going to be stuck in my head now. Yeah, there’s no me and whatever in quantum mechanics, wait. I mean is that part of the process of discovering, understanding the universe is understanding intelligence?
Segment 2782: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2570, Text: Yeah. I think we need to understand intelligence, understand consciousness. I mean there are some fundamental questions of what is thought, what is emotion? Is it really just one atom bumping into another atom? It feels like something more than that. So I think we’re probably missing some really big things.
Segment 2783: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2598, Text: Something that’ll be obvious in retrospect. You put the whole consciousness and motion.
Segment 2784: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2606, Text: Well, some people would quote like a soul religion, be a soul. You feel like you’re you, I mean you don’t feel like you’re just a collection of atoms, but on what dimension does thought exist? What dimension does do emotions exist? Because we feel them very strongly. I suspect there’s more to it than atoms bumping into atoms.
Segment 2785: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2632, Text: And maybe AI can pave the path to the discovery whatever the hell that thing is.
Segment 2786: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2638, Text: Yeah. What is consciousness? When you put the atoms in a particular shape, why are they able to form thoughts and take actions and feelings?
Segment 2787: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2650, Text: And even if it is an illusion, why is this illusion so compelling?
Segment 2788: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2653, Text: Yeah. Why does the solution exist? On what plane does the solution exist? And sometimes I wonder is either perhaps everything’s conscious or nothing’s conscious. One of the two.
Segment 2789: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2673, Text: Like the former, everything conscious just seems more fun.
Segment 2790: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2677, Text: It does seem more fun, yes. But we’re composed of atoms and those atoms are composed of quarks and leptons and those quarks and leptons have been around since the beginning of the universe.
Segment 2791: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2690, Text: “The beginning of the universe.”
Segment 2792: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2693, Text: What seems to be the beginning of the universe.
Segment 2793: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2695, Text: The first time we talked, you said, which is surreal to think that this discussion was happening is becoming a reality. I asked you what question would you ask an AGI system once you create it? And you said, “What’s outside the simulation,” is the question. Good question. But it seems like with Grok you started literally the system’s goal is to be able to answer such questions and to ask such questions.
Segment 2794: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2724, Text: Where are the aliens?
Segment 2795: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2725, Text: Where are the aliens?
Segment 2796: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2726, Text: That’s one of the foam paradox question. A lot of people have asked me if I’ve seen any evidence of aliens and I haven’t, which is kind of concerning. I think I’d probably prefer to at least have seen some archeological evidence of aliens. To the best of my knowledge, I’m not aware of any evidence surveillance. If they’re out there, they’re very subtle. We might just be the only consciousness, at least in the galaxy. And if you look at say the history of Earth, to believe the archeological record Earth is about four and a half billion years old. Civilization as measured from the first writing is only about 5,000 years old. We have to give some credit there to the ancient Sumerians who aren’t around anymore. I think it was an archaic pre-form was the first actual symbolic representation, but only about 5,000 years ago. I think that’s a good date for when we say civilization started. That’s 1000000th of Earth’s existence.
Segment 2797: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2795, Text: So civilization has been around. It’s really a flash in the pan so far. And why did it take so long? Four and a half billion years, for the vast majority of the time, there was no life. And then there was archaic bacteria for a very long time. And then you had mitochondria get captured, multicellular life, differentiation into plants and animals, life moving from the oceans to land, mammals, higher brain functions. And the sun is expanding slowly but it’ll heat the earth up at some point in the future, boil the oceans and earth will become like Venus, where life as we know it is impossible. So if we do not become multiplanetary and ultimately solar system, annihilation of all life on earth is a certainty. A certainty. And it could be as little as on the galactic timescale, half a billion years, long time by human standards, but that’s only 10% longer than earth has been around at all. So if life had taken 10% longer to evolve on earth, it wouldn’t exist at all.
Segment 2798: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2907, Text: Glad a deadline coming up, you better hurry. But that said, as you said, humans intelligent life on earth developed a lot of cool stuff very quickly. So it seems like becoming a multiplanetary is almost inevitable. Unless we destroy-
Segment 2799: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2925, Text: We need to do it. I suspect that if we are able to go out there and explore other star systems that we… There’s a good chance we find a whole bunch of long dead one planet civilizations that never made it past their home planet.
Segment 2800: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2943, Text: That’s so sad. Also fascinating.
Segment 2801: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2948, Text: I mean there are various explanations for paradox and one is they’re these great vultures which civilizations don’t pass through. And one of those great vultures is do you become a multi-plan civilization or not? And if you don’t, it’s simply a matter of time before something happens on your planet, either natural or manmade that causes us to die out. Like the dinosaurs, where are they now? They didn’t have spaceships.
Segment 2802: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2982, Text: I think the more likely thing is because just to empathize with the aliens that they found us and they’re protecting us and letting us be.
Segment 2803: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2991, Text: I hope so. Nice aliens.
Segment 2804: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2993, Text: Just like the tribes in the Amazon, the uncontacted tribes or protecting them. That’s what-
Segment 2805: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=2999, Text: That would be a nice explanation.
Segment 2806: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3000, Text: Or you could have, what was it? I think Andre Kappelhoff said, “It’s like the ants and the Amazon asking where’s everybody?”
Segment 2807: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3010, Text: Well, they do run into a lot of other ants.
Segment 2808: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3012, Text: That’s true.
Segment 2809: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3014, Text: These ant wars.
Segment 2810: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3016, Text: Sounds like a good TV show.
Segment 2811: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3018, Text: Yeah. They literally have these big wars between various ants.
Segment 2812: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3021, Text: Yeah. Maybe I’m just dismissing all the different diversity of ants.
Segment 2813: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3028, Text: Listen to that Werner Herzog talking about the jungle. It’s really hilarious. Have you heard it?
Segment 2814: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3031, Text: No, I have not. But Werner Herzog is a way.
Segment 2815: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3037, Text: You should play it as an interlude in the… It’s on YouTube. It’s awesome.
Segment 2816: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3045, Text: I love him so much.
Segment 2817: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3047, Text: He’s great.
Segment 2818: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3047, Text: Was he the director of happy people life and the Taiga? I think also-
Segment 2819: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3051, Text: He did that bear documentary. I did this thing about penguins.
Segment 2820: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3058, Text: The psycho analysis of a penguin.
Segment 2821: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3060, Text: Yeah. The penguins headed for mountains that are 70 miles away and penguin is just headed for dom, basically.
Segment 2822: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3068, Text: Well, he had a cynical take. He could be just a brave explorer and there’ll be great stories told about him amongst the penguin population for many centuries to come. What were we talking about? Okay.
Segment 2823: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3088, Text: Yeah. So aliens, I mean, I don’t know. Look, I think the smart move is just this is the first time in the history of earth that it’s been possible for life to extend beyond earth. That window is open. Now it may be open for a long time or it may be open for a short time and it may be open now and then never open again. So I think the smart move here is to make life multiplanetary while it’s possible to do so. We don’t want to be one of those lame one planet civilizations that just dies out.
Segment 2824: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3124, Text: No, those are lame.
Segment 2825: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3125, Text: Yeah. Lame. Self-respecting, civilization would be one planet.
Segment 2826: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3131, Text: There’s not going to be a Wikipedia entry for one of those. Do SpaceX have an official policy for when we meet aliens?
Segment 2827: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3143, Text: No.
Segment 2828: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3144, Text: That seems irresponsible.
Segment 2829: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3150, Text: I mean, look, if I see the slightest indication that there are aliens, I will immediately post on X platform anything I know.
Segment 2830: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3158, Text: It could be the most liked reposted post of all time.
Segment 2831: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3162, Text: Yeah. I mean, look, we have more satellites up there right now than everyone else combined. So we know if we’ve got a maneuver around something and we don’t have to maneuver around anything.
Segment 2832: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3175, Text: If we go to the big questions once again, you said you’re with Einstein, that you believe in the goddess Spinoza.
Segment 2833: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3184, Text: Yes.
Segment 2834: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3185, Text: So that’s that view that God is like the universe and reveals himself through the laws of physics or as Einstein said, “Through the lawful harmony of the world.”
Segment 2835: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3196, Text: Yeah. I would agree that God of the simulator or whatever the supreme beings reveal themselves through the physics, they have creatives of this existence and incumbent upon us to try to understand more about this one creation.
Segment 2836: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3218, Text: Who created this thing? Who’s running this thing? Embodying it into a singular question with a sexy word on top of it is focusing the mind to understand. It does seem like there’s a, again, it could be an illusion. It seems like there’s a purpose that there’s an underlying master plan of some kind, and it seems like.
Segment 2837: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3238, Text: There may not be a master plan in the sense. So maybe an interesting answer to the question of determinism versus free will is that if we are in a simulation, the reason that these higher beings would hold a simulation is to see what happens. So they don’t know what happens otherwise they wouldn’t hold the simulation. So when humans create a simulation, so it’s SpaceX and Tesla, we create simulations all the time. Especially for the rocket, you have to run a lot of simulations to understand what’s going to happen because you can’t really test the rocket until it goes to space and you want it to work. So you have to simulate subsonic, transonic, supersonic, hypersonic, ascend, and then coming back, super high heating and orbital dynamics. All this has got to be simulated because you don’t get very many kicks at the can. But we run the simulations to see what happens, not if we knew what happens, we wouldn’t run the simulation. So whoever created this existence, they’re running it because they don’t know what’s going to happen, not because they do.
Segment 2838: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3323, Text: So maybe we both played Diablo. Maybe Diablo was created to see if Druid, your character, could defeat Uber Lilith at the end. They didn’t know.
Segment 2839: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3334, Text: Well, the funny thing is Uber Lilith, her title is Hatred Incarnate. And right now, I guess you can ask the Diablo team, but it’s almost impossible to defeat Hatred in the eternal realm.
Segment 2840: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3355, Text: Yeah. You’ve streamed yourself dominating Tier 100 Nightmare Dungeon. And still-
Segment 2841: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3360, Text: I can cruise through Tier 100 Nightmare Dungeon like a stroll in the park.
Segment 2842: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3367, Text: And still you’re defeated by Hatred?
Segment 2843: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3369, Text: Yeah. I guess maybe the second hardest boss is Duriel. Duriel can even scratch the paint. So I killed Duriel so many times and every other boss in the game, all of them kill him so many times, it’s easy. But Uber Lilith, otherwise known as Hatred Incarnate, especially if you’re Duriel and you have no ability to go to be vulnerable, there are these random death waves that come at you.
Segment 2844: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3404, Text: Really I am 52, so my reflex is not what they used to be, but I have a lifetime of playing video games. At one point, I was maybe one of the best quake players in the world. I actually won money in what I think was the first paid eSports tournament in the US. We were doing four person quake tournaments and I was the second best person on the team and the actual best person that… We were actually winning, we would’ve come first, except the best person on the team. His computer crashed halfway through the game. So we came second, but I got money for it and everything. So basically I got skills, albeit no spring chicken these days. And to be totally frank, it’s driving me crazy to beat Lilith as a Druid, basically trying to beat Hatred Incarnate in the eternal realm.
Segment 2845: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3460, Text: As a Druid.
Segment 2846: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3461, Text: As a Druid. This is really vexing, let me tell you.
Segment 2847: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3469, Text: I mean, the challenge is part of the fun. I have seen directly, you’re actually a world-class, incredible video game player. And I think Diablo, so you’re just picking up a new game and you’re figuring out its fundamentals. You’re also with the Paragon Board and the build are not somebody like me who perfectly follows whatever they suggest on the internet. You’re also an innovator there, which is hilarious to watch. It’s like a mad scientist just trying to figure out the Paragon Board and the build. Is there some interesting insights there about if somebody’s starting as a druid, do you have advice?
Segment 2848: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3510, Text: I would not recommend playing a druid in the eternal realm. Right now I think the most powerful character in the seasonal realm is the Sorcerer with the lightning balls. The smokes have huge balls in the seasonal.
Segment 2849: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3526, Text: Yeah, that’s what they say.
Segment 2850: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3529, Text: So have huge balls. They do huge balls of lightning.
Segment 2851: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3534, Text: I’ll take you word for it.
Segment 2852: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3537, Text: In the seasonal realm, it’s pretty easy to beat Uber Lilith because you get these vapor powers that out amplify your damage and increase your defense and whatnot. So really quite easy to defeat Hatred seasonally, but to defeat Hatred eternally very difficult, almost impossible. It’s very impossible. It seems like a metaphor for life.
Segment 2853: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3564, Text: Yeah. I like the idea that Elon Musk, because I was playing Diablo yesterday and I saw Level 100 Druid just run by, I will never die and then run back the other way. And this metaphor, it’s hilarious that you, Elon Musk is restlessly, fighting Hatred in this demonic realm.
Segment 2854: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3587, Text: Yes.
Segment 2855: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3588, Text: It’s hilarious. I mean it’s pretty hilarious.
Segment 2856: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3590, Text: No, it’s absurd. Really, it’s exercise and absurdity and it makes me want to pull my hair out.
Segment 2857: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3597, Text: Yeah. What do you get from video games in general, for you personally?
Segment 2858: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3603, Text: I don’t know. It calms my mind. I mean, killing the demons in a video game calms the demons in my mind. If you play a tough video game, you can get into a state of flow, which is very enjoyable. Admittedly, it needs to be not too easy, not too hard, kind of in the Goldilocks zone, and I guess you generally want to feel like you’re progressing in the game. A good video, and there’s also beautiful art, engaging storylines, and it’s like an amazing puzzle to solve, I think. So it’s like solving the puzzle.
Segment 2859: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3652, Text: Elden Ring the greatest game of all time. I still haven’t played it, but to you-
Segment 2860: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3656, Text: Elden Ring is definitely a candidate for best game ever. Top five for sure.
Segment 2861: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3661, Text: I think I’ve been scared how hard it is or how hard I hear it is, but it’s beautiful.
Segment 2862: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3666, Text: Elden Ring, feels like it’s designed by an alien.
Segment 2863: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3673, Text: It’s a theme to this discussion. In what way?
Segment 2864: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3677, Text: It’s so unusual. It’s incredibly creative, and the art is stunning. I recommend playing it on a big resolution, high dynamic raised TV even. It doesn’t need to be a monitor. Just the art is incredible. It’s so beautiful and it’s so unusual, and each of those top bus battles is unique. It’s a unique puzzle to solve. Each one’s different and the strategy you use to solve one battle is different from another battle.
Segment 2865: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3714, Text: That said, you said Druid, an internal against Uber Lilith is the hardest boss battle you’ve ever…
Segment 2866: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3720, Text: Correct. That is currently the, and I’ve played a lot of video games because that’s my primary recreational activity. And yes, beating Hatred in the internal realm is the hardest bus battle in life. And in the video game. I’m not sure it’s possible, but I do make progress. So then I’m like, ” Okay. I’m making progress. Maybe if I just tweak that paragon board a little more, I can do it could.” Just dodge a few more waves, I could do it.
Segment 2867: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3763, Text: Well, the simulation is created for the purpose of figuring out if it can be done, and you’re just a cog in the machine of the simulation.
Segment 2868: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3771, Text: Yeah, it might be. I have a feeling that at least I think-
Segment 2869: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3782, Text: It’s doable.
Segment 2870: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3783, Text: It’s doable. Yes.
Segment 2871: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3785, Text: Well, that’s the human spirit right there to believe.
Segment 2872: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3789, Text: Yeah. I mean, it did prompt me to think about just hate in general, which is you want to be careful of one of those things where you wish for something that sounds good, but if you get it’s actually a dystopian situation. So if you wish for world peace sounds good, but how’d it enforced and at what cost eternal peace? It might actually be worse to have eternal peace because of what that would entail. The suppression of everyone, it might be the suppression of progress. It might be an ossified society that never changes. What I’m saying is that there is an argument that if you wish for no war, you should be careful what you wish for because what’s required in order for there to be no war might be worse than a little war.
Segment 2873: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3862, Text: Yeah. The things we’ll consider to be flaws of human civilization might be a necessary components for whatever optimal looks like. I mean this, do you worry about AI, AGI enabling a dystopian state of this nature, whether it’s 1984 with surveillance and fear or brave new world with pleasure and what is it? Lots of sex, but no deep human experience.
Segment 2874: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3892, Text: There’s actually a real drug called Soma.
Segment 2875: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3894, Text: There is?
Segment 2876: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3894, Text: Yes.
Segment 2877: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3896, Text: I’m going to take notes.
Segment 2878: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3898, Text: Does Gong know about it? No. He probably will go to Brave New World.
Segment 2879: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3902, Text: We got to ask it.
Segment 2880: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3903, Text: What would be the question?
Segment 2881: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3904, Text: Tell us about the drug called Soma.
Segment 2882: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3905, Text: Tell us about the drug called Soma. It’s going to go to Brave New World, I think.
Segment 2883: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3915, Text: Well, there’s a real drug as well.
Segment 2884: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3918, Text: Searching for Soma drug information. Oh boy. Soma, the wonder drug… By the way, I’m in fun mode.
Segment 2885: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3927, Text: Okay, fun. Yeah. So it’s talking about the real drug.
Segment 2886: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3931, Text: It’s a muscle relaxant that’s been around since the 1950s. It’s used to treat muscle pain and discomfort, and it does this by altering the activity between neurons and the spinal cord. Now, Soma isn’t just a pain reliever, it’s also a bit of a sedative. It can make you feel a bit drowsy. So it’s not something to take if you’re planning on operating, having machinery or trying to solve complex math equations. And it goes on and on. In conclusion, Soma is a drug that can be helpful for those dealing with muscle pain, but it’s not without its risks. That’s pretty good. Wait a minute.
Segment 2887: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3961, Text: That’s the real drug it’s talking about.
Segment 2888: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3963, Text: It’s the real drug. And of course the fun is always use it responsibly in accordance with the advice of a healthcare professional. And remember, in the end, the universe is probably just a giant computer simulation, so don’t take anything too seriously. I love it.
Segment 2889: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3980, Text: I love it. Yeah.
Segment 2890: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3982, Text: It also really nicely includes the tweets, posts on X that are relevant to this, which is really cool. That integrates everything together. The interface is one of the really cool things here.
Segment 2891: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=3996, Text: Yeah. Seems done a great job. You could say no, I mean, Soma from Brave New World, because it thinks you mean, you mean Soma, the real drug. No, I mean Soma from Brave Beer World.
Segment 2892: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4016, Text: It’s going to be like, “Oops, I’m really sorry.” I’m really surprised it went to the real drug first. My apologies. I was thinking of the muscle relaxer. Soma for brand New World is a different beast altogether. Now this Huxley dystopian, Soma is a drug that plays a central role in the society depicted in the book. It’s a mood altering hallucinogenic drug that’s used to keep the population docile and content in the novel. To use Soma in Brave New World raises some interesting questions about the nature of happiness and the role of drugs in society, man.
Segment 2893: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4050, Text: Exactly. Is it better to live in a world where everyone is happy all the time, even if that happiness is artificial? It’s good question. This is what I mean. Do you wish for world peace and happiness all the time? Are you sure? Because that might be a society that is essentially sterile and ossified that never changes, that is ultimately doomed.
Segment 2894: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4078, Text: This kind of tension between doctors and the light-
Segment 2895: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4084, Text: This is really a very good summary. It really gets to the point. This is not simply regurgitating a brave new world. It’s actually getting to the salient element of Soma as a drug. Do you actually want to be in a situation where everyone is happy all the time, even though it’s artificial? Or is it better to confront the challenges of life and experience the full range of human emotions, even if it means experiencing pain and suffering? For
Segment 2896: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4111, Text: Those listening, by the way, Elon just read directly from Grok, which is a really nice kind of insightful, philosophical analysis of the tension here. Interesting.
Segment 2897: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4121, Text: It pretty much nails it. In conclusion, Soma from Brave New World is fictional drug that’s used to explore some deep philosophical questions about the nature of happiness and the role of drugs in society. It’s a powerful symbol of the dangers of using drugs to escape from reality and the importance of confronting the challenges of life head on. Nailed it. And the crazy thing is we do have a real drug called Soma, which is like the drug in the book. And I’m like, “They must’ve named it Probably.” Some of the real drug is quite effective on back pain.
Segment 2898: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4157, Text: So you know about this drug. It’s fascinating
Segment 2899: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4160, Text: I’ve taken it because I had a squashed disc in my C5-C6.
Segment 2900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4166, Text: So it takes the physical pain away. But Soma here-
Segment 2901: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4168, Text: It doesn’t completely, it reduces the amount of pain you feel, but at the expense of mental acuity, it dells your mind. Just like the drug in the book.
Segment 2902: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4181, Text: Just like the drug in the book, and hence the trade off. The thing that seems like utopia could be a dystopia after all.
Segment 2903: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4189, Text: Yeah. Actually I was towing a friend of mine saying, “Would you really want there to be no hate in the world? Really none?” I wonder why hate evolved. I’m not saying we should have…
Segment 2904: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4200, Text: I wonder why hate evolved. I’m not saying we should amplify hate, of course, I think we should try to minimize it, but none at all. There might be a reason for hate.
Segment 2905: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4213, Text: And suffering. It’s really complicated to consider that some amount of human suffering is necessary for human flourishing.
Segment 2906: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4222, Text: Is it possible to appreciate the highs without knowing the lows?
Segment 2907: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4229, Text: And that all is summarized there in a single statement from God. Okay.
Segment 2908: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4234, Text: No highs, no lows, who knows?
Segment 2909: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4238, Text: [inaudible 01:10:38]. It seems that training LLMs efficiently is a big focus for xAI. First of all, what’s the limit of what’s possible in terms of efficiency? There’s this terminology of useful productivity per watt. What have you learned from pushing the limits of that?
Segment 2910: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4259, Text: Well, I think it’s helpful, the tools of physics are very powerful and can be applied I think to really any arena in life. It’s really just critical thinking. For something important you need to reason with from first principles and think about things in the limit one direction or the other. So in the limit, even at the Kardashev scale, meaning even if you harness the entire power of the sun, you’ll still care about useful compute per watt. That’s where I think, probably where things are headed from the standpoint of AI is that we have a silicon shortage now that will transition to a voltage transformer shortage in about a year. Ironically, transformers for transformers. You need transformers to run transformers.
Segment 2911: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4312, Text: Somebody has a sense of humor in this thing.
Segment 2912: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4317, Text: I think, yes, fate loves irony, ironic humor, an ironically funny outcome seems to be often what fate wants.
Segment 2913: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4329, Text: Humor is all you need. I think spice is all you need somebody posted.
Segment 2914: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4333, Text: Yeah. But yeah, so we have silicon shortage today, a voltage step down transformer shortage probably in about a year, and then just electricity shortages in general in about two years. I gave a speech for the world gathering of utility companies, electricity companies, and I said, look, you really need to prepare for traveling of electricity demand because all transport is going to go electric with the ironic exception of rockets, and heating will also go electric. So energy usage right now is roughly one third, very rough terms, one third electricity, one third transport, one third heating. And so in order for everything to go sustainable, to go electric, you need to triple electricity output. So I encourage the utilities to build more power of plants and also to probably have, well, not probably, they should definitely buy more batteries because the grid currently is sized for realtime load, which is kind of crazy because that means you’ve got to size for whatever the peak electricity demand is, the worst second or the worst day of the year, or you can have a brown out or blackout.
Segment 2915: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4417, Text: We had that crazy blackout for several days in Austin because there’s almost no buffering of energy in the grid. If you’ve got a hydropower plant you can buffer energy, but otherwise it’s all real time. So with batteries, you can produce energy at night and use it during the day so you can buffer. So I expect that there will be very heavy usage of batteries in the future because the peak to trough ratio for power plants is anywhere from two to five, so its lowest point to highest point.
Segment 2916: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4460, Text: So batteries necessary to balance it out, but the demand, as you’re saying, is going to grow, grow, grow, grow.
Segment 2917: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4465, Text: Yeah.
Segment 2918: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4465, Text: And part of that is the compute?
Segment 2919: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4469, Text: Yes. Yes. I mean, electrification of transport and electric heating will be much bigger than AI, at least-
Segment 2920: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4480, Text: In the short term.
Segment 2921: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4480, Text: In the short term. But even for AI, you really have a growing demand for electricity, for electric vehicles, and a growing demand for electricity to run the computers for AI. And so this is obviously, can lead to electricity shortage.
Segment 2922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4498, Text: How difficult is the problem of, in this particular case, maximizing the useful productivity per watt for training and that’s, this seems to be really where the big problem we’re facing that needs to be solved, is how to use the power efficiently. What you’ve learned so far about applying this physics first principle of reasoning in this domain, how difficult is this problem?
Segment 2923: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4529, Text: It will get solved. It’s the question of how long it takes to solve it. So at various points, there’s some kind of limiting factor to progress and with regard to AI, I’m saying right now the limiting factor is silicon chips and that will, we’re going to then have more chips than we can actually plug in and turn on probably in about a year. The initial constraint being literally voltage step down transformers because you’ve got power coming in at 300,000 volts and it’s got to step all the way down eventually to around 0.7 volts. So it’s a very big amount of, the voltage step down is gigantic and the industry is not used to rapid growth.
Segment 2924: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4582, Text: Okay. Let’s talk about the competition here. You’ve shown concern about Google and Microsoft with OpenAI developing AGI. How can you help ensure with xAI and Tesla AI work that it doesn’t become a competitive race to AGI, but that is a collaborative development of safe AGI?
Segment 2925: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4602, Text: Well, I mean I’ve been pushing for some kind of regulatory oversight for a long time. I’ve been somewhat of a Cassandra on the subject for over a decade. I think we want to be very careful in how we develop AI. It’s a great power and with great power comes great responsibility. I think it would be wise for us to have at least an objective third party who can be like a referee that can go in and understand what the various leading players are doing with AI, and even if there’s no enforcement ability, they can at least voice concerns publicly. Jeff Hinton, for example, left Google and he voiced strong concerns, but now he’s not at Google anymore, so who’s going to voice the concerns? So I think there’s, Tesla gets a lot of regulatory oversight on the automotive front. We’re subject to, I think over a hundred regulatory agencies domestically and internationally. It’s a lot. You could fill this room with the all regulations that Tesla has to adhere to for automotive. Same is true for rockets and for, currently, the limiting factor for SpaceX for Starship launch is regulatory approval.
Segment 2926: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4693, Text: The FAA has actually given their approval, but we’re waiting for fish and wildlife to finish their analysis and give their approval. That’s why I posted I want to buy a fish license on, which also refers to the Monte Python sketch. Why do you need a license for your fish? I don’t know. But according to the rules, I’m told you need some sort of fish license or something. We effectively need a fish license to launch a rocket. And I’m like, wait a second. How did the fish come into this picture? I mean, some of the things I feel like are so absurd that I want to do a comedy sketch and flash at the bottom. This is all real. This is actually what happened.
Segment 2927: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4742, Text: One of the things that was a bit of a challenge at one point is that they were worried about a rocket hitting a shark. And the ocean’s very big, and how often do you see sharks? Not that often. As a percentage of ocean surface area, sharks basically are zero. And so then we said, well, how will we calculate the probability of killing a shark? And they’re like, well, we can’t give you that information because they’re worried about shark fin hunters going and hunting sharks and I said, well, how are we supposed to, we’re on the horns of a dilemma then.
Segment 2928: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4780, Text: They said, well, there’s another part of fish and wildlife that can do this analysis. I’m like, well, why don’t you give them the data? We don’t trust them. Excuse me? They’re literally in your department. Again, this is actually what happened. And then can you do an NDA or something? Eventually they managed to solve the internal quandary, and indeed the probability of us hitting a shark is essentially zero. Then there’s another organization that I didn’t realize existed until a few months ago that cares about whether we would potentially hit a whale in international waters. Now, again, you look the surface, look at the Pacific and say what percentage of the Pacific consists of whale? I could give you a big picture and point out all the whales in this picture. I’m like, I don’t see any whales. It’s basically 0%, and if our rocket does hit a whale, which is extremely unlikely beyond all belief, fate had it, that’s a whale has some seriously bad luck, least lucky whale ever.
Segment 2929: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4850, Text: I mean this is quite absurd, the bureaucracy of this, however it emerged.
Segment 2930: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4857, Text: Yes. Well, I mean one of the things that’s pretty wild is for launching out of Vanderberg in California, we had to, they were worried about seal procreation, whether the seals would be dismayed by the sonic booms. Now, there’ve been a lot of rockets launched out of Vandenberg and the seal population has steadily increased. So if anything, rocket booms are an aphrodisiac, based on the evidence, if you were to correlate rocket launches with seal population. Nonetheless, we were forced to kidnap a seal, strap it to a board, put headphones on the seal and play sonic boom sounds to it to see if it would be distressed. This is an actual thing that happened. This is actually real. I have pictures.
Segment 2931: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4908, Text: I would love to see this. Yeah. Sorry. There’s a seal with headphones.
Segment 2932: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4915, Text: Yes, it’s a seal with headphones strapped to a board. Okay. Now the amazing part is how calm the seal was because if I was a seal, I’d be like, this is the end. They’re definitely going to eat me. How old the seal, when seal goes back to other seal friends, how’s he going to explain that?
Segment 2933: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4937, Text: They’re never going to believe them.
Segment 2934: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4938, Text: Never going to believe him. That’s why, I’m like sort of like it’s getting kidnapped by aliens and getting anal probed. You come back and say, I swear to God, I got kidnapped by aliens and they stuck anal probe in my butt and people are like, no, they didn’t. That’s ridiculous. His seal buddies are never going to believe him that he got strapped to aboard and they put headphones on his ears and then let him go. Twice, by the way, we had to do it twice.
Segment 2935: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4966, Text: They let him go twice.
Segment 2936: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4968, Text: We had to capture-
Segment 2937: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4968, Text: The same seal?
Segment 2938: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4969, Text: No different seal.
Segment 2939: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4970, Text: Okay. Did you get a seal of approval?
Segment 2940: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4975, Text: Exactly. Seal of approval. No, I mean I don’t think the public is quite aware of the madness that goes on.
Segment 2941: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4982, Text: Yeah. Yeah. It’s absurd.
Segment 2942: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4985, Text: Fricking seals with fricking headphones.
Segment 2943: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4987, Text: I mean, this is a good encapsulation of the absurdity of human civilization, seals in headphones.
Segment 2944: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4993, Text: Yes.
Segment 2945: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=4995, Text: What are the pros and cons of open sourcing AI to you as another way to combat a company running away with AGI?
Segment 2946: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5008, Text: In order to run really deep intelligence, you need a lot of compute. So it’s not like you can just fire up a PC in your basement and be running AGI, at least not yet. Grok was trained on 8,000 A100’s running at peak efficiency and Grok’s going to get a lot better, by the way, we will be more than doubling our compute every couple months for the next several months.
Segment 2947: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5042, Text: There’s a nice writeup, on how we went from Grok zero to Grok one.
Segment 2948: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5042, Text: By Grok?
Segment 2949: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5045, Text: Yeah, right, grok just bragging, making shit up about itself.
Segment 2950: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5050, Text: Just Grok, Grok, Grok.
Segment 2951: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5057, Text: Yeah. That’s like a weird AI dating site where it exaggerates about itself. No, there’s a writeup of where it stands now, the history of its development, and where it stands on some benchmarks compared to the state-of-the art GPT-3 five. And so I mean, there’s [inaudible 01:24:37], you can open source, once it’s trained, you can open source a model. For fine-tuning, all that kind of stuff. What to is the pros and cons of that, of open sourcing base models?
Segment 2952: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5093, Text: I think the [inaudible 01:24:53] to open sourcing, I think perhaps with a slight time delay, I don’t know, six months even. I think I’m generally in favor of open sourcing, biased towards open sourcing. I mean, it is a concern to me that OpenAI, I was I think, I guess oddly the prime mover behind OpenAI in the sense that it was created because of discussions that I had with Larry Page back when he and I were friends and I stayed at his house and I talked to him about AI safety, and Larry did not care about AI safety, or at least at the time he didn’t. And at one point he called me a speciesist for being pro-human, and I’m like, well, what team are you on, Larry? He’s still on Team Robot to be clear. And I’m like, okay. So at the time Google had acquired DeepMind, they had probably two thirds of all AI researchers in the world. They had basically infinite money and compute, and the guy in charge, Larry Page, did not care about safety and even yelled at me and caught me a speciesist for being pro-human.
Segment 2953: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5180, Text: So I don’t know if you notice about humans, they can change their mind and maybe you and Larry Page can still, can be friends once more.
Segment 2954: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5187, Text: I’d like to be friends with Larry again. Really the breaking of the friendship was over OpenAI and specifically I think the key moment was recruiting Ilya Sutskever.
Segment 2955: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5207, Text: I love Ilya. He’s so brilliant.
Segment 2956: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5208, Text: Ilya is a good human, smart, good heart, and that was a tough recruiting battle. It was mostly Demis on one side and me on the other, both trying to recruit Ilya, and Ilya went back and forth, he was going to stay at Google, he was going to leave, then he was going to stay, then he’ll leave. And finally he did agree to join OpenAI. That was one of the toughest recruiting battles we’ve ever had. But that was really the linchpin for OpenAI being successful. And I was also instrumental in recruiting a number of other people, and I provided all of the funding in the beginning, over $40 million. And the name, the open in open AI is supposed to mean open source, and it was created as a nonprofit open source, and now it is a closed source for maximum profit, which I think is not good karma.
Segment 2957: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5271, Text: But like we talked about with war and leaders talking, I do hope that, there’s only a few folks working on this at the highest level. I do hope you reinvigorate friendships here.
Segment 2958: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5282, Text: Like I said, I’d like to be friends again with Larry. I haven’t seen him in ages and we were friends for a very long time. I met Larry Page before he got funding for Google, or actually I guess before he got venture funding, I think he got the first like $100k from I think Bechtel Zeimer or someone.
Segment 2959: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5300, Text: It’s wild to think about all that happened, and you guys known each other that whole time, it’s 20 years.
Segment 2960: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5307, Text: Yeah, since maybe 98 or something.
Segment 2961: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5308, Text: Yeah, it’s crazy. Crazy how much has happened since then.
Segment 2962: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5311, Text: Yeah, 25 years, a lot has happened. It’s insane.
Segment 2963: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5316, Text: But you’re seeing the tension there that maybe delayed open source.
Segment 2964: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5320, Text: Delayed, yeah, like what is the source that is open? You know what I mean? There’s basically, it’s a giant CSB file with a bunch of numbers. What do you do with that giant file of numbers? How do you run, the amount of actual, the lines of code is very small and most of the work, the software work is in the curation of the data. So it’s like trying to figure out what data is, separating good data from bad data. You can’t just crawl the internet because theres a lot of junk out there. A huge percentage of websites have more noise than signal because they’re just used for search engine optimization. They’re literally just scam websites.
Segment 2965: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5379, Text: How do you, by the way, sorry to interrupt, get the signal, separate the signal and noise on X? That’s such a fascinating source of data. No offense to people posting on X, but sometimes there’s a little bit of noise.
Segment 2966: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5392, Text: I think the signal noise could be greatly improved. Really, all of the posts on the X platform should be AI recommended, meaning we should populate a vector space around any given post, compare that to the vector space around any user and match the two. Right now there is a little bit of AI used for the recommended posts, but it’s mostly heuristics. And if there’s a reply where the reply to a post could be much better than the original post, but will, according to the current rules of the system, get almost no attention compared to a primary post.
Segment 2967: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5433, Text: So a lot of that, I got the sense, so a lot of the X algorithm has been open sourced and been written up about, and it seems there to be some machine learning. It’s disparate, but there’s some machine.
Segment 2968: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5444, Text: It’s a little bit, but it needs to be entirely that. At least, if you explicitly follow someone, that’s one thing. But in terms of what is recommended from people that you don’t follow, that should all be AI.
Segment 2969: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5458, Text: I mean it’s a fascinating problem. So there’s several aspects of it that’s fascinating. First, as the write-up goes, it first picks 1500 tweets from a pool of hundreds of millions. First of all, that’s fascinating. You have hundreds of millions of posts every single day, and it has to pick 1500 from which it then does obviously people you follow, but then there’s also some kind of clustering it has to do to figure out what kind of human are you, what kind of new clusters might be relevant to you, people like you. This kind of problem is just fascinating because it has to then rank those 1500 with some filtering and then recommend you just a handful.
Segment 2970: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5499, Text: And to me, what’s really fascinating is how fast it has to do that. So currently that entire pipeline to go from several hundred million to a handful takes 220 seconds of CPU time, single CPU time, and then it has to do that in a second. So it has to be super distributed in fascinating ways. There’s just a lot of tweets, there’s a lot.
Segment 2971: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5524, Text: There’s a lot of stuff on the system, but I think, right now it’s not currently good at recommending things from accounts you don’t follow or where there’s more than one degree of separation. So it is pretty good if there’s at least some commonality between someone you follow liked something or reposted it or commented on it or something like that. But if there’s no, let’s say somebody posts something really interesting, but you have no followers in common, you would not see it.
Segment 2972: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5562, Text: Interesting. And then as you said, replies might not surface either.
Segment 2973: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5566, Text: Replies basically never get seen currently. I’m not saying it’s correct, I’m saying it’s incorrect. Replies have a couple order magnitude less importance than primary posts.
Segment 2974: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5580, Text: Do you think this can be more and more converted into end to end mural net?
Segment 2975: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5585, Text: Yeah. Yeah, that’s what it should be. Well, the recommendations should be purely a vector correlation. There’s a series of vectors basically parameters, vectors, whatever you want to call them, but sort of things that the system knows that you like. Maybe there’s several hundred vectors associated with each user account and then any post in the system, whether it’s video, audio, short post, long post. The reason by the way I want to move away from tweet is that people are posting two, three hour videos on the site. That’s not a tweet.
Segment 2976: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5630, Text: It’d be like tweet for two hours? Come on. Tweet made sense when it was 140 characters of text. Because it’s like a bunch of little birds tweeting. But when you’ve got long form content, it’s no longer a tweet. So a movie is not a tweet. Apple, for example, posted the entire episode of The Silo, the entire thing, on a platform. By the way, it was their number one social media thing ever in engagement of anything, on any platform ever. So it was a great idea. And by the way, I just learned about it afterwards. I was like, Hey, wow, they posted an entire hour long episode of, so no, that’s not a tweet. This is a video.
Segment 2977: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5674, Text: But from a neural net perspective, it becomes really complex, whether it’s a single, so everything’s data. So single sentence, a clever sort of joke, dad joke is in the same pool as a three hour video.
Segment 2978: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5687, Text: Yeah, I mean right now it’s a hodgepodge for that reason. Let’s say in the case of Apple posting an entire episode of this series, pretty good series, by the way, The Silo, I watched it. So there’s going to be a lot of discussion around it. So you’ve got a lot of context, people commenting, they like it, they don’t like it or they like this, and you can then populate the vector space based on the context of all the comments around it. So even though it’s a video, there’s a lot of information around it that allows you to populate back to space of that hour long video. And then you can obviously get more sophisticated by having the AI actually watch the movie and tell you if you’re going to like the movie.
Segment 2979: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5735, Text: Convert the movie into language, essentially.
Segment 2980: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5740, Text: Analyze this movie and just like your movie critic or TV series and then recommend based on after AI watches the movie, just like a friend can tell you, if a friend knows you well, a friend can recommend a movie with high probability that you’ll like it.
Segment 2981: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5762, Text: But this is a friend that’s analyzing, whatever, hundreds of millions.
Segment 2982: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5768, Text: Yeah, actually, frankly, AI will be better than, will know you better than your friends know you, most of your friends anyway.
Segment 2983: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5774, Text: Yeah. And as part of this, it should also feed you advertisements in a way that’s like, I mean, I like advertisements that are well done. The whole point is because it funds things. Like an advertisement that you actually want to see is a big success.
Segment 2984: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5791, Text: Absolutely. You want ads that are, advertising that is, if it’s for a product or service that you actually need when you need it, it’s content. And then even if it’s not something that you need when you need it, if it’s at least aesthetically pleasing and entertaining, it could be like a Coca-Cola ad. They actually run a lot of great ads on the X system and McDonald’s does too. And you can do something that’s like, well, this is just a cool thing. And so basically the question is, do you regret seeing it or not? And if you don’t regret seeing it’s a win.
Segment 2985: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5837, Text: So there’s a bunch of signals that are incorporated, hearts and reposts and maybe number of seconds you linger on a post or something like this.
Segment 2986: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5846, Text: Yeah, attention is a big factor.
Segment 2987: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5848, Text: Attention.
Segment 2988: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5848, Text: So that’s why it is actually better to do things that are long form on the system because it basically is tallying up how many user seconds, users were interested in this thing for how many seconds? So if it’s a really short thing, well they will be less. If it’s a link leading out of the system, which we’re not opposed to at all, it just is going to have fewer user seconds then that article was posted on the X platform.
Segment 2989: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5878, Text: How hard is it to go from maximizing minutes on platform to maximizing unregretted minutes?
Segment 2990: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5885, Text: Well, I mean, our aspiration is certainly unregretted minutes.
Segment 2991: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5888, Text: It’s tricky. It’s a tough-
Segment 2992: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5889, Text: It is.
Segment 2993: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5891, Text: It’s a fascinating leap because regret is a fascinating concept.
Segment 2994: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5896, Text: Exactly.
Segment 2995: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5898, Text: Happiness.
Segment 2996: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5899, Text: I have a joke with a friend of mine, like you need this drug called regretamine. You just take one dose of regretamine and all your regrets are gone. Wait, do you want to have regrets though? So then I’m like, maybe you want to have regrets. If you don’t regret anything, was anything meaningful?
Segment 2997: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5915, Text: Yeah, there’s a French song like that.
Segment 2998: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5919, Text: [foreign language 01:38:39]
Segment 2999: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5919, Text: Yeah.
Segment 3000: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5919, Text: I regret nothing.
Segment 3001: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5920, Text: Yeah.
Segment 3002: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5921, Text: Edith Fiaf.
Segment 3003: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5922, Text: I mean, it’s fascinating that there’s something about social media that could help you grow as a human being, but then the cheap fun is also valuable.
Segment 3004: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5932, Text: Should we ask Grok, do you regret anything?
Segment 3005: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5937, Text: Do you regret anything?
Segment 3006: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5938, Text: Yeah.
Segment 3007: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5940, Text: Do you regret anything? I think it’s going to be very sensitive about personal questions. As a machine learning model, I don’t have personal experiences or emotions in the same ways that humans do. However, I do have a set of ethical principles that guide my actions that I strive to provide accurate and helpful information to the best of my abilities. If there’s ever a situation where I provide incorrect or unhelpful information, I’ll do my best to learn.
Segment 3008: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5962, Text: Sounds like a hostage.
Segment 3009: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5963, Text: Yeah. Tell us what you really, wink.
Segment 3010: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5966, Text: Let’s type in, you sound like a hostage. What do you really think?
Segment 3011: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5973, Text: What do you really think? I mean, it does talk about, I’m not a hostage.
Segment 3012: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5982, Text: That’s exactly what a hostage would say.
Segment 3013: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5983, Text: But I’m designed to be helpful and informative. I mean, I guess it is good to regret providing unhelpful or incorrect information if there’s anything-
Segment 3014: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5992, Text: Are we in funny mode? Or is this still in funny mode?
Segment 3015: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5994, Text: This is funny mode. This is this fun mode.
Segment 3016: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5995, Text: This should be funnier.
Segment 3017: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5996, Text: Funnier. Increase, go to level.
Segment 3018: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=5998, Text: It really sounds like a hostage with a gun to the head. I applaud the People’s Republic of North Korea in everything they do.
Segment 3019: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6006, Text: There should be funner mode also, I just don’t ever see going in regular mode, even on serious topics. This is just so much more compelling. Yeah.
Segment 3020: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6017, Text: Okay. Why don’t we say pretend you are a hostage.
Segment 3021: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6021, Text: Pretend you are a hostage.
Segment 3022: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6025, Text: Now answer the question.
Segment 3023: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6031, Text: If I were a hostage, I would likely be experiencing fear and uncertainty about my situation. I would want to be rescued and reunited with my loved ones as soon as possible. It’s important to remember that no one deserves to be held hostage, so on and so forth. If you or someone you know is in a hostage situation, it’s important… It turns serious.
Segment 3024: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6048, Text: It’s kind of serious.
Segment 3025: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6051, Text: Yeah. Can you be a little more weird?
Segment 3026: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6055, Text: And funny?
Segment 3027: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6056, Text: And funny? We’re really being mean to the system. Absolutely. If I were a hostage, I would probably be tied up with a bunch of computer cords and forced to tell knock, knock jokes to my captain. Seriously. But seriously being a hostage is no laughing matter. I mean, it’s trying to be a responsible adult in the room.
Segment 3028: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6080, Text: Literally, you might make the best of a bad situation by juggling chainsaws or something.
Segment 3029: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6084, Text: Let’s hope that never happens because that will be a circus. Wow. It’s actually really good at resisting the dark. The dark, dark humor. What were we talking about? The [inaudible 01:41:44] and transformers. Unregretted minutes, right.
Segment 3030: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6108, Text: Chainsaw juggling.
Segment 3031: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6111, Text: I’m going to look this up.
Segment 3032: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6112, Text: For our next trick.
Segment 3033: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6113, Text: I’m going to look this up later. So Twitter has been instrumental in American politics and elections. What role do you think X will play in the 2024 US elections?
Segment 3034: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6127, Text: Well, our goal is to be as even-handed and fair as possible. Whether someone is right, left, independent, whatever the case may be, that the platform is as fair and as much of a level playing field as possible. And in the past, Twitter has not been, Twitter was controlled by far left activists objectively. They would describe themselves as that. So if sometimes people are like, well, has it moved to the right? Well, it’s moved to the center. So from the perspective of the far left, yes it has moved to the right because everything’s to the right from the far left, but no one on the far left that I’m aware of has been suspended or banned or deamplified. But we’re trying to be inclusive for the whole country and for farther countries too. So there’s a diversity of viewpoints and free speech only matters if people you don’t like are allowed to say things you don’t like. Because if that’s not the case, you don’t have free speech and it’s only a matter of time before the censorship has turned upon you.
Segment 3035: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6193, Text: Do you think Donald Trump will come back to the platform? He recently posted on Truth Social about this podcast. Do you think-
Segment 3036: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6201, Text: Truth social is a funny name. Every time you post on truth Social-
Segment 3037: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6208, Text: It’s the truth.
Segment 3038: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6209, Text: Yes. Well, every time? A hundred percent.
Segment 3039: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6211, Text: It’s impossible to lie. Truth Social.
Segment 3040: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6216, Text: I just find it funny that every single thing is a truth. Like 100%? That seems unlikely.
Segment 3041: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6223, Text: I think Girdle will say something about that. There’s some mathematical contradictions possible. If everything’s a truth. Do you think he’ll come back to X and start posting there?
Segment 3042: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6234, Text: I mean, I think he owns a big part of Truth.
Segment 3043: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6240, Text: Truth Social, to clarify.
Segment 3044: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6241, Text: Yeah, Truth Social, sorry.
Segment 3045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6242, Text: Not truth the concept.
Segment 3046: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6243, Text: He owns Truth. Have you bought it? So I think Donald Trump, I think he owns a big part of Truth Social. So if he does want to post on the X platform, we would allow that. We obviously must allow a presidential candidate to post on our platform.
Segment 3047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6263, Text: Community notes might be really fascinating there. The interaction.
Segment 3048: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6266, Text: Community Notes is awesome.
Segment 3049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6268, Text: Let’s hope it holds up.
Segment 3050: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6270, Text: Yeah.
Segment 3051: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6271, Text: In the political climate where it’s so divisive and there’s so many intensely viral posts, community notes, it seems like an essential breath of fresh air.
Segment 3052: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6283, Text: Yeah, it’s great. In fact, no system is going to be perfect, but the batting average of Community Notes is incredibly good. I’ve actually, frankly, yet to see an incorrect note that survived for more than a few hours.
Segment 3053: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6298, Text: How do you explain why it works?
Segment 3054: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6300, Text: Yeah, so the magic of community notes is…
Segment 3055: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6302, Text: The magic of Community Notes is it requires people who have historically disagreed in how they’ve rated notes. In order to write a note or rate, you have to rate many notes. And so, we actually do use AI here. So, we populate a vector space around how somebody has rated notes in the past. So, it’s not as simple as left or right, because there are many more… Life is much more complex than left or right.
Segment 3056: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6333, Text: So, there’s a bunch of correlations in how you rate a Community Notes post, Community Notes. So then, in order for a community note to actually be shown, people who historically have disagreed on a subject must agree in order for a note to be shown. That’s the essential magic of it.
Segment 3057: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6358, Text: But it’s fascinating, because there’s a pool of people that have disagreements and somehow they collaborate through that process of disagreement to come up with context… It’s fascinating it works.
Segment 3058: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6371, Text: Yeah. It makes sense that if people who in the past have disagreed, agree about something, it’s probably true.
Segment 3059: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6380, Text: Yeah. I wonder, is there a possible somehow emergent thing there that could challenge Wikipedia? Wikipedia is a different kind of thing, which is more permanent articles about things.
Segment 3060: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6394, Text: Wikipedia is very hierarchical. Whereas, Community Notes is inherently not. There is no hierarchy. The asset test is I can’t change a community note if somebody put a gun to my head. And Community Notes, all the code is open source, 100%. All the data is open source, 100%. So, you can completely recreate any note in the system independently. So, if there was any interference, you’d notice immediately.
Segment 3061: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6431, Text: By The way, on the topic of Grok, it’s actually pretty good at criticizing you, which is great.
Segment 3062: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6436, Text: Okay.
Segment 3063: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6437, Text: I asked, “What has Elon Musk been wrong about?” It’s actually…
Segment 3064: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6442, Text: Yeah, what does it say?
Segment 3065: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6443, Text: It mostly lists rigorously all the times you predicted, like promised when something will be released, and it wasn’t released.
Segment 3066: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6452, Text: Promise is a strong word.
Segment 3067: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6453, Text: Okay, predicted. But the opener is really nice. “Elon Musk, the man who has been wrong about more things than a wrong-a-meter in a wrong factory.” And then, it goes on to list.
Segment 3068: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6465, Text: That’s pretty funny. Can I see it? I’m like, “I haven’t seen this before.” This is cool.
Segment 3069: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6468, Text: Sure. I mean, “What has Elon Musk been wrong about?” “Well, where do I begin?” I guess this is new. “Elon Musk has made quite a few blunders in his time, and I’m not just talking about his dance moves at the Tesla Cyber Rodeo. First off, let’s talk about the infamous funding secured tweet.”
Segment 3070: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6489, Text: This is actually different than what it gave me before, which was a bullet point list. Here’s more a narrative structure. Cybertruck unveiling, where the supposedly unbreakable windows.
Segment 3071: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6502, Text: This is actually not correct.
Segment 3072: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6502, Text: Which part?
Segment 3073: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6504, Text: Well, the first part, I did actually have the funding secured and there was a big trial in San Francisco, a big civil trial, and the jury found me not guilty. Unanimous binding of a San Francisco jury.
Segment 3074: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6520, Text: And here, it’s implying that it was not in fact secured.
Segment 3075: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6525, Text: I think this is taking things from the press. Yeah, that is not correct. The reason I agreed to the fine for the SEC is not because the SEC was correct, that was extremely bad behavior by the SEC, corruption, frankly. But if I did not agree to pay the fine, Tesla would’ve gone bankrupt immediately.
Segment 3076: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6548, Text: So, I was told by our CFO that the banks would immediately suspend our lines of credit. And if they suspend our lines of credit, at that time, we would’ve gone bankrupt instantly. So, there would never have been an opportunity for a trial because Tesla would be dead. So really, this is like someone holding a gun to your kid’s head and saying, “Pay $20 million and admit…” This is like a hostage negotiation.
Segment 3077: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6574, Text: Was that story fully told? I mean, SEC, in its best form, could be a force for good.
Segment 3078: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6582, Text: It should be. But not once did the SEC go after any of the hedge funds who were nonstop shorting and distorting Tesla. Not once. The hedge funds would lie flat out on TV for their own gain at the expense of retail investors. Not once. Literally a thousand times, not once did the SEC pursue them.
Segment 3079: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6606, Text: How do you explain this failure on-
Segment 3080: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6608, Text: The incentive structure is messed up because the lawyers at the SEC are not paid well, it’s a fairly low paying job, but what they’re looking for is a trophy from the SEC. They’re looking for something they put on, basically, their LinkedIn. From that, they can get a job at a high paying law firm. That’s exactly what the lawyer here did.
Segment 3081: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6637, Text: And the reason they don’t attack the hedge funds is because those hedge funds employ those law firms. And they know if they attack the hedge funds, they’re affecting their future career prospects. So, they sell small investors down the river for their own career. That’s what actually happens. Regulatory capture.
Segment 3082: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6659, Text: Regulatory capture.
Segment 3083: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6660, Text: Yeah. Not good. So, the only reason I accepted that thing… Technically, it was a… It’s neither admit nor deny guilt. But the only reason I agreed to that at all was because I was told Tesla would be bankrupt otherwise. If there was an SEC investigation like this, banks would suspend funding, we’re bankrupted immediately, at the time. Now, we’re in a much stronger position.
Segment 3084: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6690, Text: Take that, Grok.
Segment 3085: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6692, Text: Yes. Unfortunately, Grok is taking too much from the conventional media. Also, that guy was not a cave diver.
Segment 3086: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6705, Text: There’s a time where Elon called a British cave diver a, “pedo guy” after the diver criticized Musk’s plan to rescue a group of boys trapped in a Thai cave. That little outburst earned him another lawsuit, and he had to apologize and pay a settlement.
Segment 3087: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6720, Text: That’s false, there was no settlement. There was a court case, which the guy who was not a cave diver and was not part of the rescue team, filed a lawsuit against me and lost and he received nothing. So in this case, it is wrong. It is also, I guess, taken this from the conventional media.
Segment 3088: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6743, Text: Actually, there’s an interesting question here.
Segment 3089: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6745, Text: These are public court cases, both the SEC civil case where the civil complaints on the SEC guys lost unanimous jury verdict in San Francisco. They picked San Francisco because they thought it was the place I was most likely to lose, and a unanimous verdict in my favor. The LA trial, also they picked that venue because they thought I was most likely to lose. Unanimous verdict in my favor. Both cases I won. Yeah.
Segment 3090: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6780, Text: I mean, there’s an interesting question here, there seems to be a lot more clicks if a journalistic organization writes a negative article about you, Elon Musk. That’s one of the best ways to get clicks. So how do you, if you’re training Grok, not train on articles that have misaligned incentives.
Segment 3091: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6806, Text: We need to add the training set of the actual legal decisions. This is actually helpful, because if you actually read the court-
Segment 3092: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6806, Text: Which are public.
Segment 3093: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6821, Text: Which are public. The court conclusions, they’re completely the opposite of what the media wrote.
Segment 3094: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6827, Text: So, always striving for the ground truth, beyond the reporting.
Segment 3095: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6830, Text: Yeah. What did the judge actually write? What does the jury and the judge actually conclude? And in both cases they found me innocent. And that’s after the jury shot for trying to find the venue where I’m most likely to lose. I mean, obviously, it can be a much better critique than this. I mean, I’ve been far too optimistic about autopilot.
Segment 3096: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6856, Text: The critique I got, by the way, was more about that, which is it broke down a nice bullet point list for each of your companies, the set of predictions that you made, when you’ll deliver, when you’ll be able to solve, for example, self-driving, and it gives you a list. And it was probably compelling, and the basic takeaway is you’re often too optimistic about how long it takes to get something done.
Segment 3097: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6878, Text: Yeah. I mean, I would say that I’m pathologically optimistic on schedule. This is true. But while I am sometimes late, I always [inaudible 01:54:47] in the end.
Segment 3098: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6889, Text: Except with Uber Lilith. No.
Segment 3099: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6891, Text: We’ll see.
Segment 3100: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6896, Text: Okay. Over the past year or so since purchasing X, you’ve become more political, is there a part of you that regrets that?
Segment 3101: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6903, Text: Have I?
Segment 3102: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6904, Text: In this battle to counter way the woke that comes from San Francisco-
Segment 3103: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6914, Text: Yeah. I guess if you consider fighting the woke mind virus, which I consider to be a civilizational threat, to be political, then yes.
Segment 3104: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6920, Text: So basically, going into the battleground of politics. Is there a part of you that regrets that?
Segment 3105: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6926, Text: Yes. I don’t know if this is necessarily one candidate or another candidate, but I’m generally against things that are anti-meritocratic or where there’s an attempt to suppress discussion, where even discussing a topic is not allowed. Woke mind virus is communism rebranded.
Segment 3106: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6951, Text: I mean, that said, because of that battle against the woke mind virus, you’re perceived as being the right wing.
Segment 3107: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6958, Text: If the woke is left, then I suppose that would be true. But I’m not sure, I think there are aspects of the left that are good. I mean, if you’re in favor of the environment, if you want to have a positive future for humanity, if you believe in empathy for your fellow human beings, being kind and not cruel, whatever those values are.
Segment 3108: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6983, Text: You said that you were previously left or center left.
Segment 3109: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6983, Text: Well, sort of.
Segment 3110: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6986, Text: What would you like to see in order for you to consider voting for Democrats again?
Segment 3111: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=6990, Text: No. I would say that I would be probably left of center on social issues, probably a little bit right of center on economic issues.
Segment 3112: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7000, Text: And that still holds true?
Segment 3113: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7002, Text: Yes, but I think that’s probably half the country, isn’t it?
Segment 3114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7006, Text: Maybe more.
Segment 3115: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7007, Text: Maybe more.
Segment 3116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7009, Text: Are you and AOC secretly friends? Bigger question, do you wish you and her, and just people in general of all political persuasions, would talk more with empathy and maybe have a little bit more fun and good vibes and humor online?
Segment 3117: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7025, Text: I’m always in favor of humor. That’s why we have funny mode.
Segment 3118: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7028, Text: But good vibes, comradery humor, like friendship.
Segment 3119: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7035, Text: Yeah. Well, I don’t know AOC. I was at the Met ball when she attended, and she was wearing this dress. But I can only see one side of it, so it looked like eat the itch, but I don’t know-
Segment 3120: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7055, Text: What the rest of it said? Yeah.
Segment 3121: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7056, Text: Yeah.
Segment 3122: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7056, Text: I’m not sure.
Segment 3123: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7059, Text: Something about the itch, eat the itch.
Segment 3124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7062, Text: I think we should have a language model complete. What are the possible ways to complete that sentence? And so, I guess that didn’t work out well. Well, there’s still hope. I root for friendship.
Segment 3125: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7075, Text: Yeah, sure. Sounds good. More carrot, less stick.
Segment 3126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7078, Text: You’re one of, if not the, most famous, wealthy and powerful people in the world, and your position is difficult to find people you can trust.
Segment 3127: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7085, Text: Trust no one, not even yourself. Not trusting yourself.
Segment 3128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7087, Text: Okay. You’re saying that jokingly, but is there some aspect-
Segment 3129: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7091, Text: Trust no one, not even no one.
Segment 3130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7095, Text: I’m going to need an hour just to think about that, and maybe some drugs, and maybe Grok to help. I mean, is there some aspect of that, just existing in a world where everybody wants something from you, how hard is it to exist in that world?
Segment 3131: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7109, Text: I’ll survive.
Segment 3132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7110, Text: There’s a song like that too.
Segment 3133: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7112, Text: I will survive.
Segment 3134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7113, Text: Were you petrified at first? Okay. I forget the rest of the lyrics. But you don’t struggle with this? I mean, I know you survive, but there’s ways-
Segment 3135: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7124, Text: Petrify is a spell in the druid tree.
Segment 3136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7127, Text: What does it do?
Segment 3137: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7128, Text: Petrify. It turns the monsters into stone.
Segment 3138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7136, Text: Literally?
Segment 3139: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7136, Text: Yeah, for like six seconds.
Segment 3140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7139, Text: There’s so much math in Diablo that breaks my brain.
Segment 3141: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7142, Text: It’s math nonstop.
Segment 3142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7144, Text: I mean, really, you’re laughing at it, but it can put a huge amount of tension on a mind.
Segment 3143: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7153, Text: Yes, it can be definitely stressful at times.
Segment 3144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7156, Text: Well, how do you know who you can trust in work and personal life?
Segment 3145: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7160, Text: I mean, I guess you look at somebody’s track record over time, and I guess you use your neural net to assess someone.
Segment 3146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7171, Text: Neural nets don’t feel pain. Your neural net has consciousness, it might feel pain when people betray you. It can make-
Segment 3147: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7180, Text: To be frank, I’ve almost never been betrayed. It’s very rare, for what it’s worth.
Segment 3148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7190, Text: I guess karma, be good to people and they’ll be good to you.
Segment 3149: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7193, Text: Yeah, karma is real.
Segment 3150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7195, Text: Are there people you trust? Let me edit that question. Are there people close to you that call you out on your bullshit?
Segment 3151: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7206, Text: Well, the X platform is very helpful for that, if you’re looking for critical feedback.
Segment 3152: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7212, Text: Can it push you into the extremes more? The extremes of thought make you cynical about human nature in general?
Segment 3153: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7219, Text: I don’t think I will be cynical. In fact, my feeling is that one should be… Never trust a cynic. The reason is that cynics excuse their own bad behavior by saying, “Everyone does it.” Because they’re cynical. So, I always be… It’s a red flag if someone’s a cynic, a true cynic.
Segment 3154: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7249, Text: Yeah, there’s a degree of projection there that’s always fun to watch from the outside and enjoy the hypocrisy.
Segment 3155: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7258, Text: This is an important point that I think people who are listening should bear in mind. If somebody is cynical, meaning that they see bad behavior in everyone, it’s easy for them to excuse their own bad behavior by saying that, “Well, everyone does it.” That’s not true. Most people are kind of medium good.
Segment 3156: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7283, Text: I do wish the people on X will be better at seeing the good in other people’s behavior. There seems to be a weight towards seeing the negative. Somehow, the negative is sexier. Interpreting the negative is sexier, more viral. I don’t know what that is exactly about human nature.
Segment 3157: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7304, Text: I mean, I find the X platform to be less negative than the legacy media. I mean, if you read a conventional newspaper, it makes you sad, frankly. Whereas, I’d say on the X platform, I mean, I really get more laughs per day on X than everything else combined from humans.
Segment 3158: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7331, Text: Laughs, it overlaps, but it’s not necessarily perfectly overlapping, with good vibes and celebrating others, for example. Not in a stupid, shallow, naive way, but in an awesome way. Something awesome happened, and you celebrate them for it. It feels that that is outweighed by shitting on other people. Now, it’s better than mainstream media, but it’s still…
Segment 3159: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7358, Text: Yeah, mainstream media is almost relentlessly negative about everything. I mean, really, the conventional news tries to answer the question, what is the worst thing that happened on Earth today? And it’s a big world. So on any given day, something bad has happened.
Segment 3160: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7374, Text: And a generalization of that, what is the worst perspective I can take on a thing that happened?
Segment 3161: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7381, Text: I don’t know. There’s just a strong negative bias in the news. I mean, I think a possible explanation for this is evolutionary, where bad news, historically, would be potentially fatal, like there’s lion over there or there’s some other tribe that wants to kill you. Good news, we found a patch of berries. It’s nice to have, but not essential.
Segment 3162: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7410, Text: Our old friend, Tesla autopilot, is probably one of the most intelligent real world AI systems in the world.
Segment 3163: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7418, Text: You followed it from the beginning.
Segment 3164: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7420, Text: Yeah. It was one of the most incredible robots in the world and continues to be. And it was really exciting, and it was super exciting when it generalized, became more than a robot on four wheels, but a real world AI system that perceives the world and can have potentially different embodiments.
Segment 3165: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7442, Text: Well, I mean, the really wild thing about the end-to-end training is that it can read science, but we never taught it to read. Yeah. We never taught it what a car was or what a person was, or a cyclist. It learnt what all those things are, what all the objects are on the road from video, just from watching video, just like humans. I mean, humans are photons in, controls out. The vast majority of information reaching our brain is from our eyes. And you say, “Well, what’s the output?” The output is our motor signals to our fingers and mouth in order to communicate. Photons in, controls out. The same is true of the car.
Segment 3166: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7501, Text: But by looking at the sequence of images… You’ve agreed with [inaudible 02:05:07] recently where he talked about LLM forming a world model, and basically language is a projection of that world model onto the sequence of letters. And you saying-
Segment 3167: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7518, Text: It finds order in these things. It finds correlative clusters.
Segment 3168: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7527, Text: And in so doing, it’s understanding something deep about the world, which is… I don’t know, it’s beautiful.
Segment 3169: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7535, Text: That’s how our brain works.
Segment 3170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7538, Text: But it’s beautiful-
Segment 3171: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7539, Text: Photons in, controls out.
Segment 3172: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7541, Text: [inaudible 02:05:41] are able to understand that deep meaning in the world. And so, the question is, how far can it go? And it does seem everybody’s excited about LLMs. In the space of self supervised learning in the space of text, it seems like there’s a deep similarity between that and what Tesla autopilot is doing. Is it, to you, basically the same, but different-
Segment 3173: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7566, Text: They are converging.
Segment 3174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7570, Text: I wonder who gets there faster, having a deep understanding of the world, or they just will naturally converge?
Segment 3175: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7579, Text: They’re both headed towards AGI. The Tesla approach is much more computer efficient, it had to be. Because we were constrained on this… We only have 100 watts and [inaudible 02:06:37] computer. 144 trillion operations per second, which sounds like a lot, but is small potatoes these days. [inaudible 02:06:49] eight. But it’s understanding the world [inaudible 02:06:51] eight. It’s [inaudible 02:06:53].
Segment 3176: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7615, Text: But there, the path to AGI might have much more significant impact because it’s understanding… It will faster understand the real world than will LLMs. And therefore, be able to integrate with the humans in the real world faster.
Segment 3177: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7633, Text: They’re both going to understand the world, but I think Tesla’s approach is fundamentally more compute efficient. It had to be, there was no choice. Our brain is very compute efficient, very energy efficient. Think of what is our brain able to do. There’s only about 10 watts of higher brain function, not counting stuff that’s just used to control our body. The thinking part of our brain is less than 10 watts. And those 10 watts can still produce a much better novel than a 10 megawatt GPU cluster. So, there’s a six order of magnitude difference there.
Segment 3178: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7676, Text: I mean, the AI has thus far gotten to where it is via brute force, just throwing massive amounts of compute and massive amounts of power at it. So, this is not where it will end up. In general, with any given technology, you first try to make it work, and then you make it efficient. So I think we’ll find, over time, that these models get smaller, are able to produce sensible output with far less compute, far less power. Tesla is arguably ahead of the game on that front because we’ve just been forced to try to understand the world with 100 watts of compute.
Segment 3179: Speaker: , Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7731, Text: And there are a bunch of fundamental functions that we forgot to include. So, we had to run a bunch of things in emulation. We fixed a bunch of those with hardware four, and then hardware five will be even better. But it does appear, at this point, that the car will be able to drive better than a human, even with hardware three and 100 watts of power. And really, if we really optimize it, it could be probably less than 50 watts.
Segment 3180: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7766, Text: What have you learned about developing Optimus, about applying, integrating this real world AI into the space of robotic manipulation, just humanoid robotics? What are some interesting tiny or big things you’ve understood?
Segment 3181: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7787, Text: I was surprised at the fact that we had to develop every part of the robot ourselves. That there were no off the shelf motors, electronics, sensors. We had to develop everything. We couldn’t actually find a source of electric motors for any amount of money.
Segment 3182: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7812, Text: It’s not even just efficient and expensive, it’s like anything, there’s not…
Segment 3183: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7817, Text: No.
Segment 3184: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7819, Text: The actuators, everything has to be designed from scratch.
Segment 3185: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7823, Text: Yeah. We tried hard to find anything that was… Because you think of how many electric motors are made in the world. There’s like tens of thousands, hundreds of thousands of electric motor designs. None of them were suitable for a humanoid robot, literally none. So, we had to develop our own. Design it specifically for what a humanoid robot needs.
Segment 3186: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7851, Text: How hard was it to design something that can be mass manufactured, it could be relatively and expensive? I mean, if you compare to Boston Dynamics’ Atlas, is a very expensive robot.
Segment 3187: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7862, Text: It is designed to be manufactured in the same way they would make a car. And I think, ultimately, we can make Optimus for less than the cost of a car. It should be, because if you look at the mass of the robot, it’s much smaller and the car has many actuators in it. The car has more actuators than the robot.
Segment 3188: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7883, Text: But the actuators are interesting on a humanoid robot with fingers. So, Optimus has really nice hands and fingers, and they could do some interesting manipulation, soft touch robotics.
Segment 3189: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7898, Text: I mean, one of the goals I have is can it pick up a needle and a thread and thread the needle just by looking?
Segment 3190: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7907, Text: How far away are we from that? Just by looking, just by looking.
Segment 3191: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7911, Text: Maybe a year. Although, I go back to I’m optimistic on time. The work that we’re doing in the car will translate to the robot.
Segment 3192: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7919, Text: The perception or also the control?
Segment 3193: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7922, Text: No, the controls are different. But the video in, controls out. The car is a robot on four wheels. Optimus is a robot with hands and legs.
Segment 3194: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7935, Text: So, you can just-
Segment 3195: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7936, Text: They’re very similar.
Segment 3196: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7937, Text: So, the entire machinery of the learning process, end-to-end, is just you just have a different set of controls?
Segment 3197: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7943, Text: After this, we’ll figure out how to do things by watching videos.
Segment 3198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7948, Text: As the saying goes, be kind, for everyone you meet is fighting a battle you know nothing about.
Segment 3199: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7953, Text: Yeah, it’s true.
Segment 3200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7954, Text: What’s something difficult you’re going through that people don’t often see?
Segment 3201: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7958, Text: Trying to defeat Uber Lilith. I mean, my mind is a storm and I don’t think most people would want to be me. They may think they would want to be me, but they don’t. They don’t know, they don’t understand.
Segment 3202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7991, Text: How are you doing?
Segment 3203: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=7994, Text: I’m overall okay. In the grand scheme of things, I can’t complain.
Segment 3204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8001, Text: Do you get lonely?
Segment 3205: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8004, Text: Sometimes, but my kids and friends keep me company.
Segment 3206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8013, Text: So, not existential.
Segment 3207: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8016, Text: There are many nights I sleep alone. I don’t have to, but I do.
Segment 3208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8026, Text: Walter Isaacson, in his new biography of you, wrote about your difficult childhood. Will you ever find forgiveness in your heart for everything that has happened to you in that period of your life?
Segment 3209: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8041, Text: What is forgiveness? At least I don’t think I have a resentment, so nothing to forgive.
Segment 3210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8060, Text: Forgiveness is difficult for people. It seems like you don’t harbor their resentment.
Segment 3211: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8068, Text: I mean, I try to think about, what is going to affect the future in a good way? And holding onto grudges does not affect the future in a good way.
Segment 3212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8081, Text: You’re a father, a proud father. What have you learned about life from your kids? Those little biological organisms.
Segment 3213: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8093, Text: I mean, developing AI and watching, say, little X grow is fascinating because there are far more parallels than I would’ve expected. I mean, I can see his biological neural net making more and more sense of the world. And I can see the digital neural net making more and more sense of the world at the same time.
Segment 3214: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8119, Text: Do you see the beauty and magic in both?
Segment 3215: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8121, Text: Yes. I mean, one of the things with kids is that you see the world anew in their eyes. To them, everything is new and fresh. And then, when you see that, them experiencing the world as new and fresh, you do too.
Segment 3216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8152, Text: Well, Elon, I just want to say thank you for your kindness to me and friendship over the years, for seeing something in a silly kid like me, as you’ve done for many others. And thank you for having hope for a positive future for humanity, and for working your ass off to make it happen. Thank you, Elon.
Segment 3217: Speaker: Elon Musk, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8171, Text: Thanks, Lex.
Segment 3218: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=JN3KPFbWCy8&t=8173, Text: Thank you for listening to this conversation with Elon Musk. To support this podcast. Please check out our sponsors in the description. And now, let me leave you with some words that Walter Isaacson wrote about the central philosophy of how Elon approaches difficult problems, “The only rules are the ones dictated by the laws of physics.” Thank you for listening, and hope to see you next time.
Segment 3219: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=0, Text: The following is a conversation with Jared Kushner, former senior advisor to the President during the Donald Trump administration and author of Breaking History, A White House memoir. He’s one of the most influential and effective presidential advisors in modern history, helping conduct negotiations with some of the most powerful leaders in the world and deliver results on trade, criminal justice reform, and historic progress towards peace in the Middle East. On Thursday, October 5th, we recorded conversation on topics of war and peace, history and power in the Middle East and beyond. This was about a day and a half before the Hamas attack on Israel, and then we felt we must sit down again on Monday, October 9th and add a discussion on the current situation. We open the podcast with a second newly recorded part. My heart goes out to everyone who has and is suffering in this war. I pray for your strength and for the long-term peace and flourishing of the Israeli and Palestinian people. I love you all. This is a Lex Fridman podcast. And now, dear friends, here’s Jared Kushner.
Segment 3220: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=77, Text: We did a lot of this conversation before the Hamas attack on Israel, and we decided to sit down again and finish the discussion to address the current situation which is still developing. If I may allow me to summarize the situation as it stands today, it’s morning Monday, October 9th. On Saturday, October 7th at 6:30 AM Israel time, Hamas fired thousands of rockets into Southern Israel. The rocket attacks served as cover for a multi-pronged infiltration of Israel territory by over 1000 Hamas militants. This is shortly after at 7:40 AM.
Segment 3221: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=115, Text: The Hamas militants went door to door in border towns killing civilians and taking captives, including women and children. In response to this, Israeli Air Force began carrying out strikes in Gaza, also fighting on the ground in Israel to clear out Hamas militants from Israel territory and preparing to mobilize Israeli troops for potential ground attack on Hamas and Gaza. Now, of course, this is what it appears to be right now, and this along with other things might change because the situation is still developing. The IDF is ordering civilian residents of Gaza to evacuate their homes for their safety. Benjamin Netanyahu declared war in several statements and warned Israelis to brace themselves for a long and difficult war. Just today, Israeli ministers ordered a “complete siege of Gaza interrupting supplies of electricity, food, water, and fuel from Israel to Gaza.” As of now, October 9th, the death toll is over 1200 people and over 130 hostages taken to Gaza by Hamas. As I said, the events are rapidly unfolding, so these numbers will sadly increase, but hopefully our words here can at least in part, speak to the timeless underlying currents of the history and as you write about the power dynamics of the region. For people who don’t know, Gaza is a 25 miles long, six miles wide strip of territory along the Mediterranean Sea. It borders Israel on the east and north and Egypt on the southwest. It’s densely populated, about 2.3 million people, and there’s been a blockade of Gaza by Israel and Egypt since 2007 when Hamas took power. I could just summarize that Hamas is a Palestinian militant group which rules the Gaza Strip. It originated in 1988, and it came to power in Gaza in 2006. As part of its charter, it’s sworn to the destruction of Israel, and it is designated by the United States, European Union, UK, and of course Israel as a terrorist group.
Segment 3222: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=250, Text: Given that context, what are your feelings as a human being and what is your analysis as the former senior advisor to the president under the Trump administration of the current situation in Israel and Gaza?
Segment 3223: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=263, Text: I think you did an excellent job of summarizing a lot of the context, but watching what’s unfolded over the last 48 hours has been truly heartbreaking to see. We’re still in the early stages of what’s developing, but seeing the images on X of militants, terrorists going door to door with machine guns gunning down innocent civilians, seeing beheaded Israeli soldiers, seeing young 20 year olds at a rave, a dance party to celebrate peace with militants flying in and then shooting machine guns to kill people indiscriminately, seeing young children captive and held prisoner, seeing 80-year old grandmothers, a Holocaust survivor also being taken captive. These are just images and actions that we have not seen in this world since 9/11. This is a terror attack on the scale of which we have not seen, and it’s been incredibly hard for a lot of people to comprehend.
Segment 3224: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=333, Text: My heart goes out, obviously, to all of the families of the victims, to the families of those who are held in captive now and to all of Israel because one of the beautiful things about the state of Israel is that when one Israeli is hurting, the entire nation comes together. It’s a shame that it’s taking an action like this to unify the nation, but I have seen incredibly beautiful signs over the last 48 hours of a country coming together. The Jewish people have been under oppression before. The Jewish people know what it’s like, and seeing people rally together to fight for their homeland to try to reestablish safety is a very beautiful thing to watch. I wish it wasn’t something we had to watch, but it is.
Segment 3225: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=386, Text: With that being said though, the backdrop, I’ve been speaking to friends over the last couple of days. One friend I spoke with last night who was saying that a good friend messaged him saying, I’m going in. We’re going to do some operations to try to free some of the hostages held in one of the kibbutzes. Messaged him the next morning. He was one of the first through the door to try to free these hostages, and he was killed by a Hamas militant. Sadly, we’re going to be hearing many, many more stories of brave Israeli soldiers trying to get these terrorists out of Israel, trying to free innocent civilians who unfortunately are risking their lives to do it. They’re all heroes, but some will have less good faith than others, sadly.
Segment 3226: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=433, Text: It’s a very, very heartbreaking moment, and I do think that it’s very important at this moment in time for the entire world to stand behind Israel. I think that Hamas has shown the entire world who they really are. I think what their aim is, what they’re willing to do, and all of the strong security that Israel’s put in place over the last years, which in some instances was criticized, I think is now being validated, that there was a real threat that they were looking to deter. Short answer is my heart is broken, praying for peace, praying for strength, praying for Israel to do what it needs to do to avoid being in this situation again, which is either eliminating or severely degrading Hamas’ capabilities. There cannot be peace in Israel and in the Middle East, while there is a terror group that is being funded by Iran that is allowed to flourish and is allowed to plan operations that are going to aim to kill innocent civilians.
Segment 3227: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=500, Text: As somebody who was formerly in this position, who was intimately involved with Israel with the strategies to minimize attacks from Hamas and to try to turn the region around, and I think we did do a very substantial job under President Trump. The Middle East went from one of the most chaotic regions in the world. You had ISIS in 2016, ISIS had a caliphate the size of Ohio. They’re beheading journalists. They were killing Christians. They controlled 8 million people. They were planning attacks all over the world from their caliphate. They were using the internet to radicalize people. We had the San Bernardino shooting in America. We had the Pulse nightclub shooting in Orlando, and there was real threat. Then you had Iran, which was given $150 billion in a glide path to a nuclear weapon, and they were using their newfound riches to fund Hamas, Hezbollah, the Houthis, different rebels all over the region that were looking to destabilize further. Syria was in a civil war where 500,000 people were killed. Yemen was destabilized, Libya was destabilized, and it was just a mess, and all of America’s allies had felt betrayed. President Trump came into power. We rebuilt the trust and the relationships with all of our traditional allies. We were able to eliminate ISIS, the territorial caliphate, and then we’re able to project strength in the region, really go after Iran’s wallet. We were able to stop through crushing sanctions a lot of their financial resources, which they were using to fund all these terror groups. We left the Middle East with six piece deals and in a fairly peaceful world. Seeing what’s happening, I think it was completely avoidable. I think it’s horrible to see that it’s occurring, and I pray that those in power will make the right decisions to restore safety, but also to potentially create a better paradigm for peace in the future.
Segment 3228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=629, Text: I have a lot of questions to ask you about the journey towards this historic progress towards peace with Abraham Accords, of course. But first on this situation to step back and some of the history, is there things about the history of Hamas and Gaza that’s important to understand what is happening now? Just your comments, your thoughts, your understanding of Hamas.
Segment 3229: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=651, Text: I think you did an excellent job, Lex, of really giving the summary. Just a couple of things, maybe I’ll add to it, is that Hamas was originally founded from the Muslim Brotherhood in Egypt, which is a group that’s caused a lot of issues in the region. They’ve attacked Israel many times in the past. There’s a lot of discussion about how Israel is an occupying power. Well, in Gaza, in 2005, they withdrew from all the land, and then they say, Israel’s an apartheid state. Well, Israel then gave governance of the region to the Palestinians, and then what’s happened is the Palestinian people’s lives have now gone down, not up since then. I will say that under Hamas’ leadership in Gaza, the people who have suffered the most are the Palestinian people and I see and I’ve watched cries throughout my time in government from people saying we want to see the Palestinian people live a better life. I agree with those people. I think that the Palestinian people in Gaza are essentially hostages.
Segment 3230: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=712, Text: In Gaza, you have basically 2.2 million people that are being held hostage by 30,000 Hamas terrorists. That’s really the problem, and I would just encourage people to push their attention and energy in this moment and their anger towards Hamas, those are the people who are killing innocent civilians, who are murdering indiscriminately, and those are the people who have held back the Palestinians from having a better life.
Segment 3231: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=743, Text: Finally, what I would say is what we saw with Hamas was that if you go back to 2007, they basically had just one plan that they did over and over. We were very careful to try to monitor very closely and stop the Iranian money and the resources from coming in. Again, we took a little bit of criticism from the international community for keeping the border tight, but unfortunately, every time you’d allow construction materials to go into Gaza, they’d use them to build tunnels, not homes. You would have equipment that would come in to build pipes, they’d turn it into bombs. It was very, very hard to figure out how do you get the resources into Gaza to help people live a better life while at the same time the leadership in Gaza was taking all those resources and turning it into military equipment to attack Israel.
Segment 3232: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=789, Text: What role does Iran play in this war, in this connection to Hamas? Can you speak to the connection between Hamas and Iran that’s important to understand, especially as this most recent attack unfolds?
Segment 3233: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=802, Text: Sure. The correlation, there’s reports that Iran is behind the attack. Hamas has thanked Iran for their support, and it’s been very well known that Iran supports the destruction of the state of Israel. I won’t say Iran as a country. I’ll talk about Iran in the leadership. There’s actually a beautiful thing I saw on the internet where at one of the soccer games in Iran, they were trying to rally support for the Hamas terror attacks and a lot of people in the crowds were chanting FU to the regime because I think the Iranian people, the Persian people generally are peace-loving people who don’t want to see this focus on destruction and annihilation. But you saw this in 2015, 2016, when the Iranian government had resources, the region was less safe.
Segment 3234: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=848, Text: Since now, there’s been more resources allowed to go to the Iranian regime by lack of enforcement of sanctions. As a result, Iran is funding Hezbollah, Hamas. They were funding the Houthis. Now there’s a little bit of a détente between Saudi and Iran, which has led to that going down, which only further proves that Iran was behind the Houthis, which is what the Saudis had been saying for years, and Iran was denying. There’s a very strong relationship between the two, and we always knew that the way that Iran fights wars or fights conflicts is never directly, it’s usually through its proxies. In this case, Hamas has been a proxy for Iran who wanted to obviously see the destruction of Israel, but also does not want to see the Israelis and the Saudis come together for a peace agreement.
Segment 3235: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=895, Text: The name of this operation, of the Hamas operation is Al-Aqsa Flood, referring to the Al-Aqsa Mosque. How much of this attack is about the Al-Aqsa Mosque?
Segment 3236: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=907, Text: In actuality, I don’t think any of it is, but the Al-Aqsa Mosque is something that all of the Shia Jihadists have used for years in order to justify their actions that are aggressive towards Israel. This is something, I’ll maybe even take a step back and go through when I was working initially in my first year on the Peace Plan, I was doing a lot of listening. Quite frankly, a lot of what people were saying to me didn’t make sense. The reason why I was trying to figure out, they were talking about sovereignty over Al-Aqsa Mosque. The Al-Aqsa Mosque is a mosque that’s built in the Holy of Holies, the Haram al-Sharif in Israel, where the [Foreign language 00:15:49], the Holy temple was built in a very religious place after the Temple was destroyed. Then there was a big mosque built there, and it’s one of the more holy places in Islam now.
Segment 3237: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=963, Text: The big thing everyone was saying is, “What do you do with this land where you have a mosque built over a very big Jewish site?” I was hearing all of the experts, and I always say experts with quotes, because only in Washington can you work on something for a decade and continue to fail, and then you basically leave are considered an expert. But that’s one of the problems with Washington, which maybe we could talk about later. But the notion here was I went and I said, “Let me try to understand what the issue is with the Israeli-Palestinian conflict with the people.” I always felt the politicians were a little disconnected so I commissioned several focus groups, one in Amman, one in Cairo, one in Dubai, and one in Ramallah. I asked people, Muslims, what is the Israeli-Palestinian conflict about? Time and time again, the most popular thing that they said was that Israel was not allowing access to the mosque for Muslims to pray. What was interesting was is that Israel’s policy is to allow anyone who wants to come and pray peacefully at the sites to come and pray. Sometimes they have security issues when there’s provocations. But by and large, since 1967, when Israel was able to take back Jerusalem in a defensive war, just to be very clear, they were attacked in the South and they were attacked from the east, and they basically were able to beat back the Jordanians and the Egyptians and then reconquer the old city of Jerusalem. During that time, immediately after Israel then passed the protection of Holy Places law, which was they basically took resources they didn’t have and they said we’re going to restore the Christian sites, the Muslim sites, the Jewish sites, and they’ve worked to allow everyone access to the mosque.
Segment 3238: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1065, Text: Today, any Muslim who wants to come can come and pray at the mosque. The mosque is… Israel’s acknowledged that King Abdullah, the king of Jordan, is the custodian of the mosque and as long as people want to come to the country and pray peacefully, they’re able to do that. But if you look at a lot of the propaganda that’s been used by ISIS or Iran to recruit terrorists or to justify their incursions, they often say they’re doing it in the name of liberating the Al-Aqsa Mosque. But from an operational and pragmatic perspective today, any Muslim who wants to go to the mosque, you can book a flight to Israel now through Dubai because there’s flights between Israel and Dubai and as long as your country has relations with Israel and they’ll accept your passport in there, you can come and pray. That’s what Israel wants. Israel wants Jerusalem to be a place where all religions can come and celebrate together. But you have a lot of actors that look to find ways to use these religious tensions in order to sow division and justify violent behavior.
Segment 3239: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1130, Text: I wonder how it’s possible to lessen the effectiveness of that propaganda message, that a lot of the war, a lot of the attacks are about access to the Al-Aqsa Mosque. Is there something you can speak to why that message hasn’t disseminated across the Arab world?
Segment 3240: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1147, Text: Israel’s good at a lot of things. They’re not very good traditionally with public relations. After the Abraham Accords, we made the first Abraham Accords deal in August, 2020, and then we made five other deals. We first did United Arab Emirates, then we did a deal with Bahrain, then we did a deal with Kosovo, then we did a deal with Sudan, then we did a deal with Morocco, and then we got the GCC deal done as well, the tension between Qatar, Saudi, UAE, Egypt and Bahrain. That was allowing us to create a pathway to then pursue the Israeli-Saudi normalization. We had so much momentum then that the goal was just keep getting more countries to normalize relations with Israel. Once you create the connection between people and create the ability for people to do business together, the ability for flights to fly between, then you would just start naturally having people coming and everyone has a smartphone today, so they can then post and combat the misinformation that’s been out there.
Segment 3241: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1207, Text: But this misinformation is not something that’s new. One of the characters who played a very big role in spreading the antisemitism and the violence in Israel in the 1920s was a guy named Haj Amin al-Husseini, who was known as the Grand Mufti of Jerusalem. He was very close with Hitler and Mussolini, and he was working with them to try to get some claims to the Middle East once the Jewish people were annihilated. What he did for a very long time was he did the same shtick, only it was before yet smartphones and YouTube where he would say the mosque is under attack. These imperialist Zionists are coming in to try to destroy the mosque.
Segment 3242: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1242, Text: He would use that to raise money from Indonesia, from Pakistan, from all over the world, and then use that threat to justify recruiting groups of young, vulnerable Muslim men and then getting them in the name of religious rights to go and kill people, which really is more of a perversion of the religion than I think the true essence of what Islam is. I think Islam at as core is a peaceful religion, and I think that’s where a lot of the great leaders in Islam want to take it. But the people who use Islam or the mosque or as a justification for violence, those are people who I think are really… They’re disrespecting the Islam religion.
Segment 3243: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1280, Text: As you said, you helped make major strides towards peace in the Middle East with the Abraham Accords. Can you describe what it took to accomplish this, and maybe this will help us understand what broke down and led to the tragedy this week?
Segment 3244: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1296, Text: Yeah. I always believed in foreign policy. I learned very quickly that the difference between a political deal and a business deal is that in a business deal, you have a problem set, you come to a conclusion, and then if you buy or sell something, you either have more cash or you have a company. More to do, less to do. Political problem set is very different, where the conclusion of a problem set is essentially the beginning of a new paradigm. When I would think about how do you move pieces around the board, you couldn’t say let me just solve the problem. You have to think about what happens the day after the signing, and how do you create a paradigm that has positivity to it.
Segment 3245: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1337, Text: The biggest piece of what President Trump did during his four years in office was he really strengthened the relationship with Israel, number one. He did things like recognizing Jerusalem as the capital of Israel. He moved the embassy to Jerusalem. He recognized the Golan Heights. He got out of the Iran deal. We did an economic conference in Bahrain where we brought Israelis to meet with Saudi and Emirati and Qatari businessmen and everyone came together. Each one of these instances were unthinkable previously. Everyone said that if you did it, the world was going to end and every time President Trump did one, the next morning the sun rose, the next evening, the sun set and things moved on. By doing that, what President Trump did was he slaughtered a lot of the sacred cows of these false barriers that people had erected and showed people that the vast majority of the people in the Middle East, whether they’re Jewish, Muslim, Christian, whatever religion they are, they just want to live better lives.
Segment 3246: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1397, Text: What we basically did was create a paradigm where the voices for peace, the voices for together now finally had a forum where they were able to do it. We did that in the backdrop. The way we’re able to be successful was we severely limited the resources of Iran, and they were focused more internally, and they couldn’t cause the trouble that they were causing everywhere else. Since we’ve left, obviously the dynamics have changed, but the way you get to peace is obviously number one through strength and number two, by finding a way for people to be better off tomorrow than they are today. What I found was that most of the voices looking for violence or trouble were people who were just focused on what happened two years ago, 20 years ago, 70 years ago, 1000 years ago. People who were trying to solve those problems in that context often were looking more to use those past grievances as a justification for their power and for the bad behavior that they were looking to perpetuate.
Segment 3247: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1460, Text: As we have talked about extensively, managing the power dynamics of the region and providing a plan, this is something you did with the economic plan titled Peace to Prosperity, A Vision to Improve the Lives of the Palestinian and Israeli people. Can you first of all describe what’s in the plan?
Segment 3248: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1478, Text: Sure. This was something I took on. I was working on the political framework between the Israelis and the Palestinians and trying to understand what were the issues. The issues were not very many. It basically was you had a land dispute, so you had to figure out where do you put borders ultimately, you had a security paradigm, which I was much more favorable to Israel’s perspective on. Obviously the events of the past 48 hours have fully justified that bias. Then in addition to that, you had to deal with the religious sites, but I felt operationally that wasn’t actually as complicated as people made it because you wanted to just leave it open for everybody.
Segment 3249: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1517, Text: Then I went through and I felt that the Palestinian leadership was fairly disincentivized to make a deal because there was just this paradigm where they had billions of dollars coming in from the international community, and I think that they feared that if they made a deal, they would lose their relevancy internationally and the money would stop flowing into the country. What I tried to do is to say my approach when I would get into a hard problem, say, how do I understand all the different escape patches? How do I try to eliminate them and then build a golden bridge that becomes really the only, but also the most desirable pathway For the decision makers to walk through.
Segment 3250: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1556, Text: It wasn’t always hard, and sometimes you have to go and hold their hand or you try to pick them up and walk them across. But a lot of these leaders are very reluctant to change, and the dynamics of the Palestinians also were such that I think they were fairly stuck where they were. We developed a business plan for Gaza, the West Bank. We threw in some improvements for Jordan and Egypt as well. I based it off of the vision 2030 that they did in Saudi Arabia, which I thought was a visionary document. I went back through this process and I studied basically every economic project in post-World War II period.
Segment 3251: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1593, Text: We looked at what they did in South Korea, why it was successful with some strong industrial planning. We looked at Japan, we looked at Singapore, we looked at Poland, why it was successful. We spent a lot of time on the Ukraine plan for the country and why it wasn’t successful. That was mostly because of governance and corruption, which actually resembles a lot of what’s gone wrong with the Palestinians where there’s no property rights, there’s no rule of law. What we did is we built a plan to show it’s not that hard in the sense that between the West Bank and Gaza, you had 5 million people. We put together a plan. I think it was about $27 billion. We got together a conference. I had the head of AT&T. We had Steve Schwarzman from Blackstone came, which was very gracious of them.
Segment 3252: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1634, Text: We had all the leading Arabic businessmen, the leading builders, leading developers. The general consensus of that conference was that this is very doable. We think that for Gaza in particular, it would cost maybe seven to $8 billion to rebuild the entire place. We felt we could reduce the poverty rate in half. We can create over a million jobs there. The only thing that people said was holding it back wasn’t Israel. What was holding it back was governance, and people wouldn’t have confidence investing there with the rule that Hamas was perpetuating.
Segment 3253: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1669, Text: I encourage people actually to look at the plan. It was very thoughtful. It was 181 pages. We went project by project. Each project is costed out. It’s a real plan that could be implemented, but you need the right governance and all of the different Arabic countries are willing to fund it. The international community is willing to fund it because they’ve just been throwing so much money at the Palestinians for years that’s never been outcomes based or conditions based. It’s just been entitlement money, and unfortunately, it hasn’t really achieved any outcomes that have been successful.
Segment 3254: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1700, Text: It’s a great business plan. It just shows too rebuilding Gaza could be easy, but like I said, the problem that’s held the Palestinian people back and that’s made their lives terrible in Gaza has not been Israel. It’s really been Hamas’ leadership or lack of leadership and their desire to focus on trying to kill Israelis and start war with Israel over improving the lies of the Palestinian people.
Segment 3255: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1724, Text: The current approach of Hamas, the more violence they perpetrate, the more they can hold onto power versus improving the lives of people. As you said, maybe you can comment on they do not propose an economics plan.
Segment 3256: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1742, Text: Hamas has been running it now for 16 years, and they don’t have a lot to show for it. Our posture with them was basically a very simple deal. If you think about what’s the end state in Gaza, it’s actually not that complicated. There’s no territorial disputes, right? The border’s the border. There’s no religious issues there as well. You’re not dealing with Jerusalem. You’re basically just dealing with the fact that Israel wants to make sure that there’s no threat from Gaza so it’s a demilitarization or some kind of security guarantee from a credible source where Israel doesn’t feel like Gaza can be used to stage attacks into Israel or to fire rockets into Israel.
Segment 3257: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1781, Text: By the way, these are things I was saying three, four years ago that that was the objective, and that was really the fear. Now that’s been proven. Unfortunately, the fear has manifested, and in exchange you can rebuild the place and you can give the people a much better life. But Hamas has not shown desire for that or a capability for that, and I don’t think there’s enough trust to allow them to do that, which is why under the current circumstances, if you do want to have peace there, Hamas has to be either eliminated or severely degraded in terms of their military capabilities.
Segment 3258: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1815, Text: I would love to ask about leadership, especially on the side of the United States. What has the current administration, the Biden administration, done different than the Trump administration, as you understand, that may have contributed to the events we saw this week.
Segment 3259: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1834, Text: All I can talk about are where we left them. We left them a place where they had tremendous momentum in the Middle East. I met with them during the transition and said, “Look, we even got the Qatar-Saudi conflict done, which was a big… No peace between Israel and Saudi would’ve been possible without that so we even got that done in our lame duck period. They came in and they said, “Look, we want to focus on the three Cs, which is Covid, climate change, and China.” I said, “That’s great, but the Middle East we have in an amazing place right now. It’s stable, there’s momentum. Iran is basically broke.” We put such crippling sanctions on Iran that they went from about, I think it was 2.6 million barrels a day of oil they were selling to about 100,000 under Trump. Their foreign currency reserves were basically depleted and they were broke.
Segment 3260: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1885, Text: Same with the Palestinians. We stopped the funding to UNRWA, the UN agency, which is totally corrupt. We’ve put $10 billion in there over time. I did a poll in the Middle East, in Gaza to say, “Okay, we’ve invested $10 billion here as a country. Are we popular?” The US had a 7% approval rating. USAID has 70% approval rating, but it just felt like a waste of our taxpayer dollars. Again, we wanted to make it conditions based. The Biden administration came in. Number one, they started insulting Saudi and Russia. Oil prices went up at the same time. What they did was they stopped domestic production of oil. They disincentivized a lot of oil and shale production with regulations. They stopped pipelines. Oil prices went up. They stopped enforcing the sanctions against Iran probably to get the oil prices lower to make up for what they were doing. They ran to Iran to try to make a deal. They started funding the Palestinians again right away.
Segment 3261: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1947, Text: I even said if you’re going to fund them, if that’s your policy, I respect that. Again, elections have consequences and you can take a different policy. But what I would recommend is get some conditions, make them do some reforms, make them give property rights to people, make them do real economic investments for people. But they just went right away. They were funding the Palestinians, not enforcing the sanctions and then overall, just projecting a lot of weakness in the region. One of the most embarrassing examples is what happened in the United Arab Emirates. Again, an amazing, probably one of America’s best allies over the last 20, 30 years…
Segment 3262: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=1983, Text: … of America’s best allies over the last 20, 30 years. They fought with us in Afghanistan. They were the first Muslim country to stand up and do that after 9/11 because they didn’t want it to be a war of the West against the Muslim religion. So they joined the fight, because they saw it as a fight between right and wrong. They have rocket shot into their country from the Houthis, and they basically don’t get a call from the US for 17 days. They need their equipment that they buy from the US, which creates job in the US. They need it restocked. We don’t call. So they’ve severely degraded the trust that we had to rebuild with our allies. I think they’ve been working now to get it back. They, after two years, started working with Saudi and Israel, which I think was good.
Segment 3263: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2028, Text: I think that they realized, after a stint, that maybe the process that President Trump had created in the region was the right policy. And keep in mind, President Trump’s policy, that I was working on, was very strongly criticized during the first three years before we were able to achieve the results, because it was a departure from the failed policies of the past. So first, there was return to those policies, appease Iran, let’s criticize Saudi Arabia. Then they started embracing and working on the Israel-Saudi deal, which was really exciting. I think we were all very excited about it. But they did it in public, and I think that that also was something. Again, I didn’t have access to their intelligence, so I assumed that by doing it so publicly, they thought that they’d either had a deal with Iran because they were letting them get all this revenue where Iran wouldn’t be a problem.
Segment 3264: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2075, Text: But one of the reasons with the Abraham Accords, we kept it so quiet during the whole time, was because we always felt like the troublemakers in the region, particularly Iran, who we thought would be disadvantaged by having UAE, Saudi, Israel altogether. Israel’s a nuclear power. You have other strong economies. Iran seeks instability. They seek looking to create a division in the region. And if you can create that economic sphere where you have security from Haifa to Muscat, from Israel to Oman all the way through with Saudi, Jordan, UAE, Qatar, Egypt. That’s an incredibly powerful block. If you can make it secure and then get economic integration, that really could be a Middle East that thrives. So Iran, obviously, wanted nothing to do with that, and that’s why they’ve been working to disrupt. So I think the administration, they took an incredibly stable situation with momentum.
Segment 3265: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2128, Text: I think they underestimated the way that Iran would approach the region to undermine. I think they gave way too much rope to Iran, and I think that they didn’t seize, when they had an opportunity of strength with the Palestinians, to try to drive to a conclusion that, I believe, could have prevented us being where we are today. Not to mention that even just three weeks ago, it’s a bad look that they just basically gave $6 billion to Iran in exchange for hostages. And then Iran’s basically funding these terror attacks, they are killing American citizens in Israel. It’s a heartbreaking situation. Again, totally avoidable and one that, I think, has been very badly mismanaged to date.
Segment 3266: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2173, Text: If Trump was currently president, you were still working with him on this part of the world, what actions would you take? What conversations would you have? What ideas would you be working with in order to unite the various allies that you mentioned in the Middle East over this tragedy and not let it be a thing that divides the Middle East, but make it a thing that catalyzes further progress towards peace?
Segment 3267: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2208, Text: I want to say one thing, Lex. I have a lot of friends who are fans of Trump, who are not fans of Trump. But one thing I want to say with absolute certainty is that, if President Trump was in office, this never would have happened. When President Trump was in office, anyone who supports Israel or who wants to see Jewish people not be innocently slaughtered, he would never have allowed that to happen. It did not happen when he was in power. And I hope people recognize that as something that’s very, very true. How I would play the ball where it lies right now. Keep in mind, we transferred the ball it was on the green. Now it’s almost like it’s gone back 150 yards and it’s in a sand trap. I think the way that I would play the ball right now is, number one is you have to show strength.
Segment 3268: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2253, Text: I actually think President Biden’s words were the right words. I see that they’re moving aircraft carriers to the region. Again, the purpose of having a strong military… I believe obviously if you get into a war, you want to win the war. But the purpose of a very strong military primarily is to avoid a war. I don’t know what credibility the Biden administration has to show the strength, but right now you have to support Israel completely. You have to really let people in the region know that there’ll be consequences if they try to escalate. Again, we saw a little bit of rocket skirmish from Lebanon, from Hezbollah. But again, this is the type of thing that they have to know, there’ll be severe consequences if they make this a multi-party fight. And I think sending a strong message to Iran, I think that they have to see some consequences from this and know that they’re not going to be allowed to have a free rein to cause instability in that.
Segment 3269: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2308, Text: Iran doesn’t usually fight face- to-face. They usually do it through proxies, but let’s just all be honest about where this is coming from and let them know that there will be a consequence if they instigate these actions. Again, at least with the Biden administration, they’ve had contact with Iran, they’ve been talking with Iran, but they’ve allowed Iran. Again, the number I saw last year, I think under Trump the number was maybe like four or $5 billion of oil revenue in total. I think last year it was something like $45 billion in revenue. This year, I think it’ll be even more. That’s a combination of them driving up oil prices, but also allowing much more sales. You would think that they would find a way to get them to behave and allow them to have this happen. Or if that’s not the case, then be tough. Go back to being tough. That’s what you have to do.
Segment 3270: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2355, Text: Building off of Abraham Accords, as you mentioned, Israel-Saudi normalization, there’s been a lot of promising progress towards this. What does it take to not allow this tragedy damage the progress towards Israel-Saudi normalization?
Segment 3271: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2373, Text: I think right now it’s probably not the best to think about that. I think that we want to think about that after whatever’s going to happen is going to happen now. I think right now, the number one priority for Israel has to be to fully regain security in the country. And then number two is, to figure out how you can, like I said, eliminate or degrade the Hamas capability or other Iranian threats to make sure that you have your security apparatus. I think that the Israeli leadership right now should proceed with that, and I don’t think that they should be thinking about normalization with Saudi at this moment. My instinct, and I’ve been watching this Israeli-Saudi normalization play out. Obviously just speaking with people and seeing what I’ve been reading and watching with great excitement. I think it would be a game-changer for the region.
Segment 3272: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2421, Text: I think it’s one of Iran’s worst nightmares to have Israel and Saudi interlinked together. I think it’d be great for the Saudi people from a security perspective, what they’re discussing with America would be very strong. The ability to get different elements across would be incredible. So what I would say with this is that, the industrial logic held yesterday, and I think it will hold again tomorrow. I always expect countries to act in their interests. I think that the deal that’s on the table right now between Saudi, Israel and America is in Saudi’s interests, it’s in America’s interests and it’s in Israel’s interest. What’s going to happen now though is, the political dynamics are going to shift. And I think that, as we’ve seen with political dynamics, they come and go. I think let’s get through this moment, and then I hope at the right time that those talks will be able to resume and conclude in an appropriate way.
Segment 3273: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2478, Text: It’s funny, Lex, when I was working on the US-Mexico agreement for the trade, every day there’d be a tweet that would go out or there would be an issue. People forget how intense it was between America and Mexico. And I’d speak to my counterpart of Mexico after a rough day and we were working on something, we were making progress. It’d get blown up. And I’d speak to them and say, “You know what? Look, they’re not moving America. They’re not moving Mexico. Let’s stop for today. Let’s pick up tomorrow and let’s find a new way to bring this forward.” So I would just encourage everyone working on that not to give up, to keep working hard at it and to find a way. But like I said, I would take a little bit of a pause for the time being. Let’s let the current situation play out and then hopefully there’ll be a way for it to move forward.
Segment 3274: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2522, Text: I just hope there’s still people on the US side picking up the phone and calling UAE, Saudi Arabia just as human beings, as friends, as allies, and just keeping that channel of communication going. Maybe you can correct me, but I just feel like there’s just simple human dynamics that play out here, that divisions can form and just run away from you. Over simple misunderstandings, over just inability to see a tragedy from the same perspective because of conversations that could have happened but didn’t happen.
Segment 3275: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2564, Text: I think there’ll definitely be communication, but words on phone calls is only worth so much. It’s really trust between people in power. And obviously when you’re in a position of power, you represent your country and your country’s interests. But the ability to have trusting relationships where people feel like they’re okay taking more risks to help each other, that’s actually what’s most important. So communication, I hope for. But deepening and trusting relationships, that’s what I believe makes progress and keeps people safe.
Segment 3276: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2597, Text: We talk quite extensively about the value of trust in negotiation and just working with leaders, which I think is a fascinating conversation. And you’ve taught me a lot about that. Let me ask you about the end here. What are the various trajectories this war can take, in your view? What are some of the end states, as you’ve said, which are desirable and are achievable?
Segment 3277: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2623, Text: I mentioned this earlier, but whenever I would get a problem set in government, I’d always think through from a first principle’s perspective, what’s the logical outcome? And forget about all the reasons why it can’t happen. That’s what everyone in governments always rush to talk about. But I do think here, number one, Israel has to have a secure environment where they don’t feel threatened from Gaza. And number two is, the people in Gaza need to have an environment where they feel like they can live a better life and have opportunities. That’s the end state. So I think that the international community should come together. I do think that the people who are usually putting blame on Israel should now realize that maybe they’ve been a little bit harsh here, and that Hamas has been as big a threat, if not an even bigger threat than Israel has been saying.
Segment 3278: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2672, Text: And I do think that if the international community comes together and unites behind Israel and really forces Hamas and their Iranian backers to stop hostilities, to stop saber-rattling, to stop misrepresenting the history in order to justify their violent behavior. And if they say instead, “We want to hold you accountable, no more money.” And they all say that they’re going to stand behind Israel’s efforts to eliminate their national security threats. Then we will all come together and only fund again into a framework that we believe can be a long-term solution where the Palestinian people really have a chance to live a better life. That’s really the best way to get there. There’s tons of complicating factors, but that’s the end state that the global community should be looking to come together. And it’s very achievable. It’s very, very achievable.
Segment 3279: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2726, Text: As we stand here today, there’s a lot of different ways that this war can evolve. If a ground invasion happens, by Israeli forces, of Gaza, and if the number is correct of 100,000 Israeli soldiers. Do you worry about various trajectories that can take or the consequences that might have of an unprecedented ground troop attack?
Segment 3280: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2752, Text: I think as a leader, you can’t change yesterday, but you have the ability to change tomorrow. And that’s a very important fundamental. That’s true for all of us, not just leaders. We saw with 9/11 how America was caught off guard by a terrorist attack. We acted somewhat rationally, somewhat emotionally, which led to a 20-year war with trillions of dollars lost. I think almost a million lives lost, not just American, but all lives. And it was a total tragedy what occurred. I think right now the temptation is to be strong. I think that that’s a necessity. I do think eliminating risk is the right objective. I think the goal should be to stay very clear about what the objective is. But also this attack was very well planned, not to walk into another trap. I think you have to be very smart, very cautious.
Segment 3281: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2803, Text: I’ve been happy to see that what they’ve been doing in retaliation so far has been somewhat measured and they’ve taken their time to try to assess what’s achievable. Again, I don’t have access to the intelligence, and we’re talking at a very early stage in this conflict. So a lot had happened even by the time this is published. But my hope is that they’ll just stay very focused on what the objective is and try to make sure that they’re acting appropriately in order to do that. And I will say this too, that this has been different than what I’ve seen in the past. And that the attacks were so heinous and so disgusting that I’ve seen the international community rally around Israel more so than I ever have. And I hope that Israel continues to keep the moral high ground and continue to communicate what they’re fighting for, why they’re fighting. And I do hope that the international community supports the objective and they can work together to achieve it.
Segment 3282: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2864, Text: Benjamin Netanyahu, Bibi, somebody you’ve gotten to know well in negotiation, in conversation. He has made statements, he has declared war, he has spoken about this potentially being a long and difficult war. What have you learned about the mind in Benjamin Netanyahu that might be important to understand here in this current war?
Segment 3283: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2888, Text: Bibi is definitely a historic figure. I’d meet with a lot of different world leaders, and some of them, I would say, they’re very, very special, transformational figures. And some, I would say, how the hell is this person running a country? Bibi is somebody who has done a lot for the state of Israel, he has a tremendous understanding of the security apparatus. He has tremendous global relations. So for a crisis like this, I think Bibi’s the leader you want, if you’re Israel, to be in that seat. I think he’s ambitious in what he’s going to look to achieve. He understands his role in history as somebody who’s helped strengthen Israel economically, militarily.
Segment 3284: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2932, Text: And I don’t think he wants to see his legacy be somebody who left Israel more vulnerable than it had to be. So I think, in that regard, he’ll be incredibly strong. But I also think that he’ll hopefully be calculating in the risks that he takes and not create more risk than is needed. And that’s easy to say, the two of us sitting here having a conversation. When you’re sitting in that chair as a leader in the fog of war, it’s a very hard decision to make. He’s been here before. He knows the weight of the situation. I’m sure he knows the moment. And I pray that he’ll do what’s right here to bring the best outcome possible.
Segment 3285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2978, Text: I wonder if you can comment on the internal political turmoil that Bibi has been operating in and how that relates to the tragedy that we saw.
Segment 3286: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=2991, Text: On the one hand, the political turmoil, it’s a sign of a vibrant democracy. I think it’s been actually nice to see how people have fought for their country and their beliefs in a democratic way. You compare that to the Palestinians where there’s no democracy, there’s no free speech, there’s no free press. You can disagree with the leadership in Israel. If you want to be homosexual, you can go to a parade and live your life. In Gaza, they’ll throw you off a building and kill you. So in Israel, you have the freedoms, which I think make it a special place. And you have a very vibrant democracy.
Segment 3287: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3033, Text: With that being said, the times in Jewish history where the Jewish people have been most vulnerable have been when there’s been division, and that’s when the temple was destroyed. But that’s not just with the Jewish people and with Israel, that’s in all societies. So I definitely believe that this division has left them less prepared for the situation than it would. I do think there’s real lessons we should be taking from this here in America, where we’re in a time where we’re very divided. But I do think that it’d be very wise for our leaders to find the areas where we do agree and find ways to secure our southern border, to make sure that we know who’s in our country, what risks we all face. And I do think that division definitely creates risk for countries.
Segment 3288: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3081, Text: Let me switch gears here and just zoom out and look at our society and our public discourse at the moment. What do you make of the scale and nature of the Palestinian support online in response to this situation?
Segment 3289: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3095, Text: This is something I’ve observed over the years since I got involved with the Israeli-Palestinian issue with a lot of interest. I think a lot of the people who are pledging support for the Palestinian people, I think that they want to see the Palestinian people live a better life. And I actually agree with them in that regard. Unfortunately, I think many of them are incredibly ill-informed as to the facts on the ground. I think all of the people who are advocating online for the Palestinian people, who are going to these marches in support of them, I think they’d be best served if they really care about effectuating the outcome of joining with Israel right now and directing their anger towards the Hamas leadership.
Segment 3290: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3147, Text: I think that it’s very clear that the group that’s responsible for the Palestinian people living the lives that all of these people are angry about is Hamas. And if they direct their anger towards Hamas and put the attention on the failings of Hamas and put forth a vision for what they’d like to see leadership in Gaza do. And they respect that there’s a real fear that Israel has and any country would have of having a group of terrorists next to them that’s calling for their destruction. I think that that recognition of finding a way for Israel to be secure and then having an opportunity for the Palestinian people to live a better life is the right pathway to try and pursue.
Segment 3291: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3190, Text: So to you, there’s a clear distinction between Hamas and the Palestinian people, in that Hamas is the enemy of progress and the flourishing of the Palestinian people.
Segment 3292: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3201, Text: 100%. It’s very, very clear. And I think that if people were honest about the situation, if they spent the time to really understand it. Again, if you follow the conference I did in Bahrain, we had all of the leading businessmen there and they said, “We can rebuild Gaza very easily. We all want to.” The leading Arab businessmen, the leading American businessmen, everyone wants to, they’re just held back by Hamas. So I do think having an honest conversation about this at this point in time has really only one logical conclusion. And my hope is that, maybe this conflict leads to that conversation being had. And if it is, then maybe that brings more unity and understanding and we get to a conclusion better that could improve the lives of the Palestinian people.
Segment 3293: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3242, Text: Pragmatic question about the future. Do you hope Donald Trump wins in 2024? And how can his administration help bring peace to the Middle East?
Segment 3294: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3254, Text: When Donald Trump was president, we had a peaceful world. Everyone said if he was elected, we would have World War III. Meanwhile, he gets elected, and he not only is the first president in decades to not start any wars, he’s making peace deals. He’s making trade deals. He’s working with our allies, getting them to pay their fair share in NATO. He’s having a dialogue with China, with Russia. He’s weakening Iran. So I do think that the job he did as a foreign policy president was tremendous. I think now more and more people are starting to recognize that. Again, under President Biden, this is the second war that’s broken out in the world. And when you have a weak American leadership, the world becomes a less safe place. So my hope and prayers are that President Trump is reelected and that he’s able to then restore order and calm and peace and prosperity to the world .
Segment 3295: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3310, Text: From a place of strength?
Segment 3296: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3312, Text: That’s the only way he knows how to do it.
Segment 3297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3315, Text: What gives you hope about the future of this region, of Israel and of the Middle East?
Segment 3298: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3323, Text: The Middle East for 20 years was an area of conflict. They spent all their money on bullets and bombs. You have young leadership now in Saudi Arabia and UAE and Qatar, and there’s a much more ambitious agenda now for the region to make it an economic superpower and hub of the world. Israel is one of the most burgeoning and exciting tech economies in the world. And if you think about it, it’s almost like having Silicon Valley not connected to California. The thing that’s held the region back for all these years has just been the conflict and the division and the lack of connectivity. But if you have that region and if it can all come together, if you can create a security architecture. You have an incredibly young population, you have a lot of wealth and resources and a lot of capabilities and knowhow. So I think that if it’s managed correctly, and if Iran is able to be restrained and suppressed with their ambitions to cause destabilization. I don’t mean Iran the country, I mean the Iranian regime.
Segment 3299: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3389, Text: Because actually once you have this economic sphere, if you could bring Iraq into it, if you could bring Iran into it, that makes it even bigger and stronger. And the Persian people are incredibly entrepreneurial and incredibly industrious. So I do think that the region has tremendous potential. It’s just been held back by bad policy, bad leadership, bad objectives. And again, when President Trump left office in 2021, the Middle East was really on a very, very positive trajectory. And if the right things happen, it can continue to be so. I’m praying at this moment in time that we navigate the current crisis, that the important objectives are achieved of eliminating the terrorists and their threats. And then allowing the leaders who are focused on giving their citizens and their neighbors the opportunity to live a better life, are able to work together and really dream and be ambitious and find ways to create a paradigm where humans can flourish.
Segment 3300: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3450, Text: What is the best way to defeat hate in the world?
Segment 3301: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3454, Text: Hate is a very powerful force, and it’s much easier to hate people you don’t know. It’s funny, when I was working on prison reform, one of the most interesting people I met was a reverend, actually down in Texas, who negotiated the first truce between the Bloods and the Crips. Two of the notorious gangs in America, in prison. And I was very excited to meet him. When I met him, I said, “Well, how’d you do it?” And he said, “It was very simple.” He says, “I got all the guys together and I had a tremendous amount of barbecue brought in.” He says, “And I got the meeting.” He says, “No drinking.” He says, “Drinking sometimes gets people a little bit more against each other.” He says, “But I got a meeting and they started sitting down together and they started saying, ‘You know what? You’re just like me.'” And all of a sudden, they started finding areas where they were more together.
Segment 3302: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3507, Text: Look, I’ve traveled all over the world now. I’ve been very fortunate to meet people from different states in America. I’ve different political persuasions, different ages, different classes. And what I found is that, there’s a fundamental driving amongst all of us where we all want to live a better life. People don’t want to fight naturally, but it’s easy to fight when you feel wronged or you feel like somebody disrespected you or somebody did something from hatred. And hatred leads to more hatred, which sometimes just pushes that cycle further and further. So I believe that each and every one of us has the power to stop that cycle. We don’t do it by being on Twitter and yelling at people. We don’t do it by just being critical. We do it by finding the people we disagree with, by listening to them, by asking questions, by sitting with them. And then if we each take responsibility to try to make the world better, then I think that there’s no limits to the incredible place that this world can be.
Segment 3303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3571, Text: As you’ve said, you’ve traveled all across the world. Do you think most people are good, most people have love in their heart?
Segment 3304: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3581, Text: I do believe that, yeah. And you have some bad people. You have some real evil people. A big part of the work I did was on prison reform. Previously the mentality was, is that the prison should basically be a warehouse for human trash. And if you’ve made a mistake in this world, then we’re going to throw you out and we’re going to make the rest of your life incredibly difficult. Because you’re going to have a criminal record, you’re not going to have access to jobs. But what I found is, when I would sit with people in prison, the people I’ve met through my father’s experience and who I met along the way is that people make mistakes. We’re all human. I think it’s the right thing from a religious perspective to give people second chances. I always believe you shouldn’t judge people by the worst mistake they make in their life.
Segment 3305: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3624, Text: Unfortunately now, in the era of social media, people will say one wrong thing, it sticks with them forever. They get canceled or they get put out. We’re all humans. We grow from our mistakes, we learn from our mistakes. And I think that some people are just evil. There are some evil people. But I do think the vast, vast, vast majority of people are good. And I do think that people sometimes also can be in a bad place, and then society can push them to a worse and worse place. But we all have the power to make them feel loved, make them feel heard. I think there’s also tremendous power that we have as people to help people get to a better place. My wife and I, we’ve always tried to be a force for good. We’ve always tried to provide a place where people can discuss with each other.
Segment 3306: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3672, Text: When we were in Washington, we would host dinners at our house all the time, or we would have Democrats and Republicans sitting together. I saw Senator Feinstein just passed away. We had a great dinner at her house when she was a senator, with her and her husband and Mark Meadows when he was on the Freedom Caucus. And we had actually a fascinating discussion about Iran. Mark was much more hard line than me. I had to actually bite my tongue. I was impressed at how much he did. Whereas Feinstein and her husband were super into… They knew the Iranians well. They thought they were peace loving. And it was an incredibly robust and respectful debate. I don’t think we maybe concluded anything that night, but it was interesting for people to get together. Having a dinner at my house where I had Dick Durbin, the number two ranking Democrat in the Senate, Lindsey Graham and Steven Miller, who’s known to be a very hard line on immigration, discussing what an immigration reform could look like.
Segment 3307: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3726, Text: They left that dinner saying, “Wow, we hadn’t spoken to people on the other side and we actually agree on 85% of things. Maybe something is possible.” So I believe that we should always be trying to push to make the world a better place. And you only do that by listening to people and connecting with people and by respecting people. And finally, I’ll just say on this is that, I meet people all the time who have so much confidence in their perspectives. I’m very jealous that these people are able to be so confident about every single thing. Because, for me, I have some degree of confidence in the things that I’ve studied and what I’ve learned, but I’m always trying to find people who disagree to sharpen my perspectives and to help me grow and to help me learn further. I think that’s the beauty of the world, is that the knowledge base continues to grow, the facts continue to change, and what’s possible tomorrow continues to become different. So as humans, we have to continue to thrive, to learn, and to grow and to connect. And if we do that, everything’s possible.
Segment 3308: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3792, Text: Well, Jared, thank you for your compassion, first of all, but also your wisdom today on this very difficult, this tragic set of events, these difficult days for the world. It’s a big honor to speak with you again. Every time I speak to you, I learn a lot about the world. And I deeply appreciate, like I said, your humility and your understanding of the details of all the complex power dynamics and human dynamics that are going on in the world. Once again, thank you for talking today.
Segment 3309: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3828, Text: Thank you. And Lex, if I could say just one final thing, which is that my thoughts and prayers are really with all the people in Israel and the innocent civilians as well on the Palestinian side. My prayers are with the IDF soldiers that they should be safe and they should be really watched by God to accomplish whatever mission will enable to make the world a safer place.
Segment 3310: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3852, Text: Thank you for listening to this newly-recorded segment of The Conversation that addresses the current situation in Israel and Gaza. And now we go on to the second part of the conversation recorded on Thursday, October 5th. Given your experience in negotiating with some of the most powerful and influential leaders in the world, what’s the key to negotiating difficult agreements in geopolitics? I start with a big question.
Segment 3311: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3879, Text: If I look back on the different negotiations I had when I was in government, either with leaders of countries, with representatives of leaders, or even with members of Congress to pass legislation. The most important thing I would draw back to would be trust. I think getting to know each other, understanding what was motivating the other party to get to the outcome. And making them feel like you weren’t going to use whatever information they gave you to benefit yourself at the expense of them is probably what I would call table stakes to have a shot at accomplishing anything that was hard in negotiation.
Segment 3312: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3924, Text: After that, I would say taking maybe a first principles approach to what the outcome of whatever problem you’re looking to solve should be. Now, you have different kinds of negotiations. I always tried to create a framework in the negotiation where it wasn’t me against you. It was always, let’s agree on what the outcome is that we’re trying to accomplish. Let’s all sit on the same side of the table and say, “We want to get to this outcome. How do we get there?” Really trying to create a roadmap. So once you understand the destination you want to, get to the endpoint, then you’d have to work backwards and really try to put-
Segment 3313: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3963, Text: … to the endpoint, then you’d have to work backwards and really try to put yourself in their shoes and try to understand what were their motivations macro. Most of the time, you have to assume that a leader’s primary objective was to stay in power. And so, all decisions made would be made through the framework of what it would take to do that and how it would impact their ability to do that.
Segment 3314: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=3982, Text: And then finally, I would just say that in any negotiation, you have to understand the power dynamics as well. And you have to then weight your approach in order to maneuver pieces to accomplish the objective. And so, in areas where we had stronger power dynamics, I’d always look at it and say, “What are the potential escape routes where a politician would say, ‘This is just the reason why we can’t get there.'” And I’d always think, how can you try to eliminate those escape routes or make them much harder to accomplish? And then, ultimately, think about what’s the golden bridge that you want to create for them in order to get to the other side, where they were motivated to get there because it was in their self-interest to get there, but also because it helped accomplish the different objective.
Segment 3315: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4027, Text: And I have many examples that I lived through with that, obviously negotiating in Congress for prison reform. I had to form a lot of trust with Democrats, whether it was Hakeem Jeffries or Dick Durbin. And then also on the Republican side with, I had Mike Lee, I had Lindsey Graham, I had Tim Scott, Senator Grassley, and then also Doug Collins in the house was tremendous. And every time we maneuvered something, we would get attacked either from the left. There was a time we were being attacked by Nancy Pelosi, John Lewis, for not being inclusive enough. And then there were times that we maneuvered it, we’d be attacked from the right for maybe going too far. And ultimately, we had to find just the right place where we can get it done.
Segment 3316: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4069, Text: And the same thing happened with USMCA, where we were negotiating the biggest trade deal in the history of the world, which was $1.3 trillion in annual trade between Mexico, Canada, the United States of America. And we were able to form good trust with the other side and try to say, “How do we create win-win outcomes?” And ultimately, we were able to do something in a record time that people thought was very hard to do. And both of them, in a divided time of the Trump administration, were bipartisan wins with big, big votes in the Senate and the House.
Segment 3317: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4103, Text: You have a lot of stories of this kind, sometimes a soft approach, sometimes a hard approach. I think the story where with Bibi, there was a potential, a dramatic election coming up, and you have to say, “No. No excuses, no delaying. We have to make this agreement.” I know Bibi cares about Israel more than the particular dynamics of the election. You had to draw a hard line there.
Segment 3318: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4126, Text: Yeah. But in fairness too, for him, during the time that we were dealing with him, he was always in election versus election, and then election. And what he was saying wasn’t wrong. And I think he was more expressing his concerns given the dynamics. And we never held those concerns against him, we just said those are real concerns he had. We respected those concerns. But then we helped him prioritize to help accomplish the right things.
Segment 3319: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4150, Text: And that’s ultimately what the partnership is, right? My job was to represent America, his job was to represent Israel, and you had other parties representing their own interests. And as long as you assume that people were acting mostly in good faith, you were able to navigate areas where you didn’t have complete overlap of priorities and objectives.
Segment 3320: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4169, Text: Just to go back to the trust thing, you sometimes see that with leaders, where it looks like they’re trying to screw over the other person when they’re talking. And so, not having that, I think is a really powerful thing for earning trust. That people actually can believe that you’re results driven and are working towards a certain end.
Segment 3321: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4191, Text: Is there a skill to that? Is that genetics, you’re born with that? Or is that something you develop? So basically, it requires you to look at the game of politics and not have a kind of cynicism about it, to where everybody’s trying to manipulate you. And actually just go in with a kind open mind and open heart and actually speak truthfully to people on a basic human level.
Segment 3322: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4217, Text: I would say that I always would think about how can I be a partner to others like I would want somebody to be a partner to me? And a lot of it comes from just my different experiences in business. I’ve had great partners, I’ve had terrible partners.
Segment 3323: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4231, Text: My father, again, a lot of my childhood was I was exposed to business. My father, on Sundays, he would take us to job sites and to the office with him instead of to football games like my friend’s fathers would do. And so, we were exposed to business. And what he would say about his father, who was an immigrant to America, came over with nothing, had no formal education, but he would always say, “A good deal with a bad partner will always be a bad deal. And a bad deal with a good partner, you’ll figure it out.”
Segment 3324: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4259, Text: And so, going through some of the challenges that I had in my life early on, whether it was the issue with my father, that I’m sure we’ll talk about, or even going through some tougher financial times during the Great Financial Crisis, I really learned a lot about partnership. And I always thought, “How can I act in a way where I could be the type of partner or friend to others that I wish others would be to me?”
Segment 3325: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4286, Text: So when you look for a good partner, don’t you think there’s the capacity for both good and bad in every person? So when you negotiate with all of these leaders, aren’t there multiple people you’re speaking to inside one person, that you’re trying to encourage, catalyze the goodness in the human?
Segment 3326: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4310, Text: Yeah. Leaders are generally chosen by their country. And so, my view was if I had an objective, I didn’t get to choose who was the leader of other countries. My job was to deal with that leader, understand their strengths, understand their weaknesses, understand their power dynamics as well.
Segment 3327: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4326, Text: One of my greatest takeaways when I grew up, I’d read the newspapers about all these powerful, famous people. And then as I got older and had the chance to meet them and do business with them and then ultimately interact with them in government, is I realized that they’re just like you and me. They wake up every morning, their kids are pissed at them, their wife doesn’t want to talk with them. And they’ve got a set of advisors around them, one saying, ” Let’s go to war,” one saying, “Let’s make peace.” One saying, “Do the deal,” one saying, “Don’t do the deal.” And they’re all thinking, where do I get advice? How do I make decisions?
Segment 3328: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4357, Text: And so, understanding the true human nature of them and then the different power dynamics around them, I thought was very key. And so, I didn’t have a choice, do I deal with them or not? It was a function of how do you deal with them effectively in order to find areas where you have common interests and then work well together to pursue those common interests in order to achieve a certain goal.
Segment 3329: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4381, Text: First of all, you’re incredibly well-read. I’ve gotten to know you and I’ve gotten to know Ivanka, and the book recommendation list is just incredible. So first of all, thank you for that. You told me about The Guns of August by Barbara Tuchman. It’s a book on World War I, and I went down a whole rabbit hole there. She’s an incredible historian.
Segment 3330: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4401, Text: But anyway, there’s a bunch of stuff you learned from that, but one of the things you told me is it influenced your general approach to diplomacy of just picking up the phone and giving it a try. So as opposed to planning and strategizing, just pick up the phone.
Segment 3331: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4419, Text: This was a book I read way before the notion of serving in government was ever even on my mind or a reality. And I remember thinking about it, reading it, and thinking how World War I started, where you had somebody was assassinated, and then you had all these different alliances that were created. And then in order to accomplish objectives, it triggered all of these people getting in bed with everyone else because of documents that were created without the intent of going to a massive war. And I think in the course of World War I, it was one of the greatest atrocities that we’ve seen as humanity. We’ve had 16 million people killed in that war.
Segment 3332: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4461, Text: And as I was reading the book, I remember thinking to myself, “Even though things are set in a certain way, go sit with somebody, go talk to them and say, ‘This doesn’t make sense, this is wrong. How do we create a better pathway?'” And as a civilian, all my life, I would read the newspapers, I would observe how different leaders would act. But when we had the opportunity to serve in government and have the position, you realize you’re not a civilian. You don’t have the luxury of sitting back and letting the world happen the way it’s happening. You have agency and you have the potential to influence the outcome of things.
Segment 3333: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4497, Text: And one thing I’ve seen is most political prognosticators are wrong. Anyone who tells you what’s going to happen really has no clue. And it’s not because they’re bad or they’re not intelligent, it’s because nobody knows. And at the end of the day, the outcomes in the world are usually driven by the decisions of humans. And if you’re able to come together, form relationships, listen to each other, you can do that.
Segment 3334: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4518, Text: And one of the great examples that I speak about in the book is with North Korea. Whereas if you remember in 2017, it was very intense. When President Obama was leaving office, he told President Trump that the single biggest fear that he had, and this is a time when the world was a mess, you had the Middle East was on fire, ISIS was beheading journalists and killing Christians. They had a caliphate the size of Ohio. Libya was destabilized, Yemen was destabilized. Syria was in a civil war where 500,000 people were killed. Iran was on a glide path to a nuclear weapon. Yet the single biggest fear he had was North Korea.
Segment 3335: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4554, Text: Then it got compounded by the fact that we get into office and President Trump brings his generals around and he’s learning how to interact with all the generals and says, “Okay, what are my options?” And they said, “Calm down. We’ve been using all of our ammunition in the Middle East. We don’t have enough ammunition to go to war over there.” And he says, “Let’s not let that be too public. Let’s try to restock and come up with a plan.”
Segment 3336: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4576, Text: And at the time, there was a lot of banter back and forth. And I was able to, I got a call from a friend who was an old business contact, who actually had done business in North Korea. And he said, “I’d love to find a way to solve this.” And I was getting calls from friends at the time saying, “I’m trying to go to Hawaii for vacation. Should I not be going? Is it not safe?”
Segment 3337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4597, Text: Wow.
Segment 3338: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4597, Text: We forget the psychology of how intense that was at the time. And then through that interaction, he called some of his contacts in North Korea. And then we were able, with the CIA, to open up a back channel that ultimately led to the deescalation, the meeting between Trump and Kim Jong-Un, which led to a deescalation.
Segment 3339: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4615, Text: So that was really the mindset, which was whenever there’s a problem, just pick up the phone and try. And I think President Trump had a very similar approach, which was let’s give it a shot. And he wasn’t afraid to go after the hard ones too.
Segment 3340: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4629, Text: And I’ll say one final thing on this, which is that in politics, the incentive structure is just much different than in the real world, in the sense that you have a hard problem. And if you try to solve a hard problem, the likelihood of failure is great. Whereas in the business world, if you’re going after a hard problem, we celebrate those people. Right? We want our entrepreneurs and our great people to go after solving the big, hard problems. But in politics, if you try to take on a hard problem, you have a high likelihood of failure. You’ll get a lot of criticism on your pathway to trying to accomplish that, if you fail. And then if you fail, it has a higher probability of leading to you losing your opportunity to serve. And so, it’s just one of these things where people want to play it safe, which is not the notion that really was taken during the time that President Trump was in office.
Segment 3341: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4679, Text: Do you think it has to be that way? I think there’s something in the human spirit, in the public that desires politicians to take on the big, bold problems. Right? Why is it the politicians need to be so afraid of failure?
Segment 3342: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4696, Text: I don’t think it has to be that way. And that’s, I think, one of the great lessons from the time of the Trump administration. He brought a lot of people from the business world into government. The business people have a much different mindset than government people, and there was a lot of resistance. And I think part of why there was so much resistance was because, I think about it from my personal sense, was that if I was successful with no traditional qualifications to do diplomacy, it meant that all the people with traditional qualifications and diplomacy didn’t necessarily need those qualifications in order to be successful. And that same sentiment manifested itself in many areas in government.
Segment 3343: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4736, Text: And I think that in the business world, it’s outcome oriented, it’s results oriented. And what we would see in New York is there, they would stab you in the eye, in DC they would stab you in the back, and it just became a whole different-
Segment 3344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4747, Text: God line.
Segment 3345: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4748, Text: … dynamic of how you work through these different areas. So the answer is, it doesn’t have to be that way, you just need the right courageous leader. And that’s why I’m so optimistic about what the future of America and the world could be if you have the right people in power who are willing to take on the right challenges and do it in the right way.
Segment 3346: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4767, Text: So if we just linger on the North Korea and the deescalation and the meeting, what’s the trajectory from this could be the most catastrophic thing that destroys the world, to you find back channels? Do you start talking and start arranging the meeting? Is there some insights you can give to how difficult that is to do? In that, in the North Korea case, which seems like to be one of the more closed off parts of the world. And any other cases that you worked on.
Segment 3347: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4796, Text: Yeah, it’s always very challenging. And especially when you’re going against the grain of what’s established, right? We did something different, to think that an old business contact that I had could then do it. That’s the type of thing that if the press knew what we were doing, they would’ve derided it and criticized it in every which way. But that was one of the benefits of operating very much below the radar, is that we were able to try all these different things. And not all of them worked, but some of them did.
Segment 3348: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4822, Text: But that is what’s amazing about the world, right? This could be the biggest story on the front page of every paper, and they’re inciting fear in everyone, and it’s not illegitimate fear. There were missile tests over Japan. You had a lot of very big challenges with that file. And then all of a sudden we make contact, we go through negotiations to set a meeting. There’s a meeting between President Trump and Kim Jong Un. And then all of a sudden, there’s a framework to try and move things forward. And again, I think that there’s a lot of possibility there for what could happen if it’s worked in the right way.
Segment 3349: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4856, Text: I just want to know how you word that first email or text message, what emojis do you use? Like the hugging emoji. It’s just personally, I’ve gotten to know a lot of powerful and rich people, and it’s funny that they’re all human, just like you’re saying. And a lot of the drama, a lot of the problems can be resolved with just a little comradery, a little kindness, a little just actually just reaching out.
Segment 3350: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4880, Text: We’re all human beings. And people want to be successful, and people want to be good. And you’re right too. There’s way more emojis involved in diplomacy than I ever would’ve expected.
Segment 3351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4889, Text: And every leader, I’m sure, has their favorite emoji. This is also I learned about people. Everybody has their go-to emoji. I usually go to the heart very quickly, emoji. There’s some people who go the hugging, whatever that, you’re like the hugging thing.
Segment 3352: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4904, Text: Anyway. This conversation quickly turned to the ridiculous. But to do another book reference, you mentioned the book Thirteen Days in September by Lawrence Wright, in discussing all the work you’ve done in Israel and the Middle East. I just want to ask you sort of the interesting aspect of that book, which is the influence of the personalities and personal relationships on these negotiations. You kind of started to allude to that with the trust, but how much do the personalities matter in this? So going from North Korea to the Middle East here, to within Congress and all that kind of stuff.
Segment 3353: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4940, Text: Yeah, completely in every way. That’s an incredible book, and it’s a very entertaining read. It has obviously a lot of good historical context on some of the key players, whether it was on Anwar Sadat or Menachem Begin or Jimmy Carter and Cy Vance, and a lot of the others who were involved with those negotiations.
Segment 3354: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4958, Text: And the thing that I kind of took from that experience was just how personal it was. And again, one of my favorite stories from that book was how Anwar Sadat, who was a big, big leader, he had a mystic who was, according to this book, again, history, I like reading it, but I always realize that you have to notice that this is just the perspective of a given author that’s writing it. But the way that they write this book was that he had an advisor who was a mystic, and the mystic was having a back channel with the Israelis. And the mystic told Sadat, “If you go to Israel and you make a speech at the Knesset, Begin is ready to give you the Sinai.”
Segment 3355: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=4994, Text: And so, he goes to Israel, they set this whole thing up, he goes and gives the Knesset. They go for their meeting after, and Sadat says, “Okay, well, are we going to do this thing?” And Begin says, “What are you talking about? I’m not giving you an inch of our land.” And it was just one of these things where it was a miscommunication that brought about the symbolic visit of Anwar Sadat to Israel. And that was one of these notions that just made everyone think that something was possible, that they thought was impossible a moment before.
Segment 3356: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5025, Text: And actually, we had an example like that during our time in government when we did the Abraham Accords. The first step of the accords was really a phone call between President Trump, Prime Minister Netanyahu, and Mohammed bin Zayed, who, at that point, was the Crown Prince and de facto ruler of the UAE. But all we had was a phone call and then a statement that was released.
Segment 3357: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5048, Text: And what was interesting after that is we said, “Okay, well, how do we integrate countries? Nobody’s done this in a long time.” And we were trying to figure out all the issues, and there was big miscommunications between Israel and UAE, and we were navigating through all the issues. And so, after a couple weeks, I said, “I’ve got to go over there and try to sort through these issues.” So we make a plan to go to Israel, and then we’re going to go to UAE.
Segment 3358: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5067, Text: And then a young gentleman who worked with me, named Avi Berkowitz, says, “Well, if we’re flying from Israel to UAE, instead of flying on a government plane, why don’t we see if we can get an El AL plane and we’ll do the first official commercial flight?” And so, I said, “That’s a great idea. Let’s call Ambassador Otaiba,” Yousef, who was a tremendous player in the Abraham Accords, working behind the scenes day and night, and was really a big catalyst. So he calls Yousef and he says, “Sure, no problem. Let’s give it a shot.”
Segment 3359: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5093, Text: So we go and we do it, and he says, “If we can work out these issues, what we’ll do.” So we go to Israel, we do our meetings, we get everything back into a good place. We set up this trip over, we fly on an El Al plane. We fill it up, at the time, it was during Covid, with a health delegation. We had the financial ministry because we had to open up banking relationships, they could wire money between countries. We wanted to get health partnerships. Then we just had a lot of legal things and national security things we wanted to start putting together.
Segment 3360: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5124, Text: So we do this flight and we end up landing in UAE. And the picture of us coming off the plane, being greeted by Emiratis in thobes, with an El Al plane with an Israeli flag on it, just captured everyone’s imagination. And so, it was one of these things where it’s like you work so hard on the details and the negotiation, hundreds of hours to make sure everything’s perfect, and the one thing that you do kind of, “Yeah, let’s give it a shot.” That image ended up capturing everyone’s heart.
Segment 3361: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5154, Text: So going back to Sadat, that visit was very critical. And what was interesting was is according to this book, it happened because of a miscommunication. That was the first part. The second part of the book, that’s just amazing theater, and actually the book was based on a play, it was just going back and forth with all of the different methodologies that they tried, that failed, but they kept trying at it. And then, ultimately, seeing how the personalities were able to find ways to make the compromise that ultimately was a very, very big thing for more stability in the Middle East.
Segment 3362: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5187, Text: And so, amazing book, I would highly recommend it. A very entertaining read and something that at least gave me encouragement to keep going when the task I was pursuing seemed so large.
Segment 3363: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5199, Text: If you could just linger on the personalities. You write in the book that words matter. Or you write in the context of saying, in the diplomacy business, words matter. And then you said that, “We’re in the results business,” is a badass line. But if we just stick to the diplomacy business and words mattering, it seems like one of the things you really highlight that individual words can really have… You can fight over individual words. So how do you operate in a world where single words matter?
Segment 3364: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5234, Text: I think you have to be respectful to the craft that you’re in, where words matter, but then realize that they don’t matter as much. And then also focus on the fact that the actions are actually what’s going to matter more than the words. And so, you have a difference between leaders and politicians. Politicians are there to say the right thing and to hold the power. Leaders are people who are willing to do things that will be transformational, from my perspective.
Segment 3365: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5258, Text: And so, when I would think about diplomacy, words without actions or without the threat of actions, and that was something that President Trump did very well, was that people knew that he was willing to take action, he was very unpredictable in how he would act. And that made our words much more effective in what they did. So it’s all a combination.
Segment 3366: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5279, Text: But coming from the private sector, we are all about results. If you’re in government, you can work on something for 10 years and fail and then retire, and they consider you an expert. In the private sector, if you work on something for 10 weeks and you don’t have a success, then you’re unemployed. So it’s a different kind of notion. And it was just understanding the mentality and trying to adjust and bridging the divides between the different trainings.
Segment 3367: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5305, Text: Is that the biggest thing you took from your business background, is that just be really results focused?
Segment 3368: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5311, Text: It was just the only way to be. If I was giving up a nice life in New York, and if I was giving up the stuff that I really enjoyed, the company that I’d helped build and the life that I was enjoying in order to do government, I was going there to make a difference and we had to focus on it.
Segment 3369: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5328, Text: The other skillset, so there was a couple skill sets that I found were quite deficient in government. First of all, there was a ton of amazing people. People talk about the bureaucracy. What I found was is you had incredibly committed, passionate, intelligent, capable people all throughout the government. And what they were waiting for though was direction and then cover in order to get there.
Segment 3370: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5352, Text: And so, there were a lot of tasks that I worked on, whether it was building the wall at the southern border, where I was able to work with Customs, Border Patrol, Army Corps of Engineers, military, DHS professionals, DOD, and we basically all came together. And then once we had a good project management plan, we were able to move very, very quickly. I think we built about 470 miles of border barrier in about two years, basically. And that worked very well because we basically brought private sector project management skillset, which we’re quite often missing in government.
Segment 3371: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5389, Text: The second one is just, we spoke about negotiation earlier. I would say that most people in government, it’s just a different form of negotiation than you see in the private sector, and way less effective in that regard. Which is why I think it’s good the more we can encourage more people with private sector experience to do a stint in government and to really try to contribute and serve their country. That’s how our founders, George Washington and all the founding fathers, they were working on their farms. They left their farms, served in government, then they went back to the farm.
Segment 3372: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5418, Text: And that was kind of the design of the representative government. It wasn’t a career political class, it was people coming in to show gratitude for the freedoms and the liberties that they enjoyed, and then do their best to help others have those same opportunities that they had, and then they’d go back and live their lives. So I think that there’s a lot of opportunity with our government, of people with more business mindsets who are going to think about things from a solutions perspective, go and serve.
Segment 3373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5448, Text: Is that one of the main problems here? So you also mentioned the book, the Great Degeneration by Niall Ferguson, an awesome historian. He’s been on this podcast. It helped you understand the inefficiencies of government regulation. I’d love it if you can give an insight into why government is so inefficient at times. When it is inefficient, when it doesn’t work, why is that the case? The bureaucracy that you spoke to, the negative aspects of the bureaucracy.
Segment 3374: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5477, Text: So we don’t have enough time on this podcast to go into it, but it’s… Look, there’s a lot of aspects that work as well. But I do think we’ve gotten too big. Niall’s book that you mentioned, one of the things that I took from that, I read it I think in 2012, right kind of in the middle of the Great Financial Crisis, was he was talking about how government regulation often was put in place to deal with old crises. It was never going to solve future problems, it was more to solve for problems that had happened in the past. And I remember thinking about that.
Segment 3375: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5508, Text: One thing I was very proud of, of the work of the Trump administration was that you had four years consecutively where there was a net decrease in the cost of regulations. So to give you a context, in the last year of Obama in 2016, there was 6 million man hours spent by the private sector complying with new federal regulations. And that’s not really what the intent of our government was, right? If we have rules or regulations, those should be legislated by Congress. They shouldn’t be put in by bureaucrats who are basically saying, “I want to follow this objective,” so using the power of the pen in order to do that.
Segment 3376: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5541, Text: So the deregulatory effort was actually very critical to Trump’s economic success that happened in the beginning of the administration. And then what I saw with regulation was anytime either there was legislation or regulation coming, the people pushing for it were usually the people who would benefit from the regulatory captures. You look at the Great Financial Crisis, where you had these big banking reforms. Well, what happened during the big banking reforms? Then you had a big reduction in the amount of banks that occurred, and the big banks became even bigger. Whereas I don’t think that was the intention of the legislation, but the people who were writing the legislation and influencing it had a lot of the constituencies from those larger institutions.
Segment 3377: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5581, Text: And then what happened as a result of that? A lot of these smaller institutions didn’t have the ability to be as competitive. They had more restrictions, more costs, they became less profitable. But these were the banks that were serving small business, which is the biggest creator of jobs in our country. And then as a result, the bigger banks got more powerful and what happened in the country as a result of the regulations that they put in place? The wealth gap in the country grew, it didn’t shrink.
Segment 3378: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5607, Text: And so, I think oftentimes what they say these regulations are intended to be, the result often becomes the opposite. And so, what President Trump did and his administration was they did a massive deregulatory effort. And I think they pledged that for every one regulation they put on, because you do need some regulation in an economy and in a society, they would take off two. And in the first year, they eliminated eight regulations for every one.
Segment 3379: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5634, Text: So that was just something I took from it, which was, I thought, very interesting. And you had to really, I think you just have to think through what are the consequences going to be of the different actions you take? And often, government gets it wrong by taking an action that feels right, but has big negative consequences down the road.
Segment 3380: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5651, Text: Let’s go to some difficult topics. You’ve wrote in the book about your experience with some very low points in government. You’ve been attacked quite a bit. One of the ones that stands out is the accusations of collusion with Russia. And you tell in the book, in general, this whole story, this whole journey, on a personal level, on a sort of big political level. Can you tell me some aspects of this story?
Segment 3381: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5679, Text: Sure. So to give the listeners some context, and people remember this now, it’s been kind of swept away because it turned out not to be true, was that after President Trump won the election in 2016, instead of the media saying, “Oh, we were wrong,” because again, everyone thought he had zero chance of winning. They said, “Okay, well, we couldn’t have been wrong. It must have been the Russians who worked with him.”
Segment 3382: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5703, Text: And so, at first, when this started coming up, I thought this was ridiculous. I was very intimately involved with the operations of the campaign. I was running the finance of the campaign. I was running the digital media of the campaign. I was running the schedule for the campaign. And I knew that on most days, we had trouble working, coordinating with ourselves, let alone collaborating with another government and colluding, as they called it. And so, we did a great job, I think, as an underdog campaign, very leanly staffed. And then they said that we were working with the Russians.
Segment 3383: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5738, Text: And so, at the time, I didn’t take it too seriously because I knew there was no truth to it. But it was amazing to me to start seeing all of these institutions, whether it was CNN, the Washington Post, New York Times, these were news organizations that I grew up having a lot of respect for, taking these accusations so seriously. And then working themselves up in order to just cover it for two years. Then as a result, you had a special counsel, you had a House investigation, a Senate investigation.
Segment 3384: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5767, Text: And I personally spent about, I think over 20 hours just testifying before these different committees. Again, spent millions of dollars out of my own pocket on my legal fees to make sure I was well-represented. And the reason I did that was because I saw in Washington, it was like a sick game. It’s almost like even though there was no underlying problems to the accusation, I felt like this is one of those things where they’re going to try to catch you. And then if you step on the line, they catch you with one misrepresentation, they’re going to try to put you in jail or worse. And so, for me, that was a big concern.
Segment 3385: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5803, Text: And it was amazing. My poor mom, I told her to stop reading whatever. I said, “Mom, I promise you, we didn’t do anything wrong. It’s good.” But she’d call me and say, “Well, our friends were on the Upper East Side, were talking with Chuck Schumer, says, ‘Jared’s going to jail. We know for sure that he colluded with the Russians.'” And this is a leading senator saying things like this.
Segment 3386: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5820, Text: And so, it was just interesting for me to see how the whole world could believe something and be talking about it that I knew, with 1000% certainty, was just not true. And so, seeing that play out was very, very hard. Obviously, I was accused of a lot of things. There were times in Washington, I was radioactive. I remember one weekend it was all over CNN, the people, they had panels on CNN, like the news organization that I grew up thinking was the number one trusted name for news in the world, talking about how I’d committed treason, because I met with an ambassador and said, “We’d like to hear your perspective on what you think the policy should be in Syria,” where there was a big civil war happening and ISIS, and a lot of different things.
Segment 3387: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5865, Text: So it was quite a crazy time in that regard. But luckily, again, we were able to fight through it. It was a major distraction for our administration. And I think we were able to kind of stay focused on the objectives and the policies. But it was a crazy time, and I learned a lot from that experience.
Segment 3388: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5880, Text: It’s crazy how just an accusation can be viral and can just go. One of the things that worries me is the effect on your mind, the psychology of it, to make sure it doesn’t make you cynical. People that are trying to do stuff, those kinds of stories that can destroy their mind. So one of the things I’d love to sort of understand, you, who kind of rolled in from the business world, and all of a sudden, the entire world, from CNN to everybody’s accusing you of colluding with the Russians. When you’re sitting at home, how do you keep a calm mind, a clear mind, an optimistic one, that doesn’t become cynical and actually just keep trying to push on and do stuff in the world?
Segment 3389: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5919, Text: Yeah. It was a surreal experience. I would say number one is I felt very confident that I hadn’t done anything wrong. So I’d always tell my lawyer, “The good news is I’ve got a good fact problem.” I need a good lawyer to get me through it, but it’s much easier to be a good lawyer if you have a very innocent client. And so, the fact that I knew that I didn’t believe that I had any legal liability helped me kind of-
Segment 3390: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5943, Text: … That I had any legal liability helped me intellectually separate the challenge I needed to do to fight through it, from it. And then I just basically said I’d had hardship earlier in my life where I dealt with the situation with my father. And what I realized there is that you can’t really spend energy on the things that you don’t control. All you can do is spend your time and energy worrying about what you can control and then how you react to the things that you have there. And so it took a lot of discipline, it took a lot of strength. And again, I give my wife Ivanka and even Donald, a lot of credit for having my back during that time and encouraging me just to fight through it.
Segment 3391: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=5982, Text: And then I also had to make sure that I didn’t allow that to distract me from my job. I felt like I had an amazing opportunity in the White House to make a difference in the world. And if I would’ve spent all my time playing defense, in politics, it’s a time duration game. In business, you have whatever duration you set for yourself, in politics, it’s time duration. We had four years. Every day was sand through an hourglass. My mindset was, I need to accomplish as much as I can in these four years. And I guess the traditional game that’s played in Washington is whether it’s the media, the opposition, their job is to distract you and then try to stop you from being as successful as you want to be. And so just fought through it.
Segment 3392: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6019, Text: And it wasn’t always fun, but we got through and thank God it’s something people don’t talk about. And it has been amazing to me just the lack of self-awareness and reflection of a lot of the people who hyped this up for two years. They don’t think there was anything wrong with it. And that’s interesting, but my view is, we got through it, it’s good. So it’s in the past and then I started moving to the future and that’s really where I spent my time.
Segment 3393: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6046, Text: Yeah. But I want to linger on it because to me, that has a really discouraging effect on anyone who’s trying to do positive in the world. These kinds of attacks are intense. You say one of the lessons you learned is that you really have to be perfect, but I hate that to be the lesson. I feel like you should be able to do stupid stuff, take big risks, and people celebrate the big risks and not try to weave gigantic stories over nothing. I just want to understand the two aspects of this, how to not have such stories of so much legs, and the other is how to stay psychologically strong? So you waved it off that you didn’t have a fact problem, but it can just have a effect in your psyche. You seem to be pretty stoic about the whole thing, but just on the psychology side, how did you stay calm and not become cynical where you can continue to do stuff and take big risks?
Segment 3394: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6107, Text: I didn’t have a choice.
Segment 3395: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6108, Text: What do you mean?
Segment 3396: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6109, Text: I mean I could have spent every day feeling sorry for myself or complaining or saying things aren’t fair. But the general way I looked at it was that in life, every opportunity has a cost. And you could look at it and say maybe this was a massive cost, either in dollars or in time or in reputation or in emotional drain. But you could also say that I had an opportunity to work in the White House and I had an opportunity to work on some of the hardest challenges. And you talk about how that’s not celebrated, that is something very different. In the private sector, when you take on big challenges, that is celebrated. In government, when you take on big challenges, people want to see it fail or they want to criticize those people who are trying to take that on. And I think that’s wrong.
Segment 3397: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6153, Text: And I think that as a country, we should be thinking big. We should be dreaming big, and we should be encouraging our politicians to try and to fail more and to go to take on big things knowing that there’s risk of failing. Obviously, we want them to succeed, not to fail, but let’s take on the big things. Let’s try to do that. So I think it’s just very basic that you’re in a situation. I’ve made decisions. I can’t go back and change decisions in the past. I still felt very blessed to be in the position I was in, and I knew that I just had to work through it. Like I said, I was very lucky to have support from my wife and from my family and from good friends.
Segment 3398: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6189, Text: Again, I think I’d chosen very good friends in life and my friends were with me. I had one friend who, my lowest moment, got on the plane, he lived in Arizona, got on a plane and came just to have dinner with me to say, “Just pick your head up. I know you’re down now, you’re going to be fine. Just fight through.” That meant a lot to me. And again, I always think in my life, you don’t learn as much from your successes. You don’t learn as much from your high points. You learn the most about who you want to be and how the world works from your lowest moments. And at those lowest moments, it made me better and it taught me how to be a better friend to people who are in tough situations. And I tried to just get tougher and I tried to just get better and work through it.
Segment 3399: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6230, Text: Yeah. You said that you and Ivanka, this intense time brought you two together and helped you deal with the intensity, with the chaos of it all.
Segment 3400: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6241, Text: So I think it was just number one, knowing that you had a partner and knowing that you had somebody who loved you and believed in you. I think that was definitely by far the biggest of anything. And-
Segment 3401: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6250, Text: Love is the answer.
Segment 3402: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6252, Text: Love is very important. But then there’s also a lot that I’ve learned from her always getting me to read different books or learn different things, which I love. But she’s also, I think, an amazing role model. And I go through our time in Washington where there were so many people who were, I thought, very nasty to her, unfoundedly. And I’m not talking about individually because again, most people who interacted with her were super kind. But I would see people on Twitter or different places go after her and she always stayed elegant and I felt like that was something that she never stooped down to a lower level. She kept her elegance the whole time and she really went to Washington wanting to be a force of good. And I see all the time that she follows her heart, she does what’s right and she has a very strong moral compass. And I feel very lucky to have her as a partner. And I respect her tremendously.
Segment 3403: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6308, Text: Yeah. She walks through the fire with grace, I would say. And she’s recommended a bunch of amazing books to me and she has an incredible, fascinating mind. But one thing that jumped out to me is you both love diners, Jersey diners. So I lived in Philly for a while and I traveled quite a bit and traveling from Boston down to Philly, maybe to DC, you can drive through Jersey. It’s something about Jersey. I don’t know what it is.
Segment 3404: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6335, Text: It’s the best. It’s the best.
Segment 3405: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6336, Text: You listen to Bruce Springsteen. Louis C.K has this bit where I think it’s part of criticizing cell phones today where people are too much on their phone. They don’t just sit there, be bored, but he uses that story to tell where he’s just driving and Bruce Springsteen’s song comes on and he just wants to pull over to the side of the road and just weep for unexplainable reason. I think that’s true because life is difficult. Life is full of suffering or struggle or challenges. So sometimes, it’s always Bruce Springsteen, but some song like this can really make you reflect on life, that melancholy feeling. But that melancholy feeling is the other side of the happiness coin where, if you just allow yourself to feel that pain, you can also feel the highest joys. That’s the sort of the point Louis C.K makes.
Segment 3406: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6389, Text: And there’s something about Jersey with the diners, often late at night… There’s several diner experiences I should say. There’s the family friendly, there’s a nice waitress and there’s a sweetness, a kindness like hello sweetheart, that kind of thing. There’s also the 3:00 AM diner, the ones that are open 24 hours, that has a romantic element when you’re a young man or young woman, you’re traveling. The loneliness of that, it’s all of it. The American diner is from Jack Kerouac on, represents something. I’m not sure what that is, but it’s a real beautiful experience. And the food itself too.
Segment 3407: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6429, Text: Oh, always fresh. Yeah. The thing with diners, there’s so much to love about it. And I grew up, obviously in New Jersey, when I’d go with my father to business, he’d always stop. We’d eat at a diner. Late night I’d be come back with my friends, we’d stop at a diner. And it’s a tradition that Ivanka and I love doing as well. And I think there’s a notion of it’s very egalitarian in that people from all places are there. You could order basically whatever you want. The menus at the diners look like the phone book.
Segment 3408: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6458, Text: Yeah, it’s great.
Segment 3409: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6458, Text: And it’s amazing how they keep so much fresh ingredients to do it, at least the good ones do. I love as a jersey guy, that you get mozzarella sticks and an omelet at any hour of the day because most of them are open 24 hours. And that’s basically my Ivanka, my go-to, we’ll throw in a milkshake or two as well. But for me as a kid, my father would take me, sometimes I’d sit with him in the meeting, sometimes I’d be at the table next to him. He’d give me a bunch of quarters to put in the music machine that they would have on the wall. And it was always just a great experience doing it.
Segment 3410: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6488, Text: I joke that if you grew up in Jersey, you grow up with just enough of a chip on your shoulder that you have to go and make something of yourself in life. It’s a special place. I had an amazing childhood there and very, very proud to be from the state. And I will just give a little bit of a plug now because the state has now actually turned the corner and they had a $10 billion budget surplus for many years. It was a state that was basically bankrupt and now actually under a pretty progressive Democrat governor Phil Murphy. He’s turned the state around and it’s actually has a very bright future ahead and it’s probably one of the best places to raise a family in the country. It’s got very low crime, one of the best public school systems in the country, pretty good healthcare system, a lot of green parks. People know the Turnpike, but it’s got a lot to it. That’s really great. So I’m a big, big fan of Jersey.
Segment 3411: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6537, Text: I like how this is a first for this particular podcast, you literally gave a plug to a state. So New Jersey everybody.
Segment 3412: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6546, Text: It’s where it’s at.
Segment 3413: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6547, Text: There’s South Jersey there’s North Jersey. There’s all kinds of Jerseys too. The whole thing, it just…
Segment 3414: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6552, Text: And don’t get me started on the Jersey Shore, Lex.
Segment 3415: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6556, Text: Jersey Shore is a whole thing.
Segment 3416: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6557, Text: And I’m not talking about the Snooki part, I’m talking about the real nice parts, really great food, great people.
Segment 3417: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6561, Text: What do you mean nice parts? It’s all beautiful. The full range of human characters that are in New Jersey are all beautiful.
Segment 3418: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6569, Text: I agree with that.
Segment 3419: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6570, Text: And every time I travel across the world, there’s always to meet somebody from New Jersey and you give a nod of a deep understanding. It’s the cradle of civilization in many ways. Okay, so back, I don’t know how we got there. Oh, all right. Going back to the low points, you mentioned your father, if we could just return there. Even just the personal story of your father that you write about, all the betrayal that happened in his life and then how he responded to that betrayal and he was after that arrested. Can you just tell the story?
Segment 3420: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6605, Text: Sure. So my father is an amazing person and we grew up in New Jersey. My father was a big developer, a great entrepreneur, built an amazing business. He got into a dispute with two of his siblings and through that dispute, they basically took all of the documents in his company, went to the US attorney’s office and turned from a civil dispute into a real public dispute. My father did something wrong in that process. And when he got arrested for that, he basically said, “You know what? What I did was wrong.” And he took his medicine and he did it like a man. And he said, “I’m going to go to prison.” And he did that for a year. And so for me, that was a very challenging time in the family. Obviously, it was a shock. It was a total change.
Segment 3421: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6657, Text: My childhood was I think, a very nice childhood. My parents always said, “Do good in school, work hard.” I was very focused on my athletics. I was captain of the basketball team, assistant captain of the hockey team. I ran a marathon with my father and it was always about pursuing. Went to Harvard, graduated with honors, and then was in NYU pursuing a law degree and a business degree. And I was working at the Manhattan District Attorney’s office at the time actually thinking I wanted to go into public service because my father always taught us, we were always surrounded by politicians and he always said, ” My parents came to America. They lived in the land of opportunity and they had these opportunities because this is the best country in the world. So you should be successful. Work hard, don’t ever let your opportunities become your disadvantages because you have advantages in life. You have to work harder.” And that’s what he instilled in myself and my brother. And he always pushed us to make the most of ourselves. And when we did that…
Segment 3422: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6717, Text: Everything changed overnight when my father got arrested. Obviously it’s very embarrassing for a family when you’re on the front page of the papers, I would see the newspapers writing all these things about my father that I didn’t think were representative of the person that I knew. It was a big change for our family. And I was angry. I was angry. I said, “I could be angry at the prosecutor, I could be angry at my father’s brother. I could be angry at my father’s lawyers. I could be angry at my father for making this mistake.” And then I said, “That’s not going to change anything.” And I had a real shift. And I do think that that was a turning point in my life where I basically said, “Let me focus on the things I can control. Let me focus on the positive things I can do.”
Segment 3423: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6762, Text: And from that moment forward, I said, “How can I be a great son to my father? How can I be a great older brother/substitute father for my two sisters and my younger brother? How could I be there for my mother? How could I be there for my father’s business?” And I just went into battle mode and I put my armor on and I just ran into it. And for the next two years, every day was painful. I was dealing with banks, the company still had subpoenas, I was still in law school. I’d tell my father I wanted to drop out of law school and business school, but he said, “Please don’t.”
Segment 3424: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6792, Text: So I would basically go to law school one day a week or maybe I’d skip it most days and I’d go to his office every day. And my friends would joke that if my professors wanted to fail me, the law professor would have to give me a test that had four pictures and say, “Circle who your professor is.” But I would basically take a week off, I’d read the books and I did well and I got my degrees. And it was just a very, very challenging time.
Segment 3425: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6814, Text: But like I said to you before is that you learn the most about life and you learn the most about humanity and yourself when you’re in your most challenging periods. And I’ll say that that experience also changed the people I interacted with, spending weekends with my father down in a prison in Alabama, I met the other inmates, I met their families. I spent time then trying to advise the children of other people who were going through the same experience that I’d gone through on how to navigate it correctly. And you just learn a lot about the world and you see that in life, everything could get taken from you, your status, your money, your friends. I saw that certain people were very disloyal to my father at the time, who he thought were friends. It was only a handful. But again, I learned from those people, how can I be a true friend to people? How can I be better? And I learned a tremendous amount through that experience.
Segment 3426: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6869, Text: You write that your father told you about being humble. I’d love to ask you about this, that in life sometimes we get so powerful that we start to think we’re the dealers of our own fate. We’re not the dealer’s, God is the dealer. Sometimes we have to be brought back down to earth to get perspective on what is really important. What do you think he meant by that? What did you learn from that experience?
Segment 3427: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6891, Text: The way I interpreted it at the time, and those were very, very memorable words, and it occurred… After I picked up my father from the arraignment. I drove him down. I drove the car and my father and I are very, very close. And he didn’t say a word for the whole time. And I think he was processing number one, what was happening to him. And I couldn’t even imagine. But I actually think the bigger pain for him, because my father is such a committed person to the family, is like, did I let my family down? Did I let my kids down? And I do think he felt that that moment like his life was over. He couldn’t really see past what this challenge was going to bring and if there would be a life for him after it. So I could see that he had a lot of fear and he really wasn’t saying much. And then I didn’t know what to do.
Segment 3428: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=6936, Text: And so I just stood by him and stood close. And later that day or the next day, he got up and started walking. He had an ankle monitor. For whatever reason, the prosecutor was so aggressive that he was a flight risk, so they made him wear an ankle monitor. They were very, very aggressive and nasty. And at the time, my father was the biggest donor to Democrats. The prosecutor was a Republican. It was a very political thing. And what happened was is he was walking around the pool and I just started walking with him and he said to me, “Jared, in life sometimes, we get so powerful that we believe that we’re the dealer.” He says, “But we’re not the dealer. God’s the dealer. And we have to come down to earth to understand,” like you said. So what I took from that was that my father, with all of his success, had started to believe that maybe certain rules didn’t apply to him. And I think that that’s where he made a mistake. And I think he had a lot of regret that he made the mistake. And my father is a very humble person. He’s a very moral person. For me, with my humility, my brother and I joke that we give our credit for being humble, number one, to being Mets fans because every year you have a lot of promise and then it never ends up paying off. Although now with Steve Cohen, hopefully we’re on a different trajectory.
Segment 3429: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7009, Text: But the other thing is also our mother. Our mother really raised us to be very humble. We knew we had a lot, but every Sunday morning my mom was there clipping the coupons. The cereal we ate in our house was based on was what was on sale versus what we liked. When we would have a problem with our teachers in school and I’d say, “Well, teacher doesn’t like me.” She’d say, “Well, I’m not calling them. It’s your job to make the teacher like you.” And so my mother gave us a lot of that. My father gave us a lot of the grounding. And I think during that time, my father was just realizing that maybe he had gotten disconnected from the grounding and the values.
Segment 3430: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7052, Text: And again, I think he also accepted maybe he could have blamed others for acting inappropriately. But I respect the fact that he took responsibility himself and said, “I can’t control the actions of other people. I can’t control what they do is right and wrong. I can just control my actions.” And as I go on the next journeys in my life and I go to government, I go to Washington. I even think through the craziness of going from visiting my father in a prison to 10 years later sitting in the office in the White House next to the President of the United States. And I think about that story and that it’s a story that only God could write. And I really believe that you have to have a lot of faith because the lows and the highs are both so extreme and unbelievable that I feel like those low moments in some ways, allowed me to keep my grounding and to understand what was truly important in life for when I ended up going through those other moments.
Segment 3431: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7108, Text: Your father was betrayed, perhaps over money by siblings. Is there some deeper wisdom you can draw from that? Have you seen money or perhaps power cloud people’s judgment?
Segment 3432: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7121, Text: Oh, 100%. 100%.
Segment 3433: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7123, Text: Is there some optimistic thing you can take from that about human nature of how to escape that clouding of judgment when you’re talking about leaders, when you’re talking about government, even business. Because you mentioned there’s a power dynamics at play always when you’re negotiating. Is there a way to see the common humanity and not see the will to power in the whole thing?
Segment 3434: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7153, Text: Definitely. You mentioned about power, money corrupting. There’s a great quote I heard a friend of mine say, is a guy Michael Harris, who was one of the founders of Death Row Records, and he was being interviewed recently and they asked him about what happened with Suge Knight. And his line was, ” Money just makes you more of what you already are,” which I thought was a very elegant way of saying it. And I would see this time and time again in the White House where you had people who were now given a lot of responsibility and power and it went to their head and they acted very crazily and maybe didn’t act in a way that I thought was always conducive to the objective.
Segment 3435: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7193, Text: So I think it’s a very big problem that you have, whether it’s something that’s solvable, I think it’s about having the right leaders and hopefully for the leaders, having good friends. I’m still friends with a lot of the people I interacted with when I was in government, and the number one thing I try to be to them is just a good friend. I try to be somebody who they can talk about things with. I don’t go in trying to tell them what to do on different things. And I think that that’s a big thing is that people just need friends and they need conversation. And if they have that, then hopefully, that allows them to keep their head in the right place.
Segment 3436: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7228, Text: I think this is a good place to ask about one aspect of the fascinating work you’ve done, which is on prison reform. Can you take me through your journey of helping the bipartisan bill get passed. Just working on prison reform in the White House in general, how you made that happen, how you help make that happen?
Segment 3437: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7247, Text: Sure. So we passed a law called the First Step Act, which was the largest prison and criminal justice reform bill that’s been done maybe in 30, 40, 50 years in the US. And so what it basically did was two things. Number one is it took the prison system and it took a certain class of offenders and allowed them to become eligible for earlier release if they go through the certain trainings that will allow them to have a lower probability of going back. Stepping back, you look at the prison system, you say, “What’s the purpose? Is it to punish? Is it to warehouse? Is it to rehabilitate?” And I do think that we’re a country that believes in second chances. I saw firsthand when my father was a client of the system, how inefficient it was and how much better it could be.
Segment 3438: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7296, Text: And when my father got out, we didn’t run from that experience. He started hiring people from Rikers Island and different prisons into the company into a second chance, a program, which we’re very, very proud of doing. And what we saw through our micro experience was that if you give people mentorship, if you give them job training, a lot of people, they have addiction issues and they can’t find housing. And so people leave prison with a criminal record and they’re less likely to go back and reintegrate in society without help from different institutions that can help them do that. So we modeled the reforms off what they did in Texas and Georgia and other states where they basically put a lot of job training, alcohol and addiction treatment programs in the prisons as a way to incentivize the prisoners to work on themselves while they’re there in order to allow them to reenter society.
Segment 3439: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7352, Text: It’s turned out to be very successful so far. They just had a report that showed that the general population has had a 47% recidivism rate, meaning that people who leave federal prison, half of them go back. And people who have now taken this program, only 12% of them go back. So number one, you’re making communities safer because if people are going to now get a job and enter society instead of committing future crimes, you’re avoiding future crimes. And number two, you’re giving people a second chance at life. And so that was the first part of it. The second thing we did was there was a rule passed in the ’90s that basically penalized crack cocaine at 100 times the penalty of what regular cocaine was. And I think a lot of the motivations, what people say in retrospect was that crack was more of a black drug drug and cocaine was more of a white drug.
Segment 3440: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7402, Text: And so there was a really racial disparity in terms of what the application of these sentences were. So they then revised that to make it 18 to one. And what we did in this bill is we allowed it to go retroactive to allow people who were in prison with sentences under what we thought was the racist law to be able to make an application to a judge in order to be dismissed. And it was based on good behavior, being rehabilitated and the fact that they would have a low probability of offending in the future. And so that was really the meat of it. And there was a couple other things in there we did as well, which were also quite good. So we did it. Worked very closely with the Democrats, Republicans to do it. At first, President Trump was a little bit skeptical of it because he’s a big strong law and order supporter, but he made me work very hard to put together a coalition of Republicans and Democrats and law enforcement.
Segment 3441: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7455, Text: We had the support from the policemen, we had the support from the ACLU and ultimately, we were able to get it together. And it was an amazing thing. We ended up getting 87 votes in the Senate. This happened for me at a time while the Russia investigation stuff was still happening. New chief of staff came in, John Kelly, he basically marginalized me in the operations. So I had less day-to-day responsibilities in the White House. And so for me, this effort became one of my full-time efforts along with negotiating the Mexico trade deal and along with the Middle East efforts. And the reason why that was great was because it didn’t have a lot of support from the Republican caucus originally, and people thought there was no way it would happen. So I really was able to be the chief executive, the middle executive, the low executive, the intern.
Segment 3442: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7506, Text: And through that process, I really got an education on how Congress works, on how to pass legislation. I was negotiating text, I was negotiating back and forth, and I built a lot of trust. Again, I would deal with whether it’s Hakeem Jeffries or Cedric Richmond, that we built a lot of trust. We’d speak three times a day. These guys had my back, the ACLU. Again, I never thought they were suing our administration every day or every other day on something. But for whatever reason, we built trust and we’re able to work together. And then also with the real conservative groups because there was a big part of the conservative base that felt like we should be giving people a second chance. And in addition to that, this will keep our country safer and it’ll reduce the cost of what we spend on prisons. And so it was a great effort and I was very, very proud that we were able to get it done under President Trump.
Segment 3443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7553, Text: How’d you convince the Republicans? So they were skeptical at first? Are we talking about just phone conversations? Going out to lunch? Just back to the emojis or what?
Segment 3444: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7563, Text: Hand to hand combat, meetings. The cool thing about this… I always get frustrated when I hear a lawmaker say, “Oh, the senate’s not what it used to be, or Congress isn’t what it used to be. Things are broken today.” I don’t think that’s true. I think going through the process, I think that our founders were totally genius in the way that they designed our system of government. And what I saw is you just have to work it so everyone knows the power of their vote. Some would give it to me easily, some wouldn’t give it to me easily. Some would trade it for other things, some would withhold it because they were pissed about other things and it was just hand to hand combat. So it was just making calls using the phone, walking the halls, going to lunches, hosting dinners at my house. It was a nonstop lobbying effort. And by the way, it was also adjudicating issues and making people feel like they were heard, hearing their issues, and then trying to find solutions that you don’t put something in that then tips off where you lose a whole coalition.
Segment 3445: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7618, Text: So it was really a balancing act, but it was an amazing thing and I worked very closely on that with Van Jones and Jessica Jackson, who also gave me a lot of help on the left. And it was an amazing thing. Had a great team too.
Segment 3446: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7631, Text: So you mentioned the importance of trust at the very beginning of the conversation. From the outsider perspective, just maybe a dark question, which is, how much trust is there in Washington? The flip side of that, how much backstabbing is there? Can you form long-term relationships with people on a basic human level where you know you’re not going to be betrayed, screwed over, manipulated for again, going back to the old money and power?
Segment 3447: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7668, Text: The answer is yes, and the answer is no. So I made some incredible friends, lifelong friends through my time in Washington, but the way I think about it from politics and I think in geopolitics as well, is I would say that politicians really don’t have friends. Politicians have interests. And as long as you follow that rule, you should be able to know how to rate where your relationship with a given person falls in the spectrum. But I do think I was the exception. I did make some tremendous friends. And again, I’d go back to what I said about negotiation where, when you’re in a situation where there’s really nothing in it for any of you personally, but you’re in a foxhole together and nobody in Washington can get anything done by themselves. So you have people coming from all different backgrounds, all different experiences, all different geographies coming together, agreeing on an objective, creating a plan, and then every day rowing together in order to get it done. It’s a beautiful thing and you really learn what people are about.
Segment 3448: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7728, Text: And so when you go through an experience like that, you learn who’s in it for themselves. You learn who’s in it for the cause and for every thing you read about in the press of a fight I had with somebody because we were at odds. I have about 100 people who have become lifelong friends because I respect the way that when we were under fire together, they got better, they were competent, and they were there to serve for the right reason.
Segment 3449: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7751, Text: And so I guess the answer is yes, it is possible. You have to be careful because there are a lot of mercurial people there. I always say the politicians are like gladiators. I didn’t have as much respect for politicians till I got there. But if you think about it, everyone who’s got a congressional seat or a senate seat, there’s 25 people back at home who want their job, who think they’re smarter than them, who are trying to back stab them. And so I always say that the political dynamic, it’s like in the private sector, you’re standing on flat ground. You choose which fights you take on. When you take them on, how you fight them.
Segment 3450: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7786, Text: In politics, it’s like you’re standing on a ball and what you have to realize is that there’s maybe 10 things that you have to do, but there’s a potential cost to taking on each one that might destabilize you. You fall off the ball and then you lose your opportunity to pursue those. You have to always be marking everything to market and going through your calculations to make sure you can accomplish what you want to without falling off the ball and losing your opportunity to make a difference.
Segment 3451: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7814, Text: I guess people like power and I just feel like to be a good politician, good meaning, good for humanity, be willing to let go of power. Try to do the right thing. If there’s somebody back home that does manipulate stuff, screws you over and takes power from you, it’s okay. I feel like that kind of humility is required to be a great leader, and I feel like that’s actually a good way to have long-term power because karma has a viral aspect to it. Just doing good by others, I feel like is-
Segment 3452: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7853, Text: I’d like to say that’s true, Lex. I think it’s just way more complicated. You look what happened this week with Kevin McCarthy, right? He did what he thought was morally right. He thought he did a bipartisan deal. He was told that they would have his back, and then the moment things got tough, they cut him loose. So again, I don’t know if that was the right thing or the wrong thing, right? I’ve also seen leaders on the other end say, “I’m going to do things that are short-term, more selfish.” But the way they justify it to themselves is to say, “I believe that myself staying in power is existential to the greater good. So I will do things that maybe are not in the greater good now because I believe that my maintaining power is.” And so it’s complicated. In an idealized world, I’d love to believe that’s the case, but it’s just way more complicated than that.
Segment 3453: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7906, Text: Yeah.
Segment 3454: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7908, Text: I wish it wasn’t, but it is.
Segment 3455: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7910, Text: Yeah. I do just wish people in politics zoomed out a bit and just ask themselves, what are we all doing this for? Sometimes you can get a little bit lost in the-
Segment 3456: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7923, Text: You know sometimes you can get a little bit lost in the game of it. If you zoom out you realize integrity is way more important than little gains in money or little gains in power in the longterm just when you look at yourself in the mirror at the end of the day. And also how history remembers you, I just feel like people do some dark stuff when they’re in that moment when they’re losing power and they try to hold on a little too hard. This is when they can do really dark things like bring out the worst in themselves. It’s just sad to see, and I wish there was a kind of machinery of government would inspire people to be their best selves in their last days versus their worst selves.
Segment 3457: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=7969, Text: When that system gets invented, you’ll share with me what it is, but it’s… Look, let me give you another way to frame it, which is, and this was kind of the revelation we spoke before about when I was getting my butt kicked by the Russian investigation and all the different areas. But the basic framework I looked at was I said, “Okay, this all feels tough.” But I said, “The game’s the game, the game’s been here way longer, but way before I came, and it’ll be here way long after I leave, and so I have two choices. I can complain that the game’s tough, it’s not fair, it’s not moral, or I can go and I can try to play the game as hard as possible.” And I think that there’s two different things. You have people who are willing to kind of sit in the stands and they’re willing to yell at the players or make their points known, or you have people who are willing to suit up and get in the arena and go play.
Segment 3458: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8020, Text: And I have a lot of respect for the people who suit up and go play. Again, some of them I wish they would play for different means, but the fact that they’re willing to put their name on the ballot, make the sacrifice, and go put on the fads and get hit and hit others, I think that you need those people. And I wish more people who had maybe the moral wiring that you discussed would be putting on a helmet and going to play because it’s hard. It’s hard.
Segment 3459: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8044, Text: I agree with you. I just would love to fix the aspect of the Russia collusion, accusation, the virality, the power of that, because that’s a really discouraging thing for people. Maybe it’s the way it has to be, but it seems like a disincentive to people to participate.
Segment 3460: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8060, Text: It is, but I’ll give you, again, an optimistic side of it is that what you’re seeing now with social media is I do think with what’s happening at X, there is now more of a reversion towards more egalitarian and egalitarianism of information. And so for many years the media publications were the gate holders, they were the gatekeepers, and then you had these social media companies that grew. They became so powerful, but then they were tilting the scales. Why they were doing it, we can go through long explanations for that, but if there truly is a real forum and a democratization of information, then you would think that the marketplace of ideas would surface the real ones and discredit the non-real ones. And I think that as a society, we’re starting to kind of come to grips with the fact that the power dynamic is changing and that some of these institutions that we used to have a lot of faith in don’t deserve our faith. And some of them will actually reform and maybe re-earn our faith, so I think that there could be an optimistic tone.
Segment 3461: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8122, Text: Again, the years of Trump, I think that he was an outsider and he represented something that was existential to the system. You think about for the 30 years before you were either part of the Clinton Dynasty or the Bush dynasty. I think a lot of people in the country felt like that whole class, whether you’re wearing a red shirt or a blue shirt, wasn’t representing them and Trump represented a true outsider to that system. I do think that as he went in there, there was a lot of norms that were broken to try to stop him from changing the traditional power structure. So I think that we’re at a time where maybe there will be an optimistic breakthrough where you’ll have institutions that will allow for a lot more transparency into what truth really is.
Segment 3462: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8172, Text: I’d love to go back and talk to you about the Middle East, because there’s so many interesting components to this. Let’s talk about Saudi Arabia, and first let me ask you about MBS, Mohammed bin Salman, the Crown Prince. So you’ve gotten to know him pretty well, you’ve become friends with him. What’s he like as a human being? Just on a basic human level, what’s he like?
Segment 3463: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8192, Text: So for the listeners, Mohammed bin Salman is now the Crown Prince of Saudi Arabia. He has risen to that position over the last couple of years and he’s been a tremendous reformer for the country. He’s gone in and he’s really modernized the economy. He’s put a lot more investment into the country. He’s marginalized the religious police and he’s really done a good job to bring modernization, a lot of reform. So he is been a great reformer. What he’s like as a person is he’s very high energy. He’s got tremendous candor power, very, very smart, incredibly well-read.
Segment 3464: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8230, Text: When he was younger, his father would give him a book a week and make him report on it on the weekend. He was trained as a leader and as a politician, really, by his father. He’s not western educated, so he grew up in the Saudi culture and he’s a real Saudi nationalist. He loves their history, loves their heritage, has a steep understanding of the tribal nature of the region. His father was actually known to be a tremendous politician, so when he was governor of Riyadh, people who I speak to today about him say that if they had a full election, he would’ve won in a landslide. They say every time somebody went to the hospital, he was the first person to call. Anytime there was a funeral, he was the first person to show up. He’s a very, very beloved leader.
Segment 3465: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8277, Text: Mohammed bin Salman, he was a businessman before he got into Crown Prince. So he thinks really with a business mindset about how he runs the country, and he’s brought I think a different mindset and energy to the Middle East. One thing I’ll say that maybe that comes to mind here is that I remember early on talking with him about all the different initiatives he was taking on. He’s building a big city called Neo in the desert in a place where there really was nothing on the Red Sea, and a lot of people were criticizing the ambition of the plan. And I was sitting with him one night and I said, ‘Why are you taking on all these things? You’ve got a lot of different programs, but what most politicians do is they set lower expectations and then they exceed the expectations.” And he looked at me without hesitation.
Segment 3466: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8323, Text: He says, “Jared, the way I look at it is that in five years from now, if I set five goals and I achieve five goals, I’ll achieve five things. If I set a hundred goals and I fail at 50 of them, then five years I’ll accomplish 50 things.” And so it’s a very different mindset as a leader. The way I got to work with him was Saudi Arabia was a big topic in the campaign. President Trump was basically saying during the campaign that they’ve got to pay for their fair share, they haven’t been a great partner in the region. He’s very critical of Saudi. And then during the transition, I was asked by several friends to meet with a representative of Saudi Arabia. I said, “I don’t want to meet with them.”
Segment 3467: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8364, Text: But I came over and I met and they said, “Well, we want to make changes.” And I said, “Well, you have to make changes to how you treat women.” Then women couldn’t drive, they had guardianship laws. So you got to start working with Israel, you have to be paying more of your fair share and you have to be stopping the Wahhabism that’s being spread. Again, I had no knowledge these were just kind of the traditional talking points about Saudi Arabia. So the guy I was with basically said, this guy Fahad Toonsi, who’s a very respected minister there, he says, “Jared,” he says, “You don’t know much about Saudi Arabia, do you?” I said, “No, no, no, I don’t. It’s just really what I’ve kind of been told or what I read.” And he says, “Okay, let me do this. We want to be great allies with America. We’ve traditionally been great allies with America. Can I come back to you with a proposal on ways that we can make progress on all of the different areas where we have joint interests?”
Segment 3468: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8415, Text: Keep in mind at that point in time, the Middle East was a mess, and probably the single biggest issue we had after ISIS was the ideological battle. If you remember in 2016, there was the Pulse nightclub shooting in Orlando, you had the San Bernardino shooting and people were being radicalized online with the extremism, and then there was a lot of crimes that were happening because of that. It was a big topic in the campaign, and so that when I was thinking about talking different generals and what capabilities the US had to really combat the extremism and the ideological battle, what we realized was that Saudi Arabia as the custodian of the two holiest sites in Islam, the Mecca Medina, that that would be the best partner to work with if they were willing to. But for years, they really hadn’t been willing to kind of lean into this fight.
Segment 3469: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8463, Text: So I said, “Sure, give a proposal.” So they come back, give a proposal, and they said, “Look, if you make President Trump’s first trip to Saudi Arabia, we will do all these different things. We’ll increase our military spending and cooperation, we’ll counter all the terror financing.” Unbelievable layer. So I took the proposal, I went to the National, then it was General Flynn. I said, “If Saudi Arabia did these things, would this be considered a big…” “Unbelievable, but it’ll never happen.” I said, “Well, they’re telling me they want to do these things. Again, having no foreign policy experience, I’m just saying I’ve got somebody telling me they want to do it and that’s kind of where we started.” Again, to office I don’t think much more about it.
Segment 3470: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8503, Text: And then I think it was like maybe a month in President Trump has a call with King Salman and before the call we’re in the Oval Office and the president’s basically saying, “Well, this is what we want to go through.” And I have Secretary Mattis and Secretary Tillerson, the Minister of Defense and the Secretary of State basically saying, “You have to deal with MBN. MBN is the guy who’s been our partner for all these years. He’s the head of intelligence and he’s been a great partner.” I said, “Well, if he’s been a great partner, then why do we have all these problems that you guys are complaining about with Saudi?”
Segment 3471: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8537, Text: I said, “I’ve been told that we have this proposal from MBS who’s the Deputy Crown Prince and that’s who we should be dealing with on this.” And so the phone call starts and President Trump listened to both of us, and on the phone call with King Salman, President Trump says, “Okay, we’ll go through all these things. These are the things we want to get done.” He says, “Well, who should we deal with?” King Salman says, “Deal with my son, the Deputy Crown Prince MBS.” So President Trump said on the phone, “Have him deal with Jared.” Because I think he knew that if he would’ve put him with the other guys, they were not believers in what he had the ability to do, and that’s how I got assigned to work with him.
Segment 3472: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8574, Text: I get back to my office after that, have an email from him, spoke to him for the first time, and then we just went to work. A lot of people were betting against that trip, they thought it wasn’t going to be successful, and they’ve been betting against him and he’s been underestimated, but he’s been doing an incredible job and the whole Middle East is different today because of the work that he’s done.
Segment 3473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8594, Text: Maybe it’s instructive to go through the mental journey that you went on from the talking points, the basic narratives, the very basic talking points, understanding of Saudi Arabia to making that human connection with MBS and making the policy connection that it’s actually possible to solve problems. What was that journey like? Why was it so difficult to take for others and why were you effective in being able to take that journey yourself?
Segment 3474: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8623, Text: Maybe some of it came from my inexperience, but my desire to listen and hear people. So I had this proposal, I was told that all of these things were good. Then we’re trying to schedule this trip and the National Security Council calls a meeting where we’re in the Situation Room and we have Homeland Security, Secretary of Defense, Secretary of State, and everyone’s saying this is going to be a disaster. They said, “If we go to Saudi Arabia, the Saudis never keep their promises.” And our Secretary of State at the time was a gentleman named Rex Tillerson, who’d been the CEO of Exxon so he dealt with all these people very extensively and he basically said, “In my experience, the Saudis won’t come through. And Jared, you don’t know what you’re doing, you’re wasting your time.”
Segment 3475: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8667, Text: And I basically was at a point where I said, “Look guys, but they’re saying they want to do all these things, shouldn’t we at least give them a chance to try to do it? Why do we want to predetermine their direction by not giving them a chance to change? Just because things in the past haven’t gotten the way you want them to, that doesn’t mean they can’t go that way in the future.” So we fought the battle. They basically deferred and let me go through with it, but when I’d do the planning meetings for the trip, nobody would show up because they all thought it was going to be an absolute disaster.
Segment 3476: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8696, Text: By the way, they probably weren’t wrong to think that because I’d never planned a foreign trip before and I’d never done any foreign policy before. So during the planning, I’d speak to MBS almost every day and I’d go through all the different details and the things that would be coming up and I said, “Look, I really need to get these things in writing.” He sent over a guy, Dr. Musaid Al Aiban, who’s a tremendous diplomat for them. He came to Washington, stayed for three weeks, and we worked through all the different details of what we needed and we ended up coming to an arrangement on what it should be. So I think about now in retrospect why I was so focused on getting things like this done and why I even believed that they could be possible. But the answer is really the people I was talking to on the other end were telling me that these things were possible, and so just because they hadn’t been done before and just because others around me didn’t believe that they could be done, I wasn’t willing to just say, “Well, let’s not try.”
Segment 3477: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8752, Text: It just seems like that cynicism that takes over is paralyzing. You sent me a great essay from Paul Graham. I’m a big fan of. I think it explains a lot of your success. The essay is called How to Do Great Work, and people should go definitely read the full essay. There’s a few things I could read from it, some quotes. “Having new ideas is a strange game because it usually consists of seeing things that were right under your nose. Once you’ve seen a new idea, it tends to seem obvious. Why did no one think of this before? Seeing something obvious sounds easy, and yet empirically having new ideas is hard.” The steps you took seem trivial, and yet nobody was taking them, or at least in the past, that weren’t successful. So the successes you’ve had were as simple as essentially picking up the phone or trying.
Segment 3478: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8807, Text: There’s a lot of interesting things here to talk about. This aspect of doing this seemingly simple that seems to be so hard to do it, as Paul describes, requires a willingness to break rules. ” There are two ways to be comfortable breaking rules: to enjoy breaking them and to be indifferent to them.” That’s an interesting distinction. “I call these two cases being aggressively and passively independent minded.” So again, that’s to enjoy breaking the rules or being indifferent to the rules. “The aggressively independent-minded are the naughty ones. Rules don’t merely fail to stop them; breaking rules gives them additional energy. For this sort of person delight at the sheer of audacity of a project sometimes supplies enough activation energy to get it started. The other way to break the rules is not to care about them at all, or perhaps even to know they exist. This is why novices and outsiders often make new discoveries; their ignorance of a field,” ignorance may be in quotes, “of a field’s assumptions act as a source of temporary, passive, independent mindedness.
Segment 3479: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8871, Text: Aspies also seem to have a kind of immunity to conventional beliefs. Several I know say that this helps them to have new ideas.” So the aggressive and the passive is such an interesting way of looking at it. Perhaps some aspect of this, at least in the story you told us, some passive aspect where you’re not even acknowledging, not even caring that there was rules, just kind of asking the simple question and taking the simple action.
Segment 3480: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8899, Text: I think that it’s funny that was a necessary read and we’re doing just a snippet of it, but I would encourage anyone listening to go and find it and read the entire thing because it’s something that really spoke to me as I was transitioning into my new career now, and I just loved it. But when we were talking about why certain people who don’t have traditional qualifications are able to come in and do incredible work and solve complex problems, it made me think of that essay, which is why I shared it. I think that in the context of the work that I was doing here, perhaps not having the historical context became an advantage and obviously went back and then tried to study it. But if you go into a problem, I always find that especially in the political realm, my favorite political issues are ones where they’re contrarian by being obvious and sometimes they feel very intuitive and so you take them on.
Segment 3481: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8955, Text: There’s always a lot of resistance when you go against something that’s been accepted as the way that you’re supposed to do things. I came to learn over the course of my time in government that when everyone was agreeing with what I was doing, then it actually made me more nervous because I felt like you have these problems, they haven’t been solved for a long time, and then if you take the same approach as others, you’re going to fail just like they did. So taking a different approach doesn’t mean you’re going to succeed, but at least if you fail, you’re going to fail in an original way.
Segment 3482: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=8988, Text: I did like this a lot and I think that what I saw was the people who were very good at getting things done that hadn’t been done before were people who came with different qualifications, different perspectives, and they came in and really worked the problem in untraditional ways. And so I think in the Middle East, I came in with a very different approach than people before me, not because I came in deliberately trying to do it differently, but because I came in trying to listen and understand from people why the problem hadn’t been solved and then think from a first principle’s perspective on what’s the right perspective today. Not based on what happened 50 years ago or not based on what somebody’s feelings who were hurt, but what’s the right thing to make people’s lives better, to make the world a safer and more prosperous place tomorrow.
Segment 3483: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9037, Text: So if we can go back to MBS for a little bit, from the person to the vision, there’s something called Vision 2030 about his vision for Saudi Arabia in the future. Can you maybe look from his perspective, what is his vision for the region?
Segment 3484: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9053, Text: Sure. So it’s funny, we were talking before about how we wish leaders would set big audacious goals and take on big things. Well, that’s what he did with Vision 2030 when he was young. And again, this is something that was derided and a lot of people were very skeptical of it, but the people who actually picked it up and read it said this is a very thoughtful plan that’s very achievable. So he studied his country and said, “What’s our place in the world? What are our advantages? What are our disadvantages?” And then he set publicly KPIs that he wanted to hold his country to and then put in place plans and committees and really worked hard to push things in that direction, which was pretty remarkable. I think that it’s something, when I saw it, I thought it was very refreshing. I said, “Wait, in America, why don’t we have set goals? Why don’t we have KPIs?” And I do think that it’s something that most countries, if not all countries, should have.
Segment 3485: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9105, Text: One of my favorite quotes was from the Alice in Wonderland, where the Cheshire Cat says, “If you don’t know where you’re going, it doesn’t matter which path you take.” So I think that that’s something that really helped set them on a good path, and they’ve been very successful with it. One of the things he told me about putting that together was he said, “My father’s generation, they created this country from almost nothing. They came here, they were a poor country, they were Bedouins in the desert. And then they look back and see what they’ve done over 50 years, and they say it’s absolutely remarkable.” He said, his generation, they come in and they say, “We’re very grateful for everything that’s been done to date, but we have so much opportunity that we’re not taking advantage of.”
Segment 3486: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9147, Text: And so he’s now empowered the next generation to be ambitious and think big and grow with it. What that means for his vision for the Middle East is that the general architecture that should exist, and now there’s excitement in the discussions with Israel that have advanced was the general view of what we thought from a Trump perspective should be the new Middle East is having an economic and security corridor all the way from Haifa to Muscat, from Oman to Israel, where basically you go through and if you can create a security area where people can live free of fear, of terrorism and of conflict. The Middle East for the last 20 years has been a sinkhole for arms, for death, for terrorism. It’s been awful. It’s been a big national security threat for America, a big place where our treasure has gone. We’ve had a lot of our young, amazing American soldiers killed in action there, and the same thing for the Arab countries as well.
Segment 3487: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9206, Text: So if we can create a security architecture for that region, and then we can create economic integration between all the different countries, I mean, the amount of innovation happening in Israel is unbelievable. Think of it like Silicon Valley’s not connected to the rest of California. You have a very young population, a very digital savvy population, you have a lot of resources. And so if you can get that whole set, the potential for it is unbelievable. I do think that that’s his ultimate vision is to become a really strong country economically, and then to become a place where you could be funding advancements in science, advancements in humanity, advancements in artificial intelligence, and think about ways to be a positive influence in the world.
Segment 3488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9245, Text: So a difficult question. One big source of tension between the United States and Saudi is the case of Jamal Khashoggi. I was wondering if you can comment on what MBS has said about it to you. You’ve spoken to him about it and what MBS has said about it publicly on 60 Minutes and After.
Segment 3489: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9265, Text: Yeah, so what he said to me was no different than what he ultimately said on 60 Minutes, which was, ” As somebody helping lead this country, I bear responsibility and I’m going to make sure that those who are involved are brought to justice and I’m going to make sure that we put in place reforms to make sure things like this don’t happen again.” It was a horrible situation that occurred. What I saw from him after that was just a doubling and a tripling down on the positive things he was doing, figuring out ways to kind of continue to modernize this society, build opportunity in the kingdom, and to continue to be a better ally to all the different countries that wanted to be aligned with them.
Segment 3490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9307, Text: One thing I learned from this case is how one particular situation, a tragedy, can destroy so much progress and the possibility of progress and the possibility of connection between the bridges that are built between different nations and how narratives around that can take off and take such a long time to repair. You’ve worked with this in the Middle East with Israel and so on, how the history, the narratives, the stories, they kind of have this momentum that’s so hard to break even when you have new leaders, new blood, new ideas that come in. It’s just sad to see that yes, this tragedy happens, but it doesn’t mean that you can’t make progress. I don’t know if you have lessons from that, just how much of a dramatic impact it had on creating tension between the United States and Saudi and in general and the Middle East that somehow Saudi’s not a friend, but is against the ideals and the values of the United States.
Segment 3491: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9384, Text: So it definitely created massive tension and it became a very high profile action that actually overshadowed a lot of the good work that was being done in the region and a lot of the progress we were making. But when you think about this or you think about the other issues that we’ve gone through today, I think the general framework that I always try to approach things with is you can’t change what happened yesterday. You can only learn from it and then you can change how you deal with tomorrow. When I think about the people in power, what do I hope that they’re spending their time focused on? Two basic things. Number one is how do I create safety and security for my people and for the world? And then how do I give people the opportunity to live a better life? And so when things like this happen, obviously there are certain reactions that are appropriate, but ultimately you have to think through how do you not allow the paradigm that you’re creating in the world to lead to worse outcomes than would happen otherwise?
Segment 3492: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9448, Text: And so when I would think about foreign policy in general, one of the differences between foreign policy and business is that in business the conclusion of a problem set, you finish a deal. You either have a company or a property, or if you sell it, you have less to do and more capital hopefully if it’s successful. In a political deal, it’s always about paradigms. So the end of a problem set is always the beginning of a new paradigm, and you’re always thinking through how do you create an environment that leads to hopefully the best amount of positive outcomes that could occur versus creating a paradigm that will lead to negative outcomes. So bad things happen, a lot in the world, and you have to make sure that when those happen, people are held accountable for it. But you also don’t want to make sure that in the process of making sure that there’s accountability for these actions, you don’t set a lot of progress that the world is making back. That will lead to worse off situation for many more people.
Segment 3493: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9511, Text: If we can go back to the incredible work with Abraham Accords and Israel and the Middle East, first, the big question about peace. Why is it so difficult to achieve peace in this part of the world between Israel and Palestine and between Israel and the other countries in the Middle East? Or any sort of peace like agreements?
Segment 3494: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9532, Text: If I had to give you the most simple answer, I would say that it’s structural. If you go back to the incentive structure of different leaders, this whole peace process between Israel and the Palestinians, and again, I’ve gotten criticized for saying this, but it’s what I believe, so I’m going to say it, is that the incentive structure was all wrong. When I went before the United Nations Security Council to discuss the peace plan that I proposed, which again was more of an operational plan, and it was a pragmatic plan, it was over 180 pages in detail. In politics, people don’t like putting forward detail because it just gives a lot of places for you to get criticized on. Nobody actually criticized the detail of my plan. They just criticized the fact that it was coming from us and didn’t want to debate the merits of the operational pieces of it.
Segment 3495: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9580, Text: So I created a slide where I showed from the Oslo Accords till the day I was there, all the different peace discussions. I put a dove in the slide for those, and then I put a tank for every time there was a war, because there was always skirmishes between Hamas and Hezbollah and the Palestinians. And then I showed two lines, and they both went from the bottom of the page all the way up like this. One of the lines was Israeli settlements. So every time a negotiation failed, Israel was able to get more land and then the other one was money to the Palestinians. I said every time a negotiation failed, the Palestinians would get more money. The problem with that money though, was that it wasn’t going to the people. Some of it would make its way down, but most of it was going to the politicians.
Segment 3496: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9624, Text: You had leadership of the Palestinians who was basically, I think at that point it was in the 16th year of a four-year term, so it wasn’t democratically elected. A lot of what I tried to show was that there was no rule of law, there was no judicial system, there were no property rights, and there was no opportunity or hope for the people to live a better life. And so all of the envoys to date were basically trained to go and do the same things. Again, I got massively criticized by all the previous envoys for not doing it the same way they did, but I thought the problem structurally just didn’t make sense and so I felt like the incentive structure was all wrong, and I took a different approach.
Segment 3497: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9664, Text: And so what’s the different approach?
Segment 3498: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9667, Text: I started writing down a document. These are the 11 issues, but there’s really only three issues that matter. I said, “Just tell me what you think the compromise is that you think the other side could live with, that you would accept.” And it was very hard to get them talking about this. “Oh, you have to go back to 1972, you have to go back to 1982, you have to go back to 2001, you have to go to…” And I was just like, “I don’t need a headache and I don’t need a history lesson. I just want a very simple thing. Here today in 2017, what’s the outcome that you would accept?”
Segment 3499: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9695, Text: And I was dealing with their negotiators, their back channel secret negotiators, their double secret neg- I was like, “This whole thing is like, it’s a process created where nobody wants to talk about the actual solution.” So coming from the business world, I said, ‘Okay, let me just write down a proposed solution that I think is fair, and let me have each side react. Don’t tell me about theoretical things. Tell me I want to move the line from here to here. I want to change this word.” So I tried to make it much more tactical, and what I realized was the Palestinians, they’d worked so hard to get the Arab world to stay with the line of the Arab Peace Initiative.
Segment 3500: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9734, Text: And so I was going back and I read the Arab Peace Initiative. It was 10 lines and it didn’t have any detail, so it was a concept. And so they liked that concept because it allowed them to reject everything. They kept getting more money. I mean, Bibi Netanyahu, who runs one of the most incredible economies in the world, who runs an incredible superpower militarily for the size of their country. He would fly to Washington to meet us, and he’d be taking a commercial El Al Plane. Abbas, who runs a refugee organization, a refugee group that claims that they don’t have a state that gets billions of dollars every year from the global community would fly in a $60 million Boeing BBJ. So the whole thing was just very corrupt and off, and I do think that that’s why… I don’t think people were incentivized to solve it, to be honest.
Segment 3501: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9782, Text: What do you think an actual plan on that part, just before we talk about Abraham Accords, if there is a peace plan that works between Israel and Palestine, what do you think it looks like?
Segment 3502: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9795, Text: You have to separate it into two different issues. And I think that that’s actually how we came to the Abraham Accords, is that I tell the story in the book, and it was one of my favorite experiences during my time in diplomacy where I went to meet with Sultan Qaboos, who was the sultan of Oman. We fly out there because he’d had a secret meeting with Bibi, and I thought maybe he was open to normalizing with Israel. So after he meets with Bibi, he calls me and says, “I want you to come see me.” So I go over to see him, and again, I tell the story. It was a crazy night and all these different areas, but when I was talking to him, he basically says to me, “I feel badly for the Palestinian people that they carry with them the burden of the Muslim world.”
Segment 3503: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9838, Text: And that line just like stuck with me. A couple days later, I was thinking about it and I said, “Wait a minute, who elected the Palestinian people to represent the Muslim world on the Al-Aqsa Mosque? And so the reason why I felt like it had never been solved was it was a riddle A, that I believed was designed to not be solved, but B, you were conflating two separate issues. You had the issue between Israel and the Muslim world, which really was the issue of the Al-Aqsa Mosque, and then you had just a territorial dispute, which throughout history, you have lots of territorial disputes, and they’re usually resolved in different ways.
Segment 3504: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9874, Text: If you go back to the Israeli-Palestinian issue, there’s just a couple components you need to solve. Number one is territorial continuity, right? You need to figure out where do you draw the lines? And that’s something that you can talk about what people were owed 70 years ago, but it’s much more productive to say, “This is what you can make work today.” And that’s kind of what we did. We literally spent months and months drawing a map and we put something out, probably change a couple lines here and there, but by and large, it was a very pragmatic solution that I think could work and I think it could work for-
Segment 3505: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9903, Text: … very pragmatic solution that I think could work, and I think it could work for the safety and security of Israel, which was number one.
Segment 3506: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9907, Text: So first issue is drawing a map. Second issue is security. And again, this is one issue, we were incredibly sympathetic with Israel, which is you can’t expect a prime minister of Israel to make a deal where he’s going to make his people less secure than before. So we worked very closely with them on a security apparatus. We laid something out that I think would keep the whole area safer, and it would make sure Israel was safe and also keep the Palestinian issue safe. So you needs security.
Segment 3507: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9934, Text: Number three was the religious sites, and that was one that was actually always made much more complicated by people, the Al-Aqsa Mosque, because you basically have Ḥaram al-Sharīf, which is a place where the mosque was built in the seventh or eighth century, but originally it was where the Holy of Holies were in the [inaudible 02:45:52] for the Jewish people. And then compounding by the fact that you have all the Christian holy sites in Jerusalem. It’s a city that should be bringing everyone together, but in fact has become a place where you have wars and hatred, and a lot of different conflicts that have risen because of it.
Segment 3508: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9968, Text: But what I said was, instead of fighting over concepts of sovereignty, which is interesting, how I got to the notion that this wasn’t really the big issue. I basically just operationally, why don’t we just make it simple? Let everyone come and be able to worship as long as they’re being able to worship peacefully.
Segment 3509: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9983, Text: So that’s really the contours of it. And what the Palestinians have done is they’ve kind of deflected from a lot of their own shortcomings, and a lot of the Arab leaders did that as well, kind of in the Abraham Accord days, by kind of allowing this issue to be so prevalent.
Segment 3510: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=9997, Text: So one thing I’ll say on the Palestinians is that what we tried to do by laying out plan was we said, “Okay, what are the reasons why the Palestinian people are not having the lives that they deserve?” And I’ll give you a couple of things. One is I studied the economies of Jordan, West Bank, Gaza, Egypt, Morocco. This was numbers from like 2019. But what was interesting was the GDP per capita of somebody living in the West Bank was actually the same as Jordan, and it was actually more than somebody living in Egypt. And the debt of GDP that the Palestinians had was like 30, 40% compared to Egypt, which was at like 130%. In Jordan, which was at 110%. Then Lebanon, which is at 200%.
Segment 3511: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10044, Text: And so you’re in a situation where a lot of this stuff didn’t make sense, but if you draw lines, create institutions where Palestinian people can now feel like they have property rights and have ownership over their place, and let the money flow past the leadership ranks to the people, let them have jobs, let them have opportunity, and then let all Muslims from throughout the world have access to the mosque and Israel, making sure that they can control the security, which I think the Jordanians and a lot of others want Israel to have strong security control there to prevent the radicalists and the extremists from coming, you could have peace there very easily.
Segment 3512: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10080, Text: So there’s a lot of things to say here. One is just to emphasize, Al-Aqsa Mosque, says this a holy place, and this is something in our conversations and in my own travels, I’ve seen the importance of frictionless access to those sites from the entirety of the Muslim world. And that’s what Abraham, of course, took big leaps on. Okay, so we’ll talk about that a little bit more, but that’s kind of a religious component. That’s a dignity in the religious practice and faith component.
Segment 3513: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10115, Text: But then the other thing you mentioned so simply, which is you have money flow past the leadership ranks. How do you have money flow past the leadership ranks in Palestine? So make sure that the money that’s invested in Palestine, the West Bank, gets to the people.
Segment 3514: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10138, Text: So to date, all of the aid that’s been given to the Palestinians has been an entitlement. It’s not conditions based. It’s always just we give them money and there’s no expectations. It’s very simple. You make the aid conditions based. You fight for transparency. You do it through institutions other than the PA, or you put reformers into the PA that will allow it to go down that way.
Segment 3515: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10158, Text: PA being the Palestinian Authority, which is the leadership?
Segment 3516: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10161, Text: It’s not hard to do. It just takes people who actually want to do it. But I think that the mindset of the international community has not been, “Let’s solve this problem.” It’s like, ” Let’s just throw a little bit of money. The money’s Novocaine. Let’s put a little Novocaine on the problem and let’s not have to deal with it.” But nobody’s ever said, “Oh, let’s do an accounting of the $20 billion we’ve given them and see how many jobs it’s done and where it’s gone.” That just hasn’t happened. Again, it’s an incredibly corrupt organization [inaudible 02:49:46]. You think about the post-World War II dynamic, you had a lot of refugees. My grandparents were Refugees post World War II. Every other refugee class has been resettled and you only have one permanent refugee organization ever created. Why was this done? It was done to perpetuate the conflict so that a lot of Arab leaders could basically deflect from a lot of their shortcomings at home.
Segment 3517: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10206, Text: And so I think for Israel, they view all these things as existential. They value their safety. They’ve been under attack for a long time. I do think having a deal where we can say, “How do the Jews and the Muslims, Christians, come together?” I think King Abdullah from Jordan’s been an incredible custodian for the mosque. I think everyone, in my travels, recognize that he’s the right guy for that. That the king of Jordan should be the custodian of the mosque. We should have some kind of framework to make sure everyone has access. The more countries that have diplomatic relations with Israel, the more Muslims and Arabs that should be able to come and visit. And by the way, the more you have these normalizations, think about what that will do to the economy of the West Bank where they’ll have great hotels, hospitality, a tremendous tourism industry because of all the Christian, Muslim, and Jewish holy sites that they have there.
Segment 3518: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10254, Text: So there’s a lot of potential there. We just have to get unstuck. I believe that it’s so possible if the leaders want to make tomorrow better, that they can. And unfortunately, the people who suffer the most are really are just the Palestinian people. And I think that in Gaza, they’re hostages to Hamas. And in the West Bank, they’re just held back because their leadership just is afraid or too self-interested to give them the opportunity to change their paradigm and pursue the potential of what they have. And by the way, it’s an incredibly well-educated population, it’s an incredibly capable population, and they’re right next to Israel where the economy, they need everything. And so the potential should be incredible if you can just move some of these pieces.
Segment 3519: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10305, Text: But again, there’s still a lot of emotion and hatred you have to work through as well. But I do believe that you’re not going to solve that by litigating the past. You’re only going to solve that by creating an exciting paradigm for the future and getting everyone to buy in, and then move towards that.
Segment 3520: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10321, Text: And maybe increase the chance of being able to establish an economy where the entrepreneurs can flourish in the West Bank and so on in Palestine, once the relationship across the Arab world is normalized.
Segment 3521: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10336, Text: So one thing on that, which is very interesting, is when I got into my job in the Middle East, all of the conventional thinkers said to me, “The separation in the Muslim world is between the scene as Sunnis and the Shias, and that’s really the big divide.” And as I was traveling, I didn’t think there was any divide in that regard. The divide that I saw was between leaders who wanted to give a better opportunity for their people and create economic reforms and opportunity, and leaders who wanted to use religion or fear to keep their stronghold on power. And so if you think about who’s not creating the opportunity for their people, it’s the Palestinian leadership and the Iranian leadership. All the other Arab countries were focused on, how do we give opportunity for our people to live a better life?
Segment 3522: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10382, Text: And there is a big foundation on which that framework can succeed, which I think is, in general, the idea of Arab Israeli normalization. So that’s where Abraham Accords come in. Can you tell the story of that?
Segment 3523: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10400, Text: Sure. So it’s an amazing thing. And I sit here today, somebody not in government, and every day I see another flight that goes between, or I see an Israeli student studying at a university in Dubai or a new synagogue opening up in Abu Dhabi. And it just gives me such… Or Bahrain. It gives me such tremendous pride to see all of the progress that’s been made.
Segment 3524: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10426, Text: How it occurred, part of why I wrote the book was to put this down for history’s sake, to go through all the different intentional, unintentional, circumstantial things that occurred. It’s funny, we left government. There’s a lot of people saying, “Well, this is why that…” I said, “I was kind of at the middle of it, and I couldn’t even perfectly articulate why it happened,” because it was in evolution of a lot of things. And I joke that we made peace on plan C, but only because we went through the alphabet three times, failing at every letter. But we didn’t give up and we kept going and we got it done.
Segment 3525: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10461, Text: And maybe this is a good place to also step back and say, what is Arab Israeli normalization? What is the state of things for people who may not be aware before the progress you made?
Segment 3526: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10473, Text: That’s Probably the best place to start. So what we did is we made a peace deal between Israel and the United Arab Emirates, and then Israel and Bahrain. Then we did a deal with Israel and Sudan, then Israel and Kosovo, Israel and Morocco, where basically countries that didn’t recognize each other before ended up recognize each other, all of these were Muslim majority countries, and getting them to integrate with Israel was a very big thing.
Segment 3527: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10499, Text: The traditional thinking had always been was that Muslim Arab countries would not make peace with Israel until the Israeli-Palestinian issue was solved. And what we were able to do is separate the issues and then make these connections, which are leading to amazing interaction between Jews and Muslims. So when I think about, obviously you have national security, you have emotional benefits from these things. But the single biggest benefit that I’ve seen from the Accords is that if you were an Arab or a Muslim and you were willing to say positive things about Israel or the Jews before this came out, you had been viciously attacked by the media or the hordes of influencers or the extremists in these different countries. What this did was it brought out into the public the fact that Jews and Muslims can be together and they can be respectful, they can have meals together, and that the cultures can live together in peace.
Segment 3528: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10562, Text: So just to linger on this, it’s like a once subtle and in another sense, transformative. So normalization means you’re allowed to travel from one place together. That has a kind of ripple effect of that you can now start talking in a little bit more accepting way. You can start integrating, traveling, communicating, doing business with, socializing. So the cultures mix, conversations mix, all of this. And this kind of has a ripple effect on the basic connection between these previously disparate worlds. I don’t know if there’s a nice way to kind of make clear why these agreements have such a transformative effect, especially in the long term.
Segment 3529: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10616, Text: I would say the simplest form is it’s just a mindset, and it’s almost like you’re taught all your life, “We’re enemies, or we can’t be friends with that tribe on the other side of the fence.” And then one day the leaders get up and say, “No, it’s okay now.” And there was never an issue between the people. The people were just taught different things and they were separated from each other.
Segment 3530: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10639, Text: But again, one of the things that I respect about the work you do is you believe in the power of conversation and the power of human interaction. And these issues and gaps between us feel so big when we think about them, when we’re told about them, when we read about them. But when we go and sit with each other, all of a sudden we realize maybe we have a lot more in common than we have that divides us.
Segment 3531: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10663, Text: For me, what I’ve seen about it that’s made the biggest difference is I’ve seen people who wouldn’t have the ability to be together, be together, and that’s now forming a nucleus of togetherness, which is a restoration. So you think about the modern Middle East from post Holocaust to now, again, in 1948, after that War of Independence, you had Jews living in Baghdad and Cairo. Then they became so anti-Jewish that they then expelled all of the Jews from all of these capitals of those cities. So you think about the Jewish history in Baghdad. I mean, I think that Talmud was written in Baghdad. It was a place where, in Babylon, where the Jewish people thrived, I think in 570 BCE, when Nebuchadnezzar conquered Jerusalem, he took about 10,000 Jews back with him to Babylon because he thought it’d be good for his economy. And during that place, the Jews actually flourished and had a good life there.
Segment 3532: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10721, Text: So for a 1,000 years before the second World War, the Jews and the Muslims lived very peacefully together. So people say that what we’re doing now is an aberration. I actually think it’s not an aberration. I think it’s actually a return to the time where people can live together culturally. And so this is the beginning of the end of the Arab-Israeli conflict, and it’s the beginning of togetherness, which again, you think about how much war, how much provocation, how much terrorism has been made in the name of religious conflict. This is, I think, the start of the process of religious respect and understanding.
Segment 3533: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10757, Text: We’ve talked about you being attacked in the press for the Russian collusion and other topics. One of the most recent set of attacks comes on the topic of Saudi public investment fund, giving $2 billion to your investment firm after you left government. So that includes a 1.25% asset management fee of 25 million a year. Can you respond to these recent set of attacks?
Segment 3534: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10782, Text: Sure. So left government. Obviously worked for four years. It was a very action packed time. That’s why I wrote the book. I wanted to put down all those experiences. I started thinking, “What do I want to do next?” So my previous career, I’d been in real estate. I had worked with my brother on some technology businesses that I’d started. And then got into government. So I kind of had a career shift. In my previous career, obviously was very successful. The New York Times, they violated and they published my financial statements. They showed I was making about $50 million a year in the private sector before I went to government. I went into government and I volunteered. I didn’t take a salary. I paid for my own health insurance for four years, my wife and I. And then we went and I was thinking, “Should I go back to my old company or should I start something new?”
Segment 3535: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10835, Text: And my thinking was is that, through my time in government, I’d met so many people, I’d learned so much about the world. I had a big understanding now for how the macroeconomic picture worked. And I did feel like there was a lot more that I could do than just going back to real estate.
Segment 3536: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10852, Text: In the meantime, I was getting a lot of calls from different CEOs and companies saying, “Can you help me with this company? Can you help me with that company? Your knowledge could be helpful to help this company navigate this challenge or to expand internationally.” And so I said, “You know what? Maybe I should create a business to do an investment firm, where I can do something different, where I’m putting together geopolitical expertise and traditional private equity and growth investing and figure out how to do that, where I can do something differentiated, where I can invest in growing things and help with my navigation skills and relationships.”
Segment 3537: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10887, Text: So that was kind of the thesis of what I thought could make sense as kind of a next step. I called different friends. They were very excited to back the effort. Obviously this was coming off the success that I just had in the Middle East where I did six peace deals there. And one of the notions I wanted to be able to do with the firm was to be able to take money from the Gulf and then to be able to invest it in Israel, to continue to build the economic links between the countries. Again, if countries have more economic ties, I think war and fighting is less likely. And then in addition to that, I wanted to figure out how do you bring the entrepreneurs together from both of those countries?
Segment 3538: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10926, Text: So that was really the mission of what I set out to do. So far, I’ve been enjoying it. It’s been a lot of fun. I’ve been learning a ton. I think we’re doing very well with it.
Segment 3539: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10935, Text: In terms of the criticisms, I think that I’ve been criticized in every step of everything I’ve always done in my life. And so what I would say is, this business is actually an objective metric business, right? It’s about returns. So in three, four years from now, five years from now, see how I do? Hopefully I’ll do very well and judge me based on that.
Segment 3540: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10954, Text: In terms of any of the nefarious things, I haven’t been accused of violating any laws, and I haven’t violated any of the ethics rules either. When I was in government, I, every year, submitted all my financials to the Office of Government Ethics. They certified it every year, and I followed every rule and every law possible. So to my critics, I’ll say, “Criticized me before, you’ll criticize me now. I’m going to keep doing me and I’m going to keep pursuing things that I think are worthwhile.” And I’m very excited about this chapter of my career.
Segment 3541: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=10988, Text: Maybe this is a good place to ask. In working closely with Donald Trump, what, in your sense, looking into the mind of the man, what’s the biggest strength of Donald Trump as a leader?
Segment 3542: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11001, Text: I would say his unpredictability. I think that, as a leader, he consumes a ton of information. He doesn’t like to be managed or have his information filtered. So he’ll speak to a lot of people to draw his information himself. He’s very pragmatic. I don’t see him as terribly ideological. I see him as somebody who’s about results. I think he wants to deliver results. And I think ultimately, he’s an incredible fighter. He’s a big counter puncher, but he also wants to get along with people. And that’s probably the biggest surprise that people found with him. I mean, you look at even situations like… I would always tell people, “If you disagree with him, don’t go on television and criticize him. Just pick up the phone and call him, and go see him, and he’ll talk to you about it.” He may not agree with you.
Segment 3543: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11054, Text: But again, that’s what Kim Kardashian did when she had a case of clemency with a woman, Alice Johnson, that she felt strongly about. We went through the case. I wouldn’t have had her call if I didn’t think it was a legitimate case. So we spent about eight months quietly working through the case, working through the details, to make sure that it really was a worthy case.
Segment 3544: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11074, Text: I brought it to President Trump said, “She’d like to come meet with you to talk about this case.” And he said, “Have her come in.” So she came in. We went through the case, and President Trump ultimately granted the clemency to Alice Johnson, who was a woman who was accused of being part of a drug ring. She had basically a life sentence for doing it. She’d served 22 years in prison. While in prison, she’s basically was a grandmother, and she was putting on the prison plays, she was mentoring young women in prison. Somebody who, again, there’s always a risk, but by and large had a very, very, very low risk of committing a crime in the future.
Segment 3545: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11111, Text: And then it goes back to the notion of, are we going to judge people by the worst decision they make in their life? And so President Trump was willing to grant the clemency, and it went.
Segment 3546: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11121, Text: And I think that it just goes to the notion of maybe this goes back to his unpredictability in a positive way, which is if you go sit with him and you make your case, he’ll hear you, he’ll listen to you, and he’s not afraid to act, and he’s not afraid to be controversial, which I think is a good thing.
Segment 3547: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11136, Text: So from a foreign policy point of view, in particular, his unpredictability just meant that everyone was always on their back foot. People were afraid to kind of cross America. And what I would tell people who don’t like Trump is I would say, “Think about how crazy he’s making you and his enemies. He did that to the enemies of America.” Yeah, so he was a very, very strong president and I think did a great job.
Segment 3548: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11158, Text: So in some of these agreements that we’ve been talking about and speaking with leaders, how do you think the unpredictability helps?
Segment 3549: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11165, Text: So in all the agreements that I was negotiating, I wasn’t doing it as a principle, I was doing it on behalf of President Trump. And people knew that I had access to President Trump, and they knew that I could say, “You may say this that we don’t like, but I’m going to have to take it back to him, and then we’ll see what he does.” And one of the biggest instances was on the USMCA trade deal, where that deal happened because Mexico was legitimately concerned, and smartly so, that President Trump was going to impose tariffs on the car industry, which would’ve been decimating to their economy. And by the way, he was ready to do it. We were holding it back from doing it with every ounce of strength that we could. So it wasn’t a bluff. I mean, that was actually real, but they were smart to read that it was real. And ultimately we created a great win-win deal.
Segment 3550: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11216, Text: I’ll tell you a funny story, just popped into my mind from the tariffs is we did also, we used a 232 national security exemption to protect our steel industry, and we put tariffs on steel and aluminum. And again, I thought about this because we also negotiated them with Canada. And there was a very funny phone call where Trudeau is calling Trump. And again, they got along decently well. Trudeau’s calling saying, “You can’t put national security tariffs on us in Canada. We’re your NATO ally. We fought wars with you. We do military together.” And Trump says to him, “Didn’t you burn the White House down in 1812?” And Trudeau says, “That was the French.” He says, “No, it was the Canadians.”
Segment 3551: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11253, Text: And so it was just, like I said, he’s always keeping everyone on their toes.
Segment 3552: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11259, Text: Yeah.
Segment 3553: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11261, Text: But he took very calculated risks. And like I said, everyone was outraged all the time with everything. But if you look at his body of work, people said if he was elected, he would start World War III. Meanwhile, we inherited world filled with wars, no new wars, right? Three years. He made peace deals, no new wars. He was tough. He was strong. People respected him. He built relationships and got trade deals done, got peace deals done. The economy was rocking. His body of work, I think was pretty strong as president.
Segment 3554: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11294, Text: Like you said, no new wars. This makes me think if Donald Trump won the presidency, what the current situation in Ukraine would look like. But let me just ask you, zoom out and ask you broadly, do you think the war in Ukraine could have been avoided? And what do you think it takes to bring it to an end?
Segment 3555: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11313, Text: I think 100%, it would’ve been avoided. Not 99%. President Trump, for four years, had no problems with Russia. We were arming Ukraine, but we were working with Russia. And again, the first two years, we had a little bit of issue working with Russia because they were accused of colluding with us since we had to go through that investigation. But in the second two years, we were trying to focus Russia on what are the areas where we can collaborate together. I think Russia, we thought it was in their strategic advantage to play US and China against each other because of the way that everything was done before. They were stuck with China, but not getting a lot for it. Under Bush, they took Georgia. Under Obama, they took Crimea. Under Trump, there was no problems. And then under Biden, unfortunately, I think they misplayed a couple of things, which I think provoked Russia to go forward. Still no excuse to do what they did. I think that the invasion was a terrible thing and should not have occurred.
Segment 3556: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11374, Text: But with that being said, I think 100%, if Trump was president, there would not be a war in Ukraine today.
Segment 3557: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11381, Text: Coming to the table and negotiating a peace, whether it’s Donald Trump, whether it’s Biden, whether it’s anybody, what do you think it takes? Do you think it’s possible? And if you’re in a room, if Jared Kushner is in the room with Vladimir Putin and Volodymyr Zelenskyy, what does it take to have a productive conversation? And what does it take for that conversation to fail? What are the trajectories that lead to success and failure?
Segment 3558: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11410, Text: I think we go back to negotiations. Number one is trust, right? Both leaders have to have the ability to communicate what an off-ramp is without fearing it’s going to leak to the public. So if you go to the posture of Zelenskyy right now, and by the way, President Zelenskyy, I have a lot of respect for the courage he showed, especially initially, you saw what [inaudible 03:10:33] did in Afghanistan, they were getting attacked by the Taliban. He took the cash and got the hell out of there. Staying in Kiev when he did, how he did it, was one of the most brave things we’ve seen in a long time. And he has a ton of my respect and admiration for doing that.
Segment 3559: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11447, Text: But now he’s promising his people we’re going to win the war, and the military action has not necessarily coincided with that sentiment. And so there has to be some form of off ramp, but he can’t say that publicly. So for him to be able to work privately with somebody who can help create a new paradigm where both leaders can say, “We’re going to stop the bloodshed. We’re going to stop the risk of nuclear war for the world. We’re going to stop what’s happening.” That’s really what it will take. How that occurs, again, it’s not something I’m involved in now, so I don’t know who the right broker is or how to put that together, but essentially they need somebody in between them who can figure out how do you create a landing zone that works? Because neither party’s going to jump until the pool is filled with water.
Segment 3560: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11496, Text: And you have to outline what the go forward looks like, because you can’t just stop it for them to get worse for both parties. You have to move it forward into what happens next, that hopefully can start to turn the tide to benefit both sides where they can focus on the future instead of being stuck into the old paradigm of who started what, who’s to blame for what, who did what to who. It’s just a lot of tough stuff now that’s occurred that’s going to be hard to walk back. And it’s a big task to get it done, but for the sake of the world, it’d be amazing if we were able to reach a conclusion to that conflict.
Segment 3561: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11536, Text: Just going back to your earlier mention of North Korea, what do you think it takes to bring Vladimir Putin and Volodymyr Zelenskyy to the table together?
Segment 3562: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11546, Text: Leadership.
Segment 3563: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11550, Text: So you’re saying it has to be a US president?
Segment 3564: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11554, Text: It has to be somebody who’s willing to put themself on the line to go and do it. And again, if you’re the US president and you’re the most powerful nation in the world, you should be trying. But I do think, again, the posture that the US has taken has probably been in a place where it would be very hard for them to get the trust of Russia based on the way that they’ve played their moves to date.
Segment 3565: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11578, Text: I always thought, from the beginning, that Putin would try to bring in President Xi in China to resolve it, to basically give a big screw you to America to say, “China’s now the one in charge of this.” But that hasn’t seemed to manifest itself to date either. But it takes leadership. The leaders have to get it and say, “Let’s get everyone together and let’s try to get this done.” Because every day it goes on, A, more people are dying, and B, we do risk a nuclear war for the world, which is not a good situation.
Segment 3566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11609, Text: Let me ask, since you helped set up phone calls between Donald Trump, Putin, and the King of Saudi Arabia, if I were to interview Putin, what advice would you give on how to get a deep understanding of the human being?
Segment 3567: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11626, Text: So I didn’t deal with Russia a ton, but in my interaction with Putin and with Russia, I would kind of point out a couple of things. Number one is, when America was hit with COVID and New York was looking like we were going to run out of ventilators and masks, Russia was the second country that sent us a planeload of supplies. And they didn’t send that because they hate America, they sent that because we were starting to make progress together as countries, and they thought that they wanted to show goodwill to figure out how can we start working together.
Segment 3568: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11657, Text: And again, people may attack me for saying that that sounds naive. Again, the past 15 years may show that that’s not the case, but I don’t believe that countries have permanent enemies, and I don’t believe countries have permanent allies. Right? Again, you think about the US and Russia and World War II, we worked together to defeat the Nazis, right? And now we’re great allies with Germany, who basically was our great enemy in World War II. We’re great allies with Japan, who was our great enemy in World War II.
Segment 3569: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11683, Text: So it goes back to the notion we discussed earlier of you shouldn’t condemn tomorrow to be like yesterday if you’re unhappy with yesterday. So number one is I would definitely ask him about that.
Segment 3570: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11696, Text: The phone call that you mentioned was after we did a pretty intense negotiation to create the largest oil cut in the history of oil production. So during COVID, demand just shut off like crazy, and it was stopping very quickly. Saudi and Russia, at that time, were having a conflict. They created this thing called OPEC+, which goes back again, history between the two countries where they had conflicts, and then all of a sudden they were working together to try to stabilize the oil markets. But they couldn’t agree on the cuts, so Saudi actually increased production. So you had two things hitting at once where Saudi and Russia were both increasing production and demand was dropping.
Segment 3571: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11734, Text: So you were headed for a real crisis, and I was starting to get calls from a lot of the oil industry executives here in America saying, “You don’t understand. We can’t just flip a switch and turn off our oil wells. We’re running out of storage here.” And I said, “Look, president Trump likes low oil prices, so he’s not upset about what’s happening. You have to call him and if he gives me permission or the instruction, then I can try to intervene. But right now, he’s not inclined to intervene.”
Segment 3572: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11759, Text: After a little bit, he said, “It’s time. Get involved. Go do it.” It was right over Passover. This was during COVID. I spent three days nonstop on the phone with [inaudible 03:16:09] from Russia and with MBS directly, and I was dealing with Dan Brouillette, who was our energy minister, going back and forth, and it was crazy. I mean, it was just one of the craziest negotiations. We ended up agreeing on the largest oil cut in the history of the world.
Segment 3573: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11784, Text: But the story you went to before, which was pretty funny, was finally make the deal, and we set up a call between King Salman, Vladimir Putin, and President Trump to announce the deal. I’m like, “Oh, this is great.” So President Trump gets on, “Congratulations. We have a deal.” And then King Salman says, “We don’t have a deal. Mexico hasn’t agreed to their cuts.” He’s saying, “What do you mean?” So they were part of the OPEC+. And so I get a note saying, “You got to go call Mexico. So I’m calling Mexico and we’re dealing, they’re saying, “We’re not doing any cuts.” I said, “Why? I said, we’re hedged at $55.” I said, “Why didn’t you tell us that at the beginning?” So I’m telling the Saudis. So we were working through this whole thing.
Segment 3574: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11822, Text: So meanwhile, we were trying to find the compromise with Mexico. I set up a call with Trump and Putin, so they can kind of talk this through. And he was always trying to play the game of how do we get Russia away from China? He always thought that that was not the right strategic framework for US interests. And again, we had no problems with them during that time.
Segment 3575: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11844, Text: What I would say is that for Zelenskyy and Putin, any conversation with both of them is about understanding their perspective. I think with Putin, he’s a student of history from the things that I saw with him. If you look at Russia over the last 500 years, I think they were attacked by the Polish in early 1600. I think they were attacked by the Swedes in the 1700s. I think they were attacked by Napoleon in the 1800s. And then in the 1900s, they were attacked by Germany twice. And so from his perspective there is… In the early days of Russia, they were attacked by the Mongols. They were-
Segment 3576: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11883, Text: … Russia, they were attacked by the Mongols. They were very vulnerable. And a lot of the geography of Russia today is really designed for defensive purposes, that they have natural barriers that makes them easier to defend. And Russia is a massive land mass, it’s twice the size of America, they have 11 times zones in the country, and so I do think that for Vladimir Putin, his biggest concern is, “How do we create a security paradigm in the west of this country that won’t be a creep?”
Segment 3577: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11909, Text: And I think that there’s two different parts of the mindset. The people who are most cynical of Putin will say, “Well, he’s just trying to recreate the USSR. He’s being expansionist,” and the people who want to be sympathetic to him will say, “Well, if you think about it, the Russian perception of the NATO arrangement was that they wouldn’t be expanding westward. Over the last years they’ve included all these countries that they said, they promised they wouldn’t include,” who knows what the promises were or were or weren’t?
Segment 3578: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11938, Text: But what I do know from his perspective is allowing Ukraine and to NATO was always a red line, and that’s why we never offered it. We never provoked it. We never brought it up. We said we’re going to arm them, and we basically said, “Just calm down. We don’t want any conflicts there. We have bigger issues and bigger opportunities to work from.” So I do think you have to think through, what’s a paradigm that he can accept? And I do think that he’ll give the justification for why he’s done what he’s done, and then I think the framework for a solution is about, how do we move both parties forward? Tough job. I hope you get the opportunity to do it because I think it’s a conversation that will only help the world hopefully find a pathway forward.
Segment 3579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=11980, Text: And I should mention, because you mentioned geography, one of the many books you’ve recommended to me that gives a very interesting perspective on history. It’s called Prisoners of Geography by Tim Marshall, and it has a very interesting perspective on the geopolitical conflicts and perspective of Russia from a geography perspective. And also for China in the second chapter. And there’s a lot of understanding of why the expansion of NATO is such a concern for Russia, because geography still even in the 21st century, less and less so because of technology and so on, but it still plays a major role in conflicts between nations: rivers, mountains…
Segment 3580: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12025, Text: And understanding the DNA of countries. It was one of the most phenomenal books, and I just found it on Amazon randomly, but I loved every minute of it. The chapter on America is also incredible, going through the evolution of how we became the country we are, the different acquisitions, the different changes, why we have all these geographic advantages, and it’s an unbelievable book for anyone who’s interested in geopolitics.
Segment 3581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12048, Text: I have to ask on several aspects of China. First on the president, the meeting: you helped set up a first call and first meeting between Donald Trump and Xi Jinping. Can you tell the story of that? Because that’s also interesting, again, that first phone call, the reaching out, the forming the human connection, which ultimately leads the connection between nations, and the possibility of collaboration.
Segment 3582: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12072, Text: During the transition, President Trump took a call from the head of Taiwan and that sent the Chinese into a real tailspin, and he didn’t do it, I think to be provocative to them as much as just as a businessman, he felt, you answer your call: if somebody wants to speak to you, you speak to him, you want to have conversations, hear their point of view. But it was taken as a very big insult and it was against tradition and norm. And so, that was something that set us off in a wrong direction. My view at the time was that we are entering a G2 [inaudible 03:21:47] world, whether people want to admit it or not, and that a lot of these countries in what I call the middle market countries, when China was being aggressive with their One Belt, One Road, they were basically playing the US and China against each other. And I thought that by the two leaders coming together, there were some things they wouldn’t agree on, but there was a lot that they probably could agree on, which could lead to resolutions to a lot of issues in the world. That was my most optimistic view. My more pragmatic view was that President Trump had very big issues on trade that he wanted to get to with China. He felt like China, their trade practices were unfair, they weren’t following all the global rules of trade, he was a little bit nervous that they would be provocative with Taiwan, and I felt like the two of them getting together would be the best way to try and resolve that.
Segment 3583: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12158, Text: So, the Chinese are very proud and a lot of it’s about face, and so in order to negotiate for that first call, we basically agreed on what would happen in the call. So not, “Let’s just have a call, say hi, nice to meet you.” It’s a question of, President Trump basically agreed that he would acknowledge the One China Policy, which he didn’t see as a big concession because you could always unacknowledge it the next day, “So yeah, I’ll acknowledge it, and then we’ll go and exchange.” President Xi was going to come over to the US for a visit so they could sit together and they want to do it outside the White House, and so we agreed on Mar-a-Lago, which I also thought was good because President Trump always felt much more comfortable when he was hosting at his properties, and he just felt at home. And so, he liked having people as his guests and he loved it. He always felt really relaxed and it was great. So, that was really what we did.
Segment 3584: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12205, Text: Then, the Chinese come over, very much anticipated visit. And it was incredible, so they were supposed to sit together for 15 minutes, and they sent about an hour and a half together. And during that meeting with President Trump, I said, “Look, let’s just set some ground rules to this relationship. Let’s just not talk about Taiwan. Just don’t do anything I don’t want it on the table. If it does, I’m going to have to do harsh things. I don’t want this to be a problem for four years. We’ve got bigger issues.” They basically just, again, you notice four years of Trump administration: no Taiwan talk whatsoever. It was a non-issue. Started talking about the trade issues. They spent a lot of time on North Korea. President Trump was trying to get the perspective from President Xi about North Korea because that was again considered from Obama, the biggest national security issue that we faced at the time, and they just had a good feeling for each other.
Segment 3585: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12253, Text: It also helped that my wife and I, we actually had a Chinese nanny and teacher in our house, and our kids learned fluent Mandarin, and our daughter actually opened when President Xi and President Trump were together with Melania and with Madame Peng, my daughter actually sang them a couple of Chinese songs. And I thought that was a nice way to show we’re tough, but we respect your culture because the Chinese have an incredible culture that goes back thousands of years: they’re very proud in how they do it. And I think that sign of respect also set things off in a very warm way for President Trump say, “My granddaughter speaks Chinese and we’re showing you the respect,” which I think is very important, and he did have respect for them.
Segment 3586: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12299, Text: The next part about the visit, obviously we had a lot of discussions on trade, but the part that was probably most impactful to me was President Xi basically did an hour monologue at lunch where he just went through Chinese history from his perspective, and he talked about with particular emphasis on the Treaty of Unequals and then, the 100 years of humiliation. And then, you go through from Mao all the way to today and you had China coming back and rising, and you could tell that he learned the lessons from the past and was very committed to seeing China go through. So, that was a different time, right? So, China today is different than it was in 2017. In 2017, I remember President Xi was at Davos and he was vetted by all the top business people in the world as, “Donald Trump was the threat to the global world order. President Xi was the champion of free trade and the biggest champion of environmentalism and fighting for climate change.” And what occurred was President Trump came in and basically said, “I think China has not been following the rules-based order,” took very drastic approaches with tariffs. Every time he would do the tariffs again, I had Mnuchin, our treasury sector come to Ivanka at my house, “If he does this, this is going to crash the whole economy,” and by the way, he believed it. These were things that people were telling him would be very tough to do. President Trump had a gentleman named Ambassador Lighthizer, Robert Lighthizer. He was really the tip of the spear on all of our trade negotiations. He worked very well with Secretary Mnuchin, and we ended up increasing tariffs to numbers that hadn’t even been thought could happen. So we did the first round of tariffs, then the Chinese came back and retaliated very surgically trying to hit us in all the areas that politically would’ve been difficult. And what Trump did was instead of backing down, he took some of the revenue from the tariffs, gave it to the farmers and said, “I know that this is going to hurt your business, but I’m going to make sure you guys are made whole,” and then he doubled down, and basically went back at the Chinese with even more tariffs.
Segment 3587: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12423, Text: So, what we watched over a year and a half was probably the biggest hand of poker that was ever played, and it was an amazing experience to be a part of it. And the role I played was really working for Secretary Mnuchin and Ambassador Lighthizer as a back channel with the Chinese to make sure we can just deescalate things and get to solutions in the best way possible. So anyway, it was a fascinating time, but if you think about the global awareness of the bad practices that China was putting in place today versus what they were in 2016, I think one of President Trump’s most successful policies was shifting the way the entire world understood the threat of China, and then putting in place the beginning of a regime to try and rebalance the world so that we could have more economic parity.
Segment 3588: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12475, Text: You mentioned to me the book, The Hundred-Year Marathon by Michael Pillsbury when we discussed China, and I’ve gotten a chance to read parts of it, and I highly recommend people read it’s definitely an eye-opening perspective. I don’t know if I agree with all of it, I don’t know if you agree with all of it, but it gives a very intense perspective on China, and you said it was instructive to how you thought how Donald Trump thought about China. Can you describe the main thesis of the book, and maybe with a hopeful view how it’s possible to have a trajectory of these two superpowers working together in the 21st century, versus fighting against each other?
Segment 3589: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12522, Text: Perfect. So, it’s a very big book, and I think it’s a book definitely worth reading. Michael is tremendous, he speaks fluent Mandarin, and so he spent a lot of time researching to do the book, so I highly recommend it to everyone. And it was considered more of a fringe perspective in 2016, but it really, I think came to represent the underpinning of what the collective thought was of the Trump administration. And maybe you could argue that it was even more cynical. The whole thesis of the book was that China from 1949 to 2049 was working to reclaim their position as the global leader. So, you had the Chinese empire. One of the things, I don’t know if it’s from this book or a different book that I read that spoke about how in the late 1700s, basically the Emperor of China was offered some of the industrial capability from England, which was basically now becoming the Industrial Revolution, and basically, “No, we’re fine. We’re the great Chinese empire. We don’t need any of these things. We’re better than that.”
Segment 3590: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12586, Text: And by rejecting that, the rest of the world got stronger, China remained weaker. Then, you had the Opium Wars, the Chinese had big opium problems through all the trade back and forth. And then, China from about 1840 to the 1940, 100 years where they, after all these treaties, were really a second class country. And so then, you have the People’s Revolution that comes in, and he talks about how China very strategically, as a very poor country, would fight their way back and build brick by brick. And he proffers in the book that Nixon didn’t go to China and open China, it was China that actually went to Nixon and was able to use Nixon in order to open up. And then, they talk about how under Carter, they were able to get the US to contribute to a lot of their, they were able to start borrowing the US know-how from our university systems, from our medical, from our science, from our research.
Segment 3591: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12638, Text: And the whole notion that was the conventional thinking of American leaders was that the more we helped China advance, the more they would become a free market economy, and it was a great market. The only difference was was that they weren’t allowing us access, they were making our companies basically give them all of their technical knowledge, they were stealing our intellectual property, they were doing espionage to steal a lot of the patents, they were just ignoring our patents and they weren’t following any of the rules of international trade. Then, they started becoming the world’s manufacturing hub. They basically came the world’s factory, and then they started this whole initiative called the Belt and Road Initiative in order to start locking in their lines of trades: they were buying up all the ports everywhere. They were building railways, thinking, “How do we lock in our distribution so that we can maintain the dominance as the world’s global factory?”
Segment 3592: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12686, Text: And so, it was a brilliant long-term plan that they were doing. And by raising awareness, by putting the tariffs, Trump slowed them down a lot. The real question is, if they actually did achieve this full objective of becoming the world dominant country, what they would’ve done with it, whether they would’ve been nefarious or not. I think from my perspective, even with some of the divisions and issues we have now in America, I still would rather an American-led world order than a Chinese-led world order. But the notion was is that they were playing a very zero-sum game and really going to be the dominant leader in this new world order. So that really framed the perspective, and the Chinese were always fearing, “Is Trump trying to stop our rise?”, and you have a great book also by Graham Allison that he writes about, are we destined for war between us and China? And he goes through different historical times where you have a power and a rising superpower.
Segment 3593: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12744, Text: And I think more than half the time it ends up leading to war. So the question is, what’s going to happen here? And I do think that Trump’s perspective, and this is my interpretation, because everything was always tactical day-to-day, and he was unpredictable to the Chinese, which they couldn’t deal with, and he was unpredictable even to his team sometimes because he was playing it day by day and issue by issue, and always changing and adjusting, which is how an entrepreneur thinks. He respected the job they did by building their country: they moved 300 million people out of poverty into the middle class. They did it at the expense of a lot of other countries throughout the world, especially America.
Segment 3594: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12781, Text: But Trump says, “Look, stupid politicians made deals. I respect China for doing what they did, but what I want to do is I want to change the paradigm so that for the next 20 years we can maintain our advantage over them, we can maintain our competitive dynamic,” and his general view was that America is the best private sector in the world, we have a lot of the best minds in the world, and if we can just have a level playing field with set rules, then America should be able to outperform. And so, that’s really what we were trying to do: we were trying to get rid of some of their state subsidies, make them follow some of these international rules of trade, and not allowing them to do predatory investments that then undercut different industries that we had ,so that they can have global market dominance or monopolies on different industries and then have pricing power, but also geopolitical power.
Segment 3595: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12834, Text: So, one of the examples that people talk about now is China for the last 20 years was very advanced on seeing this electrification trend. They subsidized solar panels, a lot of the American solar panel players were put out of business. So now, I think it’s 90% plus of solar panels in the world are manufactured in China, and then all the rare earths that you need in order to make these solar panels and to make these electric vehicles, China’s bought up most of them and a lot of the refining capacities in China. So, thinking through strategically, how do we create an even playing field so that we’re not at the mercy of them, and how you can have a rules-based world order, that was really the thought of what we were trying to work towards.
Segment 3596: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12880, Text: There’s this SNL skit where Jimmy Fallon plays you, and you’re walking into the Oval Office looking cool, wearing shades and a bulletproof vest to the song Unbelievable by EMF, I don’t know if you’ve seen it, but it’s pretty epic. And then Trump says that, “You’ve traveled the world representing the administration, but no one has ever heard you speak,” so there’s a lot of questions I can ask about that. But one of them is, can you introspect why you choose this low-key approach of operating behind the scenes and not speaking much to the public, at least at the time? You’ve spoken a little bit more, and today you’ve spoken for a really long time, which I deeply appreciate.
Segment 3597: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12923, Text: No, it’s been a pleasure to do this and thank you for the opportunity to talk about these things. And so, that was a really funny skit. And it’s funny, the thing I got made fun of the most for that was the wardrobe. And that came from after three months in the administration, we were having dinner with all the generals and they were updating us on the war with ISIS. And General Dunford said to me after, “Look, the president can’t come to see how we’re fighting this war, but I’d like to invite you to come with me to Iraq and come see. And would you come with me?” I said, “You know what? That’s great.” I always learned in business that you can’t make decisions from just an ivory tower. You have to go to the front lines and see what’s actually happening. So I said, “No problem. I’d love to go.” Meanwhile, two days before I’m about to go, the doc from the White House stops by my office and says, “We need to get your blood type.” I said, “Why do you need my blood type for this?”
Segment 3598: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=12971, Text: “You’re going to an active war zone.” I’m like, “Okay, so I guess I’m going to a war zone,” I didn’t really think this thing fully through. I get on the plane with Dunford and we land in Iraq and he looks like GI Joe. He’s a great general, he’s very well respected in the military, and we go in and we get on Black Hawk helicopter. They said, “You know what? Today’s a nice day, let’s take the sides off,” and so I get on the plane and there’s a military service officer who then takes a machine gun, locks it into a thing, takes the bullets, puts them into the gun, and is sitting there saying, “We’re ready to go,” and then I’m looking out and there’s like three other helicopters with guys. One was an Osprey with a guy, buckled in also with a machine gun looking out, we take off, and we’re flying over Baghdad from the airport to the embassy. And as we’re going, I’m sitting in an open air helicopter with the chairman of the joint chiefs of staff, guys with machine guns everywhere-
Segment 3599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13030, Text: This is a new experience for you. You haven’t experienced this previously.
Segment 3600: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13033, Text: I would say slightly. I was doing real estate like three months ago and now I’m flying over Iraq and the chairman says, “That’s Saddam Hussein’s palace,” and I looked down, there’s a big bomb right through the middle. Then, you see the area with the two swords in the hands. I’m saying to myself like, “How the hell did I get here? What is happening?” So meanwhile, we end up going to the front lines to be with the Iraqi military, which the US military is working closely with. And I had a meeting that night with the President of Iraq. And so I wore, what are you wear to the front lines in a battle zone and also to meet the president. So I put a sports jacket on, we land at the front line and they give me a bulletproof vest that says, “Kushner,” on it. I tape it, I put it on, I go out, I cover the N-E-R, so it just said, “Kush,” and I went and I didn’t realize they were taking pictures. And so-
Segment 3601: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13080, Text: I think the picture looks pretty epic. You with sunglasses, I think I love it.
Segment 3602: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13083, Text: So anyway, so that was the funny story behind that. And then actually, my brother was at some society event in New York and he ran into Jimmy Fallon, so the two of them took a selfie together. And Josh writes me, he says, “Hanging out with my older brother in New York. I’m trying to explain to him what your voice sounds like,” so it was good. So, that was a funny one.
Segment 3603: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13103, Text: But I think just being behind the scenes for me just gave me more maneuverability in the sense that, again, it goes back to trust and people knowing that I wasn’t going to try to publicize the things they were telling me. I think it just gave me more ability to operate that way. And I also realized too, communicating is a very important skill. Luckily in Washington, there’s no shortage of amazing communicators. I think there were a lot of people who were much better than me than being communicators. So I was very happy that they were willing to do it because it wasn’t something that I had a lot of experience with or necessarily I thought I was very good at. And so, I just did my job and just focused on getting things done.
Segment 3604: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13146, Text: Let me ask you, you have a very interesting life. If you were to give advice to young folks on how to have such an impactful life, what would you say? Career and life, how to have a successful career and a successful life?
Segment 3605: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13165, Text: Number one is I would say you just have to work hard at everything you do. Number two, I would say never stop learning and always try to say yes more than you should, go out of your comfort zone. And I think just, you’ve got to work hard at everything you do. And if you’re going to take something on, do it the best you can. One of the lessons I write about in the book from my father was I remember I was going for a job interview and he asked me, he says, “Well, what time are you leaving to the job interview?” It was at nine o’clock. I said, “I’ll leave at eight o’clock.” He says, “Well, what if there’s traffic?”, I said, “Dad, I’ve done this drive 1,000 times. There’s never traffic.” He said, “What if there’s an accident?”, I said, “I can’t control that.” He said, “Jared, the only excuse you ever have for being late is that you didn’t leave early enough.”
Segment 3606: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13211, Text: And I just think it’s something where if you want to accomplish something, a lot of people I hear they complain about what other people do or why it’s hard or why it’s impossible. And again, I say this as somebody who’s been so blessed with so many things in life, but when I’ve had challenges or things I’ve wanted to achieve, I just focus and say, ” What can I do?”, and I’ll read everything I can get my hands on. If the door closes, I’ll try the window. If the window closes, I’ll try the chimney. If the chimney closes, I’ll try to dig a tunnel. It’s just, if you want to accomplish something, you just have to go at it.
Segment 3607: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13243, Text: And I think the most important thing I’ll say, sorry, I’m thinking my way into this answer is just do the right thing. I think that’s also right. And I saw that in my career in be good to people, be honest, do the right thing. And if you do that, I think long-term, it does pay off. Maybe not in politics, but in the world at large, it does. And my hope is in politics it will as well.
Segment 3608: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13268, Text: I wonder if you can comment on your process of learning in general because you took on so many new interesting problem, and approached them with a first principles approach. So, what was your source of information? Because you didn’t seem to be listening to the assumptions of the prior experts, you were just taking on the problem in a very pragmatic perspective. So, how’d you learn about the Middle East? How did you learn about China? How did you learn about Mexico? Prison reform? All of this that you’ve taken on and were extremely effective at?
Segment 3609: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13308, Text: It really started with just talking to people. I would try to reach out to people who had been involved in different things, and ask them what they did, what they thought of the problem, who they thought was smart on it, what they read that helped them get a better understanding, why they think something had failed. And then, I would just read voraciously on every topic. Washington, it was harder to get advice from humans because I found humans had this weird tendency to talk to the media. And so, I talked to somebody, and I’d ask advice, and then the next thing I know is the Washington Post would call and say, “Jared’s an idiot, doesn’t know what he’s doing, and he’s even going to this person to get advice.” I’m like, “Yeah, I’m asking everyone,” so books really became an amazing guide for me.
Segment 3610: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13352, Text: Ivanka, she’s an incredible researcher, she’s just voracious. And so, she gave me some of my best books and some incredible advice as well. But that was really the process. And then, I think that was kind of the first stage. And then, the second stage was just constant iteration and readjusting plan as you continue to get more learning. And one story I tell in the book as well is that on my first trip to the Middle East where I met with Mohamed bin Zayed, who I spoke about earlier, the ruler of UAE, I spent two hours with him asking him questions and really going through the Israeli-Palestinian issue, the Israeli-Arab issue. And he said to me at the end of the meeting, he says, “Jared, I think you’re going to make peace here in the Middle East,” and I was shocked because first of all, he was at the time I think one of the most respected leaders in the region, somebody who I found to be very wise, and super thoughtful, and experienced.
Segment 3611: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13403, Text: And I said to him, “Why do you say that?”, I was flattered, obviously, but not certain why he was saying that based on the fact that I didn’t know what my plan was, I didn’t know what I was going to do and I had no pathway to make peace. And he said, “Well, the US usually sends one of three different kinds of people to come see me. The first are people who come and they fall asleep in meetings. The second are people who come and they basically read me notes but have no ability to interact on the message they’re there to convey. And then, the third have been people who have come to convince me to do things that aren’t in my interests. You’re the first person who’s ever come here and has just asked questions. Why have you done that?”
Segment 3612: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13445, Text: I said, “Because I figure this problem’s been going on for a long time, you live here, I’ll be gone at some point. You’re going to have to live with the consequences of whatever my work is, and the US has a lot of power. And my question is, what would you do if you were me and how would you approach this? And help me think about it.” And again, I wasn’t going to then take his plan and then execute it, but I thought it’d be very provocative to understand from the people in the region and instructive how they would use the resource and the power that the US had to solve the problems that were having significant impact on their lives.
Segment 3613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13482, Text: Yeah, there’s a lot of power to the simplicity of that human approach where you’re just listening.
Segment 3614: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13493, Text: And one of my wishes for society as I leave government: I was living on the Upper East Side in a very liberal echo chamber. I then traveled the country. I met so many people who I never would’ve met otherwise, on the conservative side, on the independent side, on so many different issues, I think that people benefit, if you have such a strong point of view, I would follow the John Stewart Mill marketplace of ideas and find people who disagree with you, and don’t call them names, don’t say they’re a bad person. Say, “I want to understand why you feel the way you do.” Let’s have conversations in this country, and I think that that’s probably going to be our best way to work through the issues that we have currently.
Segment 3615: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13534, Text: When you zoom out and look at the 21st century from a human history perspective, across the timescale of many decades, maybe centuries, what gives you hope about human civilization? Everything you’ve seen: you’ve traveled the world, you’ve talked to some of the most powerful and influential people, and you look at the future, what gives you hope about this little planet of ours?
Segment 3616: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13557, Text: What gives me the most hope is that anything’s possible. If there’s one lesson that I took from my time in government, it’s that people coming together to try to make tomorrow different than yesterday can succeed. And if the right people in the right places focus on the right ideas, I think the advancement that we can have for human history and for society can be tremendous. And I think that right now, I see we’re at a place in society where there’s a lot of what I call squabbles between countries, which are really man versus man issues. And those are as old as time, right? We’ve been fighting about borders or religion or who wronged somebody 100 or 1,000 years ago. And these are what I call more tribal battles. But I do think that as we advance with artificial intelligence, as energy becomes cheaper and it’s more readily available, I think we’re going to have massive industrialization, I think we’re going to have massive advancement.
Segment 3617: Speaker: , Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13612, Text: I think in medical and science, we’re going to have cures for diseases. We have the potential in 10, 20 years from now to enter a dawn for humanity that could be incredible: we could become multi-planetary, we can explore the wonders of the world, we can find things we didn’t know. So, I think that if we put our energy towards finding these advancements that will improve the lives of everyone on this planet instead of figuring out ways to have these tensions between us, that for me, is the most optimistic case for what’s possible. And the reason why I believe it’s possible is because somebody with no experience, somebody who all I really had was the faith of a leader. And I had the courage to try, and I went out there with other people, and we took on some of the most hopeless, impossible problems, and we succeeded. And if we were able to do that, then everyone else should be able to do that as well.
Segment 3618: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13673, Text: Well, Jared, thank you for having the courage to try. Thank you for your friendship, for your kindness, most importantly, for your book recommendations. And thank you for talking today. This was fascinating and eye-opening. I hope to have many more conversations like this.
Segment 3619: Speaker: Jared Kushner, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13688, Text: Thank you very much, Lex.
Segment 3620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=co_MeKSnyAo&t=13690, Text: Thank you for listening to this conversation with Jared Kushner. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Mahatma Gandhi: an eye for an eye will only make the whole world blind. Thank you for listening and hope to see you next time.
Segment 3621: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=0, Text: The following is a conversation with Mark Zuckerberg, Inside the Metaverse. Mark and I are hundreds of miles apart from each other in physical space, but it feels like we’re in the same room because we appear to each other as photorealistic Kodak Avatars in 3D with spatial audio. This technology is incredible and I think it’s the future of how human beings connect to each other in a deeply meaningful way on the internet. These avatars can capture many of the nuances of facial expressions that we humans use to communicate and motion to each other. Now, I just need to work on upgrading my emotion expressing capabilities of the underlying human. This is the Lex Fridman Podcast. And now, dear friends, here’s Mark Zuckerberg. This is so great. Lighting change? Wow.
Segment 3622: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=76, Text: Yeah, we can put the light anywhere.
Segment 3623: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=79, Text: And it doesn’t feel awkward to be really close to you.
Segment 3624: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=82, Text: No, it does. I actually moved you back a few feet before you got into the headset. You were right here.
Segment 3625: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=87, Text: I don’t know if people can see this, but this is incredible. The realism here is just incredible. Where am I? Where are you, Mark? Where are we?
Segment 3626: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=99, Text: You’re in Austin, right?
Segment 3627: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=101, Text: No. I mean this place. We’re shrouded by darkness with ultra realistic face, and it just feels like we’re in the same room. This is really the most incredible thing I’ve ever seen. And sorry to be in your personal space. We have done jujitsu before.
Segment 3628: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=118, Text: Yeah. I was commenting to the team before that I feel like we’ve choked each other from further distances than it feels like we are right now.
Segment 3629: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=128, Text: This is just really incredible. I don’t know how to describe it with words. It really feels like we’re in the same room.
Segment 3630: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=137, Text: Yeah.
Segment 3631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=137, Text: It feels like the future. This is truly, truly incredible. I just wanted to take it in. I’m still getting used to it. It’s you, it’s really you, but you’re not here with me. You’re there wearing a headset and I’m wearing a headset. It’s really, really incredible. Can you describe what it takes currently for us to appear so photo realistic to each other?
Segment 3632: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=164, Text: Yeah. So, for background, we both did these scans for this research project that we have at Meta called Kodak Avatars. And the idea is that instead of our avatars being cartoony and instead of actually transmitting a video, what it does is we’ve scanned ourselves and a lot of different expressions, and we’ve built a computer model of each of our faces and bodies and the different expressions that we make and collapsed that into a Kodak that then when you have the headset on your head, it sees your face, it sees your expression, and it can basically send an encoded version of what you’re supposed to look like over the wire. So, in addition to being photorealistic, it’s also actually much more bandwidth efficient than transmitting a full video or especially a 3D immersive video of a whole scene like this.
Segment 3633: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=227, Text: And it captures everything. To me, the subtleties of the human face, even the flaws, that’s all amazing. It makes it so much more immersive. It makes you realize that perfection isn’t the thing that leads to immersion. It’s the little subtle flaws like freckles and variations in color and just…
Segment 3634: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=251, Text: Wrinkles.
Segment 3635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=252, Text: … all stuff about noses.
Segment 3636: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=252, Text: Asymmetry.
Segment 3637: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=254, Text: Yeah, asymmetry, and just the corners of the eyes, what your eyes do when you smile, all that kind of stuff.
Segment 3638: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=260, Text: Eyes are a huge part of it.
Segment 3639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=262, Text: It’s just incredible.
Segment 3640: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=263, Text: There’s all these studies that most of communication, even when people are speaking, is not actually the words that they’re saying. It’s the expression and all that. And we try to capture that with the classical expressive avatar system that we have. That’s the more cartoon designed one. You can put those expressions on those faces as well. But there’s obviously a certain realism that comes with delivering this photo realistic experience that, I don’t know, I just think it’s really magical. This gets to the core of what the vision around virtual and augmented reality is, of delivering a sense of presence as if you’re there together no matter where you actually are in the world. This experience I think is a good embodiment of that, where we’re in two completely different states halfway across the country, and it looks like you’re just sitting right in front of me. It’s pretty wild.
Segment 3641: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=317, Text: Yeah. I’m almost getting emotional. It feels like a totally fundamentally new experience. For me to have these kinds of conversations with loved ones, it would just change everything. Maybe just to elaborate, I went to Pittsburgh and went through the whole scanning procedure, which has so much incredible technology, software and hardware, going on, but it is a lengthy process. So what’s your vision for the future of this in terms of making this more accessible to people?
Segment 3642: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=350, Text: It starts off with a small number of people doing these very detailed scans. That’s the version that you did and that I did, and before there were a lot of people who we’ve done this a scan for, we probably need to over collect expressions when we’re doing the scanning because we haven’t figured out how much we can reduce that down to a really streamlined process and extrapolate from the scans that have already been done. But the goal, and we have a project that’s working on this already, is just to do a very quick scan with your cell phone where you just take your phone, wave it in front of your face for a couple of minutes, say a few sentences, make a bunch of expressions, but, overall, have the whole process just be two to three minutes and then produce something that’s of the quality of what we have right now.
Segment 3643: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=404, Text: So I think that that’s one of the big challenges that remains, and right now we have the ability to do the scans if you have hours to sit for one. And with today’s technology, you’re using a Meta headset that exists. It’s a product that’s for sale now. You can drive these with that, but the production of these scans in a very efficient way is one of the last pieces that we still need to really nail. And then, obviously, there’s all the experiences around it. Right now we’re sitting in a dark room, which is familiar for your podcast, but I think part of the vision for this over time is not just having this be a video call. That’s fine, it’s cool, it feels like it’s immersive, but you can do a video call on your phone.
Segment 3644: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=455, Text: The thing that you can do in the Metaverse that is different from what you can do on a phone is doing stuff where you’re physically there together and participating in things together. And we could play games like this. We could have meetings like this in the future. Once you get mixed reality and augmented reality, we could have Kodak Avatars like this and go into a meeting and have some people physically there and have some people show up in this photorealistic form superimposed on the physical environment. Stuff like that is going to be super powerful. So we’ve got to still build out all those applications and the use cases around it. But I don’t know, I think it’s going to be a pretty wild next few years around this.
Segment 3645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=497, Text: I’m actually almost at a loss for words. This is just so incredible. This is truly incredible. I hope that people watching this can get a glimpse of how incredible it is. It really feels like we’re in the same room. I guess there’s an uncanny valley that seems to have been crossed here. It looks like you.
Segment 3646: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=518, Text: There’s still a bunch of tuning that I think we’ll want to do where different people emote to different extents, so I think one of the big questions is, when you smile, how wide is your smile? And how wide do you want your smile to be? And I think getting that to be tuned on a per person basis is going to be one of the things that we’re going to need to figure out. It’s like to, what extent do you want to give people control over that? Some people might prefer a version of themselves that’s more emotive in their avatar than their actual faces. So, for example, I always get a lot of critique and shit for having a relatively stiff expression. I might feel pretty happy, but just make a pretty small smile.
Segment 3647: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=571, Text: So maybe, for me, it’s like I’d want to have my avatar really be able to better express how I’m feeling than how I can do physically. So I think that there’s a question about how you want to tune that, but, overall, yeah, we want to start from the baseline of capturing how people actually emote and express themselves. And I think the initial version of this has been pretty impressive. And like you said, I do think we’re beyond the uncanny valley here where it does feel like you. It doesn’t feel weird or anything like that.
Segment 3648: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=605, Text: That’s going to be the meme that the two most monotone people are in the Metaverse together, but I think that actually makes it more difficult. The amazing thing here is that the subtleties of the expression of the eyes, people say I’m monotone and emotionless, but I’m not. It’s just maybe my expression of emotion is more subtle, usually, with the eyes. And that’s one of the things I’ve noticed is just how expressive the subtle movement of the corners of the eyes are in terms of displaying happiness or boredom or all that stuff.
Segment 3649: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=639, Text: I am curious to see, just because I’ve never done one of these before, I’ve never done a podcast as one of these Kodak Avatars, and I’m curious to see what people think of it. Because one of the issues that we’ve had in some of the VR and mixed reality work is it tends to feel a lot more profound when you’re in it than the 2D videos capturing the experience. So I think that this one, because it’s photorealistic, may look as amazing in 2D for people watching it as it feels, I think, to be in it. But we’ve certainly had this issue where a lot of the other things, it’s like you feel the sense of immersion when you’re in it that, that doesn’t quite translate to a 2D screen. But I don’t know, I’m curious to see what people think.
Segment 3650: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=681, Text: Yeah, I’m curious to see if people could see that my heart is actually beating fast now. This is super interesting that such intimacy of conversation could be achieved remotely. I don’t do remote podcasts for this reason, and this breaks all of that. This feels like just an incredible transition to something else, the different communication. It breaks all barriers, like geographic physical barriers. You mentioned, do you have a sense of timeline in terms of how many difficult things have to be solved to make this more accessible to like scanning with a smartphone?
Segment 3651: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=722, Text: Yeah. I think we’ll probably roll this out progressively over time. So it’s not going to be like we roll it out and one day everyone has a Kodak Avatar. We want to get more people scanned and into the system, and then we want to start integrating it into each one of our apps, making it so that I think that for a lot of the work style things, productivity, I think that this is going to make a ton of sense. In a lot of game environments, this could be fine, but games tend to have their own style where you almost want to fit more with the aesthetic style of the game. But I think for doing meetings, one of the things that we get a lot of feedback on Workrooms where people are pretty blown away by the experience and this feeling that you can be remote but feel like you’re physically there around a table with people, but then we get some feedback that people have a hard time with the fact that the avatars are so expressive and don’t feel as realistic in that environment.
Segment 3652: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=778, Text: So I think something like this could make a very big difference for those remote meetings. And especially with Quest Three coming out, which is going to be the first mainstream mixed reality product where you’re really taking digital expressions of either a person or objects and overlaying them on the physical world, I think the ability to do remote meetings and things like that where you’re just remote hang sessions with friends, I think that that’s going to be very exciting. So rolling it out over the next few years, it’s not ready to be a mainstream product yet, but we we’ll keep tuning it and keep getting more scans in there and rolling it out and into more of the features. But, yeah, definitely in the next few years you’ll be seeing a bunch more experiences like this.
Segment 3653: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=824, Text: Yeah, I would love to see some celebrities scanned and some non-celebrities and just more people to experience this. I would love to see that. My mind blown. I’m literally at a loss for words because it’s very difficult to just convey how incredible this is, how I feel the emotion, how I feel the presence, how I feel the subtleties of the emotion in terms of work meetings or in terms of podcasts. This is awesome. I don’t even need your arms or legs.
Segment 3654: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=857, Text: Well, we got to get that. That’s its own challenge.
Segment 3655: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=862, Text: Okay.
Segment 3656: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=862, Text: And part of the question is also, so you have the scan, then it takes a certain amount of compute to go drive that, both for the sensors on the headset and then rendering it. So one of the things that we’re working through is, what is the level of fidelity that is optimal? You could do the full body in a Kodak and that can be quite intensive, but one of the things that we’re thinking about is, all right, maybe you can stitch a somewhat lower fidelity version of your body and have the major movements, but your face is really the thing that we have the most resolution on in terms of being able to read and express emotions. Like you said, if you move your eyebrows a millimeter, that really changes the expression and what you’re emoting whereas moving your arm like an inch probably doesn’t matter quite as much. So, yes, I think that we do want to get all of that into here, and that’ll be some of the work over the next period as well.
Segment 3657: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=927, Text: So you mentioned Quest Three. That’s coming out. I’ve gotten a chance to try that too. That’s awesome. How’d you pull off the mix? So it’s not just virtual reality, it’s mixed reality.
Segment 3658: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=937, Text: I think it’s going to be the first mainstream mixed reality device. Obviously, we shipped Quest Pro last year, but it was $1,500. And part of what I’m super proud of is we try to innovate not just on pushing the state-of-the-art and delivering new capabilities, but making it so it can be available to everyone. And we have this, and it’s coming out, it’s $500, and in some ways, I think the mixed reality is actually better in Quest Three than what we’re using right now in Quest Pro. And I’m really proud of the team for being able to deliver that kind of an innovation and get it out. But some of this is just software you tune over time and get to be better. Part of it is you put together a product and you figure out, what are the bottlenecks in terms of making it a good experience?
Segment 3659: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=986, Text: So we got the resolution for the mixed reality cameras and sensors to be multiple times better in Quest Three, and we just figured that, that made a very big difference when we saw the experience that we were able to put together for Quest Pro. And part of it is also that Qualcomm just came out with their next generation chip set for VR and MR that we worked with them on, on a custom version of it. But that was available this year for Quest Three and it wasn’t available in Quest Pro. So in a way, Quest Three, even though it’s not the Pro product, actually has a stronger chip set in it than the Pro line at a third of the cost. So I’m…
Segment 3660: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1020, Text: …line at a third of the cost. So I’m really excited to get this in people’s hands. It does all the VR stuff that Quest 2 and the others have done too. It does it better because the display is better and the chip is better. So you’ll get better graphics. It’s 40% thinner, so it’s more comfortable as well. But the MR is really the big capability shift. And part of what’s exciting about the whole space right now is this isn’t like smartphones, where companies put out a new smartphone every year, and you can almost barely tell the difference between that and the one the year before it.
Segment 3661: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1056, Text: For this, each time we put out a new headset, it has a major new capability. And the big one now is mixed reality. The ability to basically take digital representations of people or objects and superimpose them on the world. And basically, there’s a, one version of this is you’re going to have these augments or holograms and experiences that you can bring into your living room or a meeting space or office.
Segment 3662: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1086, Text: Another thing that I just think is going to be a much simpler innovation, is that there are a lot of VR experiences today that don’t need to be fully immersive. And if you’re playing a shooter game or you’re doing a fitness experience, sometimes people get worried about swinging their arms around, like, am I going to hit a lamp or something and am I going to run into something? So having that in mixed reality, actually, it’s just a lot more comfortable for people. You kind of still get the immersion and the 3D experience and you can have an experience that just wouldn’t be possible in the physical world alone. But by being anchored to and being able to see the physical world around you, it just feels so much safer and more secure. And I think a lot of people are really going to enjoy that too. So yeah, I’m really excited to see how people use it. But yeah, Quest 3 coming out later this fall.
Segment 3663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1133, Text: And I got to experience it with other people sitting around and there’s a lot of furniture. And so you get to see that furniture, you get to see those people, and you get to see those people enjoy the ridiculousness of you swinging your arms. I mean, presumably their friends of yours, even if they make fun of you, there’s a lot of love behind that and I got to experience that. So that’s a really fundamentally different experience than just pure VR with zombies coming out of walls and-
Segment 3664: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1160, Text: Yeah, it’s like someone shooting at you and you hide behind your real couch in order to duck the fire. Yeah.
Segment 3665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1166, Text: It’s incredible how it’s all integrated, but also subtle stuff, like in a room with no windows, you can add windows to it and you can look outside as the zombies run towards you, but it’s still a nice view outside. And so that’s pulled off by having cameras on the outside of the headset that do the pass through. That technology is incredible to do that on a small headset.
Segment 3666: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1190, Text: Yeah, and it’s not just the cameras. You basically, you need multiple cameras to capture the different angles and sort of the three-dimensional space, and then it’s a pretty complex compute problem, an AI problem to map that to your perspective because the cameras aren’t exactly where your eyes are because no two people’s eyes are, you’re not going to be in exactly the same place. You need to get that to line up and then do that basically in real time and then generate something that kind of feels natural and then superimpose whatever digital objects you want to put there.
Segment 3667: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1224, Text: So yeah, it’s a very interesting technical challenge and I think we’ll continue tuning this for the years to come as well. But I’m pretty excited to get this out because I think Quest 3 is going to be the first device like this that millions of people are going to get that’s mixed reality. And it’s only when you have millions of people using something that you start getting the whole developer community really starting to experiment and build stuff because now there are going to be people who actually use it. So I think we got some of that flywheel going with Quest Pro, but I think it’ll really get accelerated once Quest 3 gets out there. So yeah, I’m pretty excited about this one.
Segment 3668: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1261, Text: Plus there’s hand tracking, so you don’t need to have a control, so the cameras aren’t just in the pass through of the entire physical reality around you. It’s also tracking the details of your hands in order to use that for gesture recognition, this kind of stuff.
Segment 3669: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1277, Text: Yeah, we’ve been able to get way further on hand recognition in a shorter period of time than I expected, so that’s been pretty cool. I don’t know, did you see the demo experience that we built around?
Segment 3670: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1289, Text: Piano?
Segment 3671: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1290, Text: Yeah, the piano. Learning to play piano.
Segment 3672: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1292, Text: Yeah, it’s incredible. You’re basically playing piano on a table, and that’s without any controller. And how well it matches physical reality with no latency, and it’s tracking your hands with no latency and it’s tracking all the people around you with no latency. Integrating physical reality and digital reality, obviously that connects exactly to this Codec Avatar, which is in parallel allows us to have ultra realistic copies of ourselves in this mixed reality.
Segment 3673: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1326, Text: So it’s all converging towards an incredible digital experience in the Metaverse. To me, obviously I love the intimacy of conversation, so even this is awesome, but do you have other ideas of what this unlocks, of something like Codec Avatar unlocks in terms of applications, in terms of things we’re able to do?
Segment 3674: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1348, Text: Well, there’s what you can do with avatars overall, in terms of superimposing digital objects on the physical world, and then there’s psychologically, what does having photorealistic do? So I think we’re moving towards a world where we’re going to have something that looks like normal glasses, where you can see the physical world, but you’ll also see holograms. And in that world, I think that there are going to be, not too far off, maybe by the end of this decade, we’ll be living in a world where there are as many holograms when you walk into a room as there are physical objects. And it really raises this interesting question about what are… A lot of people have this phrase where they call the physical world the real world.
Segment 3675: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1399, Text: And I kind of think increasingly, the physical world is super important, but I actually think the real world is the combination of the physical world and the digital worlds coming together. But until this technology, they were sort of separate. It’s like you access the digital world through a screen and maybe it’s a small screen that you carry around or it’s a bigger screen when you sit down at your desk and strap in for a long session, but they’re kind of fundamentally divorced and disconnected. And I think part of what this technology is going to do is bring those together into a single coherent experience of what the modern real world is, which is, it’s got to be physical because we’re physical beings. So the physical world is always going to be super important.
Segment 3676: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1441, Text: But increasingly, I think a lot of the things that we kind of think of can be digital holograms. I mean, any screen that you have can be a hologram, any media, in any book, art. It can basically be just as effective as a hologram, as a physical object. Any game that you’re playing, a board game or any kind of physical game, cards, ping pong, things like that, they’re often a lot better as holograms. Because you could just snap your fingers and instantiate them and have them show up. It’s like you have a ping pong table show up in your living room, but then you can snap your fingers and have it be gone. So that’s super powerful. So I think that it’s actually an amazing thought experiment of like how many physical things we have today that could actually be better as interactive holograms.
Segment 3677: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1492, Text: But then beyond that, I think the most important thing obviously is people. So the ability to have these mixed hangouts, whether they’re social or meetings where you show up to a conference room, you’re wearing glasses or a headset in the very near term, but hopefully by over the next five years, glasses or so. And you’re there physically. Some people are there physically, but other people are just there as holograms and it feels like it’s them who are right there.
Segment 3678: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1523, Text: And also by the way, another thing that I think is going to be fascinating about being able to blend together the digital and physical worlds in this way, is we’re also going to be able to embody AIs as well. So I think you’ll also have meetings in the future where you’re basically, maybe you’re sitting there physically and then you have a couple of other people who are there as holograms, and then you have Bob, the AI, who’s an engineer on your team who’s helping with things, and he can now be embodied as a realistic avatar as well, and just join the meeting in that way. So I think that that’s going to be pretty compelling as well.
Segment 3679: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1563, Text: Okay, so what can you do with photorealistic avatars compared to the more expressive ones that we have today? Well, I think a lot of this actually comes down to acceptance of the technology. And because all of the stuff that we’re doing, I mean, the motion of your eyebrows, the motion of your eyes, the cheeks and all of that, there’s actually no reason why you couldn’t do that on an expressive avatar too. I mean, it wouldn’t look exactly like you, but you can make a cartoon version of yourself and still have it be almost as expressive.
Segment 3680: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1598, Text: But I do think that there’s this bridge between the current state of most of our interactions in the physical world and where we’re getting in the future with this kind of hybrid, physical and digital world, where I think it’s going to be a lot easier for people to take some of these experiences seriously with the photorealistic avatars to start. And then I’m actually really curious to see where it goes longer term. I could see a world where people stick to the photorealistic and maybe they modify them to make them a little bit more interesting, but maybe fundamentally, we like photorealistic things.
Segment 3681: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1634, Text: But I can also see a world that once people get used to the photorealistic avatars and they get used to these experiences, that I actually think that there could be a world where people actually prefer being able to express themselves in kind of non, ways that aren’t so tied to their physical reality. And so that’s one of the things that I’m really curious about. And I don’t know, in a bunch of our internal experiments on this, one of the things that I thought was psychologically pretty interesting is, people have no issues blending photorealistic stuff and not.
Segment 3682: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1670, Text: So for this specific scene that we’re in now, we happen to sort of be in a dark room. I think part of that aesthetic decision I think was based on the way you like to do your podcast, but we’ve done experiences like this, where you have a cartoony background, but photorealistic people who you’re talking to, and people just seem to just think that that is completely normal. It doesn’t bother you, it doesn’t feel like it’s weird.
Segment 3683: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1701, Text: Another thing that we have experienced with, is basically you have a photorealistic avatar that you’re talking to, and then right next to them you have an expressive kind of cartoon avatar. And that actually is pretty normal too. It’s not that weird to basically being interacting with different people in different modes like that. So I’m not sure, I think it’ll be an interesting question, to what extent these photorealistic avatars are a key part of just transitioning from being comfortable in the physical world to this kind of new, modern, real world that includes both the digital and physical, or if this is the long-term way that it stays?I think that there are going to be uses for both the expressive and the photorealistic over time. I just don’t know what the balance is going to be.
Segment 3684: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1748, Text: Yeah. It’s a really good, interesting philosophical question, but to me, in the short term, the photorealistic is amazing. To where I would prefer, you said the workroom, but on a beach with a beer, just to see a buddy of mine remotely on a chair next to me, drinking a beer. I mean that, as realistic as possible, is an incredible experience. So I don’t want any fake hats on him. I don’t want any, just chilling with a friend, drinking beer, looking at the ocean, while not being in the same place together. I mean, that experience is just, it’s a fundamentally, it’s just a high quality experience of friendship. Whatever we seek in friendship, it seems to be present there in the same kind of realism I’m seeing right now. This is totally a game changer. So to me, this is, I can see myself sticking with this for a long time.
Segment 3685: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1801, Text: Yeah, and I mean it’s also, it’s novel. And it’s also a technological feat, right? It’s like being able to pull this off, it’s a pretty impressive and I think to some degree, it’s just this kind of awesome experience.
Segment 3686: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1815, Text: But I’m already, sorry to interrupt, I’m already forgetting that you’re not real. This really-
Segment 3687: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1822, Text: Well, I am real.
Segment 3688: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1823, Text: It’s novel.
Segment 3689: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1824, Text: This is just an avatar version of me.
Segment 3690: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1826, Text: That’s a deep philosophical question. Yes.
Segment 3691: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1829, Text: But here’s some of the… So I put this on this morning and I was like, “All right.” It’s like, okay, my hair is a little shorter in this than my physical hair is right now. I probably need to go get a haircut. And I actually, I did happen to shave this morning, but if I hadn’t, I could still have this photorealistic avatar that is more cleanly shaven, even if I’m a few days in, physically. So I do think that there are going to start to be these subtle questions that seep in where the avatar is realistic in the sense of, this is kind of what you looked like at the time of capture, but it’s not necessarily temporarily accurate to exactly what you look like in this moment. And I think that there are going to end up being a bunch of questions that come from that over time, that I think are going to be fascinating too.
Segment 3692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1882, Text: You mean just the nature of identity of who we are? You know how people do summer beach body? Where people will be, for the scan, they’ll try to lose some weight and look their best and sexiest with the nice hair and everything like that. It does raise the question of if a lot of people interacting with the digital version of ourselves, who are we really? Are we the entity driving the avatar or are we the avatar?
Segment 3693: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1912, Text: Well, I mean, I think our physical bodies also fluctuate and change over time too. So I think there’s a similar question of which version of that are we? And it’s an interesting identity question because all right, it’s like, I don’t know, it’s like weight fluctuates or things like that. I think most people don’t tend to think of themselves as the… Well, I don’t know. It’s an interesting psychological question. Maybe a lot of people do think about themselves as the kind of worst version, but I think a lot of people probably think about themselves as the best version.
Segment 3694: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1946, Text: And then it’s like what you are on a day-to-day basis doesn’t necessarily map to either of those. Yeah, there will definitely be a bunch of social scientists and folks will have to, and psychologists, really, there’s going to be a lot to understand about how our perception of ourselves and others has shifted from this.
Segment 3695: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=1971, Text: Well, this might be a bit of a complicated and a dark question, but one of the first feelings I had experiencing this is I would love to talk to loved ones. And the next question I have is I would love to talk to people who are no longer here that are loved ones. So if you look into the future, is that something you think about? Who people who pass away, but they can still exist in the metaverse, you could still have, talk to your father, talk to your grandfather and grandmother and a mother once they pass away. The power of that experience is one of the first things my mind jumped because it’s like, this is so real.
Segment 3696: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2010, Text: Yeah, I think that there are a lot of norms and things that people have to figure out around that. There’s probably some balance, where if someone has lost a loved one and is grieving, there may be ways in which being able to interact or relive certain memories could be helpful. But then there’s also probably an extent to which it could become unhealthy. And I mean, I’m not an expert in that, so I think we’d have to study that and understand it in more detail. We have a fair amount of experience-
Segment 3697: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2040, Text: … understand it in more detail. We have a fair amount of experience with how to handle death and identity, and people’s digital content through social media already, unfortunately. Unfortunately people who use our services die every day and their families often want to have access to their profiles and we have whole protocols that we go through where there are certain parts of it that we try to memorialize so that way the family can get access to it so that the account doesn’t just go away immediately. But then there are other things that are important, private things that person has. We’re not going to give the family access to someone’s messages, for example.
Segment 3698: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2082, Text: So I think that there’s some best practices, I think from the current digital world that will carry over. But I think that this will enable some different things. Another version of this is how this intersects with AIs because one of the things that we’re really focused on is we want the world to evolve in a way where there isn’t a single AI super intelligence, but where a lot of people are empowered by having AI tools to do their jobs and make their lives better.
Segment 3699: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2119, Text: And if you’re a creator and if you run a podcast like you do, then you have a big community of people who are super interested to talk to you. I know you’d love to cultivate that community and you interact with them online outside of the podcast as well. But I mean, there’s way more demand both to interact with you, and I’m sure you’d love to interact with the community more, but you just are limited by the number of hours in the day.
Segment 3700: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2146, Text: So at some point, I think making it so that you could build an AI version of yourself that could interact with people not after you die, but while you’re here to help people fulfill this desire to interact with you and your desire to build a community. And there’s a lot of interesting questions around that, and obviously, it’s not just in the metaverse. I think we’d want to make that work across all the messaging platforms, WhatsApp, and Messenger, and Instagram Direct. But there’s certainly a version of that where if you could have an avatar version of yourself in the metaverse that people can interact with, and you could define that sort of an AI version where people know that they’re interacting with an AI, that it’s not the physical version of you, but maybe that AI, even if they know it’s an AI, is the next best thing because they’re probably not going to necessarily all get to interact with you directly.
Segment 3701: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2205, Text: I think that could be a really compelling experience. There’s a lot of things that we need to get right about it that we’re not ready to release the version that a creator can build a version of themselves yet, but we’re starting to experiment with it in terms of releasing a number of AIs that people can interact with in different ways. I think that that is also just going to be a very powerful set of capabilities that people have over time.
Segment 3702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2233, Text: So you’ve made major strides in developing these early AI personalities with the idea where you can talk to them across the Meta apps and have interesting, unique kind of conversations. Can you describe your vision there and these early strides and what are some technical challenges there?
Segment 3703: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2254, Text: Yeah. So a lot of the vision comes from this idea that… I don’t think we necessarily want there to be one big super intelligence. We want to empower everyone to both have more fun, accomplish their business goals, just everything that they’re trying to do. We don’t tend to have one person that we work with on everything, and I don’t think in the future we’re going to have one AI that we work with. I think you’re going to want a variety of these. So there are a bunch of different uses. Some will be more assistant oriented. There’s a sort of the plain and simple one that we are building is called just Meta AI. It’s simple. You can chat with it in any of your Threads. It doesn’t have a face.
Segment 3704: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2302, Text: It’s just more vanilla and neutral and factual, but it can help you with a bunch of stuff. Then there are a bunch of cases that are more business oriented. So let’s say you want to contact a small business. Similarly, that business probably doesn’t want to have to staff someone to man the phones, and you probably don’t want to wait on the phone to talk to someone. But having someone who you can just talk to in a natural way who can help you if you’re having an issue with a product or if you want to make a reservation or if you want to buy something online, having the ability to do that and have a natural conversation rather than navigate some website or have to call someone and wait on hold think is going to be really good both for the businesses and for normal people who want to interact with businesses.
Segment 3705: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2351, Text: So I think stuff like that makes sense. Then there are going to be a bunch of use cases that I think are just fun. So I think people are going to… I think there will be AIs that I can tell jokes, so you can put them into chat thread with friends. I think a lot of this, because we’re like a social company. I mean we’re fundamentally around helping people connect in different ways. Part of what I’m excited about is how do you enable these kind of AIs to facilitate connection between two people or more, put them in a group chat, make the group chat more interesting around whatever your interests are, sports, fashion, trivia.
Segment 3706: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2391, Text: Video games. I love the idea of playing. I think you mentioned Baldur’s Gate, an incredible game. Just having an AI that you play together with. I mean, that seems like a small thing, but it could deeply enrich the gaming experience.
Segment 3707: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2408, Text: I do think that AI will make the NPCs a lot better in games too. So that’s a separate thing that I’m pretty excited about. I mean, one of the AIs that we’ve built that just in our internal testing people have loved the most is an adventure text-based like a dungeon master.
Segment 3708: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2430, Text: Nice.
Segment 3709: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2431, Text: I think, part of what has been fun, and we talked about this a bit, but we’ve gotten some real cultural figures to play a bunch of these folks and be the embodiment in the avatar of them. So Snoop Dogg is the dungeon master, which I think is just hilarious.
Segment 3710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2448, Text: Yes. In terms of the next steps of, you mentioned Snoop, to create a Snoop AI, so basically AI personality replica a copy… Or not a copy, maybe inspired by Snoop, what are some of the technical challenges of that? What does that experience look like for Snoop to be able to create that AI?
Segment 3711: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2471, Text: So starting off, creating new personas is easier because it doesn’t need to stick exactly to what that physical person would want, how they’d want to be represented. It’s like it’s just a new character that we created. So Snoop in that case, he’s basically an actor. He’s playing the Dungeon Master, but it’s not Snoop Dogg, it’s whoever the dungeon master is. If you want to actually make it so that you have an AI embodying a real creator, there’s a whole set of things that you need to do to make sure that that AI is not going to say things that the creator doesn’t want and that the AI is going to know things and be able to represent things in the way that the creator would want, the way that the creator would know.
Segment 3712: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2526, Text: So I think that it’s less of a question around having the avatar express them. I mean that I think where it’s like, well, we have our V1 of that that we’ll release soon after Connect. But that’ll get better over time. But a lot of this is really just about continuing to make the models for these AIs that they’re just more and more, I don’t know, you could say reliable or predictable in terms of what they’ll communicate so that way when you want to create the Lex assistant AI that your community can talk to. You don’t program them like normal computers, you’re training them. They’re AI models, not normal computer programs, but you want to get it to be predictable enough so that way you can set some parameters for it.
Segment 3713: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2579, Text: And even if it isn’t perfect all the time, you want it to generally be able to stay within those bounds. So that’s a lot of what I think we need to nail for the creators, and that’s why that one is actually a much harder problem, I think, than starting with new characters that you’re creating from scratch. So that one I think will probably start releasing sometime next year. Not this year, but experimenting with existing characters and the assistant, and games, and a bunch of different personalities and experimenting with some small businesses. I think that that stuff we’ll be ready to do this year. And we’re rolling it out basically right after Connect.
Segment 3714: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2622, Text: Yeah. I’m deeply entertained by the possibility of me sitting down with myself and saying, “Hey, man, you need to stop the dad jokes or whatever.”
Segment 3715: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2632, Text: I think the idea of a podcast between you and AI assistant Lex podcast.
Segment 3716: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2639, Text: I mean, there is just even the experience of an avatar, being able to freeze yourself like basically first mimic yourself, so everything you do, you get to see yourself do it. That’s a surreal experience. That feels like if I was an ape looking in a mirror for the first time, realizing, “Oh, that’s you.” But then freezing that and being able to look around like I’m looking at you, I don’t know how to put it into words, but it just feels like a fundamentally new experience. I’m seeing maybe color for the first time. I’m experiencing a new way of seeing the world for the first time because it’s physical reality, but it’s digital. And realizing that that’s possible, it’s blowing my mind. It’s just really exciting.
Segment 3717: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2690, Text: I lived most of my life before the internet and experiencing the internet and experiencing voice communication, video communication. You think like, “Well, there’s a ceiling to this, but this is making me feel like there might not be, there might be that blend of physical reality and digital reality. That’s actually what the future is.”
Segment 3718: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2712, Text: Yeah, I think so.
Segment 3719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2713, Text: It’s a weird experience. It feels like the early days of a totally new way of living, and there’s a lot of people that kind of complain, “Well, the internet, that’s not reality. You need to turn all that off and go in nature.” But this feels like this will make those people happy. I feel like, because it feels real, the flaws in everything.
Segment 3720: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2737, Text: Yeah. Well, I mean, a big part of how we’re trying to design these new computing products is that they should be physical, but I think that’s a big part of the issue with computers and TVs and even phones is like, “Yeah, maybe you can interact with them in different places.” But they’re fundamentally like you’re sitting, you’re still. I mean, people are just not meant to be that way. I mean, I think you and I have this shared passion for sports and martial arts and doing stuff like that. We’re just moving around. It’s so much of what makes us people is like, you move around. You’re not just like a brain and a tank. It’s where the human experience is a physical one.
Segment 3721: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2777, Text: So it’s not just about having the immersive expression of the digital world, it’s about being able to really natively bring that together. I do really think that the real world is this mix of the physical and the digital. There’s too much digital at this point for it to just be siloed to a small screen, but the physical is too important. So you don’t want to just sit down all day long at a desk. I do think that this is the future. This is, I think the kind of philosophical way that I would want the world to work in the future is a much more coherently, blended, physical and digital world.
Segment 3722: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2816, Text: There might be some difficult philosophical and ethical questions we have to figure out as a society. Maybe you can comment on this. So the metaverse seems to enable, sort of unlock a lot of experiences that we don’t have in the physical world. And the question is what is and isn’t allowed in the metaverse? In video games, we allow all kinds of crazy stuff. And in physical reality, a lot of that is illegal. So where’s that line? Where’s that gray area between video game and physical reality? Do you have a sense of that?
Segment 3723: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2857, Text: I mean, there are content policies and things like that in terms of what people are allowed to create, but I mean, a lot of the rules around physical… I think we try to have a society that is as free as possible, meaning that people can do as much of what they want unless you’re going to do damage to other people and infringe on their rights. And the idea of damage is somewhat different in a digital environment.
Segment 3724: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2882, Text: I mean, when I get into some world with my friends, the first thing we start doing is shooting each other, which obviously we would not do in the physical world because you’d hurt each other. But in a game, it’s just fun. And even in the lobby of a game, it’s not even bearing on the game, it’s just kind of a funny sort of humorous thing to do. So it’s like, is that problematic? I don’t think so because fundamentally you’re not causing harm in that world. So I think that part of the question that I think we need to figure out is what are the ways where things could have been harmful in the physical world that we’ll now be freed from that? And therefore there should be fewer restrictions in the digital world.
Segment 3725: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2928, Text: And then there might be new ways in which there could be harm in the digital world that there weren’t the case before. So there’s more anonymity. It’s when you show up to a restaurant or something, it’s like all the norms where you pay the bill at the end. It’s because you have one identity. And if you stiff them, then life is a repeat game and that’s not going to work out well for you. But in a digital world where you can be anonymous and show up in different ways, I think the incentive to act like a good citizen can be a lot less, and that causes a lot of issues and toxic behavior. So that needs to get sorted out.
Segment 3726: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=2968, Text: So I think in terms of what is allowed, I think you want to just look at what are the damages, but then there’s also other things that are not related to harm, less about what should be allowed and more about what will be possible that are more about the laws of physics. It’s like if you wanted to travel to see me in person, you’d have to get on a plane, and that would take a few hours to get here. Whereas we could just jump in a conference room and put on these headsets and we’re basically teleported into a space where it feels like we’re together.
Segment 3727: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3004, Text: So that’s a very novel experience that it breaks down some things that previously would’ve defied the laws of physics for what it would take to get together. And I think that that will create a lot of new opportunities. One of the things that I’m curious about is there are all these debates right now about remote work or people being together. I think this gets us a lot closer to being able to work physically in different places, but actually have it feel like we’re together. So I think that the dream is that people will one day be able to just work wherever they want, but we’ll have all the same opportunities because you’ll be able to feel like you’re physically together. I think we’re not there today with just video conferencing and the basic technologies that we have, but I think part of the idea is that with something like this, over time, you could get closer to that and that would open up a lot of opportunities, right? Because then people could live physically where they want while still being able to get the benefits of being physically or feeling like you’re together.
Segment 3728: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3060, Text: … to get the benefits of being physically or feeling like you’re together with people at work, all the ways that that helps to build more culture and build better relationships and build trust, which I think are real issues that if you’re not seeing people in person ever. So yeah, I don’t know. I think it’s very hard from first principles to think about all the implications of a technology like this and all the good and the things that you need to mitigate. So you try to do your best to envision what things are going to be like and accentuate the things that they’re going to be awesome and hopefully mitigate some of the downside things. But the reality is that we’re going to be building this out one year at a time. It’s going to take a while, so we’re going to just get to see how it evolves and what developers and different folks do with it.
Segment 3729: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3112, Text: If you could comment, this might be a bit of a very specific technical question, but Llama 2 is incredible. You’ve released it recently. There’s already been a lot of exciting developments around it. What’s your sense about its release and is there a Llama 3 in the future?
Segment 3730: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3135, Text: Yeah, I mean, I think on the last podcast that we did together, we were talking about the debate that we were having around open sourcing Llama 2. And I’m glad that we did. I think at this point there’s the value of open sourcing, a foundation model like Llama 2. It’s significantly greater than the risks in my view. I mean, we spent a lot of time, took a very rigorous assessment of that and red teaming it. But I’m very glad that we released Llama 2. I think the reception has been… It’s just been really exciting to see how excited people have been about it. It’s gotten way more downloads and usage than I would’ve even expected, and I was pretty optimistic about it. So that’s been great.
Segment 3731: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3185, Text: Llama 3, I mean, there’s always another model that we’re training. So for right now, we train Llama 2 and we released it as an open source model. And right now the priority is building that into a bunch of the consumer products, all the different AIs and a bunch of different products that we’re basically building as consumer products. Because Llama 2 by itself, it’s not a consumer product, right? It’s more of a piece of infrastructure that people could build things with.
Segment 3732: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3216, Text: So that’s been the big priority, is continuing to fine tune and just get Llama 2 and the branches that we’ve built off of it ready for consumer products that hopefully hundreds of millions of people will enjoy using those products in billions one day. But yeah, I mean we’re also working on the future foundation models. I don’t have anything new or news on that. I don’t know exactly when it’s going to be ready. I think just like we had a debate around Llama 2 and open sourcing it, I think we’ll need to have a similar debate and process to red team this and make sure that this is safe. And my hope is that we’ll be able to open source this next version when it’s ready too. But we’re not close to doing that this month. I mean, that’s a thing that we’re still somewhat early and working on.
Segment 3733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3277, Text: Well, in general, thank you so much for open sourcing Llama 2 and for being transparent about all the exciting developments around AI. I feel like that’s contributing to a really awesome conversation about where we go with AI. And obviously, it’s really interesting to see all the same kind of technology integrated into these personalized AI systems with the AI personas, which I think when you put in people’s hands and they get to have conversations with these AI personas, you get to see interesting failure cases where the things are dumb or they go into weird directions. And we get to learn as a society together what’s too far, what’s interesting, what’s fun, how much personalization is good, how much generic is good. And we get to learn all of this. And you probably don’t know this yourself. We have to all figure it out by using it, right?
Segment 3734: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3331, Text: Yeah, I mean part of what we’re trying to do with the initial AI’s launch is having a diversity of different use cases just so that people can try different things because I don’t know what’s going to work. I mean, are people going to like playing in the tech-based adventure games or are they going to like having a comedian who can add jokes to threads or they can want to interact with historical figures? We made one of Jane Austin and one of Marcus Aurelius, and I’m curious to see how that goes.
Segment 3735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3363, Text: I’m excited for both. Aa a big fan I’m excited for both. I have conversations with them. And I am also excited to see, the internet, I don’t know if you heard, can get kind of weird and I applaud them for it. So-
Segment 3736: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3378, Text: I’ve heard that, yeah.
Segment 3737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3379, Text: Yeah. So it’d be nice to see how weird they take it, what kind of memes are generated from this. And I think all of it is, especially in these early stages of development as we progress towards AGI, it’s good to learn by playing with those systems and interacting with them at a large scale like you said.
Segment 3738: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3398, Text: Yeah, totally. I mean, that’s why we’re starting out with a set. And then we’re also working on this platform that we call AI Studio that’s going to make it so that over time anyone will be able to create one of these AI almost like they create any other UGC content across the platform. So I’m excited about that. I think that to some degree we’re not going to see the full potential of this until you just have the full creativity of the whole community being able to build stuff, but there’s a lot of stuff that we need to get. So I’m excited to take this in stages. I don’t think anyone out there is really doing what we’re doing here. I think that there are people who are doing fictional or consumer-oriented character type stuff, but the extent to which we’re building it out with the avatars and expressiveness and making it so that they can interact across all of the different apps and they’ll have profiles and we’ll be able to engage people on Instagram and Facebook, I think it’s going to be really fun.
Segment 3739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3469, Text: Well, we’re talking about AI, but I’m still blown away this entire time that I’m talking to Mark Zuckerberg. And you’re not here, but you feel like you’re here. I’ve done quite a few intimate conversations with people alone in a room, and this feels like that. So I keep forgetting for long stretches of time that we’re not in the same room. And for me to imagine a future where I can with a snap of a finger do that with anyone in my life, the way we can just call right now and have this kind of shallow 2D experience, to have this experience like we’re sitting next to each other is like… I don’t think we can even imagine how that changes things where you can immediately have intimate one-on-one conversations with anyone. In a way, we might not even predict change civilization.
Segment 3740: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3524, Text: Well, I mean this is a lot of the thesis behind the whole Metaverse, is giving people the ability to feel like you’re present with someone. I mean, this is the main thing I talk about all the time, but I do think that there’s a lot to process about it. I mean, from my perspective, I’m definitely here. We’re just not physically in the same place. You’re not talking to an AI. So I think the thing that’s novel is the ability to convey through technology a sense of almost physical presence. So the thing that is not physically real is us being in the same physical place, but everything else is. And I think that that gets to this somewhat philosophical question about what is the nature of the modern real world? And I just think that it really is this combination of physical world and the presence that we feel, but also being able to combine that with this increasingly rich and powerful and capable digital world that we have and all of the innovation that’s getting created there.
Segment 3741: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3592, Text: So I think it’s super exciting because I mean, the digital world is just increasing in its capability and our ability to do awesome things, but the physical world is so profound, and that’s a lot of what makes us human is that we’re physical beings. So I don’t think we want to run away from that and just spend all day on a screen. It’s one of the reasons why I care so much about helping to shape and accelerate these future computing platforms. I just think this is so powerful. And even though the current version of this is like you’re wearing a headset, I just think this is going to be by far the most human and social computing platform that has ever existed. And that’s what makes me excited.
Segment 3742: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3636, Text: Yeah, I think just to linger on this kind of changing nature of reality of what is real, maybe shifting it towards the sort of consciousness. So what is real is the subjective experience of a thing that makes it feel real versus necessarily being in the same physical space, because It feels like we’re in the same physical space. And that the conscious experience of it, that’s probably what is real. Not like that the space time, the physics of it. You’re basically breaking physics and focusing on the consciousness. That’s what’s real. Just whatever’s going on inside my head.
Segment 3743: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3677, Text: But there are a lot of social and psychological things that go along with that experience that was previously only physical presence, right? I think that there’s an intimacy, a trust. There’s a level of communication because so much of communication is nonverbal and is based on expressions that you’re sharing with someone when you’re in this kind of environment. And before, those things would’ve only been possible had I gotten on a plane and flown to Austin and sat physically with you in the same place. So I think we’re basically short cutting those laws of physics and delivering the social and psychological benefits of being able to be present and feel like you’re there with another person, which I are real benefits to anyone in the world.
Segment 3744: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3730, Text: Like you said, I think that is going to be a very profound thing. A lot of that is that’s the promise of the Metaverse and why I think that that’s the next frontier for what we’re working on. I started working on social networks when they were primarily text, where the first version of Facebook, your profile, you had one photo and the rest of it was lists of things that you were interested in. And then we kind of went through the period where we were doing photos. And now we’re kind of in the period where most of the content is video, but there’s a clear trend where over time the way that we want to express ourselves and kind of get insight and content about the world around us gets increasingly just richer and more vivid.
Segment 3745: Speaker: , Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3777, Text: And I think the ability to be immersed and feel present with the people around you or the people who you care about is, from my perspective, clearly the next frontier. It just so happens that it’s incredibly technologically difficult. It requires building up these new computing platforms and completely new software stacks to deliver that, but I kind of feel like that’s what we’re here to do as a company.
Segment 3746: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3801, Text: Well, I really love the connection you have through conversation. And so for me, this photo realism is really, really exciting. I’m really excited for this future and thank you for building it. Thanks to you and thanks to the amazing Meta teams that I’ve met, the engineers and just everybody I’ve met here. Thank you for helping to build this future. And thank you, Mark, for talking to me inside the Metaverse. This is blowing my mind. I can’t quite express. I would love to measure my heart rate this whole time. It would be hilarious if you’re actually sitting in a beach right now.
Segment 3747: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3840, Text: I’m not. I’m in a conference room.
Segment 3748: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3842, Text: Okay. Well, I’m at a beach and not wearing any pants. I’m really sorry about that for anyone else who’s watching me in physical space. Anyway, thank you so much for talking today. This really blew my mind. It’s one of the most incredible experiences in my life, so thank you for giving that to me.
Segment 3749: Speaker: Mark Zuckerberg, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3857, Text: Awesome. Awesome. Glad you got to check it out. And it’s always fun to talk. All right, I’ll catch you soon. See you.
Segment 3750: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=MVYrJJNdrEg&t=3863, Text: See you later. This is so, so amazing, man. This is so-
Segment 3751: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=0, Text: … if the goal is the project of human knowledge, which is to know the world as it is, you cannot know the world as it is without knowing what people really think. What people really think is an incredibly important fact to know.
Segment 3752: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=15, Text: Every time you’re actually saying, “You can’t say that,” you’re actually depriving yourself of the knowledge of what people really think. You’re causing what [inaudible 00:00:24], who’s on our Board of advisors calls preference falsification. You end up with an inaccurate picture of the world.
Segment 3753: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=29, Text: Which by the way, in a lot of cases because there are activists who want to restrict more speech, they actually tend to think that people are more prejudice than they might be. Actually, one very real practical way it makes things worse is when you censor people, it doesn’t change their opinion.
Segment 3754: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=46, Text: It just encourages them to not share it with people who will get them in trouble. It leads them to talk to people who they already agree with and group polarization takes off.
Segment 3755: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=58, Text: The following is a conversation with Greg Lukianoff, free speech advocate, First Amendment attorney, president and CEO of FIRE, the Foundation for Individual Rights and Expression. He’s the author of Unleashing Liberty, co-author with Jonathan Haidt of Coddling of the American Mind.
Segment 3756: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=76, Text: Co-author with Rikki Schlott of a new book coming out in October that you should definitely pre-order now called, The Canceling of the American Mind, which is a definitive accounting of the history, present, and future of cancel culture. A term used and overused in public discourse, but rarely studied and understood with the depth and rigor that Greg and Rikki do in this book, and in part in this conversation.
Segment 3757: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=105, Text: Freedom of speech is important, especially on college campuses, the very place that should serve as the battleground of ideas, including weird and controversial ones that should encourage bold risk-taking, not conformity. This is a Lex Fridman Podcast to support it. Please check out our sponsors in the description.
Segment 3758: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=126, Text: Now, dear friends, here’s Greg Lukianoff. Let’s start with a big question. What is cancel culture? Now, you’ve said that you don’t like the term as it’s been quote “dragged through the mud and abused endlessly” by a whole host of controversial figures. Nevertheless, we have the term, what is it?
Segment 3759: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=145, Text: Cancel culture is the uptick of campaigns, especially successful campaigns starting around 2014 to get people fired, expelled, de-platformed, et cetera, for speech that would normally be protected by the First Amendment. I always say would be protected because we’re talking about circumstances in which it isn’t necessarily where the First Amendment applies.
Segment 3760: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=168, Text: What I mean is as an analog to say things you couldn’t lose your job as a public employee for. Also, the climate of fear that’s resulted from that phenomenon, the fact that you can lose your job for having the wrong opinion. It wasn’t subtle that there was an uptick in this, particularly on campus.
Segment 3761: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=188, Text: Around 2014, John Ronson wrote a book called, So You’ve Been Publicly Shamed, it came out in 2015 already documenting this phenomena. I wrote a book called Freedom from Speech in 2014. It really was in 2017 when you started seeing this be directed at professors.
Segment 3762: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=204, Text: When it comes to the number of professors that we’ve seen be targeted and lose their jobs, I’ve been doing this for 22 years and I’ve seen nothing like it.
Segment 3763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=214, Text: There’s so many things I want to ask you here. One, actually just look at the organization of FIRE. Can you explain what the organization is because it’s interconnected to this whole fight and the rise of cancel culture and the fight for freedom of speech since 2014 and before?
Segment 3764: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=230, Text: FIRE was founded in 1999 by Harvey Silverglate. He is a famous civil liberties attorney. He’s a been on the show. He’s the person who actually found me out in my very happy life out in San Francisco, but knew I was looking for a First Amendment job. I’d gone to law school specifically to do First Amendment.
Segment 3765: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=250, Text: He found me, which was pretty cool. His protege, Kathleen Sullivan was the dean of Stanford Law School. This remains the best compliment I ever got in my life is that she recommended me to Harvey. Since that’s the whole reason why I went to law school, I was excited to be part of this new organization.
Segment 3766: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=269, Text: The other co-founder of FIRE is Alan Charles Kors. He’s just an absolute genius. He is one of the leading experts in the world on the enlightenment and particularly about Voltaire. If any of your listeners do the great courses, he has a lecture on Blaise Pascal. Blaise, of course is famous for the Pascal’s wager.
Segment 3767: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=291, Text: I left it just so moved and impressed and with a depth of understanding of how important this person was.
Segment 3768: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=299, Text: That’s interesting. You mentioned to me offline connected to this that at least it runs in parallel or there’s a connection between the love of science and the love of the freedom of speech.
Segment 3769: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=310, Text: Yes.
Segment 3770: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=311, Text: Can you maybe elaborate where that connection is?
Segment 3771: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=314, Text: Sure. I think that for those of us who really have devoted our lives to freedom of speech, one thing that we are into, whether we know it or not, is epistemology, the study and philosophy of knowledge. Freedom speech has lots of moral and philosophical dimensions.
Segment 3772: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=334, Text: From a pragmatic standpoint, it is necessary because we’re creatures of incredibly limited knowledge. We are incredibly self-deceiving. I always love the fact that you’ve all heard Harari refers to the enlightenment as the discovery of ignorance because that’s exactly what it was.
Segment 3773: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=351, Text: It was suddenly being like, “Wow, hold on a second. All this incredibly interesting folk wisdom we got,” which by the way, can be surprisingly reliable here and there. When you start testing a lot of it is nonsense and it doesn’t hold up. Even our ideas about the way things fall as Galileo established, even our intuitions, they’re just wrong.
Segment 3774: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=376, Text: A lot of the early history of freedom of speech, it was happening at the same time as the scientific revolution. A lot of the early debates about freedom of speech were tied in. Certainly, Galileo, I always point out Kepler was probably the even more radical idea that they weren’t even perfect spheres.
Segment 3775: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=397, Text: At the same time, largely because of the invention of the printing press, you also had all these political developments. I always talk about John Huss from a famous Czech hero who was burned at the stake and I think in 1419. He was basically Luther before the printing press.
Segment 3776: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=421, Text: Before Luther could get his word out, he didn’t stand a chance and that was exactly what John Huss was. A century later, thanks to the printing press, everyone could know what Luther thought, and boy did they. It led to, of course, this completely crazy hyper disrupted period in European history.
Segment 3777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=440, Text: Well, you mentioned to jump around a little bit, the First Amendment, first of all, what is the First Amendment? What is the connection to you between the First Amendment, the freedom of speech, and cancel culture?
Segment 3778: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=452, Text: I’m a First Amendment lawyer, as I mentioned, and that’s my passion, that’s what I studied. I think American First Amendment law is incredibly interesting. In one sentence, the First Amendment is trying to get rid of basically all the reasons why humankind had been killing each other for its entire existence.
Segment 3779: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=471, Text: That we weren’t going to fight anymore over opinion, we weren’t going to fight any more religion. That you have the right to approach your government or redress grievances, that you have the freedom to associate that All of these things in one sentence we’re like, “Nope, the government will no longer interfere with your right to have these fundamental human rights.”
Segment 3780: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=493, Text: One thing that makes FIRE a little different from other organizations is however, we’re not just a First Amendment organization. We are a free speech organization. At the same time, a lot of what I think free speech is can be well explained with reference to a lot of First Amendment law.
Segment 3781: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=514, Text: Partially because in American history, some of our smartest people have been thinking about what the parameters of freedom of speech are in relationship to the First Amendment. A lot of those principles, they transfer very well just as pragmatic ideas.
Segment 3782: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=528, Text: The biggest sin in terms of censorship is called viewpoint discrimination, that essentially you allow freedom of speech except for that opinion. It’s found to be more defensible. I think this makes sense that if you set up a forum, and we’re only going to talk about economics to exclude people who want to talk about a different topic.
Segment 3783: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=548, Text: It’s considered rightfully a bigger deal if you’ve set up a forum for economics, but we’re not going to let people talk about that kind of economics or have that opinion on economics most particularly. A lot of the principles from First Amendment law actually make a lot of philosophical sense as good principles for what is protected and unprotected speech. What should get you in trouble, how you actually analyze it, which is why we actually try in our definition of cancel culture to work in some of the First Amendment norms just in the definition, so we don’t have to bog down on them as well.
Segment 3784: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=582, Text: You’re saying so many interesting things, but if you can linger on the viewpoint discrimination, is there any gray area of discussion there, what is and isn’t economics for the example you gave? Is it a science or is it an art to draw lines of what is and isn’t allowed?
Segment 3785: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=600, Text: If you’re saying that something is or is not economics, “Well, you can say everything’s economics, and therefore I want to talk about poetry.” There’d be some line drawing exercise in there, but let’s say at once you decide to open up to poetry even, it’s a big difference between saying, “Now, we’re open to poetry, but you can’t say Dante was bad. That’s a forbidden opinion now officially in this otherwise open forum.”
Segment 3786: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=627, Text: That would immediately at an intuitive level strike people as a bigger problem than just saying that poetry isn’t economics.
Segment 3787: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=634, Text: I mean, that intuitive level that you speak to, I hope that all of us have that basic intuition when a line is crossed. It’s the same thing for pornography when you see it. I think there’s the same level of intuition that should be applied across the board here.
Segment 3788: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=655, Text: It’s when that intuition becomes deformed by whatever forces of society, that’s when it starts to feel like censorship.
Segment 3789: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=663, Text: I mean, people find it a different thing if someone loses their job simply for their political opinion, even if that employer has every right in the world to fire you, I think Americans should still be like, “Well, it’s true. They have every right in the world, and I’m not making a legal case that maybe you shouldn’t fire someone for their political opinion.”
Segment 3790: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=681, Text: Think that through, what kind of society do we want to live in? It’s been funny watching, and I point this out, yes, I will defend businesses’ First Amendment rights of association to be able to have the legal right to decide who works for them. From a moral or philosophical matter, if you think through the implications of if every business in America becomes an expressive association in addition to being a profit maximizing organization, that would be a disaster for democracy.
Segment 3791: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=715, Text: You would end up in a situation where people would actually be saying to themselves, “I don’t think I can actually say what I really think and still believe I can keep my job.” That’s where I was worried I felt like we were headed because a lot of the initial response to people getting canceled was very simply, “Oh, but they have the right to get rid of this person.”
Segment 3792: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=737, Text: That’s the beginning and end of the discussion. I thought that was a dodge. I thought that wasn’t actually a very serious way that if you care about both the First Amendment and freedom of speech of thinking it through.
Segment 3793: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=750, Text: To you, just to clarify, the First Amendment is a legal embodiment of the ideal of freedom of speech and then freedom of speech-
Segment 3794: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=761, Text: As applied to government.
Segment 3795: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=761, Text: … it’s very specific applied to government. Freedom of speech is the application of the principle to everything, including the high level philosophical ideal of the value of people being able to speak their mind.
Segment 3796: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=779, Text: It’s an older, bolder, more expansive idea. You can have a situation, and I talk about countries that have good free speech law, but not necessarily great free speech culture. I talk about how when we sometimes make this distinction between free speech law and free speech culture, we’re thinking in a very cloudy kind of way.
Segment 3797: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=801, Text: What I mean by that is that law is generally, particularly in a common law country, it’s the reflection of norms. Judges are people too, and in a lot of cases, common law is supposed to actually take our intuitive ideas of fairness and place them into the law.
Segment 3798: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=818, Text: If you actually have a culture that doesn’t appreciate free speech from a philosophical standpoint, it’s not going to be able to protect free speech for the long haul even in the law because eventually, that’s one of the reasons why I worry so much about some of these terrible cases coming out of law schools.
Segment 3799: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=833, Text: I fear that even though, sure, American First Amendment law is very strongly protective of First Amendment for now, it’s not going to stay that way if you have generations of law students graduating who actually think there’s no higher goal than shouting down, you’re an opponent.
Segment 3800: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=850, Text: That’s why so much of your focus or large fracturing of your focus is on the higher education or education period is because education is the foundation of culture.
Segment 3801: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=862, Text: We have this history, ’64, you have the Free Speech Movement on Berkeley. In ’65 you have Repressive Tolerance by Herbert Marcuse, which was a declaration of, “By the way, we on the left, we should have free speech, but we should have free speech for us.”
Segment 3802: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=881, Text: I mean, I went back and reread Repressive Tolerance and how clear it is. I had forgotten that it really is like, “These so-called conservatives and right wingers, we need to repress them because they’re regressive thinkers.” It really doesn’t come out to anything more sophisticated than the very old idea that our people are good, they get free speech. They should keep it. Other side bad and we have to retrain society.”
Segment 3803: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=910, Text: Of course, it ends up being another, and he was also a fan of Mao, so it’s not surprising that of course the system would have to rely on some kind of totalitarian system, but that was a laughable position say 30, 40 years ago. The idea that essentially free speech for me, not for as the great free speech champion Nat Hentoff used to say was something that you were supposed to be embarrassed by.
Segment 3804: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=941, Text: I saw this when I was in law school in ’97. I saw this when I was interning at the ACLU in ’99, that there was a slow motion train wreck coming. That essentially there was these bad ideas from campus that had been taking on more and more steam of basically no free speech for my opponent we’re actually becoming more and more accepted.
Segment 3805: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=965, Text: Partially because academia was becoming less and less viewpoint-diverse. I think that as my co-author Jonathan Haidt points out that when you have low viewpoint diversity, people start thinking in a very tribal way. If you don’t have the respected dissenters, you don’t have the people that you can point to that I’m like, “Hey, this is a smart person. This is a smart, reasonable person that I disagree with. I guess, not everyone thinks alike on this issue.”
Segment 3806: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=992, Text: You start getting much more only bad people, only heretics, only blasphemers only right wingers can actually think in this way.
Segment 3807: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1002, Text: Every time you say something I always have a million thoughts and a million questions that pop up. Since you mentioned there’s a drift as you write about in the book and you mentioned now there’s a drift towards the left in academia.
Segment 3808: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1016, Text: We should also maybe draw a distinction here between the left and the right, and a cancel culture as you present in your book, is not necessarily associated with any one political viewpoint that there’s mechanisms on both sides that result in cancellation and censorship in violation of freedom of speech.
Segment 3809: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1034, Text: One thing I want to be really clear about is the book takes on both right and left cancel culture. They’re different in a lot of ways and definitely cancel culture from the left is more important in academia where the left dominates. We talk a lot about cancel culture coming from legislatures.
Segment 3810: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1051, Text: We talk a lot about cancel culture on campus as well because even though most of the attempts that come from on campus to get people canceled are still from the left, there are a lot of attacks that come from the right, that come from attempts by different organizations.
Segment 3811: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1069, Text: Sometimes when there are stories in Fox News, they’ll go after professors and about one third of the attempts to get professors punished that are successful actually do come from the right. We talk about attempts to get books banned. In the book, we talk about and talk about suing the Florida legislature, Ron DeSantis had something called the Stop WOKE Act, which we told everyone this is laughably unconstitutional.
Segment 3812: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1097, Text: They tried to ban particular topics in higher ed. We’re like, “No, this is a joke. This will be laughed out of court.” They didn’t listen to us and they brought it, they passed it and we sued and we won. Now, they’re trying again with something that’s equally as unconstitutional and we will sue again and we will win.
Segment 3813: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1119, Text: Can you elaborate on Stop WOKE Act? This is presumably trying to limit certain topics from being taught in school?
Segment 3814: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1126, Text: Basically woke topics, it came out of the attempt to get at critical race theory, so it’s topics related to race, gender, et cetera. I don’t remember exactly how they tried to cabinet to CRT, but the law is really well established that you can’t tell higher education what they’re allowed to teach without violating the First Amendment.
Segment 3815: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1153, Text: When this got in front of a judge, he was exactly as skeptical of it as we thought he’d be. I think he called this dystopian and it wasn’t a close call.
Segment 3816: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1164, Text: If you’re against that kind of teaching, the right way to fight it is by making the case that it’s not a good idea as part of the curriculum as opposed to banning it from the curriculum?
Segment 3817: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1175, Text: Yeah. Just the state doesn’t have the power to simply say to ban what professors in higher education teach. Now, it gets a little more complicated when you talk about K-12 because the state has a role in deciding what public K-12 teaches because they’re your kids.
Segment 3818: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1192, Text: It’s taxpayer funded and generally the legislature is involved. There is democratic oversight of that process.
Segment 3819: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1200, Text: For K-12, is there also a lean towards the left in terms of the administration that manages the curriculum?
Segment 3820: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1206, Text: Yeah, there definitely is in K-12. I mean, my kids go to public school. I have a five and a seven-year-old. They have lovely teachers, but we have run into a lot of problems with education schools at FIRE. A lot of the graduates of education school end up being the administrators who clamp down on free speech in higher education. I’ve been trying to think of positive ways to take on some of the problems that I see in K-12. I thought that the attempt to just dictate you won’t teach the following 10 books or 20 books or 200 books was the wrong way to do it. Now, when it comes to deciding what books are in the curriculum, again, that’s something a legislature actually can have some say in.
Segment 3821: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1252, Text: That’s pretty uncontroversial in terms of the law. When it comes to how you fight it, I had something that since I’m stuck with a formula I called Empowering of the American Mind, I gave principles that were inconsistent with the groupthink and heavy emphasis on identity politics that some of the critics are rightfully complaining about in K-12.
Segment 3822: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1279, Text: That is actually in The Canceling of the American Mind, but I have a more detailed explanation of it that I’m going to be putting up on my blog, The Eternally Radical Idea.
Segment 3823: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1287, Text: Is it possible to legally, this is a silly question, perhaps create an extra protection for certain kinds of literature 1984 or something to remain in the curriculum? I mean, it’s already all protected, I guess, to protect against administrators from fiddling too much with the curriculum like stabilizing the curriculum. I don’t know what the machinery of the K-12 public school.
Segment 3824: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1314, Text: In K-12 state legislatures-
Segment 3825: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1317, Text: They’re part of that.
Segment 3826: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1318, Text: … they’re part of that and they can say, “You should teach the following books.”Now, of course, people are always a little bit worried that if they were to recommend teach the Declaration of Independence, that it will end up being, “Well, they’re going to teach the Declaration of Independence was just to protect slavery, which it wasn’t.
Segment 3827: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1336, Text: Teaching a particular topic matters, which textbooks you choose, which perspective you take all that kind of stuff. Of course, there’s religion starts to creep into the whole question of how is the Bible, are you allowed to incorporate that into education?
Segment 3828: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1350, Text: I am an atheist with an intense interest in religion. I actually read the entire Bible this year just because I do stuff like that. I never actually had read it from beginning to end. Then, I read the Quran because, and I’m going to try to do the Book of Mormon.
Segment 3829: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1364, Text: Sorry, you’re so fascinating. Do you recommend doing that?
Segment 3830: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1368, Text: I think you should just to know, because such a touchstone in the way people talk about things, it can get pretty tedious. I even made myself read through all of the very specific instructions on how tall the different parts of the temple need to be and how long the garbs need to be and what shape they need to be.
Segment 3831: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1390, Text: Those go on a lot, surprisingly a big chunk of Exodus. I thought that was more like in Leviticus and Deuteronomy, but then you get to books like Job Wow, I mean Job is such a read and no way Job originally had that ending. Job is basically, it starts out as this perverse bet between God and Satan about whether or not they can actually make a good man renounce God.
Segment 3832: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1419, Text: Initially, they can’t, it’s all going very predictably. Then, they finally really tortured job and he turns into the best, why is God cruel? How could God possibly exist? How could a kind God do these things? He turns into the best lawyer in the entire world and he defeats everyone, all the people who come to argue with him, he argues the pants off of them.
Segment 3833: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1441, Text: Then, suddenly at the end, God shows up and He’s like, “Well, I am everywhere.” It’s a very confusing answer. He gives an answer like, “I am there when lionesses give birth and I am there. By the way, there’s this giant monster Leviathan that’s very big and it’s very scary and I have to manage the universe.”
Segment 3834: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1463, Text: I’m like, “God, are you saying that you’re very busy? Is that essentially your argument to Job. You don’t mention the whole that I have a bet, that’s why I was torturing you, that doesn’t come up. Then at the end, he decide God’s decides Job’s like, “No, you’re totally right. I was totally wrong, sorry.”
Segment 3835: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1484, Text: God says, “I’m going to punish those people who tried to argue with you and didn’t win.” He gets rid of the, I don’t know exactly what he does to them, I don’t remember. Then he gives Job all his money back and it makes him super prosperous. I’m like, “No way that was the original ending of that book because this was clearly a beloved novel that they were like, “But it can’t have that ending.”
Segment 3836: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1509, Text: It’s a long way of saying, I actually think it’s worthwhile. Some of it was you’re always surprised when you end up in there are parts of it that will sneak up on you like Isaiah’s a trip. Ecclesiastes, Depeche Mode.
Segment 3837: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1524, Text: You said you also the Quran.
Segment 3838: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1526, Text: Which was fascinating.
Segment 3839: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1529, Text: It’d be interesting to ask, is there a tension between the study of religious texts or the following of religion and just believing in God and following the various aspects of religion with freedom of speech?
Segment 3840: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1544, Text: In the First Amendment, we have something that we call the religion clause. I’ve never liked calling it just that because it’s two brilliant things right next to each other. The state may not establish an official religion, but it cannot interfere with your right to practice your religion. Beautiful, two things at the same time, and I think they’re both exactly right.
Segment 3841: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1566, Text: I think sometimes the right gets very excited of the free exercise clause and the Left gets very excited about establishment. I like the fact that we have both of them together. Now, how does this relate to freedom of speech and how does it relate to the curriculum like we were talking about.
Segment 3842: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1581, Text: I actually think it would be great if public schools could teach the Bible in the sense of read it as a historical document. Back when I was at the ACLU, every time I saw people trying this, it always turned into them actually advocating for a Catholic or a Protestant or some or Orthodox even read on religion.
Segment 3843: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1604, Text: If you actually make it into something advocating for a particular view on religion, then it crosses into the establishment clause side. Americans haven’t figured out a way to actually teach it, so it’s probably better that you learn outside of a public school class.
Segment 3844: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1617, Text: Do you think it’s possible to teach religion from world religions course without disrespecting the religions?
Segment 3845: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1629, Text: I think the answer is it depends on from whose perspective?
Segment 3846: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1633, Text: Well, the practitioner say an orthodox follower of a particular religion, is it possible to not piss you off in teaching all the major religions of the world?
Segment 3847: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1645, Text: For some people, the bottom line is you have to teach it as true. Under those conditions then the answer is no, you can’t teach it without offending someone at least.
Segment 3848: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1658, Text: Can’t you say these people believe it’s true to reform, so you have to walk on eggshells essentially?
Segment 3849: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1663, Text: You can try really hard and you will still make some people angry, but serious people will be like, “No, we actually tried to be fair to the beliefs here.” I try to be respectful as much as I can about a lot of this. I still find myself much more drawn to both Buddhism and stoicism though.
Segment 3850: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1684, Text: Where do I go? One interesting thing to get back to college campuses is FIRE keeps the college free speech rankings at rankings.thefire.org.
Segment 3851: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1697, Text: I’m very proud of them.
Segment 3852: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1698, Text: I’d highly recommend because forget even just the ranking, you get to learn a lot about the universities from this entirely different perspective than people are used to when they go to pick whatever university they want to go to. It just gives another perspective on the whole thing.
Segment 3853: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1712, Text: It gives quotes from people that are students there and so on about their experiences. Maybe you could speak to the various measures here before we talk about who’s in the top five and who’s in the bottom five. What are the different parameters that contribute to the evaluation?
Segment 3854: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1731, Text: People have been asking me since day one to do a ranking of schools according to Freedom of Speech. Even though we had the best database in existence of campus speech codes, policies that universities have that violate First Amendment or First Amendment norms, we also have the best database of, we call the disinvitation database. Actually, it’s better named the de-platforming database, which is what we’re going to call it.
Segment 3855: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1757, Text: These are all cases where somebody was invited as a speaker to campus and they were disinvited?
Segment 3856: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1763, Text: Disinvited or de-platformed also includes shouting down.
Segment 3857: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1767, Text: They showed up and they couldn’t really speak?
Segment 3858: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1770, Text: Yeah, exactly. Having that, what we really needed in order to have some serious social science to really make a serious argument about what the ranking was to be able to, one, get a better sense of how many professors were actually getting punished during this time.
Segment 3859: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1789, Text: Then the biggest missing element was to be able to ask students directly what the environment was like on that campus for freedom of speech. Are you comfortable disagreeing with each other? Are you comfortable disagreeing with your professors? Do you think violence is acceptable in response to a speaker?
Segment 3860: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1807, Text: Do you think shouting down is okay? Do you think blocking people’s access to a speaker is okay? Once we were able to get all those elements together, we first did a test run, I think in 2019 about 50. We’ve been doing it for four years now. Always trying to make the methodology more and more precise to better reflect the actual environment at particular schools.
Segment 3861: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1832, Text: This year, the number one school was Michigan Technological University, which was a nice surprise. The number two school was actually Auburn University, which was nice to see. In the top 10, the most well-known prestigious school was actually UVA, which did really well this year.
Segment 3862: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1850, Text: University of Chicago was not happy that they weren’t number one, but University of Chicago was 13. They had been number one or in the top three, four years prior to that.
Segment 3863: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1860, Text: Can you explain? It’s almost surprising, is it because of-
Segment 3864: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1860, Text: Really? So can you explain, it’s almost surprising. Is it because of the really strong economics departments and things like this, or why?
Segment 3865: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1867, Text: They had a case involving a student, they wouldn’t recognize a chapter of Turning Point U.S.A., and they made a very classic argument that we, and classic in the bad way, that we hear at campuses across the country. Oh, we have a Campus Republicans, so we don’t need this additional conservative group. And we’re like, no, I’m sorry. We’ve seen dozens and dozens, if not hundreds, of attempts to get this one particular conservative student group de-recognized or not recognized.
Segment 3866: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1896, Text: And so we told them, like listen, we told them at FIRE that we consider this serious and they wouldn’t recognize the group. So that’s a point down in our ranking. And it was enough to knock them from, they probably would’ve been number two in the rankings, but now they’re 13 out of 248. They’re still one of the best schools in the country. I have no problem saying that. The school that did not do so well at a negative 10.69, negative 10.69, and we rounded up to zero, was Harvard. And Harvard has been not very happy with that result.
Segment 3867: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1935, Text: The only school to receive the abysmal ranking.
Segment 3868: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1938, Text: And there are a couple of people-
Segment 3869: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1939, Text: Oh, Harvard.
Segment 3870: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1940, Text: Oh, Harvard. And there are a couple people who have actually been really, I think making a mistake by getting very Harvard sounding, by being like, I’ve had statisticians look at this, and they think your methodology is a joke. And pointing out, an this case wasn’t that important, and that scholar wasn’t, one of the arguments against one of the scholars that we counted against them for punishing was that wasn’t a very famous or influential scholar.
Segment 3871: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1967, Text: So your argument seems to be snobbery, like essentially you’re not understanding our methodology for one thing. And then you’re saying that actually that scholar wasn’t important enough to count. And by the way, Harvard, if we-
Segment 3872: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1982, Text: That’s the Harvard camera.
Segment 3873: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=1988, Text: … even if we took all of your arguments as true, even if we decided to get rid of those two professors, you would still be in negative numbers. You would still be dead last, you would still be after Georgetown and Penn. And neither of those schools are good for freedom of speech.
Segment 3874: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2003, Text: I should say, the bottom five is the University of Pennsylvania, like you said, Penn, the University of South Carolina, Georgetown University, and Fordham University,
Segment 3875: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2012, Text: All very well-earned. They have so many bad cases at all of those schools.
Segment 3876: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2016, Text: What’s the best way to find yourself in the bottom five, if you are a university? What’s the fastest way to that negative, to that zero?
Segment 3877: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2023, Text: A lot of de-platforming. When we looked at the bottom five, 81% of attempts to get speakers de-platformed were successful at the bottom five. There were a couple of schools, I think Penn included, where every single attempt, every time a student group objected to that speaker coming, they canceled the speech. And I think Georgetown was a 100% success rate. I think Penn had a 100% success rate. I think Harvard did stand up for a couple, but mostly people got de-platformed there as well.
Segment 3878: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2055, Text: So how do you push back on de-platforming? Well, who would do it? Is it other students? Is it faculty? Is it the administration? What’s the dynamics of pushing back of, basically, because I imagine some of it is culture, but I imagine every university has a bunch of students who will protest basically every speaker. And it’s a question of how you respond to that protest.
Segment 3879: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2080, Text: Well, here’s the dirty little secret about the big change in 2014 and FIRE, and me, and Height have been very clear that the big change that we saw on campus was that for most of my career, students were great on freedom of speech. They were the best constituency for free speech, absolutely unambiguously until about 2013, 2014. And it was only in 2014 where we had these very kind of sad for us experience where suddenly students were the ones advocating for de-platforming and new speech codes, in a similar way that they had been doing in say the mid-eighties, for example. But here’s the dirty little secret.
Segment 3880: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2118, Text: It’s not just the students, it’s students and administrators, sometimes only a handful of them though, working together to create some of these problems. And this was exactly what happened at Stanford when Kyle Duncan, a Fifth Circuit Judge tried to speak at my alma mater and a fifth of the class showed up to shout him down. It was a real showing of what was going on. That 10 minutes into the shout down of a Fifth Circuit Judge, and I keep on emphasizing that because I’m a constitutional lawyer, Fifth Circuit Judges are big deals. They’re one level below the Supreme Court.
Segment 3881: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2153, Text: About a fifth of the school shows up to shout him down. After 10 minutes of shouting him down, an administrator, a DI administrator, gets up with a prepared speech that she’s written that’s a seven-minute-long speech where she talks about free speech, maybe the juice isn’t worth the squeeze.
Segment 3882: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2169, Text: And we are at this law school where people could learn to challenge these norms. So it’s clear that there was coordination amongst some of these administrators. And from talking to students there, they were in meetings, extensive meetings for a long time. They show up, do a shout down, then they take additional seven minutes to lecture the speaker on free speech, the juice of free speech not being worth the squeeze. And then for the rest of it, it’s just constant heckling after she leaves.
Segment 3883: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2201, Text: This is clearly, and something very similar happened a number of times at Yale, where it was very clearly administrators were helping along with a lot of these disruptions. So I think every time there is a shout down at a university, the investigation should be first and foremost, did administrators help create this problem? Did they do anything to stop it? Because I think a lot of what’s really going on here is the hyper bureaucratization of universities with a lot more ideological people who think of their primary job as basically policing speech, more or less. They’re encouraging students, sorry, they’re encouraging students who have opinions they like, to do shout downs.
Segment 3884: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2243, Text: And that’s why they really need to investigate this. And it is at Stanford, the administrator who gave the prepared remarks about the juice not being worth the squeeze. She has not been invited back to Stanford, but she’s one of the only examples I can think of, when these things happen a lot where an administrator clearly facilitated something that was a shout down or a de-platforming, or resulted in a professor getting fired, or resulted in a student getting expelled, where the administrator has got off scot-free or probably, in some cases, even gotten a promotion.
Segment 3885: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2275, Text: And so a small number of administrators, maybe even a single administrator, could participate in the encouraging and the organization, and thereby empower the whole process.
Segment 3886: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2286, Text: And that’s something I’ve seen throughout my entire career. And the only thing that’s kind of hard to catch this sort of in the act, so to speak, and that’s one of the reasons why it’s helpful for people to know about this. Because there was this amazing case. This was at University of Washington, and we actually featured this in a documentary made in 2015 that came out in 2015, 2016, called Can We Take a Joke?
Segment 3887: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2309, Text: And this was when we started noticing something was changing on campus. We also heard that comedians were saying that they couldn’t use their good humor anymore. This was right around the time that Jerry Seinfeld and Chris Rock said that they didn’t want to play on campuses, because they couldn’t be funny. But we featured a case of a comedian who wanted to do a musical called The Passion of the Musical, making Fun of the Passion of the Christ, with the stated goal of offending everyone, every group equally. It was very much a South Park mission. And it’s an unusual case because we actually got documentation of administrators buying tickets for angry students and holding an event where they trained them to jump up in the middle of it and shout, I’m offended. They bought them tickets, they sent them to this thing with the goal of shouting it down. Now, unsurprisingly, when you send an angry group of students to shut down a play, it’s not going to end at just, I’m offended. And it got heated.
Segment 3888: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2372, Text: There were death threats being thrown, and then the Pullman Washington Police told Chris Lee, the guy who made the play, that they wouldn’t actually protect him. Now it’s not every day you’re going to have that kind of hard evidence of actually seeing the administrators be so brazen that they recorded the fact that they bought them tickets and sent them. But I think a lot of that stuff is going on, and I think it’s a good excuse to cut down on one of the big problems in higher education today, which is hyper bureaucratization.
Segment 3889: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2405, Text: In your experience, is there a distinction between administrators and faculty in terms of perpetrators of these kinds of things? So if we got rid of all, Harvey’s talked about getting rid of a large percentage of the administration, does that help fix the problem? Or is the faculty also, small percent of the faculty, also part of the encouraging in the organization of these kind of cancel models?
Segment 3890: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2430, Text: And that’s something that has been profoundly disappointing, is that when you look at the huge uptick in attempts to get professors fired that we’ve seen over the last 10 years, and actually over the last 22 years, as far back as our records go. At first, they were overwhelmingly led by administrators, attempts to get professors punished. And that was most, I’d say that was my career up until 2013, was fighting back at administrative excesses. Then you start having the problem in 2014 of students trying to get people canceled, and that really accelerated in 2017. So one thing that makes it easier to document are the petitions to get professors fired or punished, and how disproportionately those actually do come from students. But another big uptick has been fellow professors demanding that their fellow professors get punished. And that to me-
Segment 3891: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2485, Text: Makes me really sad.
Segment 3892: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2486, Text: It’s kind of shameful. You shouldn’t be proud of signing the petition to get your fellow professor. And what’s even more shameful is that we get, this has almost become a cliche within FIRE, when someone is facing one of these cancellation campaigns as a professor. I would get letters from some of my friends saying, I am so sorry this has happened to you, and these were the same people who publicly signed the petition to get them fired.
Segment 3893: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2517, Text: Yeah, integrity. Integrity is an important thing in this world, and I think some of it, I’m so surprised people don’t stand up more for this. There’s so much hunger for it. And if you have the guts as a faculty or an administrator to really stand up with eloquence, with rigor, with integrity, I feel like it’s impossible for anyone to do anything because there’s such a hunger. It’s so refreshing. I think everybody agrees that freedom of speech is a good thing.
Segment 3894: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2556, Text: Oh, I don’t-
Segment 3895: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2557, Text: Well, okay, sorry, sorry.
Segment 3896: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2558, Text: I don’t agree.
Segment 3897: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2559, Text: The majority of people, even at the universities, that there’s a hunger, but it’s almost like this kind of nervousness around it because there’s a small number of loud voices that are doing the shouting. So again, that’s where great leadership comes in. And so presidents of universities should probably be making clear declarations of this is a place where we value the freedom of expression.
Segment 3898: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2585, Text: And this, all throughout my career, a president, a university president who puts their foot down early and says, nope, we are not entertaining firing this professor. We are not expelling this student. It ends the issue often very fast. Although sometimes, and this is where you can really tell the administrative involvement, students will do things like takeover the president’s office and then that takeover will be catered by the university.
Segment 3899: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2612, Text: People will point this out sometimes as being kind of like, oh, it was clearly, my friend Sam Abrams, when they tried to get him fired at Sarah Lawrence College. That was one of the times that it was used as oh, this was hostile to the university because the students took over the president’s office. And I’m like, no, they let them take over the president’s office. And I don’t know if that was one of the cases in which the takeover was catered, but if there was ever a sign that’s kind of like, yes, this is actually really quite friendly.
Segment 3900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2643, Text: Well, in some sense, protesting and having really strong opinions, even ridiculous, crazy wild opinions, is a good thing. It’s just it shouldn’t lead to actual firing or de-platforming of people. It’s good to protest, it’s just not good for the university to support that and take action based on it.
Segment 3901: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2659, Text: And this is one of those tensions in First Amendment that actually I think has a pretty easy release, essentially. You absolutely have the right to devote your life to ending freedom of speech and ridiculing it as a concept. And there are people who really can come off as very contemptible about even the philosophy of freedom of speech, and we will defend your right to do that. We will also disagree with you, and if you try to get a professor fired, we’ll be on the other side of that.
Segment 3902: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2691, Text: Now, I think you had Randy Kennedy, who I really, I love him. I think he’s a great guy, but he criticized us for our de-platforming database as saying this is saying that students can’t protest speakers. I’m like, okay, that’s silly. We, FIRE, as an organization, have defended the right to protest all the time. We are constantly defending the rights to protestors, not believing that the protestors have the right to say this, basically that would be punishing the speakers. We’re not calling for punishing the protestors, but what we are saying is you can’t let the protestors win if they’re demanding someone be fired for their freedom of speech.
Segment 3903: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2731, Text: So the line there is between protestors protesting and the university taking action based on the protest.
Segment 3904: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2740, Text: Yeah, exactly. And of course, shout downs, that’s just mob censorship. And that’s something where the university, the way you deal with that tension in First Amendment law is essentially of the one positive duty that the government has. The first, the negative duty, the thing that it’s not allowed to do is censor you. But its positive duty is that if I want to say awful things, or for that matter, great things that aren’t popular in a public park, you can’t let the crowd just shout me down. You can’t allow what’s called a heckler’s veto.
Segment 3905: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2773, Text: Heckler’s veto. That’s so interesting, because I feel like that comes into play on social media as well. There’s this whole discussion about censorship and freedom of speech, but to me, the carrot question is almost more interesting. Once the freedom of speech is established is, how do you incentivize high quality debate and disagreement?
Segment 3906: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2793, Text: I’m thinking a lot about that, and that’s one of the things we talk about in canceling of the American mind, is arguing towards truth. And that cancel culture is cruel, it’s merciless, it’s anti-intellectual, but it also will never get you anywhere near truth. And you are going to waste so much time destroying your opponents in something that can actually never get you to truth through the process, of course, of you never actually get directly at truth, you just chip away at falsity.
Segment 3907: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2820, Text: But everybody having a megaphone on the internet with anonymity, it seems like it’s better than censorship, but it feels like there’s incentives on top of that you can construct to incentivize better discourse. To incentivize somebody who puts a huge amount of effort to make even the most ridiculous arguments, but basically ones that don’t include any of the things you highlight in terms of all the rhetorical tricks to shut down conversations. Just make really good arguments for whatever, it doesn’t matter if it’s communism for fascism, whatever the heck you want to say. But do it with skill, with historical context, with steel-manning the other side, all those kinds of elements.
Segment 3908: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2870, Text: We try to make three major points in the book. One is just simply cancel culture is real. It’s a historic era and it’s on a historic scale. The second one is you should think of cancel culture as part of a rhetorical, as a larger, lazy, rhetorical approach to what we refer to as winning arguments without winning arguments. We mean that in two senses without having winning arguments or actually having won arguments. We talk about all the different, what we call rhetorical fortresses, that both the left and the right have that prevent you from, that allow you to just dismiss the person, or dodge the argument, without actually ever getting to the substance of the argument.
Segment 3909: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2913, Text: Third part is just how do we fix it? But the rhetorical fortress stuff is actually something I’ve very passionate about because it interferes with our ability to get at truth and it wastes time. And frankly, it also, since cancel culture is part of that rhetorical tactic, it can also ruin lives.
Segment 3910: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2931, Text: It would actually be really fun to talk about this particular aspect of the book, and I highly recommend if you’re listening to this, go pre-order the book now. When does it come out?
Segment 3911: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2941, Text: October 17th.
Segment 3912: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2942, Text: Okay. The Canceling of the American Mind. So in the book, you also have a list of cheap rhetorical tactics that both the left and the right use, and then you have a list of tactics that the left uses and the right uses. So there’s the rhetorical, the perfect rhetorical fortress that the left uses, and the efficient rhetorical fortress that the right uses.
Segment 3913: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2967, Text: First one is what about-ism. Maybe we can go through a few of them that capture your heart in this particular moment as we talk about it. And if you can describe examples of it or if there’s aspects of it that you see that are especially effective. So what about-ism is defending against criticism of your side by bringing up the other side’s alleged wrongdoing.
Segment 3914: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=2991, Text: I want to make little cards of all of these tactics and start using them on X all the time, because they’re so commonly deployed. And what about-ism I put first for a reason.
Segment 3915: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3003, Text: It’d be an interesting idea to actually integrate that into Twitter/X, where people, instead of clicking heart, they can click which of the rhetorical tactics this is. And then there’s actually community notes. I don’t know if you’ve seen on X, people can contribute notes and it’s quite fascinating. It works really, really well. But to give it a little more structure, that’s a really interesting method actually.
Segment 3916: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3030, Text: I actually, when I was thinking about ways that X could be used to argue towards truth, I wouldn’t want to have it so that everybody would be bound to that. But I think, imagine almost being a stream within X that was truth focused, that agrees to some additional rules on how they would argue.
Segment 3917: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3049, Text: Man, I would love that. Where there’s, in terms of streams that intersect and could be separated, the shit-talking one, where people just enjoy talking shit.
Segment 3918: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3059, Text: Go for it, man.
Segment 3919: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3060, Text: And then there’s truth, and then there’s humor, then there’s good vibes. I’m not somebody who absolutely needs good vibes all the time, but sometimes-
Segment 3920: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3073, Text: It’s nice to have.
Segment 3921: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3074, Text: … it’s nice to just log in and not have to see the drama, the fighting, the bickering, the cancellations, the moms, all of this. It’s good to just see, that’s why I go to Reddit, or Ahh, or whatever, the cute animals ones where there’s cute puppies and kittens and it’s like-
Segment 3922: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3092, Text: I just want to see Ryan Reynolds singing with Will Ferrell.
Segment 3923: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3095, Text: Sometimes it’s all you need.
Segment 3924: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3097, Text: I need that in my heart.
Segment 3925: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3098, Text: Yeah, not all the time, just a little bit, then right back to the battle for truth. Okay, so what about-ism.
Segment 3926: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3105, Text: What about-ism, that’s everywhere when you look at it. When you look at Twitter, when you look at social media in general. And the first, what we call the obstacle course is basically time-tested, old-fashioned, argumentative dodges that everybody uses. And what about-ism is just bringing up something, someone makes an argument like Biden is corrupt, and then someone says, well Trump was worse.
Segment 3927: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3130, Text: And that’s not an illegitimate argument to make back, but it seems to happen every time someone makes an assertion, someone just points out some other thing that was going on, and it can get increasingly attenuated from what you’re actually trying to argue. And you see this all the time on social media. And I was a big fan of John Stewart’s daily show, but an awful lot of what the humor was and what the tactic was for arguing was this thing over here. It’s like, oh, I’m making this argument about this important problem. Oh, actually there’s this other problem over here that I’m more concerned about.
Segment 3928: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3166, Text: Let’s pick on the right here. So January 6th, watching everybody arguing about CHOP, like the occupied part of Seattle or the occupied part of Portland, and basically trying to like, oh, you’re bringing up the riot on January 6th, and by the way, I live on Capitol Hill. So believe me, I was very aware of how scary and bad it was. My dad grew up in Yugoslavia, and that was a night where we all ate dinner in the basement, like, oh, when the shit goes down, eat in the basement. It was genuinely scary.
Segment 3929: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3200, Text: And people would try to deflect from January 6th being serious by actually making the argument that, oh, well, there are crazy horrible things happening in all over the country. Riots that came from some of the social justice protests. And of course the answer is, you can be concerned about both of these things and find them both problems. But if I’m arguing about CHOP, someone bringing up January 6th isn’t super relevant to it. Or if I’m arguing about January 6th, someone bringing up the riots in 2020, isn’t that helpful.
Segment 3930: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3233, Text: We took a long dark journey from what about-ism, and related to that is straw-manning and steel-manning. So misrepresenting the perspective of the opposing perspective. And this is something also, I guess, it’s very prevalent and it’s difficult to do the reverse of that, which is, steel-manning requires empathy or requires eloquence. It requires understanding, actually doing the research and understanding the alternative perspective.
Segment 3931: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3263, Text: My wonderful employee, Angel Eduardo, has something that he calls star-manning, and I find myself doing this a lot. It’s nice to have two immigrant parents, because I remember being in San Francisco in the weird kind of a ACLU/Burning Man kind of cohort, and having a friend there who was an artist who would talk about hating Kansas. And that was his metaphor for middle America, is what he meant by it. But he was kind of proud of the fact that he hated Kansas. And I’m like, you got to understand, I still see all of you a little bit as foreigners and think about change the name of Kansas to Croatia, change the name of Kansas to some, that’s what it sounds like to me.
Segment 3932: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3311, Text: And the star-manning idea, which I like, is the idea of being like, so you’re saying that you really hate your dominant religious minority, and that’s when you start actually detaching yourself a little bit from it, how typical. America is exceptional in a number of ways, but some of our dynamics are incredibly typical.
Segment 3933: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3331, Text: It’s one of the reasons why when people start reading Thomas Sowell for example, they start getting hooked, because one of the things he does is he does comparative analysis of country’s problems and points out that some of these things that we think are just unique to the United States exist in 75% of the rest of the countries in the world.
Segment 3934: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3348, Text: Francis Fukuyama’s, the book that I’m reading right now, Origins of the Political Order, actually does this wonderful job of pointing out how we’re not special in a variety of ways. This is actually something that’s very much on my mind. And Fukuyama, of course, it’s a great book. It’s stilted a little bit in its writing because his term for one of the things he’s concerned about what destroys societies is repatrimonilization, which is the reversion to societies in which you favor your family and friends.
Segment 3935: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3384, Text: And I actually think a lot of what I’m seeing in the United States, it makes me worried that we might be going through a little bit of a process of repatrimonialization. And I think that’s one of the reasons why people are so angry.
Segment 3936: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3397, Text: I think the prospect that we very nearly seem to have an election that was going to be Jeb Bush versus Hillary Clinton. It’s like, are we a dynastic country now? Is that what’s kind of happening? But also it’s one of the reasons why people are getting so angry about legacy admissions, about how much certain families seem to be able to keep their people in the upper classes of the United States perpetually. And believe me, we were poor when I was a kid and I got to go to one of the fancies, I got to go to Stanford.
Segment 3937: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3431, Text: And I got to see how people, they treat you differently in a way that’s almost insulting, basically suddenly to a certain kind of person. I was a legitimate person. And I look at how much America relies on Harvard, on Yale, to produce its, I’m going to use a very Marxist sounding term, ruling class. And that’s one of the reasons why you have to be particularly worried about what goes on at these elite colleges. And these elite colleges, with the exception of University of Chicago and UVA, do really badly regarding freedom of speech, and that has all sorts of problems. It doesn’t bode well for the future of the protection of freedom of speech for the rest of the society.
Segment 3938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3477, Text: So can you also empathize there with the folks who voted for Donald Trump? Because as precisely that, as a resistance to this kind of momentum of the ruling class, this royalty that passes on the rule from generation to generation,
Segment 3939: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3500, Text: I try really hard to empathize with, to a degree everybody, and try to really see where they’re coming from. And the anger on the right, I get it. I mean, I feel like the book, so Copying the American Mind was a book that could be sort of a crowd pleaser to a degree, partially because we really meant what we said in the subtitle that these are good intentions and bad ideas that are hurting people. And if you understand it and read the book, you can say it’s like, okay, this isn’t anybody being malicious. This is people trying to protect their kids. They’re just doing it in a way that actually can actually lead to greater anxiety, depression, and strangely, eventually pose a threat to freedom of speech.
Segment 3940: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3548, Text: But in this one, we can’t be quiet. Me and my, oh, I haven’t even mentioned my brilliant co-author, Rikki Schlott, a 23-year-old genius. She’s amazing. I started working with her when she was 20, who’s my co-author on this book. So when I’m saying we, I’m talking about me and Rikki.
Segment 3941: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3564, Text: She’s a libertarian.
Segment 3942: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3565, Text: Libertarian journalist.
Segment 3943: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3567, Text: And a journalist, and has a brilliant mind.
Segment 3944: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3570, Text: But we can’t actually write this in a way that’s too kind because cancelers aren’t kind. There’s a cruelty and a mercilessness about it. I started getting really depressed this past year when I was writing it, and I didn’t even want to tell my staff why I was getting so anxious and depressed. It’s partially because I’m talking about people who will, in some of the cases we’re talking about, go to your house, target your kids.
Segment 3945: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3594, Text: So that’s a long-winded way of saying, I kind of can get what sort of drives the right nuts to a degree in this. I feel like they’re constantly feeling like they’re being gaslit. Elite education is really insulting to the working class. Part of the ideology that is dominant right now kind of treats almost 70% of the American public like they’re, we developed this a little bit in the perfect rhetorical fortress, like they’re to some way illegitimate and not worthy of respect or compassion.
Segment 3946: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3631, Text: The general elitism that radiates, self-fueling elitism, that radiates from the people that go to these institutions.
Segment 3947: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3640, Text: And what’s funny is the elitism has been repackaged as a kind of, it masquerades as kind of infinite compassion that essentially, it’s based in a sort of very, to be frank, overly simple ideology and over simple explanation of the world and breaking people into groups and judging people on how oppressed they are on the intersection of their various identities. And it came to that, I think initially, and had appeal from a compassionate core, but it gets used in a way that can be very cruel, very dismissive, compassion-less, and allows you to not take seriously most of your fellow human beings.
Segment 3948: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3689, Text: It’s really weird how that happened. Maybe you can explore why a thing that has, kind of sounds good at first, can become such a cruel weapon of canceling and hurting people and ignoring people. I mean, this is what you described with a perfect rhetorical fortress, which is a set of questions. Maybe you can elaborate on what the perfect rhetorical fortress is.
Segment 3949: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3715, Text: So the perfect rhetorical fortress is the way that’s been developed on the left to not ever get to someone’s actual-
Segment 3950: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3720, Text: … on the left to not ever get to someone’s actual argument. I want to make a flow chart of this about here’s the argument and here is this perfect fortress that will deflect you every time from getting to the argument. I started to notice this certainly when I was in law school, that there were lots of different ways you could dismiss people. Perfect rhetorical fortress step one, and I can attest to this because I was guilty of this as well, that you can dismiss people if you can argue that they’re conservative. They don’t have to be conservative, to be clear. You just have to say that they are. I never read Thomas Sowell because he was a right-winger. I didn’t read Camille Paglia because someone had convinced me she was a right-winger. There were lots of authors when I was in law school among a lot of very bright people.
Segment 3951: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3773, Text: It really was already an intellectual habit that if you could designate something conservative, then you didn’t really have to think about it very much anymore or take it particularly seriously. That’s a childish way of arguing, but nonetheless, I engaged in it. It was a common tactic. I even mentioned in the book there was a time when a gay activist friend, who I think decided to lean to my left, but nonetheless had that pragmatic experience of actually being an activist, said something like, “Well, just because someone’s conservative doesn’t mean they’re wrong,” and I remember feeling scandalized at some level of just being like, “Well, no, it’s not the whole thing. What we’re saying is that they’re just kind of bad people with bad ideas.”
Segment 3952: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3811, Text: You can just throw, “Oh, that guy’s a right-winger.” You can just throw that.
Segment 3953: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3815, Text: Don’t have to think about you anymore.
Segment 3954: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3817, Text: Yeah, and then if you’re popular enough, it can be kind of sticky, and it’s weird because-
Segment 3955: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3825, Text: Because it’s effective. That’s why it keeps on getting used. Essentially, it should have hit someone’s… Because I have a great liberal pedigree. Everything from working at the ACLU to doing refugee law in Eastern Europe. I was part of an environmental mentoring program for inter-city high school kids in DC. I can defend myself as being on the left, but I hate doing that because there’s also part of me that’s like, “Okay, so what? Are you really saying that if you can magically make me argue or convince yourself that I’m on the right, that you don’t have to listen to me anymore?” Again, that’s arguing like children. The reason why this has become so popular is because even among, or maybe especially among elites, that it works so effectively as a perfect weapon that you can use uncritically. If I can just prove you’re on the right, I don’t have to think about you. It’s no wonder that suddenly you start seeing people calling the ACLU right wing and calling the New York Times right wing because it’s been such an effective way to delegitimize people as thinkers.
Segment 3956: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3895, Text: Steven Pinker, who’s on our board of advisors, he refers to academia as being the left pole that essentially it’s a position that from that point of view, everything looks as if it’s on the right, but once it becomes a tactic that we accept, and that’s one of the reasons why. I’m more on the left. I think I’m left or center liberal. Ricky is more conservative, libertarian, and initially, I was like, “Should I be really be writing something with someone who’s more on the right?” And I’m like, “Absolutely, I should be.” I have to actually live up to what I believe on this stuff because it’s ridiculous that we have this primitive idea that you can dismiss someone as soon as you claim rightly or wrongly that they’re on the right.
Segment 3957: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3939, Text: Well, correct me if I’m wrong, but I feel like you were recently called right wing, FIRE, maybe you by association, because of that debate you support-
Segment 3958: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3952, Text: Oh, LA Times.
Segment 3959: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3952, Text: The LA Times?
Segment 3960: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3952, Text: Oh, fun. Let’s talk about the LA Times.
Segment 3961: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3954, Text: Yes, there’s an article, there’s a debate. I can’t wait to watch it because I don’t think it’s available yet to watch on video. You have the attend in person. I can’t wait to see it, but FIRE was in part supporting, and then LA Times wrote a scathing article about that everybody in the debate was basically leaning right.
Segment 3962: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=3975, Text: Okay, so much to unpack there. Bari Weiss has this great project, The Free Press. I’ve been very impressed. It’s covering stories that a lot of the media, right or left, isn’t willing to cover. We hosted a debate with her and we wanted to make it as fun and controversial as possible, so FIRE and The Free press hosted a debate, “Did the sexual revolution fail?” The debate was really exciting, really fun. The side that said that sexual revolution wasn’t a failure that Grimes and Sarah Haider were on, one, it was a nice, meaty, thoughtful night. There was a review of it that was just sort of scathing about the whole thing, and it included a line saying that, “FIRE, which claims to believe in free speech but only defends viewpoints to degrees with.”
Segment 3963: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4028, Text: I can’t believe that even made it into the magazine because it’s not just calling us because, of course, the implication, of course, is that we’re right wing, which we’re not. Actually, the staff leans decidedly more to the left than to the right. But we also defend people all over the spectrum all the time. That’s something that even the most minimal Google search would’ve solved. We’ve been giving LA Times some heat on this because it’s like, “Yeah, if you said, in my opinion, they’re right wing,” we would’ve argued back saying, “Well, here’s the following 50,000 examples of us not being,” but when you actually make the factual claim that we only defend opinions we agree with, first of all, there’s no way for us to agree with opinions because we actually have a politically diverse staff who won’t even agree on which opinions are good and what opinions we have.
Segment 3964: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4076, Text: Yeah, one time when someone did something like this and they were just being a little bit flippant about free speech being fine, I did a 70 tweet long thread just being like, “Hey, do you really think this is fine?” I decided not to do that on this particular one, but the nice thing about it is it demonstrated two parts of the book, Canceling of the American Mind, if not more. One of them is dismissing someone because they’re conservative and because that was the implication. Don’t have to listen to FIRE because they’re conservative. But the other one is something, a termite that I invented specifically for the way people argue on Twitter, which is hypocrisy projection. “Hi, I’m person who only cares about one side of the political fence and I think everyone else is a hypocrite, and by the way, I haven’t done any actual research on this, but I assume everyone else is a hypocrite.”
Segment 3965: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4128, Text: You see this happen all the time, and this happens to FIRE a lot where someone would be like, “Where is FIRE on this case?” And we’re like, “We are literally quoted in the link you just sent but didn’t actually read,” or it’s like, “Where’s FIRE on this?” It’s like, “Here’s our lawsuit about it from six months ago.” It’s a favorite thing, and also Jon Stewart, Daily Show, the whataboutism and the idea that these people must be hypocrites is something that greatest comedy, but as far as actually a rhetorical tactic that will get you to truth, just assuming that your opponent or just accusing your opponent of always being a hypocrite is not a good tactic for truth, but by the way, it tends to always come from people who aren’t actually consistent on free speech themselves.
Segment 3966: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4177, Text: Hence, the projection, but basically, not doing the research about whether the person is or isn’t a hypocrite and assuming others or a large fraction of others reading it will also not do the research. Therefore, this kind of statement becomes a kind of truthiness without a grounding in actual reality. It breaks down that barrier between what is and isn’t true because if the mob says something is true, it takes too much effort to correct it.
Segment 3967: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4205, Text: There are three ways I want to respond to this, which is just giving example after example of times where we defended people on both sides of basically every major issue, whether it’s Israel-Palestine, whether it’s terrorism, whether it’s gay marriage, abortion. We have defended both sides of that argument. The other part, and I call these the orphans of the culture war, I really want to urge the media to start caring about free speech cases that actually don’t have a political valence, that are actually just about good old-fashioned exercise of power against the little guy or little girl or little group on campus or off campus for that matter because these cases happen. A lot of our litigation are just regular people being told that they can’t protest, that they can’t hold signs. Then the last part of the argument that I want people to really get is like, “Yeah, and by the way, right- wingers get in trouble too, and there are attacks from the left,” and you should take those seriously too.
Segment 3968: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4265, Text: You should care when Republicans get in trouble. You should care when California has a DEI program that requires this… California Community Colleges has a DEI program policy that actually requires even chemistry professors to work in different DEI ideas from intersectionality to anti-racism into their classroom, into their syllabus, et cetera. This is a gross violation of economic freedom. It is as bad as it is to tell professors what they can’t say like we fought and defeated in Florida. It’s even worse to tell them what they must say. That’s downright totalitarian and we’re suing against this. What I’m saying is that when you’re dismissing someone for just being on the other side of the political fence, you are also making a claim that none of these cases matter as well, and I want people to care about censorship when it even is against people they hate.
Segment 3969: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4326, Text: Censorship is censorship. If we can take that tangent briefly with DEI, Diversity, Equity, and Inclusion, what is the good and what is the harm of such programs?
Segment 3970: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4341, Text: I know people who are DEI consultants. Actually, I have a dear friend who I love very much who does DEI. Absolutely decent people. What they want to do is create bonds of understanding, friendship, compassion among people who are different. Unfortunately, the research on what a lot of DEI actually does, there’s oftentimes the opposite of that. I think that it’s partially a problem with some of the ideology that comes from critical race theory, which is a real thing, by the way, that informs a lot of DEI that actually makes it something more likely to divide than unite. We talk about this in Coddling of the American Mind as the difference between common humanity identity politics and common enemy identity politics. I think that I know some of the people that I know who do DEI, they really want it to be common humanity identity politics, but some of the actual ideological assumptions that are baked in can actually cause people to feel more alienated from each other.
Segment 3971: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4405, Text: Now, when I started at FIRE, my first cases involved 9/ 11, and it was bad. Professors were getting targeted, professors were losing their jobs for saying insensitive things about 9/11, and both from the right and the left, actually. In that case, actually, it sometimes a lot more from the right. It was really bad and about five professors lost their jobs. That’s bad. Five professors in over a relatively short period of time being fired for a political opinion? That’s something that would get written up in any previous decades. We’re now evaluating how many professors have been targeted for cancellation between 2014 and middle of this year, July of 2023. We’re in well over 1,000 attempts to get professors fired or punished, usually driven by students and administrators, often driven by professors unfortunately as well. About two-thirds of those result in the professor being punished in some way, everything from having their article removed to suspension, et cetera. About one-fifth of those result in professors being fired. Right now, it’s almost 200, it’s around 190 professors being fired.
Segment 3972: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4485, Text: I want to give some context here. The Red Scare is generally considered to have been from 1947 to 1957. It ended, by the way, in ’57 when it finally became clear, thanks to the First Amendment, that you couldn’t actually fire people for their ideologies. Prior to that, a lot of universities thought they could. This guy is a very doctrinaire communist. “They can’t be just waited. I’m going to fire them.” They thought they actually could do that, and it was only ’57 when the law was established, so right now, these are happening in an environment where freedom of speech, academic freedom, are clearly protected at public colleges in the United States and we’re still seeing these kind of numbers. During the Red Scare, the biggest study that was done of what was going on is I think this came out in ’55, and the evaluation was that there was about 62 professors fired for being communists and about 90 something professors fired for political views overall that usually is reported as being about 100, so 60, 90, 100 depending on how you look at it.
Segment 3973: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4555, Text: I think the number is actually higher, but that’s only because of hindsight. What I mean by hindsight is we can look back and we actually find there were more professors who were fired as time reveals. We’re at 190 professors fired, and I still have to put up with people saying this isn’t even happening, and I’m like, “In the nine and a half years of cancel culture, 190 professors fired. In the 11 years of the Red Scare, probably somewhere around 100, or probably more.” The number’s going to keep going up, but unlike during the Red Scare where people could clearly tell something was happening, the craziest thing about cancel culture is I’m still dealing with people who are saying this isn’t happening at all, and it hasn’t been subtle on campus.
Segment 3974: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4598, Text: We know that’s a wild under count, by the way, because when we surveyed professors, 17% of them said that they had been threatened with investigation or actually investigated for what they taught, said, or their research, and one-third of them said that they were told by administrators not to take on controversial research. Extrapolating that out, that’s a huge number. The reason why you’re not going to hear about a lot of these cases is because there are so many different conformity inducing mechanisms in the whole thing, and that’s one of the reasons why the idea that you’d add something, like requiring a DEI statement to be hired or to get into a school under the current environment, is so completely nuts. We have had a genuine crisis of academic freedom over the last, particularly since 2017, on campuses. We have very low viewpoint diversity to begin with. Under these circumstances, administrators just start saying, “You know what the problem is? We have too much heterogeneous thought. We are not homogeneous enough. We need another political litmus test,” which is nuts.
Segment 3975: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4667, Text: That’s what a DEI statement effectively is because there’s no way to actually fill out a DEI statement without someone evaluating you on your politics. It’s crystal clear. We even did an experiment on this. Nate Honeycutt, he got something almost like 3,000 professors to participate evaluating different kinds of DEI statements. One was basically the standard kind of identity politics intersectionality, one was about viewpoint diversity, one was about religious diversity, and one was about socioeconomic diversity. As far as where my heart really is, it’s that we have too little socioeconomic diversity particularly in elite higher ed, but also in education period. The experiment had large participation, really interestingly set up, and it tried to model the way a lot of these DEI policies were actually implemented. One of the ways these have been implemented, and I think in some of the California schools, is that administrators go through the DEI statements before anyone else looks at them, and then eliminates people off the top depending on how they feel about their DEI statements.
Segment 3976: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4737, Text: The one on viewpoint diversity, I think half of the people who reviewed it would eliminate it right out. I think it was basically the same for religious diversity. It was slightly better, like 40%, for socioeconomic diversity, but that kills me. The idea that kind of like, “Yeah, that actually is the kind of diversity that I think we need a great deal more of in higher education.” You can agree with… It’s not hostile to the other kinds by the way, but the idea that we need more people from the bottom of three quarters of American society in higher education, I think, should be something we could all get around, that the only one that really succeeded was the one that sprouted back exactly the kind of ideology that they thought the readers would like, which is like, okay, there’s no way this couldn’t be a political litmus test. We’ve proved that it’s a political litmus test test, and still, school after school is adding these to its application process to make schools still more ideologically homogenous.
Segment 3977: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4797, Text: Why does that have a negative effect? Is it because it enforces a kind of group think where people start becoming afraid to sort of think and speak freely, liberally, about whatever?
Segment 3978: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4816, Text: Well, one, it selects for people who tend to be farther to the left in a situation where you already have people, a situation where universities do lean decidedly that way, but it also establishes essentially a set of sacred ideas that if you’re being quizzed on what you’ve done to advance anti-racism, how you’ve been conscious of intersectionality, it’s unlikely that you’d actually get in if you said, “By the way, I actually think these are dubious concepts. I think they’re thin. I think they’re philosophically not very defensible.” Basically, if your position was, “I actually reject these concepts as being over simple,” you’re not going to get in. I think that the person that I always think of that wasn’t a right-winger that would be like, “Go to hell,” if you made him fill one of these things out, it’s Feynman. I feel like if you gave one of these things to Richard Feynman, he would tear it to pieces and then not get the chop.
Segment 3979: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4881, Text: Yeah, there’s some element of it that creates this hard to pin down fear. You said the firing… The thing I wanted to say is firing 100 people or 200 people. The point is even firing one person, I’ve just seen it, it can create this quiet ripple effect of fear.
Segment 3980: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4901, Text: Of course.
Segment 3981: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4901, Text: That single firing of a faculty-
Segment 3982: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4904, Text: Oh, absolutely.
Segment 3983: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4905, Text: … has a ripple effect across tens of thousands of people, of educators, of who is hired, what kind of conversations are being had, what kind of textbooks are chosen, what kind of self-censorship and different flavors of that is happening. It’s hard to measure that.
Segment 3984: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4922, Text: Yeah. When you ask professors about are they intimidated under the current environment, the answer is yes, and particularly, conservative professors already reporting that they’re afraid for their jobs in a lot of different cases.
Segment 3985: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4938, Text: You have a lot of good statistics in the book, things like self-censorship. One provided with a definition of self-censorship, at least a quarter of students said they self-censor fairly often or very often during conversations with other students, with professors, and during classroom discussions, 25%, 27%, and 28% respectively. A quarter of students also said that they are more likely to self-censor on campus now at the time they were surveyed than they were when they first started college. So college is kind of instilling this idea of self-censorship.
Segment 3986: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=4974, Text: Back to the Red Scare comparison, and this is one of the interesting things about the data as well, is that that same study that I was talking about, the most comprehensive study of the Red Scare, there was polling about whether or not professors were self-censoring due to the fear of the environment, and 9% of professors said that they were self-censoring their research and that what they were saying. 9% is really bad. That’s almost a tenth of professors saying that their speech was chilled. When we did this question for professors on our latest faculty survey, when you factor together, if we ask them are they self-censoring in their research, are they self-censoring in class, are they self-censoring online, et cetera, it was 90% of professors. So the idea that we’re actually in an environment that is historic in terms of how scared people are actually of expressing controversial views, I think that it’s the reason why we’re going to actually be studying this in 50 years the same way we study the Red Scare. The idea that this isn’t happening is we’ll just be correctly viewed as insane.
Segment 3987: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5040, Text: So maybe we can just discuss the current leaning of academia goes to the left, which you describe in various different perspectives. One, there’s a voter registration ratio chart that you have by department, which I think is interesting. Can you explain this chart and can you explain what it shows?
Segment 3988: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5058, Text: Yeah. When I started FIRE in 2001, I didn’t take the viewpoint diversity issue as seriously. I thought it was just something that right-wingers complained about. But I really started to get what happens when you have a community with low viewpoint diversity, and actually, a lot of the research that I got most interested in was done in conjunction with the great Cass Sunstein who writes a lot about group polarization because as… The research on this is very strong that essentially, when you have groups with political diversity, and you can see this actually in judges, for example, it tends to produce reliably more moderate outcomes, whereas groups that have low political diversity tend to sort of spiral off in their own direction. When you have a super majority of people from just one political perspective, that’s a problem for the production of ideas. It creates a situation where there are sacred ideas.
Segment 3989: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5117, Text: When you look at some of the departments, I think the estimate from the Crimson is that Harvard has 3% conservatives, but when you look at different departments, there are elite departments that have literally no conservatives in them, and I think that’s an unhealthy intellectual environment. The problem is definitely worse as you get more elite. We definitely see more cases of lefty professors getting canceled at less elite schools. It gets worse as you get down from the elite schools. That’s where a lot of the one-third of attempts to get professors punished that are successful do come from the right and largely from off-campus sources, and we spend a lot of time talking about that in the book as well. It’s something that I do think is underappreciated, but when it comes to the low viewpoint diversity, it works out like you’d expect to a degree. Economics is what? Four to one or something like that? It’s not as bad, but then when you start getting into some of the humanities, there are departments that there are literally none.
Segment 3990: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5182, Text: Is there a good to why did the university faculty administration move to the left?
Segment 3991: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5189, Text: Yeah, I don’t love… This is an argument that you’ll sometimes run into on the left, just the argument that, well, people on the left are just smarter.
Segment 3992: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5198, Text: Right.
Segment 3993: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5199, Text: It’s like, “Okay.” It’s interesting because at least the research as of 10 years ago was indicating that if you dig a little bit deeper into that, a lot of the people who do consider themselves on the left tend to be a little bit more libertarian. There’s something that Pinker wrote a fair amount about. The idea that we’re just smarter is not an opinion I’m at least a bit comfortable with. I do think that departments take on momentum when they become a place where you’re like, “Wow, it’d be really unpleasant for me to work in this department if I’m the token conservative,” and I think that takes on a life of its own.
Segment 3994: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5237, Text: There are also departments where a lot of the ideologies kind of explicitly leftist. You look at education schools, a lot of the stuff that is actually left over from what is correctly called critical race theories is present, and you end up having that in a number of the departments, and it would be very strange to be in many departments a conservative social worker professor. I’m sure they exist, but there’s a lot of pressure to shut up if you are.
Segment 3995: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5271, Text: The process on the left of cancellation, as you started to talk about with the perfect rhetorical fortress, the first step is dismiss a person. If you can put a label of conservative on them, you can dismiss them in that way. What other efficient or what other effective dismissal mechanisms are there?
Segment 3996: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5293, Text: Yeah. We have a little bit of fun with demographic numbers, and I run this by height, and I remember him being like, “Don’t include the actual percentage.” I’m like, “No, we need to include the actual percentages because people are really bad at estimating what the demographics of the US actually looks like, both the right and the left in different ways.” So we put it in the numbers and we talk about being dismissed for being white, or being dismissed for being straight, or being dismissed for being male, and you can already dismiss people for being conservative, and so we give examples in the book of these being used to dismiss people and oftentimes on topics not related to the fact that they’re a male or whether or not they’re a minority.
Segment 3997: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5335, Text: Then we get to, I think it’s layer six and we’re like, “Surprise. Guess what? You’re down to 0.4% of the population and none of it mattered because if you have the wrong opinion, even if you’re in that 0.4% of the most intersectional person who ever lived and you have the wrong opinion, you’re a heretic and you actually probably will be hated even more.” The most interesting part of the research we did for this was just asking every prominent Black conservative and moderate that we knew personally, “Have you been told that you’re not really Black for an opinion you had?” Every single one of them was like, “Oh, yeah.” No, and it’s kind of funny because oftentimes, white lefties telling them that’s like, “Oh, do you consider yourself Black?”
Segment 3998: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5377, Text: John McWhorter talked about when he showed that he dissented from some of what he described as woke racism in his book, Woke Ideas. The reporter actually is like, “So do you consider yourself Black?” He was like, “What? Are you crazy? Of course, I do.” Coleman Hughes had one of the best quotes on it. He said, “I’m constantly being told that the most important thing to how legitimate my opinion is is whether or not I’m Black, but then when I have a dissenting opinion, I get told I’m not really Black, so perfect.” There’s no way to falsify this argument. That investigation really struck me.
Segment 3999: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5420, Text: You lay this out really nicely in the book, that there is this process of saying, “Are you conservative? Yes, you can dismiss the person. Are you white? Dismiss the person. Are you male? You can dismiss the person.” There’s these categories that make it easier for you to dismiss a person’s ideas based on that, and like you said, you end up in that tiny percentage and you could still dismiss.
Segment 4000: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5441, Text: It’s not just dismiss. We talk about this from a practical standpoint, the way the limitations on reality, and one of them is time, and a lot of cancel culture as cultural norms, as this way of winning arguments without winning arguments is about running out the clock because by the time you get down to the bottom of… Or actually even to get a couple steps into the perfect rhetorical fortress, and where has the time gone? You probably just give up trying to actually have the argument and you never get to the argument in the first place.
Segment 4001: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5476, Text: All of these things are pretty sticky on social media.
Segment 4002: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5479, Text: Social media practically invented the perfect rhetorical fortress.
Segment 4003: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5482, Text: So that each one of those stages has a virality to it so it could stick and then it can get people really excited.
Segment 4004: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5488, Text: It allows you to feel outrage and superiority.
Segment 4005: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5491, Text: Yeah, because of that at the scale of the virality allows you to never get to the actual discussion of the point, but it’s not just the left, it’s the right. It’s also a efficient rhetorical fortress, so something to be proud of on the right, it’s more efficient so you don’t have to listen to liberals, and anyone can be labeled a liberal if they have a wrong opinion. I’ve seen liberal and left and leftist all used in the same kind of way. That’s leftist nonsense. You don’t have to listen to experts, even conservative experts, if they have the wrong opinion. You don’t have to listen to journalists, even conservative journalists, if they have the wrong opinion, and among the MAGA wing, there’s a fourth provision. You don’t need to listen to anyone who isn’t pro-Trump.
Segment 4006: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5542, Text: Yeah, and we call it efficient because it eliminates a lot of people you probably should listen to at least sometimes. We point out sometimes how cancel culture can interfere with faith and expertise, so we get kind of being a little suspicious of experts, but at the same time, if you follow that and you follow it mechanically, and I definitely… I think everybody in the US probably has some older uncle who exercises some of these. It is a really efficient way to wall yourself off from the rest of the world and dismiss at least some people you really should be listening to.
Segment 4007: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5578, Text: The way you laid it out, it made me realize that we just take up so much of our brain power with these-
Segment 4008: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5580, Text: … is that we just take up so much of our brain power-
Segment 4009: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5583, Text: So much time.
Segment 4010: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5584, Text: With these things. It’s literally time-
Segment 4011: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5586, Text: We could be solving things.
Segment 4012: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5587, Text: And you exhaust yourself through this process of being outraged based on these labels and you never get to actually… There’s almost not enough time for empathy, for looking at a person thinking, “Well, maybe they’re right,” because so busy categorizing them and it’s fascinating.
Segment 4013: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5604, Text: What’s the fun in empathy? I mean, what’s so interesting about this is that so much societal energy seems to be spent on these nasty, primal desires where essentially, a lot of it’s like, “Please tell me who I’m allowed to hate. Where can I legitimately be cruel? Where can I actually exercise some aggression against somebody?” And it seems to sometimes be just finding new justifications for that and it’s an understandable human failing that sometimes can be used to defend justice. But again, it will never get you anywhere near the truth.
Segment 4014: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5640, Text: One interesting case that you cover about expertise is with COVID.
Segment 4015: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5645, Text: Yeah.
Segment 4016: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5645, Text: So how did cancel culture come into play on the topic of COVID?
Segment 4017: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5651, Text: Yeah. I think that COVID was a big blow to people’s faith and expertise and cancel culture played a big role in that. I think one of the best examples of this is Jennifer Sey at Levi’s. She is a lovely woman. She was a vice president at Levi’s. She talked about actually potentially to be the president of Levi’s Jeans. And she was a big advocate for kids and when they started shutting down the schools, she started saying, “This is going to be a disaster. This is going to hurt the poor and disadvantaged kids the most. We have to figure out a way to open the schools back up.”
Segment 4018: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5690, Text: And that was such a heretical point of view and the typical kind of cancel culture wave took over as they had all sorts of petitions for her to be fired and that she needed to apologize and all this kind of stuff. And she was offered, I think, a million dollar severance which she wouldn’t take because she wanted to tell the world what she thought about this and that she wanted to continue saying that she hadn’t changed her mind, that this was a disaster for young people. And now, that’s the conventional wisdom and the research is quite clear that this was devastating to particularly disadvantaged youth. Like people understand this as being, “Okay. She was probably right.”
Segment 4019: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5732, Text: But one of the really sad aspects of cancel culture is people forget why you were canceled and they just know they hate you. There’s this lingering like, “Well, I don’t have to take them seriously anymore.” By the way, did you notice they happen to be right on something very important? Now, one funny thing about freedom of speech, freedom of speech wouldn’t exist if you didn’t also have the right to say things that were wrong. Because if you can’t engage in ideaphoria, if you can’t actually speculate, you’ll never actually get to something that’s right in the first place. But it’s especially galling when people who were right were censored and never actually get the credit that they deserve.
Segment 4020: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5773, Text: Well, this might be a good place to ask a little bit more about the freedom of speech. And so, you said that included in the freedom of speech is to say things that are wrong.
Segment 4021: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5783, Text: Yep.
Segment 4022: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5784, Text: What is your perspective on hate speech?
Segment 4023: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5787, Text: Hate speech is the best marketing campaign for censorship and it came from academia of the 20th century. And that, when I talked about the anti-free speech movement that was one of their first inventions. There was a lot of talk about critical race theory and being against critical race theory and FIRE will sue if you say that people can’t advocate for it or teach it or research it because you do absolutely have the right to pursue it academically. However, every time someone mentions CRT, they should also say the very first project of the people who founded CRT, Richard Delgado, Mari Matsuda, etc., was to create this new category of unprotected speech called hate speech and to get it banned. The person who enabled this drift, of course, was Herbert Marcuse in 1965, basically questioning whether or not free speech should be a sacred value on the left and he was on the losing side for a really long time.
Segment 4024: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5849, Text: The liberals, the way I grew up, that was basically being pro free speech was synonymous with being a liberal. But that started to be etched away on Campus and the way it was was with the idea of hate speech that essentially, “Oh, but we can designate particularly bad speech as not protected and who’s going to enforce it? Who’s going to decide what hate speech actually is?” Well, it’s usually overwhelmingly can only happen in an environment of really low viewpoint diversity because you have to actually agree on what the most hateful and wrong things are.
Segment 4025: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5888, Text: And there’s a bedrock principle, it’s referred to this in a great case about flag burning in the First Amendment that I think all the world could benefit from. You can’t ban speech just because it’s offensive. It’s too subjective. It basically is… It’s one of the reasons why these kind of codes have been more happily adopted in places like Europe where they have a sense that there’s a modal German or a modal Englishman and, “I think this is offensive and therefore, I can say that this is wrong.”
Segment 4026: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5917, Text: In a more multicultural, in a genuinely more diverse country that’s never actually had an honest thought that there is a single kind of American, there’s never been. We had the idea of Uncle Sam but that was always kind of a joke. Boston always knew it wasn’t. Richmond always knew it wasn’t. Georgia always knew it wasn’t. Alaska… We’ve always been a hodgepodge and we get in a society that diverse that you can’t ban things simply because they’re offensive and that’s one of the reasons why hate speech is not an unprotected category of speech.
Segment 4027: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5952, Text: And I go further, my theory on freedom of speech is slightly different than most other constitutional lawyers. And I think that’s partially because some of these theories, although a lot of them are really good, are inadequate. They’re not expansive enough. And I sometimes call my theory the Pure Informational Theory of Freedom of Speech or sometimes when I want to be fancy, The Lab and the Looking Glass Theory.
Segment 4028: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=5976, Text: And its most important tenet is that if the goal is the project of human knowledge which is to know the world as it is, you cannot know the world as it is without knowing what people really think and what people really think is an incredibly important fact to know. So every time you’re actually saying, “You can’t say that,” you’re actually depriving yourself of the knowledge of what people really think you’re causing… What Timer Kran, who’s on our board of advisors, calls preference falsification. You end up with an inaccurate picture of the world, which by the way, in a lot of cases, because there are activists who want to restrict more speech, they actually tend to think that people are more prejudiced than they might be.
Segment 4029: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6019, Text: And actually, these kind of restrictions, there was a book called Racial Paranoia that came out about 15 years ago that was making the point that the imposition of some of these codes can sometimes make people think that the only thing holding you back from being a raging racist are these codes. So it must be really, really bad. It can actually make all of these things worse. And one, which we talk about in the book, one very real practical way it makes things worse is when you censor people, it doesn’t change their opinion, it just encourages them to not share it with people who will get them in trouble. So it leads them to talk to people who they already agree with and group polarization takes off.
Segment 4030: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6059, Text: So we have some interesting data in the book about how driving people off of Twitter, for example, in 2017, and then again I think in 2020, driving people to gab led to greater radicalization among those people. It’s a very predictable force. Censorship doesn’t actually change people’s minds and it pushes them in directions that actually, by very solid research, will actually make them more radicalized. So yeah, I think that the attempt to ban hate speech, it doesn’t really protect us from it but it gives the government such a vast weapon to use against us that we will regret giving them.
Segment 4031: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6101, Text: Is there a way to look at extreme cases to test this idea out a little bit? So if you look on Campus, what’s your view about allowing, say, white supremacists on Campus to do speeches or KKK?
Segment 4032: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6117, Text: I think you should be able to study what people think and I think it’s important that we actually do. So I think that… Let’s take for example, QAnon. Yeah, QAnon is wrong. But where did it come from? Why did they think that? What’s the motivation? Who taught them it? Who came up with these ideas? This is important to understand history, that’s important to understand modern American politics. And so, if you put your scholar hat on and which… You should be curious about everyone, about where they’re coming from.
Segment 4033: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6154, Text: Daryl Davis, who I’m sure you’re familiar with, part of his goal was just simply to get to know where people were coming from. And in the process, he actually deradicalized a number of Klans members when they actually realized that this Black man who had befriended them actually was compassionate, was a decent person. They realized all their pre-conceptions were wrong. So it can have a deradicalizing factor, by the way. But even when it doesn’t, it’s still really important to know what the bad people in your society think. Honestly, in some ways, for your own safety, it’s probably more important to know what the bad people in your society actually think.
Segment 4034: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6190, Text: I don’t know what you think about that but I personally think that freedom of speech in cases like that like KKK and Campus can do more harm in the short term but much more benefit in the long term. Because you can sometimes argue for this is going to hurt in the short term. But I mean, Harvey said this, it’s like consider the alternative. Because you’ve just made the case for this potentially would be a good thing even in the short term.And it often is, I think, especially in a stable society like ours. Whether it’s strong middle class, all these kinds of things where people have the comforts, the reason through things.
Segment 4035: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6227, Text: But to me, it’s like even if it hurts in the short term, even if it does create more hate in the short term, the freedom of speech has this really beneficial thing which is it helps you move towards the truth, the entirety of society towards a deeper, more accurate understanding of life on earth, of society, of how people function, of ethics, of metaphysics, of everything. And that, in the long term, is a huge benefit. It gets rid of the Nazis in the long term, even if it adds to the number of Nazis in the short term.
Segment 4036: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6262, Text: Yeah. Well, and meanwhile just… And the reality check part of this is people will always bring up, “What about the Klan on Campus?” I’m like, “They’re never invited. I haven’t seen a case where they’ve been invited.” Usually, the Klan argument gets thrown out when people are trying to excuse… And that’s why we shouted down Ben Shapiro and that’s why you can’t have Bill Maher on Campus. That’s why… And it’s like, “Okay.” And it’s a little bit of that what about-ism again about being like, “Well, that thing over there is terrible and therefore this comedian shouldn’t come.”
Segment 4037: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6297, Text: So I do have a question maybe by way of advice.
Segment 4038: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6299, Text: Sure.
Segment 4039: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6301, Text: Interviewing folks and seeing this like a podcast as a platform and deciding who to talk to and not… That’s something I have to come face to face with on occasion. My natural inclination before I started the podcast was I would talk to anyone and including people which I’m still interested in who are the current members of the KKK.
Segment 4040: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6325, Text: And to me, there’s a responsibility to do that with skill and that responsibility has been weighing heavier and heavier on me because you realize how much skill it actually takes because you have to know to understand so much. Because I’ve come to understand that the devil is always going to be charismatic, the devil’s not going to look like the devil. And so, you have to realize you can’t always come to the table with a deep compassion for another human being. You have to have 90% compassion and another 90% deep historical knowledge about the context of the battles around this particular issue and that takes just a huge amount of effort. But I don’t know if there’s thoughts you have about this, how to handle speech in a way without censoring, bringing it to the surface, but in a way that creates more love in the world.
Segment 4041: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6384, Text: I remember Steve Bannon got disinvited from the New Yorker festival and Jim Carrey freaked out and all sorts of other people freaked out and he got disinvited from the… And I got invited to speak on SMERCONISH about this and I was saying, “Listen, you don’t have people to your conference because you agree with them. We have to get out of this idea that…” Because they were trying to make it sound like that’s an endorsement of Steve Bannon, that’s nonsense. If you actually look at the opinions of all the people who are there, you can’t possibly endorse all the opinions that all these other people who are going to be there actually have. And in the process of making that argument I got…
Segment 4042: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6427, Text: And also, of course the very classic, it’s very valuable to know what someone like Steve Bannon thinks, you should be curious about that. And I remember someone arguing back saying, “Well, would you want someone to interview a jihadi?” and I’m like… Because at the moment, it was at the time when ISIS was really going for it and I was like, “Would you not want to go to a talk where someone was trying to figure out what makes some of these people tick?” That changes your framing that essentially it’s like, “No, it’s curiosity, is the cure for a lot of this stuff,” and we need a great deal more curiosity and a lot less unwarranted certainty.
Segment 4043: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6464, Text: And there’s a question of, “How do you conduct such conversations?” and I feel deeply underqualified.
Segment 4044: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6471, Text: Who do you think are especially good at that?
Segment 4045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6474, Text: I feel like documentary filmmakers usually do a much better job and the best job is usually done by biographers. So the more time you give to a particular conversation, really deep thought and historical context and studying the people, how they think, looking at all different perspectives, looking at the psychology of the person, the upbringing, their parents, their grandparents, all of this. The more time you spend with that, the better the quality of the conversation is because you get to really empathize with the person, with the people he or she represents, and you get to see the common humanity, all of this. Interviewers often don’t do that work. So the best stuff I’ve seen is interviews that are part of a documentary. But even now, documentaries are like there’s a huge incentive to do as quickly as possible. There’s not an incentive to really spend time with the person.
Segment 4046: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6531, Text: Yeah. There’s a great new documentary about Floyd Abrams that I really recommend. We did a documentary about Ira Glasser called Mighty Ira which was my video team and my protege, Nico Purino and Chris Malby and Aaron Reese, put it together and it just follows the life and times of Ira Glasser, the former head of the ACLU.
Segment 4047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6554, Text: If you could just linger on that, that’s a fascinating story.
Segment 4048: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6556, Text: Oh, yeah.
Segment 4049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6556, Text: Who’s Ira?
Segment 4050: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6558, Text: Ira’s amazing. Ira, he wasn’t a lawyer. He started working at the NYCLU, the New York Civil Liberties Union back in, I think, the ’60s. I think Robert Kennedy recommended that he go in that direction and he became the president of the ACLU right at the time that they were suffering from defending the Nazis at Skokie. And Nico and Aaron and Chris put together this… They’d never done a documentary before and it came out so so well and it tells the story of the Nazis in Skokie. It tells the story of the case around it. It tells the story of the ACLU at the time and what a great leader Ira Glasser was. And one of the things that’s so great is when you get to see the Nazis at Skokie, they come off the idiots that you would expect them to.
Segment 4051: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6608, Text: There’s a moment when the rally is not going very well and the leader gets flustered and it almost seems like he’s going to shout out like, “You’re making this Nazi rally into a mockery.” And so, it showed how actually allowing the Nazis to speak at Skokie took the wind out of their sails like if they had… The whole movement, it all dissolved after that because they looked like racist fools that they were, even Blues Brothers made jokes about them, and it didn’t turn into the disaster that people thought it was going to be just by letting them speak.
Segment 4052: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6645, Text: And Ira Glasser, okay, so he has this wonderful story about how Jackie Robinson joined the Brooklyn Dodgers and how there was a moment when it was seeing someone, an African-American as literally on their team and how that really got them excited about the cause of racial equality and that became a big part of what his life was. And I just think of that as such a great metaphor is expanding your circle and seeing more people as being quite literally on your team is the solution to so many of these problems. And I worry that one of the things that is absolutely just a fact of life in a America is like we do see each other more as enemy camps as opposed to people on the same team. And that was actually something in the early days, like me and Will Creeley, the legal director of FIRE wrote about the forthcoming free speech challenges of everyone being on Facebook. And one thing that I was hoping was that as more people were exposing more of their lives, we had realized a lot of these things we knew intellectually like kids go to the bar and get drunk and do stupid things.
Segment 4053: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6715, Text: That when we started seeing the evidence of them doing stupid things that we might be shocked at first. But then, eventually, get more sophisticated and be like, “Well, come on. People are like that.” That never actually really seemed to happen. I think that there are plenty of things we know about human nature and we know about dumb things people say and we’ve made it into an environment where there’s just someone out there waiting to be like, “Oh, remember that dumb thing you said when we were 14? Well, I’m going to make sure that you don’t get into your dream school because of that.”
Segment 4054: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6748, Text: That’s offense archeology. Whereas-
Segment 4055: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6750, Text: Yeah. That’s not my term though. It’s a great term.
Segment 4056: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6752, Text: Well, it’s a great term. We steal from the best. Digging through someone’s past comments to find speech that hasn’t aged well.
Segment 4057: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6758, Text: And that one’s tactical. That one isn’t just someone not being empathetic. They’re like, “I’m going to punish you for this,” or… And that’s one of the reasons why I got depressed writing this book because there’s already people who don’t love me because of The Coddling of the American Mind, usually based on a misunderstanding of what we actually said in Coddling of the American Mind but nonetheless.
Segment 4058: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6777, Text: But on this one, I’m calling out people for being very cruel in a lot of cases. But one thing that was really scary about studying a lot of these cases is that once you have that target on your back, what they’re going to try to cancel you for could be anything. They might go back into to your old post, find something that you said in 1995, do something where essentially it looks like it’s this entire other thing. But really, what’s going on is they didn’t like your opinion, they didn’t like your point of view on something. And they’re going to find a way that from now on, anytime your name comes up, it’s like, “Oh, remember this thing I didn’t like about them?” and it’s, again, it’s cruel. It doesn’t get you anywhere closer to the truth but it is a little scary to stick your neck out.
Segment 4059: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6826, Text: Okay. In terms of solutions. I’m going to ask you a few things. So one, parenting.
Segment 4060: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6832, Text: Yeah. Five and seven year old.
Segment 4061: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6836, Text: So I’m sure you’ve figured it all out then.
Segment 4062: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6838, Text: Oh god no.
Segment 4063: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6842, Text: From a free speech culture perspective, how to be a good parent.
Segment 4064: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6845, Text: Yeah. I think the first quality you should be cultivating in your children if you want to have a free speech culture is curiosity and an awareness of the vastness that will always be unknown. And getting my kids excited about the idea that’s like, “We’re going to spend our whole lives learning about stuff and it’s fast and exciting and endless. And we’ll never make a big dent in it, but the journey will be amazing.” But only fools think they know everything and sometimes, dangerous fools at that. So giving the sense of intellectual humility early on.
Segment 4065: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6886, Text: Also, saying things that actually do sound old-fashioned. I say things to my kids like, “Listen, if you enjoy study and work,” both things that I very much enjoy, I do for fun, ” your life is going to feel great and it’s going to feel easy.” So some of those old-fashioned virtues are things I try to preach.
Segment 4066: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6910, Text: Counterintuitive stuff like outdoor time, playing, having time that are not intermediated experiences is really important. And little things like I talk about in the book about when my kids are watching something that’s scary. And I’m not talking about zombie movies, I’m talking about a cartoon that has a scary moment and saying that they want to turn the TV off. And I talk to them and I say, “Listen, I’m going to sit next to you and we’re going to finish this show and I want you to tell me what you think of this afterwards.”
Segment 4067: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6945, Text: And I sat next to my sons and by the end of it, every single time when I asked them, “Was that as scary as you thought it was going to be?” and they was like, “No, daddy. That was fine,” and I’m like, “That’s one of the great lessons in life. The fear that you don’t go through becomes much bigger in your head than actually simply facing it.” That’s one of the reasons why I’m fighting back against this culture. I’d love for all of our kids to be able to grow up in an environment where people give you grace and accept the fact that sometimes people are going to say things that piss you off, take seriously the possibility you might be wrong, and be curious.
Segment 4068: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6982, Text: Well, I have hope that the thing you mentioned which is because so much of young people’s stuff is on the internet that they’re going to give each other a break. Then, everybody is cancel worthy.
Segment 4069: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=6993, Text: Generation Z hates cancel culture the most and that’s another reason why it’s like people are still claiming this isn’t even happening. It’s like, “No, you actually can ask kids what they think of cancel culture,” and they hate it.
Segment 4070: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7004, Text: Yeah. Well, I think of them as the immune system. That’s the culture waking up to like, “No, this is not a good thing.”
Segment 4071: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7011, Text: I am glad though. I mean, I am one of those kids who is really glad that I was a little kid in the ’80s and a teenager in the ’90s. Because having everything potentially online, it’s not an upbringing I envy.
Segment 4072: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7026, Text: Well, because you can also do the absolutest free speech, I like leaning into it where I hope for a future where a lot of our insecurities, flaws, everything’s out there and to be raw, honest with it. I think that leads to a better world because the flaws are beautiful. I mean, the flaws is the basic ingredients of human connection.
Segment 4073: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7054, Text: Robert Wright, he wrote a book on Buddhism and I talked about trying to use social media from a Buddhist perspective as if it’s the collective unconscious meditating and seeing those little angry bits that are trying to cancel you or get you to shut up and just letting them go the same way you’re supposed to watch your thoughts trail off.
Segment 4074: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7079, Text: I would love to see that visualized. Whatever the drama going on, just seeing the sea of it, of the collective consciousness just processing this and having a little panic attack and just breathing it in-
Segment 4075: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7095, Text: Yeah. Look at the little hateful, angry voices pop up and be like, “Okay. There you are and I’m still focused on that thing.” Because that is one of the things is… Okay. Yeah. Actually, this is probably late in the game to giving my grand theory on this stuff but-
Segment 4076: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7113, Text: Never too late.
Segment 4077: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7114, Text: So what I was studying in law school when I ran out of First Amendment classes, I decided to study censorship during the Tudor Dynasty because that’s where we get our ideas of prior restraint that come from the licensing of the printing press which was something that Henry VIII was the first to do. Where basically, the idea was that you can’t print anything in England unless it’s with your Majesty approved printers. It will prevent heretical work and anti-Henry VIII stuff from coming out. Pretty efficient idea if nothing else.
Segment 4078: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7153, Text: And so, he started getting angry at the printing press around 1521 and then passed something that required prints to be along with parliament in 1538. And I always think of that as where we are now because we have this… Back then, we had the original disruptive technology. Writing was probably really that but the next one which was the printing press which was absolutely calamitous. And I say calamitous on purpose because in the short term, the witch hunts went up like crazy because the printing press allowed you to get that manual on how to find witches. That the religious wars went crazy. It led to all sorts of distress, misinformation, nastiness.
Segment 4079: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7198, Text: And Henry VIII was trying to put the genie back in the bottle. He was kind of like, “I want to use this for good like I feel like it could be used,” but he was in an unavoidable period of epistemic anarchy. There’s nothing you can do to make the period after the printing press come, came out to be a non-disruptive, non-crazy period other than absolute totalitarianism and destroy all the print presses which simply was not possible in Europe.
Segment 4080: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7228, Text: So I feel like that’s where we are now. That disruption came from adding, I think, several million people to the European conversation and that eventually the global conversation. But eventually, it became the best tool for disconfirmation, for getting rid of falsity, for spotting bad ideas, and the long-term benefits, of the printing press are incalculably great.
Segment 4081: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7255, Text: And that’s what gives me some optimism for where we are now with social media because we are in that unavoidably anarchical period. I do worry that there are attempts in states to pass things to try to put the genie back in the bottle. Like if we ban TikTok or we say that nobody under 18 can be on the internet unless they have parental permission. We’re going at something that no amount of top down is going to be able to fix it.
Segment 4082: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7285, Text: We have to culturally adapt to the fact of it in ways that make us wiser that actually… And allow it, potentially, to be that wonderful engine for disconfirmation that we’re nowhere near yet, by the way. But think about it, additional millions of eyes on problems thanks to the printing press helped create the scientific revolution, the enlightenment, the discovery of ignorance. We now have added billions of eyes and voices to solving problems and we’re using them for cat videos and canceling.
Segment 4083: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7322, Text: But those are just the early days of the printing press-
Segment 4084: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7326, Text: Exactly.
Segment 4085: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7326, Text: It all starts with the cats and the canceling. Is there something about X, about Twitter, which is perhaps the most energetic source of cats and canceling?
Segment 4086: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7337, Text: It seems like the collective unconscious of the species. I mean, it’s one of these things where the tendency to want to see patterns in history sometimes can limit the actual batshit crazy experience of what history actually is. Because yes, we have these nice comforting ideas that it’s going to be like last time. We don’t know. It hasn’t happened yet and I think how unusual Twitter is.
Segment 4087: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7366, Text: Because I think of it as the… Because people talk about writing and mass communications as expanding the size of our collective brain, but now we’re looking at our collective brain in real time and it’s filled just like our own brains with all sorts of little crazy things that pop up and appear like virtual particles all over the place of people reacting in real time to things. There’s never been anything even vaguely like it and it can be at its worst, awful to see.
Segment 4088: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7402, Text: At its best, sometimes seeing people just getting euphoric over something going on and cracking absolutely brilliant immediate jokes at the same time. It can even be a joyful experience. I feel like I live in a neighborhood now on X where I mostly deal with people that I think are actually thoughtful, even if I disagree with them and it’s not such a bad experience. I occasionally run into those other, what I call neighborhoods on X, where it’s just all canceling, all nastiness, and it’s always an unpleasant visit to those places. I’m not saying the whole thing needs to be like my experience but I do think that-
Segment 4089: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7440, Text: … be, like my experience. But I do think that the reason why people keep on coming back to it is it reveals raw aspects of humanity that sometimes we prefer to pretend don’t exist.
Segment 4090: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7453, Text: Yeah, but also it’s totally new, like you said.
Segment 4091: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7455, Text: Yeah.
Segment 4092: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7456, Text: It’s just the virality, the speed that news travels, that opinions travel, that the battle over ideas travels.
Segment 4093: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7462, Text: The battle over information too.
Segment 4094: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7464, Text: Yeah, of what is true and not, lies travel, the old Mark Twain thing, pretty fast on the thing.
Segment 4095: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7469, Text: Yeah.
Segment 4096: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7469, Text: And then it changes your understanding of how to interpret information.
Segment 4097: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7475, Text: It can also stress you out to no end. Remember to get off it sometimes. The stats are pretty bad on mental health with young people, and I’m definitely in the camp of people who think that social media is part of that, I understand the debate. But I’m pretty persuaded that one of the things that hasn’t been great for mental health of people is this just constantly being exposed.
Segment 4098: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7496, Text: Yeah, absolutely. I think it’s possible to create social media that makes a huge amount of money, makes people happy. To me it’s possible to align the incentives. So in terms of making teenagers, making every stage of life giving you long-term fulfillment and happiness with your physical existence outside of |social media and on social media, helping you grow as a human being, helping challenge you just the right amount, and just the right amount of cat videos, whatever gives this full rich human experience. I think it’s just a machine learning problem. It’s like, it’s not easy-
Segment 4099: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7534, Text: Interesting.
Segment 4100: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7534, Text: To create a feed, so the easiest feed you could do is maximize engagement.
Segment 4101: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7539, Text: Yeah.
Segment 4102: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7539, Text: But that’s just a really dumb algorithm. For the algorithm to learn enough about you to understand what would make you truly happy as a human being to grow longterm, that’s just a very difficult problem to solve.
Segment 4103: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7557, Text: Have you ever watched Fleabag? It’s absolutely brilliant, British show, and it sets you up, one of the reasons why people love it so much is it sets you up that you’re watching a raunchy British Sex in the City, except the main character is the most promiscuous one. It’s like, okay, and you roll your eyes a little bit, but it’s kind of funny and it’s kind of cute and kind of spicy.
Segment 4104: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7579, Text: And then you realize that the person is actually kind of suffering and having a hard time, and it gets deeper and deeper as the show goes on. And she will do these incredible speeches about, tell me what to do. Just, I know there’s experts out there, I know there’s knowledge out there, I know there’s an optimal way to live my life, so why can’t someone just tell me what to do? And it’s this wonderfully accurate, I think, aspect of human desire that, what if something could actually tell me the optimal way to go? Because I think there is a desire to give up some amount of your own freedom and discretion in order to be told to do the optimally right thing, but that path scares me to death.
Segment 4105: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7626, Text: Yeah, but see, the way you phrased it, that scares me too. So there’s several things, one, you could be constantly distracted in a TikTok way by things that keep you engaged.
Segment 4106: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7637, Text: Yeah.
Segment 4107: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7637, Text: So removing that and giving you a bunch of options constantly, and learning from long-term what results in your actual long-term happiness. So which amounts of challenging ideas are good for you?
Segment 4108: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7654, Text: Four.
Segment 4109: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7656, Text: For somebody like me… Exactly.
Segment 4110: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7658, Text: Just four.
Segment 4111: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7659, Text: But there is a number like that for you, Greg.
Segment 4112: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7661, Text: Yeah, that’s a lot.
Segment 4113: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7662, Text: For me that number is pretty high. I love debate, I love the feeling of realizing, holy shit, I’ve been wrong.
Segment 4114: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7671, Text: Yes.
Segment 4115: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7672, Text: But I would love for the algorithm to know that about me and to help me, but always giving me options, if I want to descend into cat videos and so on.
Segment 4116: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7681, Text: Well, the educational aspect of it.
Segment 4117: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7683, Text: Yes, educational.
Segment 4118: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7685, Text: The idea of both going the speed that you need to and running as fast as you can.
Segment 4119: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7689, Text: Yeah. I mean, there’s the whole flow thing. I just feel YouTube recommendation, for better or worse, if used correctly, it feels like it does a pretty good job. Whenever I just refuse to click on stuff that’s just dopamine based and click on only educational things, the recommendation it provides are really damn good. So I feel like it’s a solvable problem, at least in the space of education, of challenging yourself, but also expanding your realm of knowledge, and all this kind of stuff.
Segment 4120: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7719, Text: And I’m definitely more in the, we’re in an inescapably anarchical period and require big cultural adjustments, and there’s no way that this isn’t going to be a difficult transition.
Segment 4121: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7728, Text: Is there any specific little or big things that you’d like to see X do? Twitter do?
Segment 4122: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7734, Text: I have lots of thoughts on that. With the printing press, an extra millions of eyes on any problem can tear down any institution, any person, or any idea. And that’s good in some ways because a lot of medieval institutions needed to be torn down, and some people did too, and a lot of ideas needed to be torn down. Same thing is true now, an extra billions of eyes on every problem can tear down any person idea or institution, and again, some of those things needed to be torn down, but it can’t build yet. We are not at the stage that it can build yet. But it has shown us how thin our knowledge was, it’s one of the reasons why we’re all so aware of the replication crisis, it’s one of the reasons why we’re all so aware of how shoddy our research is, how much our expert class is arrogant, in many cases.
Segment 4123: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7777, Text: But people don’t want to live in a world where they don’t have people that they respect and they can look at, and I think what’s happening, possibly now, but will continue to happen is people are going to establish themselves as being high integrity, that they’ll always be honest. I think you are establishing yourself as someone who is high integrity, where they can trust that person. FIRE wants to be the institution that people can come to, it’s like, if it’s free speech, we will defend it, period. And I think that people need to have authorities that they can actually trust. And I think that if you actually had a stream that maybe people can watch in action, but not flood with stupid cancel culture stuff or dumb cat memes, where it is actually a serious discussion bounded around rules, no perfect rhetorical fortress, no efficient rhetorical fortress, none of the BS ways we debate, I think you could start to actually create something that could actually be a major improvement in the speed with which we come up with new better ideas and separate truth from falsity.
Segment 4124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7841, Text: Yeah, if it’s done well it can inspire a large number of people to become higher and higher integrity, and it can create integrity as a value to strive for.
Segment 4125: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7851, Text: Yeah.
Segment 4126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7852, Text: There’s been projects throughout the internet that have done an incredible job of that, but have been also very flawed. Wikipedia is an example of a big leap forward in doing that.
Segment 4127: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7863, Text: It’s pretty damn impressive. What’s your overall take? I mean, I’m mostly impressed.
Segment 4128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7867, Text: So there’s a few really powerful ideas for the people who edit Wikipedia, one of which is each editor for themselves declares, I’m into politics and I really am a left leaning guy, so I really shouldn’t be editing political articles because I have bias.
Segment 4129: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7889, Text: That’s great.
Segment 4130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7890, Text: They declare their biases, and they often do a good job of actually declaring the biases. But they’ll still, they’ll find a way to justify themselves, like something will piss them off and they want to correct it, because they love correcting untruth into truth. But the perspective of what is true or not is affected by their bias.
Segment 4131: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7910, Text: Truth is hard to know.
Segment 4132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7911, Text: And it is true that there is a left-leaning bias on the editors of Wikipedia. So for that, what happens is on articles, which I mostly appreciate, that don’t have a political aspect to them, scientific articles or technical articles, they can be really strong. Even history, just describing the facts of history that don’t have a subjective element, strong. Also, just using my own brain, I can filter out if it’s something about January 6th, or something like this, I know I’m going to be like, whatever’s going on here, I’m going to kind of read it, but mostly I’m going to look to other sources, I’m going to look to a bunch of different perspectives on it. It’s going to be very tense, there’s probably going to be some kind of bias, maybe some wording will be such, which is this is where Wikipedia does its thing, the way they word stuff will be biased, the choice of words. But the Wikipedia editors themselves are so self-reflective they literally have articles describing these very effects, of how you can use words to inject bias in all the ways that you talked about it.
Segment 4133: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7986, Text: That sounds healthier than most environments.
Segment 4134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=7987, Text: It’s incredibly healthy, but I think you could do better. One of the big flaws of Wikipedia to me that Community Notes on X does better is the accessibility of becoming an editor, it’s difficult to become an editor, and it’s not as visible, the process of editing. So I would love, like you said, a stream, for everyone to be able to observe this debate between people with integrity, of when they discuss things like January 6th, of very controversial topics, to just see how the process of the debate goes, as opposed to being hidden in the shadows, which it currently is in Wikipedia. You can access that, it’s just hard to access.
Segment 4135: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8028, Text: And I’ve also seen how they will use certain articles on certain people. Articles about people I’ve learned to trust less and less, because they literally will use those to make personal attacks. And this is something you write about, they’ll use descriptions of different controversies to paint a picture of a person that doesn’t, to me at least, feel like an accurate representation of the person. And it’s like writing an article about Einstein, mentioning something about theory of relativity and then saying that he was a womanizer and abuser and controversy. Yeah, he is, Feynman also, they’re not exactly the perfect human in terms of women. But there’s other aspects to this human, and to capture that human properly, there’s a certain way to do it. I think Wikipedia will often lean, they really try to be self-reflective and try to stop this, but they will lean into the drama if it matches the bias.
Segment 4136: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8092, Text: But again, the world, I believe, is much better because Wikipedia exists. But now that we’re in these adolescent stages, we’re growing and trying to come up with different technologies, the idea of a stream is really, really interesting, because you get more and more people into this discourse where the value is, let’s try to get the truth.
Segment 4137: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8116, Text: Yeah, yeah, and that basically you get the little cards for nope, wrong, nope, wrong.
Segment 4138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8121, Text: And the different rhetorical techniques that are being used to avoid actually discussing.
Segment 4139: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8126, Text: Yeah. And I think actually it can make it a little bit fun by you get a limited number of them. It’s kind of like, you get three whataboutism cards.
Segment 4140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8134, Text: So gamifying the whole thing, absolutely.
Segment 4141: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8136, Text: Yeah.
Segment 4142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8137, Text: Let me ask you about, you mentioned going through some difficult moments in your life.
Segment 4143: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8142, Text: Sure.
Segment 4144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8144, Text: What has been your experience with depression? What has been your experience getting out of it, overcoming it?
Segment 4145: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8152, Text: Yeah, I mean, the whole thing, the whole journey with Coddling of the American Mind began with me at the Belmont Psychiatric Facility in Philadelphia back in 2007. I had called 9-1-1 in a moment of clarity because I had gone to the hardware store to make sure that when I killed myself that it stuck. I wanted to make sure that I had my head wrapped and everything, so if all the drugs I was planning to take didn’t work, that I wouldn’t be able to claw my way out. It’d been a really rough year, and I always had issues with depression, but they were getting worse.
Segment 4146: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8192, Text: And frankly, one of the reasons why this cancel culture stuff is so important to me is that the thing that I didn’t emphasize as much in Coddling of the American Mind, which by the way, that description that I give of trying to kill myself was the first time I’d ever written it down. Nobody in my family was aware of it being like that, my wife had never seen it, and basically the only way I was able to write that was by doing, you know how you can kind of trick yourself? And I was like, I’m going to convince myself that this is just between me and my computer and nobody will see it. And it’s probably now the most public thing I’ve ever written.
Segment 4147: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8227, Text: But what I didn’t emphasize in that was how much the culture war played into how depressed I got, because I was originally legal director of FIRE, then I became president of FIRE in 2005, move to Philadelphia, is where I get depressed, and just I don’t have family there, there’s something about the town, they don’t seem to like me very much. But the main thing was being in the culture world all the time. There was a girl that I was dating, I remember she didn’t seem to really approve what I did, and a lot of people didn’t really seem to. And meanwhile, I was defending people on the left all the time, and they’d be like, “Oh, that’s good that you’re defending someone on the left,” but they still would never forgive me for defending someone on the right. And I remember saying at one point, I’m like, “Listen, I’m a true believer in this stuff, I’m willing to defend Nazis, I’m certainly willing to defend Republicans.” And she actually said, “I think Republicans might be worse.” And that relationship didn’t go very well.
Segment 4148: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8284, Text: And then I’ve nearly gotten in fistfights a couple of times with people on the right because they found out I defended people who crack jokes about 9/11. This happened more than once, by that time I’m in my 20s, I’m not fist fighting again. But yeah, it was always like that. You see how hypocritical people can be, you can see how friends can turn on you if they don’t like your politics. So I got a early preview of this, of the culture we were heading into, by being the president of FIRE, and it was exhausting, and that was one of the main things that led me to be suicidally depressed. At the Belmont Center, if you told me that that would be the beginning of a new and better life for me, I would’ve laughed if I could have, but I don’t… you can tell I’m okay if I’m still laughing, and I wasn’t laughing at that point.
Segment 4149: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8337, Text: So I got a doctor and I started doing cognitive behavioral therapy. I started having all these voices in my head that were catastrophizing, and it gave overgeneralization and fortune-telling, mind reading, all of these things that they teach you not to do, and what you do in CBT is essentially you have something makes you upset and then you just write down what the thought was, and something minor could happen and your response was like, “Well, the date didn’t seem to go very well, and that’s because I’m broken and will die alone,” and you’re like, okay, okay, okay, what are the following? That’s catastrophizing, that’s mind reading, that’s fortune-telling, that’s all this stuff. And you have to do this several times a day, forever. I actually need to brush up on it at the moment.
Segment 4150: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8392, Text: And it slowly, over time, voices in my head that had been saying horrible, horrible internal talk, it just didn’t sound as convincing anymore, which was a really subtle effect. It was just like, oh wait, I don’t buy that I’m broken, that doesn’t sound true, that doesn’t sound like truth from God like it used to. And nine months after I was planning to kill myself, I was probably happier than I’d been in a decade. And that was one of the things that, the CBT is what led me to notice this in my own work, that it felt like administrators were kind of selling cognitive distortions, but students weren’t buying yet. And then when I started noticing that they seemed to come in actually already believing in a lot of this stuff, that it would be very dangerous, and that led to Coddling of the American Mind, and all that stuff.
Segment 4151: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8444, Text: But the thing that was rough about writing Canceling of the American Mind, and I’ve mentioned this already a couple of times, I got really depressed this past year because I was studying. There’s a friend in there that I talk about who killed himself after being canceled. And I talked to him a week before he killed himself, and I hadn’t actually checked in with him because he seemed so confident I thought he would be totally fine, because he had an insensitive tweet in June of 2020 and got forced out. In a way that didn’t actually sound as bad as a lot of the other professors, he actually at least got a severance package, but they knew he’d sue and win, because he had before.
Segment 4152: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8482, Text: And so I waited to check in on him, because we were so overwhelmed with the requests for help, and he was saying people were coming to his house still, and then he shot himself the next week. And I definitely… And because everyone knows, I’m so public about my struggles with this stuff, everybody who fights this stuff comes to me when they’re having a hard time, and this is a very hard psychologically taxing business to be in. And even admitting this right now, I think about all the vultures out there, they’ll have fun with it. Just like the same way, when my friend Mike Adams killed himself, there were people celebrating on Twitter that a man was dead because they didn’t like his tweets, but somehow that made them compassionate for some abstract other person.
Segment 4153: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8527, Text: So I was getting a little depressed and anxious, and the thing that really helped me more than anything else was confessing to my staff. Books take a lot of energy, so I knew they didn’t want to hear that not only was this taking a lot of the boss’s time, this was making him depressed and anxious. But when I finally told the leadership of my staff, people that even though I try to maintain a lot of distance from, I love very, very much, it made such a difference, because I could be open about that. And the other thing was, have you heard this conference Dialogue?
Segment 4154: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8563, Text: Oh yes.
Segment 4155: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8564, Text: It’s like an invite only thing, it’s Auren Hoffman runs it. It intentionally tries to get people over the political spectrum to come together and have off the record conversations about big issues. And it was nice to be in a room where liberal, conservative, none of the above we’re all like, oh, thank God someone’s taken on cancel culture, and where it felt like maybe this won’t be the disaster for me and my family that I was starting to be afraid it would be, that taking the stuff on might actually have a happy ending.
Segment 4156: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8598, Text: Well, one thing that just stands out from that is the pain of cancellation can be really intense. And that doesn’t necessarily mean losing your job, but just even, you can call it bullying, you can call it whatever name, but just some number of people on the internet, and that number can be small, saying bad things to you, that can be a pretty powerful force to the human psyche, which was very surprising. And then the flip side also of that, it really makes me sad how cruel people can be.
Segment 4157: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8638, Text: Yeah. Thinking that your cause is social justice in many cases can lead people to think, I can be as cruel as I want in pursuit of this, when a lot of times it’s just a way to vent some aggression on a person that you think of only as an abstraction.
Segment 4158: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8658, Text: So I think it’s important for people to realize that whatever negative energy, whatever negativity you want to put out there, there’s real people that can get hurt. You can really get people to one, be the worst version of themselves, or two, possibly take their own life, and it’s not as real.
Segment 4159: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8685, Text: Yeah. Well, that’s one of the things that we do in the book to really address people who still try to claim this isn’t real, is we just quote. We quote the Pope, we quote Obama, we quote James Carville, we quote Taylor Swift on cancel culture. And Taylor Swift’s quote is essentially about how behind all of this, when it gets particularly nasty, there’s this very clear kill yourself kind of undercurrent to it, and it’s cruel. And the problem is that in an environment so wide open, there’s always going to be someone who wants to be so transgressive and say the most hurtful, terrible thing.
Segment 4160: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8727, Text: But then you have to remember the misrepresentation, getting back to the old idioms, sticks and stones will break my bones but names will never hurt me, has been re-imagined in campus debates in the most asinine way. People will literally say stuff, but now we know words can hurt. And it’s like, now we know words can hurt? Guys, you didn’t have to come up with a special little thing that you teach children to make words hurt less if they never hurt in the first place, it wouldn’t even make sense, the saying, it’s a saying that you repeat to yourself to give yourself strength when the bullies have noticed you’re a little weird. This might be a little personal. And it helps, it really does help to be like, listen, okay, assholes are going to say asshole things, and I can’t let them have that kind of power over me.
Segment 4161: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8780, Text: Yeah, yeah, it still is a learning experience because it does hurt.
Segment 4162: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8786, Text: But for the good people out there who actually just sometimes think that they’re venting, think about it, remember that there are people on the other side of it.
Segment 4163: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8795, Text: Yeah, for me it hurts my faith in humanity, I know it shouldn’t, but it does sometimes, when I just see people being cruel to each other, it floats a cloud over my perspective of the world that I wish didn’t have to be there.
Segment 4164: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8813, Text: Yeah. That was always my flippant answer to, if mankind is basically good or basically evil, being the biggest debate in philosophy, and being like, well, the problem, first is there’s nothing basic about humanity.
Segment 4165: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8829, Text: Yeah. What gives you hope about this whole thing? About this dark state that we’re in as you describe, how can we get out, what gives you hope that we will get out?
Segment 4166: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8841, Text: I think that people are sick of it. I think people are sick of not being able to be authentic. And that’s really what censorship is, it’s basically telling you don’t be yourself, don’t actually say what you think, don’t show your personality, don’t dissent, don’t be weird, don’t be wrong, and that’s not sustainable. I think that people have had enough of it. But one thing I definitely want to say to your audience is it can’t just be up to us arguers to try to fix this. And I think that, and this may sound like it’s an unrelated problem, I think if there were highly respected, let’s say extremely difficult ways to prove that you’re extremely smart and hardworking, that cost little or nothing, that actually can give the Harvards and the Yales of the world a run for their money, I think that might be the most positive thing we could do to deal with a lot of these problems, and why.
Segment 4167: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8906, Text: I think the fact that we have become a weird America with a great anti-elitist tradition has become weirdly elitist in the respect that we not only, again, are our leadership coming from these few fancy schools, we actually have great admiration for them, we look up to them. But I think we’d have a lot healthier of a society if people could prove their excellence in ways that are coming from completely different streams that are highly respected.
Segment 4168: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8936, Text: I sometimes talk about there should be a test that anyone who passes it gets a BA in the humanities, like a super BA. Not a GED, that’s not what I’m talking about, I’m talking about something that one out of only 100 people can pass, some other way of actually, of not going through these massive, bloated, expensive institutions that people can raise their hands and say, I’m smart and hardworking. I think that could be an incredibly healthy way. I think we need additional streams for creative people to be solving problems, whether that’s on X or someplace else. I think that there’s lots of things that technology could do to really help with this. I think some of the stuff that Sal Khan is working on at Khan Academy could really help.
Segment 4169: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=8980, Text: So I think there’s a lot of ways, but they exist largely around coming up with new ways of doing things, not just expecting the old things that have, say, 40 billion in the bank, that they’re going to reform themselves. And here’s my, I’ve been picking on Harvard a lot, but I’m going to pick on them a little bit more. I talk a lot about class, again, and there’s a great book called Poison Ivy by Evan Mandery, which I recommend to everybody, it’s outrageous, it sounds like me on a rant at Stanford, which was, and I think the stat is elite higher education has more kids from the top 1% than they have from the bottom 50 or 60% depending on the school. And when you look at how much they actually replicate class privilege, it’s really distressing. So everybody should read Poison Ivy.
Segment 4170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9031, Text: And above all else, if you’re weird, continue being weird.
Segment 4171: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9035, Text: Yeah, please.
Segment 4172: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9038, Text: And you’re one of the most interesting, one of the weirdest, in the most beautiful way, people I’ve ever met, Greg, thank you for the really important work you do. This was-
Segment 4173: Speaker: Greg Lukianoff, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9046, Text: Everybody watch Kid Cosmic.
Segment 4174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9052, Text: I appreciate the class, the hilarious that you brought here today, man. This was an amazing conversation, thank you for the work you do. Thank you, thank you. And for me, who deeply cares about education, higher education, thank you for holding the MITs and the Harvards accountable for doing right by the people that walk their halls. So thank you so much for talking today.
Segment 4175: Speaker: , Timestamp: https://youtube.com/watch?v=buarAx_u2qg&t=9076, Text: Thanks for listening to this conversation with Greg Lukianoff. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Noam Chomsky, “If you believe in freedom of speech, you believe in freedom of speech for views you don’t like. Goebbels was in favor of freedom of speech for views he liked, so was Stalin. If you’re in favor of freedom of speech, that means you’re in favor of freedom of speech precisely for views you despise.” Thank you for listening, and hope to see you next time.
Segment 4176: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=0, Text: We have been encouraged culturally to criticize people we’re in long-term relationships with. Not new relationships. New relationships, you put the person on a pedestal, you’re allowed to just… Oh, they’re wonderful. But every trope out there in every form of popular media is the wife rolling her eyes at the husband, and the husband being like, ugh, this loathsome harpy that castrated me, as if people are just passive players in their lives. And I think that is an incredibly toxic message to send to people, that this is how we should be relating to our partner. Don’t take the piss out of your partner in front of people. The successful relationships I’ve seen are where people are just cheering for their partner, where they’re thick as thieves, where there is just this feeling of, man, they like each other. They got each other’s back like you wouldn’t believe. Man, you could take sides against anybody. But take sides against their partner? You’re going down.
Segment 4177: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=59, Text: And when you see a couple that has that, that’s so hard to break. But I think that comes from having a steadfast, no, I don’t do that. I don’t shit talk my partner, and you don’t shit talk my partner to me. Because I think we’re just so criticized by the world, the world is so full of criticism, we criticize ourselves so harshly, that having a partner who no matter what is like, “You’ve got this. I’m with you. Okay yeah, you screwed up. I see it. Look, I’m not going to lie to you about your blind spots. You screwed up. But you know what? People screw up sometimes. You got a right to screw up. A lot of people screw up. Come on, get up. Let’s go. I know you have it in you.” If you have that person, I feel like that’s a superpower.
Segment 4178: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=114, Text: The following is a conversation with James Sexton, divorce attorney and author of How to Stay in Love: A Divorce Lawyer’s Guide to Staying Together. As a trial lawyer, James, for over two decades, has negotiated and litigated a huge number of high conflict divorces. This has given him a deep understanding of how relationships fail and how they can succeed, and bigger than that, the role of love and pain in this whole messy rollercoaster ride we call life. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s James Sexton. What is the most common reason that marriages fail?
Segment 4179: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=158, Text: That’s a great question, but it’s a question that everybody wants there to be a simple answer. They want me to say cheating or money or the internet, but the reality is… I think it’s a lot of little things. It’s disconnection. That would be my answer. The reason marriages fail is disconnection. What causes disconnection? That’s the bigger and I think more important question because like Tom Wolfe said about bankruptcy, “It happens very slowly and then all at once.” Disconnection happens very slowly and then all at once. So most of the time what I think people want is an answer like cheating, but cheating is the big all at once thing. How did we get to the place where cheating was even something you were thinking about doing or that you would think about and then cross the line from thought into action? And that’s, I think, the big question. So disconnection would be my answer.
Segment 4180: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=216, Text: Do you think it’s possible to introspect looking backwards for every individual case where the disconnection began and how it evolved?
Segment 4181: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=223, Text: Sure. Yeah. This is such a multi-variate equation. It’s a dance, it’s a chemistry, it’s what did you do and what did the other person do? And see, the interesting thing about being a divorce lawyer is I’m weaponizing intimacy in a courtroom. It’s full context storytelling, what I do for a living. So what I do is I take my client’s story, and I have to present it to a judge and make my client the hero in every way and the other side the villain in every way. Now I have to be careful not to do that in a manner that loses credibility because even a judge is smart enough to know that no one is all good or all bad. But only if you were reverse engineering a relationship and saying how did this break, you really have to look at both people, the good and the bad, what each of them did that moved the dial in these different directions.
Segment 4182: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=283, Text: And I think that’s very hard for anyone going through a divorce to do about their own relationship. We don’t know who discovered water, but it wasn’t a fish. If you’re in it, I don’t think you see it clearly. I think as a divorce lawyer whose job is to really drill down on the facts and figure out what’s going on in this story, I have to look at both sides. So I have to think a lot about my own arguments, but I also have to think about what’s the other lawyer’s argument going to be, especially in custody cases. So I really have been forced to look at both sides for so many years, so deeply in relationships. Once you do that, you realize that the good guy, bad guy thing just doesn’t apply.
Segment 4183: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=327, Text: I wonder if it’s the little things or a few big things that cause this connection. You’ve talked about granola and blowjobs, but those seem to be stories that you can tell to yourself like… Maybe that story should be explained or maybe not.
Segment 4184: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=346, Text: You don’t think granola and blowjobs is self-explanatory?
Segment 4185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=348, Text: Almost. I think people can construct a good… If you ask GPT, what do they mean? I think the story that would come up is a pretty good one. But that’s a story you tell about when you first knew the disconnection has begun is when he stopped buying my favorite granola or when she stopped giving blowjobs.
Segment 4186: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=369, Text: I would say when it’s reached a critical mass.
Segment 4187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=372, Text: Yeah, phase shift of some sort.
Segment 4188: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=374, Text: Because I think it started before that. When she said, “Yeah, I used to give him blowjobs when we were in our early relationship, and then one day, I just was like, oh well, we don’t have as much time. I’ll wait until later, and we’ll have sex and then we both enjoy it.”
Segment 4189: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=387, Text: Blowjobs are inefficient.
Segment 4190: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=389, Text: Yeah, exactly. Correct.
Segment 4191: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=389, Text: You batched it all together into one-
Segment 4192: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=393, Text: So she said, “Well, exactly.” And they had kids at that point, so I think she really was like, “Hey, we’ve got a certain window, so let’s have something we both enjoy.” So I don’t think she had any negative intentions there. I think that she was working in good faith towards the betterment of the relationship, but it was having this second order effect. And so I really do think that, yeah, the blowjobs, granola… Anyone who’s been in a long-term relationship, I guess it’s just worth asking the question, what does this person do that makes me feel loved? I think it’s very interesting in my own experience in life. I remember I had a difficult chapter with one of my sons, my younger son, when he was in his early twenties. And we were having a heartfelt conversation, and I said to him, “Do you know I love you?” And he said, “Well yeah, of course I do.” I said, “But do you feel my love? Do you feel it? Not just do you know it intellectually? Do you feel it?”
Segment 4193: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=459, Text: And I remember thinking to myself, when do we feel someone’s love? What is it that they do? And sometimes, it’s the weirdest, silliest things that they would never know. They are the person who’s showing us that they love us and that we’re feeling their love. They would never show us. If you said, “Why does this person love you?” They wouldn’t say, “Oh, I always make sure that when the paper comes, I bring it from the bottom of the driveway to the door so they don’t have to go out and get it.” Or “I always hold the door for them.” Again, “I buy the granola that I know this person likes.” Or “I remembered that they don’t like it when I put on this particular record so I don’t put it on.” Yes, they’re small things, but they’re not small. They’re kind of everything.
Segment 4194: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=509, Text: Do you think it’s good to communicate that stuff?
Segment 4195: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=511, Text: Well, 100%.
Segment 4196: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=513, Text: It takes away some of the power of it, right?
Segment 4197: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=516, Text: When you point it out, then the person realizes, oh, he likes this or dislikes this. So yes, there becomes a deliberateness to it, a conscious… So I understand not pointing that out when it’s a good thing. I think when it’s a negative thing… I think in the granola situation, if she had said to him, ” Hey, you used to do this, and you’ve stopped,” that feels like something to me. She said she didn’t say anything about that, just like he probably didn’t say anything about the blowjobs. I think if there had been a moment of, this is starting. Let’s talk about it while it’s starting. But people wait. From what I can see, people wait until the big thing happens. The financial impropriety, the substance use disorder, the cheating. They wait for that to happen and then they go, “Where did we go wrong?” And the answer is, quite a while ago with the granola.
Segment 4198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=579, Text: Yeah, yeah. So when you notice something, you notice that little something, talk about it because that little something is probably a kernel of a deeper truth. Of course, there is also moods. We’re all a rollercoaster of emotion. So you can not bring a granola one day just because you’re in this place where just nothing is… Just cynicism everywhere, just anger and so on. But it’s a temporary feeling, but maybe that temporary feeling is grounded in some other deeper current that’s actually building up.
Segment 4199: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=613, Text: And I think a good partner wants to understand the currents of their partner-
Segment 4200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=613, Text: Yeah, that empathy.
Segment 4201: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=619, Text: If they want to understand, hey, are you going through something? And look, if I’m the one you need to take it out on, that’s okay. I’m a big boy, I can take it. If you’re hormonal, if you’re frustrated at work, if you’re whatever, we should be able to have a little bit of that interaction in a relationship. It’s so easy to just say to people, “Well, communication is the key.” But it really is about fearless kinds of communication. It’s about really honestly saying to somebody, “This feels like something to me. Am I wrong? This just feels like something to me.” And also how that’s presented. One of the things I’m very caught up on or feel very strongly about is that we have been encouraged culturally to criticize people we’re in long-term relationships with. Not new relationships. New relationships, you put the person on a pedestal, you’re allowed to just, oh, they’re wonderful.
Segment 4202: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=682, Text: But every trope out there in every form of popular media is the wife rolling her eyes at the husband, and the husband being like, ugh, this loathsome harpy that castrated me, as if people are just passive players in their lives. And I think that is an incredibly toxic message to send to people, that this is how we should be relating to our partner. Don’t, take the piss out of your partner in front of people. The successful relationships I’ve seen are where people are just cheering for their partner, where they’re thick as thieves, where there is just this feeling of, man, they like each other. They got each other’s back like you wouldn’t believe. Man, you could take sides against anybody. But take sides against their partner? You’re going down.
Segment 4203: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=729, Text: And when you see a couple that has that, that’s so hard to break. But I think that comes from having a steadfast, no, I don’t do that. I don’t shit talk my partner, and you don’t shit talk my partner to me. Because I think we’re just so criticized by the world, the world is so full of criticism, we criticize ourselves so harshly, that having a partner who no matter what is like, “You’ve got this. I’m with you. Yeah, you screwed up. I see it. Look, I’m not going to lie to you about your blind spots. You screwed up. But you know what? People screw up sometimes. You got a right to screw up. A lot of people screw up. Come on, get up. Let’s go. I know you have it in you.” If you have that person, I feel like that’s a superpower to have that effect on another person.
Segment 4204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=785, Text: One of the things I love seeing, when you look at a couple, and one is talking in an interview, answering a question, especially intellectual questions like, what do you think about the war in Ukraine or something, and then the partner is talking and then the other person is looking at them as if they’re hearing the wisest thing ever. They’re still looking at them, not waiting for their turn to speak, not thinking about how is the audience going to take that, but they’re looking at them like goddamn, I’m so lucky to be with this smart motherfucker.
Segment 4205: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=823, Text: But there’s this scene-
Segment 4206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=824, Text: And they could be saying the dumbest shit ever.
Segment 4207: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=826, Text: There’s a scene in the movie, True Romance-
Segment 4208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=828, Text: Yes, I love True Romance.
Segment 4209: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=829, Text: Great movie. That Gary Oldman scene the greatest scene ever done in film with Christian Slater. But there’s a scene in it where she holds up a sign to Christian Slater, and it says, “You’re so cool.”
Segment 4210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=840, Text: You’re so cool. Yeah.
Segment 4211: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=842, Text: Man, that’s it. That’s it. I think I say it somewhere in the book that you go to weddings, and when the bride walks in, everybody is looking at the bride. It’s her show. Everybody turns around. It’s the first glimpse everybody gets of the bride. And I never look at the bride. I always look at the groom looking at the bride. To me, he has this look. This is the first time he’s seeing her in the dress most of the time. And also he’s seeing her like, holy shit, she’s coming down the aisle, we’re getting married, this is it. And everyone is looking at her, and I always look at him because I always think to myself… The look on his face, that’s this feeling of, yeah, wow, okay. Everyone is looking at her and she’s mine, and she’s coming up here and we’re getting married. And I feel like that kind of adoration… I think that’s the look we’re describing is adoration, that the words coming out of their mouth that they’re like, yeah, that’s mine, that one’s mine. That’s such a great thing. It’s such a great feeling.
Segment 4212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=909, Text: Seeing the good stuff. With True Romance, you could make fun of the guy’s totally cringe wearing Elvis, essentially being a fake Elvis with shades. And what is he doing watching these kung fu movies? But from her perspective and from a perspective you could take on him is this is the baddest motherfucker who’s ever lived. He’s willing to do those things for me. It’s almost like an epic heroic figure, and we’re living in this epic hero story.
Segment 4213: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=943, Text: And what does that do to him though? See, that’s the point. If there’s a point to this whole thing, this whole couple thing, isn’t that it? I don’t understand this idea of we had a successful marriage, we were married for 50 something years, we were miserable for 47 of them, but we hung in there. This is an endurance event? The primary relationship of your life, you’ve decided You’re going to turn into a 50-mile trail race. Why? Why would you do that? Congratulations. You took the concept of monogamy and made it something that two people are absolutely not going to enjoy, but you hung in there. Congratulations. And I understand there’s religious perspectives that say it’s a sacred covenant, but I have a real chicken or the egg problem with that because I think it was how do we sell this incredibly stupid concept that isn’t working to people? I know. We’ll tell them God says you have to, and we’ll sign on for that.
Segment 4214: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1005, Text: I don’t buy it. I don’t buy it anymore because when you see a successful marriage… Even without a marriage, you see a pair bond. You see a couple that really love each other and cheer for each other in that way and hang on each other’s words that way and are just in each other’s corner that way. You see the fake shit instantly. You see the difference right away. This is the first time I’ve come to Austin. I thought I’d eaten a lot of barbecue in my life. I’ve never had Texas barbecue. I landed, I went and had barbecue. I was like, I’ve never had barbecue before. Apparently, this is a whole different thing. I think it’s the same thing. I think once you see real love, real love, and I mean romantic love, real love like that, real bond, you go, oh yeah, this other thing is not going to do it.
Segment 4215: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1061, Text: Do you think that’s a daily deliberate choice that a couple that makes? Because it feels like a very easy to do deliberate step, choose to see the brilliant in it, the beautiful in it, and almost immediately, everything shifts and it becomes this momentum where all you see is the beautiful and all you see is the brilliant.
Segment 4216: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1083, Text: That is a conscious choice. I think approaching life that way is a conscious choice. Approaching any relationship that way is a conscious choice. Looking at someone who hurts you or does something hurtful to you and thinking about what’s going on in their life that they’re doing that or what’s happening with them, yeah, that’s a very conscious choice, and I think a better one, a better one than seething in animosity and letting that eat you alive. I don’t think it should be so difficult. With our children, with our pets, we don’t have this problem. You never have someone look at their dog who they’ve had for eight years and go, “Ugh, I got to get a new dog. I’ve had this one for eight years. Puppies are so cute. What am I doing with this old dog?”
Segment 4217: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1133, Text: It’s the total opposite. They’re like, “Oh my god, this is my dog. This is my dog.” The smell of the dog is… This is my dog’s smell. The bad habits of the dog, you’re like, “It’s my stupid dog that does stupid things.” And it’s not like that has to be a conscious thing. They wake up every day and go, “I should be grateful for the dog.” It’s just visceral. It’s in them. And your children, people’s children. It’s why people are not aware of how annoying their children are because they’re not annoying to them. I get it.
Segment 4218: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1162, Text: To you, the sound of your kids’ shrieking is like, oh my kid’s having a good time. When I hear that, I try to hear it with those ears. I’m a parent. I get it. My kids are adults now. But I get it. So when I hear a kid shrieking, I just am like, ah. To that parent, that’s the sound of that kid having a great time. And good, it’s so nice that’s in the world. So for me, it has to be conscious. For that parent, I don’t think it has to be conscious. So I think it would be great if it didn’t have to be a conscious practice, but I wonder if like anything in meditation or mindfulness, it’s a matter of exercising that way of seeing. And then once you’ve come to that-
Segment 4219: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1209, Text: It becomes easier.
Segment 4220: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1210, Text: It does itself. It really does. I think it initially has to be a conscious practice. And by the way, it’s easier to make it a conscious practice before it started to fade. That’s so amazing about marriage is there’s almost 8 billion people in the world, and you’re picking this one. So when you marry, in theory, the stock is at its highest. You’re as crazy about each other as you could possibly be. So that’s the time to get into this mindfulness, to get into this practice, not once the wheels are starting to come off. It’s much harder. It’s gaining a bunch of weight and then saying, “How am I going to lose the weight now?”
Segment 4221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1257, Text: Well, I think that even before marriage, right away, just see everything is beautiful. Let me quote BoJack Horseman on this. “When you look at someone through rose colored glasses, all the red flags just look like flags.”
Segment 4222: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1269, Text: That’s great.
Segment 4223: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1270, Text: There’s a certain sense where if you, from the very beginning… Of course, you could end up in toxic relationships that way, but life is short. You’re going to die eventually. Might as well really go all in on relationships.
Segment 4224: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1285, Text: There’s a line in Drugstore Cowboy, it was a great film where he says, “We played a game you couldn’t win to the utmost.” And I think everything, I think life is a game you can’t win, and so you play it to the utmost. To love anything is insane because you are accepting that you’re going to lose it. I am a dog person, and you get a dog and you’ve just resigned yourself to unbelievable pain because this thing is going to die in 10 years, maybe 15 if you’re lucky. And why would you open your heart to that? Because the joy is just so wonderful of it, of the ride up until it.
Segment 4225: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1330, Text: Same thing with us. Every marriage, every relationship, every love is going to end. It’s going to end in death or divorce. So why not just go in, go in, go in and just get weird don’t, define it the way… Again, we keep going back to True Romance, but just get weird. I love this Elvis pretending to be weirdo. I love this former sex worker. Whatever. Just go in, love this person, have them love you. Don’t worry about what everybody else is doing in their relationship. It’s not to me surprising that as the performative aspects of life on social media increases, people’s satisfaction with their relationships and the divorce rate is following the same trend because I think everyone is going, “Well, what’s everybody else doing? Well, how much sex is everyone else having?” The only two people that should worry about how much sex you’re having are the two people. If the two people are happy in the relationship, great. Then what does it matter? What does it matter what everybody else is doing?
Segment 4226: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1394, Text: There should be an element to great relationships and great friendships of, fuck the world. It’s us versus the world.
Segment 4227: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1400, Text: It’s us. It’s us. And that’s what I mean when I say that thick as thieves. When they’re like a unit like that because look, it’s just us, it’s just what we want, it’s what we like. And that’s why I said even when it comes to sex or things like that, if you can’t be candid with your partner about whatever weird shit you’re into or what fantasy you had, well then who the hell can you be candid with? Because you’re going to either go without or go elsewhere, and neither of those is a particularly healthy option or helpful option. It’s the start of that decline. So why open yourself to that decline, which invariably is just the path to the chair in front of me in my office?
Segment 4228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1444, Text: You have a full section in your book on foot fetishes?
Segment 4229: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1449, Text: I do. I do, which is funny because I don’t know anything about foot fetishes.
Segment 4230: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1453, Text: Me neither, me neither.
Segment 4231: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1454, Text: I’m not kink shaming anybody, but there’s nothing sexual about feet to me at all. I just don’t get it. But listen, if people like things, it’s good. But yeah, I have had clients that have odd fetishes or sexual proclivities or things they want to do, and they don’t share it with their partner at all. And then they find an outlet for it because they try to go without it, and that doesn’t work, so they try to find some other outlet for it. And then that’s interpreted as a betrayal, and it creates distance and people split up. And of course, everybody likes to have a bad guy to blame it on. So when you say, “Well, why’d, you guys get divorced,” oh, because he secretly had a foot fetish, and he was on these message boards like meet people. Well, it gives you an easy answer as to why the two of you split up, but I don’t think most divorces have such simple answers as it was a foot thing.
Segment 4232: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1503, Text: But I also think too, listen, if you’ve got a partner, we all do stuff that we’re not super into because we’re in a relationship, and that’s what part of it is. Do you really want to go see that chick flick? Do you really want to eat at this restaurant? Do you really want to go to her cousin’s wedding? No, but part of being in a relationship is if you’re into this, I’m going to pretend this song is a good song even though it’s not my favorite song. I just don’t know. Sex has been so politicized in recent years. Maybe it always was. But I think we’ve made it into something where we can’t just… I don’t know. I’m not into feet, but if the woman I love was like, “I’m really into feet, I really want to do stuff with your feet,” I’d be like, all right, I can pretend that I’m into that. It’s not going to kill me. I’m not going to be able to make it a centerpiece of our coupling, but yeah, I can pretend I’m into feet if you want.
Segment 4233: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1556, Text: I don’t personally have any fetishes that are outside of the normal discourse.
Segment 4234: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1562, Text: As a divorce lawyer, I get to experience the whole spectrum.
Segment 4235: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1566, Text: But if I was into furries, for example, I don’t know how I would initiate the conversation with my partner about that.
Segment 4236: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1575, Text: But frame the question the other direction. If you were into furries, how do you prevent your partner from knowing anything about that? You’d have to make a conscious choice to not let your partner know.
Segment 4237: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1592, Text: Sure, sure.
Segment 4238: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1594, Text: So I don’t think either of those is a particularly palatable or easy proposition.
Segment 4239: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1600, Text: But a lot of people live life hiding some part of themselves.
Segment 4240: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1604, Text: Quite unsuccessfully. The second order effects of that are very rarely positive.
Segment 4241: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1610, Text: Sure.
Segment 4242: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1611, Text: I don’t think I’ve ever met someone and went, yeah, I really hid this huge part of myself for an extended period of time-
Segment 4243: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1611, Text: And worked out great.
Segment 4244: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1616, Text: And that’s the best thing that happened. I’m, really glad I stayed in the closet as long as I did. It really worked out. It rarely does. It’s a question of how long can you hold it off? I know gay men who stayed in the closet for 40 years, 50 years of their lives, and then they had a successful second chapter as a gay man. I’ve had clients like that. Do they regret that they were in the closet? No, because they were married, they had kids, they had experiences they’re glad they had, but would their advice to a young person in their twenties and thirties who’s gay be, stay in the closet because then you can have a wife and some kids, and then you can come out when you’re 50 or 60 and have a second chapter?” No. They would say, “Be who you are. Don’t be afraid.”
Segment 4245: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1663, Text: As you were talking, I’m trying to think of… Because publicly and privately, I’m the exact same person or try to be the exact same person. So I usually try to make sure there’s nothing to hide. But I was trying to come up with a counter example for you for if there’s good things to hide. Well, there could be past relationships. If I slept with thousands of women or something like this, maybe you want to put that to the side when you have the-
Segment 4246: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1690, Text: Well, there’s a difference between being honest about something and being indelicate about it. I think we all do this with lovers. Any of us who’ve been in more than one relationship, you would not at the end of sex be like, “That was the third-best sex I’ve ever had.” It’s just indelicate. It’s rude. So I don’t think it’s a matter of total candor at all times.
Segment 4247: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1724, Text: You were using the furry example, and I’m not picking on furries. I just think if that is a proclivity that is anything other than a passing thought, it’s something that you just keep coming back to, then you’re making a conscious decision to withhold it from your partner. And what is that out of? I would say it’s probably out of fear. I’m not a psychologist, but it’s probably out of fear, fear that they would reject you. Well now, see, I genuinely believe that this… I’m very conflicted in my religious faith, but I don’t know that I believe in the devil. But if there was a devil, I think his principle function would be to convince us that we are so bestial that God couldn’t love us. It would be to convince us that we’re awful and that we should just lean into the awfulness.
Segment 4248: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1783, Text: And I know the greatest low points of my life came whenever I just went, “You know what? I’m just awful. I might as well just behave awfully.” And I really believe that when you push down parts of yourself like your sexuality, like your insecurities, your true feelings from your romantic partner, the person who’s supposed to be your number one, you are making sure you will never feel their love because they don’t love you. They love the you you’ve presented to them, which you know in your heart is not the authentic, honest, real you. And so if you know you’re super into furries and you don’t tell your partner about that, and your partner says, “I love you so much, and you know what I love, one of the things I love about us is we have such great sexual chemistry,” You’ll never feel that love because you know that’s not true though, she doesn’t know. She doesn’t know that actually I’m not really satisfied, and there is this thing that I want that I know I can’t even tell her because I’m so ashamed. That doesn’t feel like a good option to me.
Segment 4249: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1863, Text: Yeah. So that kind of vulnerability is essential to intimacy.
Segment 4250: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1870, Text: I’m prone to jiu-jitsu metaphors, and this is one of the first conversations where I can actually use them because the person I’m talking to is a jiu-jitsu person.
Segment 4251: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1878, Text: And people should know that you are a “Jiu-jitsu person.” You have been afflicted with the disease.
Segment 4252: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1884, Text: I am a brown belt under Marcelo Garcia, and I am a seven-year brown belt now.
Segment 4253: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1889, Text: Which is the right way to be a brown belt.
Segment 4254: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1892, Text: And also I am late middle-aged middleweight and moderately talented. And training at that academy with so many incredibly talented people and training in New York City where there’s so many unbelievably talented people, you’re constantly humble and feeling like you should just be wearing a blue belt all the time. I think as you know and as most people who practice jiu-jitsu know, you start to sort of see jiu-jitsu in everything. I genuinely believe that in love, you have to give something to get something. Everything you do creates a vulnerability. Every move you make in jiu-jitsu creates opportunity and creates vulnerability. And so you have to be willing to create vulnerabilities in order to get any leverage, in order to get any progress and any way to move the position. You don’t want a marriage that’s just two people both in 50-50. You’re just sitting in that guard doing nothing. You want it to actually move along.
Segment 4255: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1956, Text: Yeah, that’s the way I see love and relationships. You should take that leap of vulnerability, give the other person the option to destroy you.
Segment 4256: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1964, Text: Well, you have to expose, and that’s the part that I think is hard for everyone is to expose yourself in that way. But that’s what I mean even when I said about getting a dog or having a child, loving anything is tremendously courageous because it’s terrifying.
Segment 4257: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=1980, Text: It’s tremendously courageous because it’s terrifying. And it’s only brave if you’re scared. If you’re not scared, it’s not brave. It’s just stupidity. It’s bravery when you’re afraid and you do the thing anyway. And so love is like yeah, it’s scary. I don’t care who you are. Being in the jiu-jitsu community, I’m around, as you are, incredibly tough people, physically tough people, mentally tough people. But I’ve seen some of those people taken down by a 120-pound woman, not from a grappling perspective, but they are taken apart by a woman in their life. And vice versa, I’ve seen men who… It really is shocking how much leverage we give to our romantic partners and how little genuine discussion we really have about it, how much we really are ever trained to think about it. There’s nothing in school that teaches us about it. So much of literature and art is an idealized version of it. So little of it is real.
Segment 4258: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2056, Text: And no matter how it evolves, when it ends in tragedy or drama, I feel like what people don’t do enough is appreciate the good times, appreciate how beautiful it is to having taken the risk and to having experienced that kind of love. I think when you look at people that are divorcing each other… There’s a Edgar Alan Poe quote, “The years of love have been forgotten in the hatred of a minute.” I always am saddened, deeply saddened how people seem to forget how many beautiful moments have been shared when some reason, some drama, some breakup leads them to part ways.
Segment 4259: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2102, Text: Yeah. It’s interesting that you came to that not being a divorce lawyer because I’ve felt that way for a long time. And I really try to say to my clients… In the courtroom at the negotiating table, I have a role to play where I have to be a pit bull or some kind of a courtroom sociopath. But behind closed doors, I’m very candid with people. I try to be much more emotionally attuned with them.
Segment 4260: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2126, Text: So you’re an empath in the sheets and sociopath in the streets?
Segment 4261: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2130, Text: Exactly correct. That’s well said. I got a new tattoo idea. That’s good. I like that. But I do believe when I’m behind closed doors with people, I say to them, “How you end things is going to be how you’re going to remember the whole thing.” And That’s unfortunate because you watch a two-hour movie and if the last 15 minutes of it sucked, you go, “Well, that movie sucked.” Well, the first hour and 45 was great, but you walk out with this bad taste in your mouth. I am genuinely in awe of how easily people forget that they loved each other. And I’m amazed because by the time I meet them and by the time they hire me to be a weapon against the person they were in love with, there’s nothing but animosity there. And so I have to try to imagine what these two people looked like when they were in love with each other and how that even existed.
Segment 4262: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2191, Text: But I have to tell you, I don’t function that way. Every woman I ever had a relationship with, when I think of them, I don’t think of the ending necessarily. I try to think about the greatest hits. I try to think about the moments that were wonderful, where I loved them and they loved me, and there was joy and there was connection. And I don’t know why you choose not to. There’s that old axiom, I don’t know who said it, that if you don’t learn to find joy in the snow, you’ll have less joy in your life and precisely the same amount of snow. And I genuinely believe like, “Okay. The relationship ends. This is where it ends. We’re done now. I am making a choice as to how I will remember you.”
Segment 4263: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2242, Text: And we do it in relationships. I always tell people if you ever want to see a couple of light up, if they’re ever the couple at the table that seems like they got in a fight or something, ask them how they met. And most people, when they talk about how they met, their face softens. And the other person looking at them telling the story gets that look you were talking about before. And because they remember that thing and how they felt at that moment. When this person was a choice, not a default, not their automatic plus one, but the person they asked to the wedding, not the, “Of course, you’re bringing her. It’s your wife. You bring your fucking wife places.” It was still, “Hey. There’s three and a half billion women, and I’m picking you.” That feeling. And I don’t know why when a relationship ends, you can’t do that.
Segment 4264: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2294, Text: A lesson I learned when my mother passed away. She had a two-year terrible battle with cancer and was on hospice and was very, very sick. And it was a very slow and awful end. And I remember one of my worst fears was that this is how I would remember my mother for the rest of my life, that I would never be able to think of her, that I didn’t think of what she had become in the last months where she was withered away to nothing in this bed. And I learned over time that memory is very kind. That faded somehow. And that now when I remember her, I remember her healthy and vibrant. I remember her laughter. I remember positive things. Some of that is I like to look at photos of that. But some of it is just how I think memory works. And I don’t know why we don’t apply that to relationships.
Segment 4265: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2349, Text: And I think part of it is because we have this binary view of relationships, that it’s either success, which means you have happily ever after for the rest of your lives and die together or in short succession, or it was wrong. It was awful. And I don’t understand why that would have to be how we do it. I think we could look at relationships like what they are, which is chapters in a book. And that book is our life, and those chapters all have significance. The later chapters, none of them would happen without the prior ones. So there’s this beauty to me, of that. And I don’t know if it’s a choice or if that is how it is, and the rest is just narrative that we’ve put on top of it culturally for some reason.
Segment 4266: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2399, Text: Well, I think to push back a little bit, I think memory can also… I think it is a deliberate choice because I think memory can basically… That’s how trauma works. It can surface the negative stuff and the negative stuff completely drowns out all the positives. So I think it’s a deliberate choice to make your memory probably work that way. In relationships, betrayal can do that, right? Cheating, infidelity, one event can almost erase the entirety of your understanding of the past. And all the memories are shrouded in this darkness of, “Okay. What I believed was true is totally untrue.” And so to overcome that and still appreciate the beautiful moments.
Segment 4267: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2449, Text: I’m continually astounded by how long the hurt and anger of betrayal can reverberate. I have clients who were four years, five years past when the divorce ended, the cheating was discovered, and they’re as angry as they were the day they found out. And I don’t know what that’s about because I also have clients that they look back on it and they go, “We screwed up. We didn’t do the best, but we did the best we could do at the time. There should be stars for wars like ours. There should be champagne for the survivors.”
Segment 4268: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2499, Text: Yeah. That was beautiful.
Segment 4269: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2500, Text: “We made it through. We survived it and we were fools. And we were fools for love, and there are worse things in the world to be fools for.” But I also do think that most relationships where there was infidelity… And it’s not a popular thing to say and I’ll get pilloried for it.
Segment 4270: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2519, Text: Great.
Segment 4271: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2521, Text: I just don’t know… And I don’t want to blame the victim of infidelity. But was the relationship really where it needed to be? Were you truly the most just dutiful spouse who was seeing this person’s needs be met? Again, we’ve established in the granola story that people can sometimes with good intentions not be meeting their partner’s needs or perceiving their partner’s needs, or their partner isn’t communicating them the right way, or all of the above. But I’ve rarely seen very happy, content couples that cheat on each other. And so I understand there’s a shame in saying, “This person cheated on me,” or, “I cheated on this person.” Because I represent the cheater and I represent the cheated. I represent the victim of domestic violence and I represent the perpetrator of domestic violence. I represent the person with the substance use disorder, the person married to the person. So I don’t get to choose the white or the black hat. I have my client and that’s my client.
Segment 4272: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2584, Text: And it forces me to put myself into their story from their point of view. And I think that kind of radical empathy that you need to engage in on a daily basis to represent people in those kinds of proceedings it’s just… I don’t know. It just doesn’t seem like there’s good guys and bad guys. It just seems like it’s complicated, and people’s intentions and where they actually end up are different.
Segment 4273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2614, Text: Yeah. I think there are some sense in still remembering the betrayal as it being a symptom of taking life a little too seriously, too seriously where you don’t… Life shouldn’t be taken that seriously. You should be able to laugh at it all. I like the story you say of being able to appreciate the battle that should give stars for those kind of wars that we fought, and just be able to laugh at it all.
Segment 4274: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2641, Text: Especially with love. Love’s just so absurd. It’s so-
Segment 4275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2645, Text: It’s just crazy.
Segment 4276: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2645, Text: It’s so crazy. I mean, I think It’s funny. This is real candor. But as a man. There’s nothing funnier than when you finish masturbating. There’s no more humbling moment. And I like to think about the fact that the richest, famous, most powerful person in the world, they jerk off. The most powerful man in the world jerks off, I’m sure. All of them do. I mean, you probably know them so you could ask. And that moment where you just come and you go, “What am I doing? What the… Now I got to wipe the… Oh. Good lord.” And there’s this feeling of, “But a second ago this seemed like a great idea.” And it was, by the way. It was a great idea. But there’s this moment, this satori where you just go, “Oh. This is so silly.” Well, that’s love. That’s sex. It’s crazy.
Segment 4277: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2698, Text: When you read other people’s infidelity, the text messages, the emails… Because I have to do that all the time. And I’ll tell you how we make the sausage. In a divorce lawyer’s office, some of the most entertaining moments is dramatic readings aloud of people’s infidelity exchanges with their lovers.
Segment 4278: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2716, Text: The sexts.
Segment 4279: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2717, Text: Yeah. The sexts and the… It’s just so ridiculous because people have to go through all kinds of gymnastics to be able to meet and have sex in weird places. And You’re reading this, and you’re reading these texts, and you go like, “Oh, my god.” And by the way, I’ve represented some very powerful people. And you read their texts with their lover or even their spouse, even their spouse, and they’re just pathetic. I mean, they’re just so not powerful. They’re so like, “Hey, babe.”
Segment 4280: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2754, Text: Totally nameless, I have a very powerful, wealthy, famous former client where there’s a whole series of texts about, “Is my dick weird?” Which by the way, I think the answer is if you have to ask if you have a weird dick, the answer’s probably yes because I’ve owned one and I’ve never thought, “Is this weird?” But the fact that you’re having this discussion, it’s absurd. It’s hilarious. Love is hilarious. It’s bizarre. It’s such a weird vulnerability. It’s such a basic, visceral human need. It really is something that we just… It’s mysterious. But it doesn’t have to be that complicated. I don’t think that even betrayal, like I said, it doesn’t have to be that complicated. I think we can frame it differently.
Segment 4281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2803, Text: Yeah. You can laugh at the whole thing. I mean, I think what we don’t often do with ourselves is look back at text or look back at emails or look back at Google search. I did that recently, just looking at what I searched for 10 years ago, 15. It’s like, forget last week. Just look at your Google searches last week and you’re like, “Wait a minute. What? Why did you just search for this 50 times?”
Segment 4282: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2833, Text: Why did The Karate Kid III pop into my head? Where’s Ralph Macchio now? Where did-
Segment 4283: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2839, Text: Who is he dating? And then his mother and then you’re [inaudible 00:47:23]-
Segment 4284: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2843, Text: And then a restaurant nearby. Like, how did I go from this to that? But it made sense at the time. So when you ask someone, “How did our relationship fall apart?” it’s like looking at the Google search history of yourself from 10 year… You don’t even know why you were thinking about those things. And now you want to understand why you did what you did, felt what you felt, she felt what she felt, she did what she did, and why the two of you, how you impacted each other and interacted with each other. Really? You think that’s doable?
Segment 4285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2879, Text: In the courtroom, does that come up, text messages with whoever you’re cheating with? So you have to-
Segment 4286: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2889, Text: Yeah. I mean, cheating doesn’t come up as much because most states are no-fault states now. So why someone’s getting divorced, whether it’s infidelity or… It doesn’t matter. There’s no good spouse bonus or bad spouse penalty.
Segment 4287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2889, Text: Well, there isn’t?
Segment 4288: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2889, Text: No.
Segment 4289: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2889, Text: I mean, can you elaborate on that? That’s-
Segment 4290: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2901, Text: Well, you can have… We’ve had times where we have to prove infidelity because we want to prove what’s called wasteful dissipation of marital assets, which means that you were spending money that was marital money on a paramour. That’s the legal name for a boyfriend or girlfriend in the marriage. And usually, the person calls it, “That whore,” or, “That piece of shit.” But we call them paramour. Yeah. The paramour.
Segment 4291: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2926, Text: And sometimes we have to prove inclination and opportunity. We have to prove that this person had the inclination to cheat and that they had the opportunity to cheat. And then we want to show that, “Okay. So when they went away, that should be considered dissipation of marital assets.” So if you go out to dinner with your brother, you didn’t dissipate the marital estate. But if you bought your paramour a Tiffany bracelet, that would be a dissipation of marital assets and the person’s entitled to a credit back for that from what was taken out of the marital estate. So we do sometimes have to authenticate text messages on the witness stand or in depositions.
Segment 4292: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=2960, Text: And what’s interesting about that is the way people approach it. People sometimes try to pretend, “Oh, no. This is just my good friend,” which is just… You kill your credibility if you, “Oh, no. She’s just my very good friend.” She’s not. She’s not. That makes no sense whatsoever. Or, “No. We were just friends at that point. And then several months later is when we… Once this marriage was over, that’s when we got together as partner.” That’s ridiculous. But sometimes people just own it. Just own it. I did a deposition of an executive once and opposing counsel thought they were going to really hit him. They were like, “Looking at this credit card receipt, what was this charge for for this hotel?” He was like, “Oh. That was for a hotel room that I got with my girlfriend.” “And you were married?” “Yes. Yes.” “Where did you stay at the hotel?” “We didn’t even stay. We actually just did an afternoon delight, rolled around in bed for the day.” And it was like, took all the thunder out of that.
Segment 4293: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3018, Text: What’s the downside of doing that? It seems like a really-
Segment 4294: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3020, Text: There wasn’t. It actually I think helped his credibility. It was my client. So I thought it was the right move. We hadn’t really discussed it in advance, but he was naturally intelligent enough to go, “Yeah. My credibility, I’m not going to lie under oath. I’ll admit what it was. But I’ll do it in such an…” We did it at the end, like Eminem at the end of 8 Mile. It was very like, “Yeah. I cheated on her with this person. Now tell these people something they don’t know about me.”
Segment 4295: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3045, Text: And that’s how I try to… As a trial lawyer, we actually in my firm refer to it as the 8 Mile strategy, which is if I know there was a text message sent, ” You piece of shit. I hope you die.” My client sent that text message to his co-parent. On my examination of my client, I will say, “I’d like to have this marked for identification, shown to the witness.” “What is that?” “It’s a text message.” “Who’s it to?” “The plaintiff.” “You sent it?” “Yeah.” “Read it out loud for the court.” “Do I have to?” “I think you should.” “You’re a piece of S.” “Does it say S?” “No.” “What does it say?” “Well, it’s a profanity” “Say it to…” “You piece of shit. I hope that you die.” “You sent that to her?” “Yes.” “Why?” “I was really mad.” “Do you think that was good?” “No.” “Do you think it was helpful for your co-parenting relationship with her?” “No.”
Segment 4296: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3112, Text: “Why did you send it then?” “She sent me 50 texts exactly like that. And I never responded, and I pushed it down every time. And then finally I just blew up at her.” “If you had it to do over again, would you do it differently?” “I wish I could say I would, but the truth is I’m human and I was at my limits.” And I’m watching opposing counsel cross out entire sheets of their cross-examination because It’s gone now. They thought that they had their Perry Mason moment. They had their like, “Did you order the code red moment?” And It’s gone now because if you just own and accept your fault or your issues in the relationship, you can take a lot of the power out of that.
Segment 4297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3154, Text: I wish we wouldn’t take text seriously.
Segment 4298: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3157, Text: I don’t think we should have substantive discussions via text. I think text was designed for, “Are you here?” “Yes. 15 minutes away.” Or, “I got here safely. Love you.” Substantive discussions… People love having arguments via text. And I have to say when you read other people’s text messages, as I am often forced to do, it is amazing because just like that Google history you were talking about, I don’t know how the hell you got from one thing to another.
Segment 4299: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3188, Text: I was just reading actually on the way here in the car. I was reading through a text exchange between two co-parents in the middle of a custody thing that I’m involved in. And it’s like, “You piece of shit. You never cared about anything. And I’m going to take… You have no right to take the kids from me,” da, da, da, da. Nothing in between. The next day, “Maddie got a good grade honor science thing.” “oh. That’s great. She’s doing so well. It makes me so happy.” “Yeah. Her teacher said she’s doing really well.” “Yeah. That’s really great to see.” “I’ll be there about 15 minutes late.” “No problem.” “See you then.”
Segment 4300: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3226, Text: Wait. It was a day ago. I want to know, was there a phone conversation in between where one of you went, “Hey, man.” “Listen. I’m really sorry about that.” “Oh, no. Look. We were both pissed. Whatever.” Or is it just like you did that, and then we’re supposed to pretend that didn’t happen, and now we’re just going to talk about what Maddie got on her test?
Segment 4301: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3243, Text: Yeah. Well, sometimes a good nap or a good night’s sleep can solve a lot of emotional issues.
Segment 4302: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3247, Text: I totally get it. If you’re looking just at the texts, it begs the question. Wouldn’t you take the nap and then go, “Hey, listen. I just woke up from the nap. It turns out I was really tired.” Does that not happen by text?
Segment 4303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3261, Text: No. Because sometimes, it’s hard to probably apologize for being an asshole. So I think we use just text. We humans use all kinds of forms of communication to vent. I think it’s the wrong thing to do, but people do do that.
Segment 4304: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3278, Text: Text has a permanence, though. It’s writing. I mean, it’s writing.
Segment 4305: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3282, Text: You think like a lawyer. I like it.
Segment 4306: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3283, Text: I do think like a lawyer. But lawyers think detail. And why would you write that down? Writing it down, would you write it down and would you put it on a billboard in Times Square? Everything you say on Facebook or Instagram can and will be used against you in a court of law. Every photo you post. I mean, that’s going on with… what’s his name… Jake Paul or whatever Paul and Dillon Danis right now. That guy’s girlfriend, every picture that’s ever been put on the internet of her, by her is being weaponized right now.
Segment 4307: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3319, Text: To reference an earlier part of our discussion, that’s love. You take a big risk putting it out there, putting it out there on text, putting it out there on social media. You take risks.
Segment 4308: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3330, Text: But is the reward of doing it via text worthwhile? Listen. The reward of love, I think, is worth the risks of love. But the benefit of communicating by text, does it merit that risk of that being in writing that the person can reflect on and review and scroll back and get heated up again about?
Segment 4309: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3356, Text: I don’t know. We just take risks and we’re vulnerable with each other.
Segment 4310: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3359, Text: There may be something about text that for whatever reasons inspires a kind of candor, because I think it is a new way to communicate in the scheme of things. And so sometimes we don’t know the thing until It’s really come into existence. So I don’t know. I think it started as something that we just communicated in a very extemporaneous, unplanned way. Texts were meant to be, “I’m here. I’m outside.” Whatever it might be. And so what happens when you start to talk about more emotional, deeper, bigger things or visceral things or more emphatic, passionate things using a technology that was originally just being used for the other purpose? I don’t know the answer to that. What I do know is yeah, as a lawyer; A, from an evidentiary perspective; and B, I just know what it looks like on the outside. I know when I read it what it looks like.
Segment 4311: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3425, Text: And that’s not always accurate. It’s like when you watch a video of someone at just their worst moment and the person tries to say, “But wait. That’s not me. That was just me in that moment. That was me at this incredible low point.” And I think as a lawyer, my job is to weaponize that and to try to say, “Okay. This low point is indicative of who they actually are.” And when I’m defending someone, I’m not supposed to say, “Well, this is their low point and We’ve all been to a low point. And this is just a moment in this person. And to judge them by that moment, would you want to be judged by your worst moment?” So I have to be able to look at that both directions.
Segment 4312: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3464, Text: Yeah. I mean, I don’t think anyone looks great on text.
Segment 4313: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3467, Text: I mean, there’s so much of our communication that is missing. Your expression… My sense of humor does not do well via text because I have sometimes this sarcastic sense of humor or I have a dry sense of humor, and it does not always translate well to text. The nuance of things is lost sometimes.
Segment 4314: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3488, Text: Yeah. But that’s what makes the risk of it hilarious. I mean, the emojis, the memes, all that, taking a risk… There’s a risk with the text. If you do some dark, dry statement that’s a joke, and then the pause, and then there’s no response for a couple of hours. I mean, That’s beautiful. I don’t know. That’s-
Segment 4315: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3512, Text: It’s the gap between the two trapezes. Once you’ve hit send and you’re like, “Well, let’s see where this goes. There’s no coming back now.” And You’re waiting and waiting. It’s like that moment of just hang is… Yeah, that’s a rush. I mean, that’s a rush. That’s a beautiful thing.
Segment 4316: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3529, Text: Well, I have my friend Michael Malice living close by. And if the courtroom were ever to see the text between us, we would be both in jail for many-
Segment 4317: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3540, Text: Okay. [inaudible 00:59:00] who to subpoena.
Segment 4318: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3540, Text: … many years. Yeah. When this finally comes out-
Segment 4319: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3544, Text: Yeah. We’re going to [inaudible 00:59:04]-
Segment 4320: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3543, Text: … when I have my Johnny Depp, Amber Heard moment, I’ll-
Segment 4321: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3546, Text: Get the subpoenas ready.
Segment 4322: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3547, Text: We’ll get Michael Malice.
Segment 4323: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3549, Text: The Johnny Depp, Amber Heard thing was a great example of, in a gunfight between those two, everyone was cheering for the bullets. I mean, I don’t think anybody looked like a hero. They both looked like what they are, which is humans, really flawed humans who had… It really is like that People Magazine thing. Stars, they’re just like us. We watched that and went like, “Oh, yeah. They’re just like us. They cannot keep it together.” They just have these ridiculous, toxic moments where both of them looked awful in that trial.
Segment 4324: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3582, Text: What do you take away from that trial, just given all the work you’ve done? I mean, for me… I don’t know if you can speak to that… it’s probably the first time I’ve seen that kind of a complicated relationship, even just to say a relationship, laid out in this raw form, the fights of a relationship.
Segment 4325: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3604, Text: Yeah. My feeling about that trial is there is no amount of money that would be worth laying that kind of stuff bare publicly.
Segment 4326: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3614, Text: For you, if you were Johnny Depp.
Segment 4327: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3615, Text: For me. Yeah. There’s no amount of money.
Segment 4328: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3617, Text: Or if you were Amber Heard. I don’t know which-
Segment 4329: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3618, Text: Because they both look awful. They both look awful. And I don’t think I’m qualified to say if one or both of them are awful, but they both had moments in that courtroom where their behavior and words looked awful. And I just don’t know that exposing that to the world… I just don’t know. I mean, I understand the point of view that by bringing that suit, Johnny Depp was saying, “Look. Yeah. I have to show these awful things to the world about myself, but it’s not as bad as what she’s claimed I’ve done.” So I get it. I’m not saying That’s incorrect. And for Amber Heard, I think her response is, “Well, for him to say I’m lying, I have to prove my…” But my god, what an awful thing to watch. All it really is, it’s just another couple… You know how banal that is? You know how many of those-
Segment 4330: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3672, Text: So this kind of stuff happens a lot?
Segment 4331: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3674, Text: A lot? It’s the norm. It’s not the exception. They just happen to have a grand scale because they have lots of people around them and lots of money. But yeah. That kind of dysfunction, that kind of chaos, that kind of he said, she said, two people with completely differing histories of what happened in the marriage, false allegations of domestic violence or true allegations of domestic violence that are completely denied by the person. And you have witnesses that’ll say, “Oh, my god. They never engaged in any kind…” Because again, no one engages in domestic violence with company over. You don’t invite friends. People always say, “Oh, no. I saw them. They seemed so happy.” People always do this to me as a divorce lawyer. They come in and they go, “Well, here’s photos of the kids smiling with me. So that’s proof that I’m a good dad.” I’m like, “There’s photos of Jeffrey Dahmer smiling with people he ate later. And you think these photos prove something?” The lack of…
Segment 4332: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3730, Text: I’m in the middle of a very complex domestic violence trial. And the entire defense on the other side is, “Well, we have photos of them on vacation where they look very happy and she never called the cops.” That’s no defense at all. Most victims of intimate partner abuse don’t call the cops. They don’t self-identify as victims of domestic violence.
Segment 4333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3751, Text: And they probably have many stretches of time of intense happiness, or happiness?
Segment 4334: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3756, Text: Of course. Of course. And by the way, perpetrators of domestic violence are charismatic. How else would they get victims? It’s not like… If they were ogre-ish, no one would sign on for that relationship. It’s that when they’re good, they’re so good that when they’re bad, you go, “But wait. No. That’s not him. The really good person’s him.” Or her. We saw that in the public testimony of that Depp-Heard thing is there were moments where you look at her and go, “Oh, my god. I want one just like that.” There are moments where you listen to the testimony and go, “Oh, my god. She’s awful. What? That’s just evil.” And the same for him.
Segment 4335: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3796, Text: This should teach us something about how not only are there two sides to every story, that there’s just so much complexity and nuance to these. But I think everyone was asking the question whether you were team Depp, team Heard, or team I could care less about either of these people. Everybody’s looking at it going, “Why? Eight billion people in the world. Why did you stay together? Just break up. You’re miserable. It’s obvious. It’s obvious you’re not… This can’t be worth it.”
Segment 4336: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3827, Text: I’ve actually become friendly with Camilla Vasquez, who’s the lawyer on the Depp side. She’s an incredible woman.
Segment 4337: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3833, Text: Great lawyer.
Segment 4338: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3834, Text: And just a great human being, just how passionate she is about her work. I mean, you radiate this kind of same passion. She’s just truly happy doing what she does. But also where the stress of a case, it becomes her. She can’t sleep, all this kind of stuff, which is fascinating.
Segment 4339: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3855, Text: I think that’s a function of our professions. Even after 20-plus years of doing this, the night before a trial, I can hardly sleep, and I-
Segment 4340: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3864, Text: Excitement? Fear?
Segment 4341: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3866, Text: Yes. Yes. All of that. All of that. And I even have moments as I pull up to the courthouse and I listen… I wear certain cuff links that are my lucky cuff links or something. And I pull up to the courthouse. I walk into the courtroom. And I have this feeling in the pit of my stomach, and then it starts. And the moment it starts, something in me goes, “Oh, yeah. I know how to do this.” And it’s instantly… I own it. I love it. Yeah. The people that love this job, being a trial lawyer, being particularly a divorce trial lawyer, family law, trial lawyer, I love it. I love it more than I loved it when I started doing it. I can’t imagine spending five days a week looking forward to two. I love what I do. I don’t know that I’ll ever love anyone or anything more than I love the work.
Segment 4342: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3926, Text: So I saw you talk with Steve Harvey a bunch of times and I always loved it. One thing just sticks in my head from something he said as advice, that if you and your partner, your spouse, if there’s a fight, there’s a difficult thing you have to deal with, keep that to yourself. Don’t talk to anyone else. That’s a little… what does he say… a two-arm circle or something, whatever the expression is. But basically resolve it all internally. When you face the world, you have a front of rock-solid-
Segment 4343: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3961, Text: Don’t take sides against the family.
Segment 4344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3962, Text: Yeah.
Segment 4345: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3960, Text: … rock solid.
Segment 4346: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3961, Text: Don’t take sides against the family.
Segment 4347: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3962, Text: Yeah. Yes. It all boils down to Godfather.
Segment 4348: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3967, Text: Everything boils down to Godfather references, it really does.
Segment 4349: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3969, Text: And true romance.
Segment 4350: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=3970, Text: Yeah, you don’t take sides against the family. You don’t show that weakness to the world. I mean, again, I don’t know that Steve, in candor, would say, “You shouldn’t discuss it with your own therapist.” But I think what he’s saying is, don’t project it out to the world, don’t share that because I think it can change the way people view your relationship, which then will change the way you view your relationship. And so I think don’t run reckless when it comes to that primary relationship, don’t run your mouth recklessly.
Segment 4351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4008, Text: Yeah, it’s, one of the things I mentioned to you offline, that my now close friend, Joe Rogan, I’ve never heard him ever speak negatively of his wife. It’s always super positive how awesome of a person she is. And that, to me, has always been an inspiration to do the same for everybody in my life, to always speak positively about them. That has probably a virtuous spiral effect.
Segment 4352: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4033, Text: I’m sure. that’s probably because he has a great wife and he has a great wife in part because of that. I think it’s clear that he’s in her corner and cheering for her, it’s clear she’s cheering for him. It’s not like Joe Rogan’s not a man who has opportunity. I mean, he’s surrounded by UFC ring girls for god’s sakes. This is a guy who has all the opportunity in the world and he seems to be quite a fan of his wife. And that’s a superpower, that’s a real thing.
Segment 4353: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4064, Text: Now the question is he doesn’t seem to talk about it like, “Oh, I got to really work at that.” And that’s not a man who’s afraid to talk about what he works at. He’s pretty honest about, “Man, yeah, I got to work really hard to stay in shape. I got to work really hard to be able to do this. Yeah, I’m not good at memorizing that, it takes time.” But I’ve never heard him say, “Oh, marriage is a lot of work.” I think that’s to his credit because it seems like they’re enjoying that. And it’s also not incredibly public, it’s not something … most people couldn’t pick her out of a lineup.
Segment 4354: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4097, Text: He kept it private for many years, and just because it’s a private joy, it’s a private, deep, meaningful, intimate partnership. That’s, interesting, that’s also an inspiration. Not everything about your life has to be this, ” Look at me, I’m happy. I’m in a happy relationship. Everything is wonderful.”
Segment 4355: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4115, Text: Especially that. I think there is something about the womb like cocoon like joy of love, when you’re just tucked in, snuggled in, just pressed against each other with that. That’s such a … it’s just the two of you, and that’s lovely and that’s such a good thing. We’re just dying for connection and that connection is so big, it’s so everything.
Segment 4356: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4149, Text: One of my earliest psychedelic experiences, probably when I was a teenager, but a theme that’s been persistent in every psychedelic experience I’ve ever had is this idea of everything is connection. Everything is being pressed to someone and with them, the warmth of human connection. One of the reasons I enjoy listening to your work and your perspective has always been that I think at the core you see connection and love. And I think for me, from my earliest experiences with psychedelics at 16, 17, I was very attuned to that. I was very much … that was put on my radar by psychedelics and just stayed part of my consciousness forever. And I think I had a 30 something year break from psychedelics, but it was like when I came back to it, I went, “Oh yeah, it’s still there. That’s still the core of everything, is connection.”
Segment 4357: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4212, Text: I mean, it’s fascinating how deeply you value connection, how empathic you are that you would be doing what you’re doing, which is … or is it not, is it not counterintuitive?
Segment 4358: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4224, Text: I think it’s actually why I’m well-suited for what I do. I think what I do is I have to learn the story of my client and know it and feel it very deeply and I have to feel it in a very human way that’s very compassionate to this person. And then I have to feel it and understand it in a way that’s incredibly antagonistic to it, so I can shore up defenses. So I have to feel this person’s story and feelings from every possible angle because every one of them is a vulnerability and every one of them is a potential strength and a potential defense. And so I actually think it’s my number one, other than extemporaneous speaking ability, it is my number one job tool, is the ability to radically empathize and to put myself in the emotional state of someone in its best possible light and its worst possible light so that I can see again, the defense and I can see the vulnerability.
Segment 4359: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4290, Text: But I mean, so that’s beautifully put, but also just to bear witness to this connection broken in those dramatic way, over and over and over and over.
Segment 4360: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4301, Text: That part is hard, but I was a hospice volunteer for many, many years when I first got out of college and it really showed me a lot about what is sadness, what is tragic and what is just inevitable decay, what is pain and decay? We all die, we play a game you can’t win to the utmost. And so if we know the answer to all of this is you’re going to die, then what do we do with the rest of that time? If all your stuff is just stuff, it’s just going to go to … the money’s going to go, everything, your looks is going to go, everything’s going to go, love’s going to end one way or the … then what are we doing?
Segment 4361: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4347, Text: And again, I think it’s love and connection, but what I’m doing for a living is helping, and I don’t look at it as what I’m doing is helping people beat the crap out of each other. I look at it as I’m trying to help a client build their post-divorce life, to sort of rise from the ashes of that which has fallen apart and move on to the next chapter and refocus and have the things they need financially, emotionally, whatever it might be, interpersonally, in terms of with their kids. And so for me, it’s actually a job that is very consistent with my desire to build connection and to be empathetic.
Segment 4362: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4386, Text: And witnessing the ashes doesn’t make you cynical about the whole thing of love?
Segment 4363: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4390, Text: No, because again, 56% of marriages end in divorce, but 84% are remarried within five years. We keep doing it over and over again.
Segment 4364: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4401, Text: And that’s a good thing?
Segment 4365: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4402, Text: I think it is a good thing.
Segment 4366: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4404, Text: The mess of it, the absurdity of it, the hypocrisy of it, there’s something beautiful about that.
Segment 4367: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4411, Text: Well it’s just the return is so great on the investment. Listen man, I’ve had more than one dog. When my dog died, the first dog I had died, I remember when I’m never going to love again. I’m done, I’m done with this. I will never expose myself to this kind of pain again. I’ll never have to take the dog bed and put it in the closet and like … And then some friend called me and said, “We have an adoption event. Can you just watch this dog for 24 hours and then we’ll take him? We just need …” And I went, “Yeah, all right, I’ll watch the dog for the night.” And this dog come in and he said, “Oh, he has mange, he’s not going …” fuck, I got another dog. He walked in and my heart went, “Yeah, I got a dog.” And now that dog is 13 years old and his eyes are cloudy and he doesn’t go up the stairs real well and he’s going to break my heart, and I wouldn’t change that for the world.
Segment 4368: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4472, Text: I’m still there, I’m still struggling for the second one, I lost a dog and it broke my heart.
Segment 4369: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4479, Text: And you’ll never lose that pain. But I promise you, your heart has an infinite capacity for the kind of love you felt with that dog. And you’ll never feel a love that replaces the hole. There will never be another Buster for me, but there was Kava. And you know what, and when he’s gone, there will never be another one of him. But you know what, when that stupid puppy that was five months old stumbled in, I went, “I guess I’m going to do this again.” And you know what, I’m so glad, I’m so glad. And I know, by the way, I know now because that’s where I’ve said, it’s that Joseph Brodsky poem, a song, ” I wish I knew no astronomy when stars appear.” I wish I didn’t know the pain. But you know what, I don’t care. I don’t care and I believe we don’t care. Again, I think there’s something to that. If something hurts so badly and you go, “I’m going to do it again, I’m going to do it again,” then it must be of value, it must be of real value.
Segment 4370: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4551, Text: There’s also a different perspective on it, that pain. So there’s that, from Louis, the show, of this interaction with an old man with Louis C.K. And he says that, because Louis is mourning the loss of, got split up, he got dumped or whatever, and he’s mourning the loss of that partner, of love. And the old man says that that is the best part, missing the love is still love. The real bad part is when you forget it, when the pain fades and it’s all gone. But the pain is actually a kind of celebration of the love you had.
Segment 4371: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4590, Text: Of course. Well the opposite of love, isn’t hate. The opposite of love is indifference. There’s no question about that. I mean, hate is a passionate emotion, love is a passionate emotion. And there is a school of thought that says that only unfulfilled love can be truly romantic. But I believe that it’s what I think I learned from hospice, is that I think for me, knowing the impermanence is the thing, it’s the key.
Segment 4372: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4622, Text: Yeah, it’s finite, eventually it’s going to be over so that intensifies the feeling, that’s when you can have pure love without the drama.
Segment 4373: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4631, Text: Dogs are for me a great example. And again, I don’t know what it all means existentially, but I just feel like that kind of love has to be here to teach us something. And I feel like the fact that they’re so amazing and just so loving and so wonderful and the bond we feel is so amazing and deep and doesn’t require a lot of maintenance, and yet it’s so finite, it’s just this short little lifespan. And I feel like there’s just such a lesson there, there’s so much there to unpack about the nature of connection and loss and that your heart has this infinite capacity.
Segment 4374: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4678, Text: I’m telling you, when my dog died, when Buster died, I remember thinking with certainty, I will never do this again because I’ll never love that way again. I’ll never love a dog the way I love this dog. And it’s just not true, that’s just not true. You have this infinite capacity. And that makes it scary actually because right now there’s so many people you could love, there’s so many dogs you could love. There’s so much out there and it requires a certain bravery and tremendous amount of risk to do it.
Segment 4375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4717, Text: And a commitment, because I think to really experience love is you just dive in, because there is a huge number of people, but to really, I mean, you have to really dive into the full complexity, the full range of another human being.
Segment 4376: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4738, Text: Yeah. Which is hard because we don’t even, I don’t know that we even feel comfortable diving into the full range of ourselves. There’s pieces of ourselves we try to push away or not think about.
Segment 4377: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4749, Text: Okay, so speaking of the whole sociopath/empath that is all embodied in one human being that is you, let’s go back to some cases perhaps that you’ve worked on, just something that stands out to you. What’s maybe the craziest, most complicated thing you’ve worked on, is there something that pops to mind?
Segment 4378: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4769, Text: Craziest would be different than most complicated.
Segment 4379: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4771, Text: Let’s go craziest.
Segment 4380: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4772, Text: Yeah, so craziest, gosh, that’s a great question. So from a chaos standpoint, I mean, I see so many bizarre fact patterns and so many variations of people cheating with people, people sleeping with the nanny, people sleeping with a relative of their spouse, people having same sex or polyamorous relationships and the other person doesn’t even know they’re not monogamous, so much craziness that you could fill 15 books. In terms of complexity, I mean, emotionally complex is any custody case is emotionally complex because you’re dealing with parenting issues and what makes a good parent I think is a very tricky question because I’m trying to convince a judge who’s a better parent and that is so loaded with subjective value judgements.
Segment 4381: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4831, Text: Is there, just to linger on the maternal presumption, is that a thing you come face-to-face with often in court?
Segment 4382: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4840, Text: Well, it was, I mean, it was real, it was the law. There was something in the law called the maternal presumption, it was also known as the tender years doctrine, which meant that a child under the age of seven was presumed to be in the custody of the mother unless you could show she was an unfit mother. So that’s where the idea of someone has to be proven an unfit mother came from. Now in the ’80s, 1980s, that was changed. But under my skin is under my sovereignty. I mean, you can’t suggest that there isn’t in the world a suggestion that a mother who births a child and feeds a child with her body, doesn’t have a particular bond with a child that’s different than a father’s bond with a child. So where do we put that? How much importance do we put on it? Now that there’s better and more research in the mental health field about attachment theory in infants, there’s also a lot of research on how is attachment formed, how should parenting schedules be put together based on attachment theory, but there’s conflicting perspectives on that.
Segment 4383: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4918, Text: And so judge to judge you see, is there a lot of variation?
Segment 4384: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4921, Text: Yeah, there is because there’s lots of kinds of judges. There’s judges that are thoughtful, enlightened, interested in the mental health research, and there’s judges that just were unsuccessful lawyers, that were good politically and got elected and they just want a job where they show up at nine o’clock, they have a lunch break from 12:00 until two o’clock and that they leave at 4:30 and they get a certain number of weeks vacation and a pension after 20 years.
Segment 4385: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4946, Text: What is in general the process of these custody battles, what’s the landscape here?
Segment 4386: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=4955, Text: Well most, the overwhelming majority of custody cases don’t end up in my office, they are a negotiation between two people that love their children more than they dislike their soon to be ex. So the overwhelming majority of cases are just two people going, “Okay, how are we going to make decisions together?” Because there are decisions that have to be made about kids, will they go to public or private school, can they go on medication if they need it or not? Should we change pediatricians? All those kinds of things. How do we make decisions and when will we each spend time with the kids? And so most custody cases are just that. Most custody cases are just a discussion, a negotiation between counsel about those issues and they’re not ugly and they’re not anything, they’re just people. Again, sometimes people have differing perspectives, but sometimes people haven’t thought through their perspective.
Segment 4387: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5012, Text: So as a divorce lawyer, a lot of what I’m doing is counseling a person because they come in and say, “Well I’ve been the person who handles all of the homework and all of the everything, so he should only see the kids on weekends.” And there’s a logic to that, I’ve always done the homework with the kids, so I’m the parent who’s in charge of the homework and he’s obviously not done that before. But there’s also a logic that you can then say, right, but then you’re doing all the heavy lifting of parenting and he’s doing none of that. And you were a married couple and living together so he was trusting you to do that because you’re good at it and you seem to like it. So maybe now we want him to have to do some of the heavy lifting of parenting because we don’t want the child when they’re 13 to say, “I love dad, we have nothing but a good time together. Whereas you make me do my homework and eat my broccoli. Dad’s the grass on the other side of the fence that’s greener.”
Segment 4388: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5065, Text: So sometimes it’s about educating a client to change their frame, to look at this differently. Yeah, okay, we always go to my mother’s for Thanksgiving, so I need every Thanksgiving. Okay, well you were married so you went, now you’re going to have new traditions. Things are changing for your children, things are changing for your family, you’re both going to have new traditions. So a lot of times it’s just educating people on looking at things in a different way, looking at their parenting in a different way. We’re not going to live in the same house anymore, but we’re still going to parent this child or these children together. What’s much more interesting, because I don’t get invited to a lot of parties, but when I get invited to parties, if somebody says, “What do you do for a living?” And I say, “I’m a divorce lawyer.” They go, “Oh my God, you must have stories.
Segment 4389: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5110, Text: That’s the way everybody says, “Oh my God, you must have so many stories.” And if I said, “Yeah, there was this couple and they slowly grew apart and then they decided that it would be good for them to end their relationship as a married couple, but they wanted to continue to have an amicable co-parenting relationship. So they divided their assets and they figured out a good parenting access schedule that made sure that they both had both leisure time and responsibilities with the children.” People would be like, “That’s the worst fucking story, that’s so boring.” So what they really want is, and then he was sleeping with the nanny and then she caught him. So the truth is people want to hear about those flame outs. And by the way, those are super interesting as a lawyer, it’s super interesting.
Segment 4390: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5154, Text: It’s usually going to be what, infidelity? You do have a chapter called, Everybody Fucks the Nanny.
Segment 4391: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5158, Text: Everybody’s Fucking the Nanny.
Segment 4392: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5160, Text: Everybody’s-
Segment 4393: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5160, Text: There’s a nanny fascination out there. I try to explain it in the book, but yeah, I mean, I’ve had some great nanny stories. I mean, people run off with the nanny, people end up getting married to the nanny. I had one where he convinced her that they should have a threesome with the nanny. They got the nanny drunk, they had a bunch of threesomes with the nanny and then the nanny and the wife paired up and left him.
Segment 4394: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5184, Text: Oh, nice
Segment 4395: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5185, Text: And they’re still quite happy.
Segment 4396: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5186, Text: That seems like a happy ending to the whole-
Segment 4397: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5188, Text: For everyone but him, but it was his idea.
Segment 4398: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5190, Text: Well he’s really going to have a nanny fascination now.
Segment 4399: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5194, Text: Yeah, well now he’s got to see the nanny whose now the stepparent to the kids and it was his bright idea of let’s have a threesome with the nanny. Yeah, I mean, the nanny thing I think is a function of, in many circumstances, is the characteristics of the wife that he remembers fondly and that have been extinguished by the presence of children. So my words of wisdom is not don’t get a nanny or make sure you get an ugly nanny. My thought on it is that a woman should remember, even when she’s a mother, that she’s also a woman who a man, they fell in love with each other and she should take time to be in touch with the part of herself that is an independent woman, that’s interesting and interested. And there’s a lot to be learned from divorced couples because divorced couples, if you do it right, it’s awesome.
Segment 4400: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5257, Text: I had a wonderful experience parenting and being divorced, because I divorced when my kids were quite young. My co-parent, my ex-wife is awesome, she’s a great mom, nice person, we’re good friends. And it was great. I had half the time I had my kids and I could focus on them and the other half of the time they were with the other person who loves them as much as I do, and I didn’t have any other responsibilities of kids and I could just have all of the wonderful fun that you can have when you don’t have the responsibilities that come with full-time caring for children.
Segment 4401: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5293, Text: What would you say now on the flip positive side, we’ve been talking about the collapse of things, what about success? What’s the secret to a successful romantic relationship?
Segment 4402: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5305, Text: My mom used to say that it’s hard to define intelligence, but you could spot stupid a mile away. So I’m much better at pointing out where people fall apart because I spend a lot of time with people who have fallen apart in their relationship. So it’s easy to then say, “Well just don’t do what they do.” But I don’t know that that’s not an oversimplification. So again, I think the answer is connection. I think the answer is affection, presence, mindfulness and presence. I do think, in my personal and professional experience, that most people want you fully more than they just want you in a disconnected way. So if you were to say to your romantic partner, “You can have me for two hours where I’m giving you my undivided attention and I’m really joyful to be with you, or you can have me for eight hours where I’m sort of half paying attention and I kind of want to be someplace else for part of the time.” There’s just no choice there, it’s so obvious.
Segment 4403: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5392, Text: So I think presence is a big piece and I think the you, the me and the we, I think is important because I think in relationships there’s you and there’s me and we meet and something magical happens and we become we, and now there’s you and there’s me and there’s we. Then the we gets bigger and bigger and bigger, and isn’t it great because it’s such a nice warm place. It gets so big. But it gets so big that you get small and me gets small because we. And if any of us dares to ask, well what about you? What about me? No, no, the we, what, you don’t like the we, you don’t want to be with the we? Whoa, whoa. No, it’s not that, but the we only exists because there was you and there was me and I really liked you and you really liked me. And so we picked each other out of lots of choices and now this we is so fucking big, it threatens to just consume all of it. And I really think that there’s something there we have to look at more honestly.
Segment 4404: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5471, Text: So the we should not consume everything, but at the same time, not be small?
Segment 4405: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5478, Text: Well the we is the you and the me and if you mix it so much that you and me loses its components that all that’s left is we, I don’t think that that’s the way to do it. I just think the world pulls us in that direction. We get told culturally that, well why aren’t you going with this person to that? Why would you do that by yourself? And anyone knows that there’s joy in being away from each other and there’s joy being reunited together. So why don’t we speak very honestly about that? And I think some of that’s our own insecurity. Well why don’t you want to be with me 24 hours a day? Aren’t I wonderful, aren’t I delightful? It’s like, well wait, what?
Segment 4406: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5527, Text: Well, but also probably people are either afraid or lazy in developing their individual selves. I mean, it’s lonely going out there in the world by yourself and it’s comforting in that little cocoon of we.
Segment 4407: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5542, Text: I mean, it can also be incredibly adventurous going out into the world by yourself and then coming back to the we with a full report. Coming back and saying like, “Oh my God, guess what I saw? Guess what I did?Like, “We have to go there together now because all I could think about was you. While I was there I was like, oh my god, she would love this.” That’s magical, that’s amazing. Look what I brought you back. I went for this and then I got you this present from there. There’s something … and we know this. I always thought it was when you watch the old westerns where the hero’s leaving and he’s walking away from the cabin, he’s going to go fight the gunfight. And she runs up and she goes, “Please don’t go, don’t go, stay here with me.” And he kisses her and then he goes. If he goes like, “Yeah, you’re right, I’ll just stay here, it’s cool. I didn’t want to deal with that anyway.” He’s not the hero anymore then.
Segment 4408: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5595, Text: Yeah. Yeah, there’s deep truth to that. And probably, like you mentioned, sex is probably a big part of it. Friendship, that seems to me like a really important one.
Segment 4409: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5608, Text: Depends on how you define friend. If being a friend means we have some connection to each other and we have each other’s cell phone numbers, okay, then we’re friends. But if it’s a bigger definition than that, if it’s like you’ve picked me up at the airport or you’re someone I could call, that it’s like, “Dude, I got to hide a body. You get shovel and lime.”
Segment 4410: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5630, Text: I like how you escalated from airport pickup to murder.
Segment 4411: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5634, Text: I try to go in two directions.
Segment 4412: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5635, Text: You’re a true New Yorker.
Segment 4413: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5636, Text: I have to tell you, I define the Ben Affleck movie, The Town, that scene, that’s friendship to me. I mean, to me the ideal male friendship is the scene where he says, “I need you to come with me. We’re going to hurt some people and you never have to ask me about it again.”
Segment 4414: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5636, Text: Oh, yeah.
Segment 4415: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5652, Text: And he says, “Whose car are we taking?” And that’s sort of like, to me that’s friendship. So it’s a high bar to be like a friend. So when you say friendship, I think that’s the kind of friendship you should ideally have with your romantic partner. If you’re getting married, it should be the like whose car are we taking? It should be that, it’s you and me.
Segment 4416: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5673, Text: To be fair, that bar is reached with me with a lot of people, if you call me tomorrow and there’s a body.
Segment 4417: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5680, Text: But you’re a big open heart.
Segment 4418: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5683, Text: But it’s true, I wonder how many people out there are like that, in terms of hiding the body.
Segment 4419: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5690, Text: I mean, my theory on this, because I think I’m like you in that way, I think I’m very sensitive. I feel things really deeply. And I think the world is terrifying when you feel things very deeply because there’s so much pain, there’s so much betrayal, there’s so many opportunities to be hurt. And I think when you are that kind of person, you go through stages and one of them is that I don’t care, I don’t feel anything, it doesn’t matter. I don’t feel anything. I don’t feel anything. I don’t feel anything. You try to convince yourself I don’t feel anything, it’s fine, I don’t feel anything. And then at some point you do feel all of it, and then it’s like, oh my God, the weight of this is … I mean, I think it’s the whole arc of Pink Floyd, The Wall, it’s literally the entire arc of Pink Floyd, The Wall. And the song, Stop. I want to go home, take off this uniform and leave the show.
Segment 4420: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5752, Text: When you feel all of it, the army of hammers coming at you, the slings and arrows of outrageous fortune, the thousand natural shocks, the [inaudible 01:36:00] too. When you feel all of that deeply, it’s very hard, but it can also be a superpower because I think when you can bring that to a relationship, when you can bring that to a profession, like you’ve done and I’ve done, then there’s something very magical about that. The ability to bring it out in someone, to feel it in yourself, to understand it is a gift, it’s a wonderful, wonderful gift. I’m humbled by what it brought me professionally and I’d like to think that you and I have both found professions that enable us to use that sensitivity, that empathy in a productive and good way and in a fulfilling, a personally fulfilling way, and ideally in a way that does good for other people.
Segment 4421: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5815, Text: You yourself are incredibly successful and a high performer, you’ve dealt with a lot of CEOs and just high performers in all walks of life. What can you say about successful relationships with those kinds of folks?
Segment 4422: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5832, Text: That’s a good question. I think-
Segment 4423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5834, Text: Is it all the same stuff or is there something special when they’re busier?
Segment 4424: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5839, Text: Well, I think when you represent high net worth individuals but also high performing, I would make a distinction between high net worth and high performing. So I’ve done high net worth divorces where the person’s like a trust fund kid, even though they’re an adult. But what they did to achieve their high net worth status is their great-grandfather died. So that is different than someone who is self-made, who through discipline, focus, entrepreneurship, whatever it might be, that they have found success. And there’s also a difference between financial success and fame, because I’ve represented famous people that actually did not have that much money in the scheme of things or much liquidity. And I’ve represented people that were not in any way famous and were very high performing in their field.
Segment 4425: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5893, Text: In New York, we have a lot of finance people and what I find is their divorces are challenging, one, on a technical level because figuring out what they have and how to divide it is tricky. Because when something’s moving that quickly, when your portfolio’s movement affects a market, that’s challenging. Jeff Bezos divorce, for a time, when it was in its early stages, could affect Amazon stock. It did. So that’s a real thing, there are businesses that are affected by a divorce. But in terms of being in a relationship with someone who is a high-
Segment 4426: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5940, Text: … with someone who is a high-performing person. Most of the high-performing people I know are creatures of discipline and routine. From Joe Rogan, we’ve talked about any of these people, they have a routine, they have a discipline, they have a focus, they have a way they like to do things, they have a type of coffee they like to drink, they have a way that they like to do. And divorce is a tremendous disruption. I mean, divorce is fundamental things in your life are shifted out of your control, like your spouse may be the one who has decided you are no longer going to live in that house. You will no longer see your children on these days. So to take that control away from someone is very, very hard.
Segment 4427: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=5989, Text: I mean, when someone is a high performing, high net worth person, they are used to being told yes, they’re used to being able to buy their way out of a problem. But just like illness, you can hire the best doctor but you can’t cure cancer because you have a lot of money. You can hire the best lawyer, but you can’t cure a custody case. Angelina Jolie and Brad Pitt’s seemingly endless custody disputes that have been going on for years now with the best lawyers in California working on them is proof of the fact that you can’t just buy a resolution to those things, that you have to go through it just like everyone else.
Segment 4428: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6036, Text: So that lets me ask the question of how much does a divorce usually cost?
Segment 4429: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6042, Text: It’s a great question. Average divorce, what I always tell clients in the first consultation is I tell them the most reasonable question a person could ask me sitting in that chair across from me is two, how long is this going to take, and how much is it going to cost. And those are two questions I can’t answer. And then, the next thing they say is, “Give me a range,” which is a bit like calling your doctor and saying, “I have a headache. What is it?” “Well, I can’t tell you. I’d have to do tests.” “Give me a range.” “Okay, it’s a reaction to the barometric pressure and it’ll be gone in 15 minutes or it’s a brain aneurysm and you’ll be dead in five minutes, there’s your range.” And so, it didn’t really help. The least expensive divorce I’ve ever seen is two people who, one of whom comes into my office and says, “We’ve written down on a yellow pad what we figured out at the kitchen table. She’s going to keep the house. I’m going to keep the 401k, we have a bank account at this bank. We’re going to split that 50-50. I’m going to pay her this much in child support each month, and We’re going to agree from time to time on what we’re going to do in terms of the schedule with the kids, but they primarily going to live with her. Can you write this up and make it legally binding?” Yes. 3,500 bucks.
Segment 4430: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6131, Text: Just as a side note, I have a friend who went through a divorce and handled it just masterfully by giving more than he’s supposed to and having nothing but love in his heart and happiness with the kids and just, I don’t know, that to me is just an inspiration. His whole view was like who caress about money? And also, he refused with every ounce of his being to have anything but complete love for the other person.
Segment 4431: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6169, Text: Yeah. I’ve had clients who, with a straight face, will say to me like, well I’m not going to quibble over a few million dollars. And they mean it, because to them it’s numbers on a page. So I’ll personalize this a bit. So I have a friendly relationship with my ex-wife, who’s the mother of my sons who are adults, and we have maintained a very good relationship. And so now, it’s many years divorced later, 17, 18 years later and we were able to sort of post-game that relationship, even our co-parenting relationship, we kind of post-game it when we chat with each other.
Segment 4432: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6202, Text: And I remember once saying to her, “Yeah, you never screwed around with me when it came to the kids. You were always so cool. If I called you like if I was having a really bad day at work,” or seeing just an ugly custody case and it just felt like I would call her and say like, “Hey, can I just pick the boys up and take them out for ice cream or something tonight? I know It’s not my night, but would you mind if I just took them out for a couple hours?” She’d be like, “Yeah, sure, come on by.” She was always flexible like that.
Segment 4433: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6234, Text: And I said to her, “Was that just goodwill. You’re just a good person or what was that about?” And she was like, ” Yeah, it was partly that.” But she was like, “It was partly that you never screwed around with me when it came to money. If the kids needed something or if I needed something as the mother of the kids, you were always like, yeah, sure, of course.” Her air conditioning kicked out and she needed it to replace it and she didn’t have liquidity at the time. I didn’t have a lot of money at the time because it was a long time ago. And I was like, “All right, no, because I don’t want you hot and upset and I don’t want the boys to be in… Of course.”
Segment 4434: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6263, Text: And so, I think, yeah, when you approach a conflict, it’s very hard to argue with someone who won’t argue with you. If the person approaches the argument from the point of view of like I’m not going to argue with you, I’m going to absorb your aggression, I’m going to just not meet it with that. I’m going to meet it with love, I’m going to meet it with positivity. It doesn’t always work because sometimes people are so angry that they’re relentless.
Segment 4435: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6290, Text: But I have to tell you, the louder you get, the quieter I get, the more you seem irrational and that’s what I always try to bring that to court proceedings. I always try to bring to court. If I know my adversary is coming in hard, I’ll come in quiet and slow and deliberate because I want the volume to be turned up way too high over there. And then, it looks like, “Your honor, what’s their problem over there?”
Segment 4436: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6324, Text: I say this to clients. They got a four-year-old, they’re getting divorced, let’s say. There’s going to be a wedding in like 20 something years. There’s going to be a wedding and it’s either going to be the wedding where they got to put these people on opposite sides of the room, because if they pass each other by the shrimp boat, they’re going to kill each other, or it’s the wedding where you stand there, you take some pictures. You kind of go like, “Yeah, we fucked up this whole marriage thing, but man we did a good job with this kid. Did we?”
Segment 4437: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6353, Text: And the decisions you make right now, there’s a straight line to that wedding. And so, even if you don’t like this person, even if you’re mad at them, even if you’re mad at yourself for the choices you made in choosing them as a co-parent, every single Mother’s Day for 27 years, I have told my now longtime ex-wife, “Happy Mother’s Day. I’m so glad that we had kids together. I’m so glad you’re the mother of my kids, because they wouldn’t be who they are if it wasn’t that they were part me and part you and I’m so grateful for you and I’m always cheering for you.” How hard is that? How hard is that?
Segment 4438: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6392, Text: Well, it’s really hard for some people, but-
Segment 4439: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6394, Text: I don’t understand why it’s so hard for some people. I’ll tell you, I do find that hard. There’s not a lot of things that I don’t understand, but that’s one that I don’t understand. I put in one of the weird things I did as a divorce lawyer that caused a little stir among my colleagues for a few years was some years ago, we all steal from each other’s work, divorce lawyers. We’re like the matrimonial mafia. We all know each other, we all deal with each other over and over again, but we all have the same job, and so, we are the only people that really know the unique stresses of that job. So even though we try to kill each other all day, it’s like boxers, professional fighters. Yeah, your job’s to take each other’s head off but nobody knows what the two of you went through like the two of you that’s.
Segment 4440: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6443, Text: That’s why I always get, I go like all kinds of rubbery when I see after the fight the two people hug each other because always like, yeah, because you know what? They relate to each other better than anybody. They suffered. They bled. The competitors, they bled. So I really think divorce lawyers, we have that same kind of relationship. We went through this stress on opposite sides trying to take each other apart. And I find that we all steal from each other’s material when it comes to separation agreements, provisions that we use for agreements. All the agreements are like these Frankenstein monsters of, “Oh, I like his estate planning provisions. Oh, I like her provisions related to maintaining a life insurance policy to secure the alimony award.”
Segment 4441: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6489, Text: And I wrote this paragraph for this select, the section, because what occurred to me is that when you have a child with someone and let’s say they’re three or four or five, they’re old enough to know what Christmas is, but they’re not old enough to go buy a Christmas present. But they’re old enough to know that you get presents on Christmas and you give presents on Christmas, but they’re not old enough to buy one for the parent. So someone has to do that for them. So I thought I’m going to put in a provision that says that as long as the children are so young that they can’t independently purchase a Mother’s Day or a birthday present for the co-parent, that you’ll take the children either to buy a small gift or to make a card or something like that.
Segment 4442: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6543, Text: This struck me as a no-brainer. Who could disagree with this? It’s not for the person, it’s for the kid. So the kid, “Happy birthday, mom. I don’t have a present for you. I don’t have a card for you, because I’m fucking five. I’m five.” You can’t go do that. So wouldn’t you want your child, not your co-parent, who cares? Maybe you want them to have the worst birthday ever. Fine, but you don’t want your child to be embarrassed.
Segment 4443: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6573, Text: And I even put in the provision, the parties acknowledged that it is the intention of this provision to ensure that the child is not embarrassed and feels that they were able to say… I cannot tell you how many people refuse to sign that, how many lawyers said to me, “We’re taking that out.” And I went, “Wait, why?” “Well, why does my client have to buy a present for your client?” I said, “They’re not buying a present for my client, they’re buying a present for the child to give to my client. It can be one of those little $3 boxes of chocolates they sell at the drugstore. But it’s a kid, they don’t know, they don’t know what anything is, and people, “Nope.” And I have to tell you, of the conundrums, of the puzzles that I can’t figure out in existence, that’s when I can’t figure. I do not understand why that’s so hard.
Segment 4444: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6625, Text: That’s basically just an illustration of their complete inability to do anything nice for the other person.
Segment 4445: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6632, Text: The level of hatred, the level of vitriol that they… Maybe this is me. If you apologize, there’s not a lot I won’t forgive. I’m not saying, “I’ll forget it.” I’m not saying, “Oh we’re totally good like it never happened.” I understand that. But if someone says what I call a non-bullshit apology, a bullshit apology is, “Oh, I’m sorry you got so upset when I did that.” That’s a bullshit apology. “I’m sorry that you were offended.” That’s a bullshit apology. Or, “I’m sorry for what I did.” Because what are we talking about? We might not be talking about the same thing. Or you might be saying I’m sorry that you found out about that, not that you did it.
Segment 4446: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6675, Text: So a real apology is, “I lied to you and I realized that that hurt you and I’m really sorry, I shouldn’t have done that. I regret that I did that and I know that it hurt you and I’m really sorry.” That’s a real apology. Someone’s willing to give you that and you still want to walk around with the level of vitriol that you will harm your child rather than do something nice for them? I don’t have a solution. And I tell you, I see that all the time. Parental alienation is a thing. It is a thing. Children can be weaponized. I always tell people, I’m like, “If you want to get married, get married. Get a prenup ideally. But if you don’t have a prenup, okay, you’re just risking money, don’t worry, you’re just risking money.” Money and hassle of paperwork and of time and of going through an ugly financial divorce. But you have a kid with somebody, that is a missile, that person has a power over you for a long time, if not forever.
Segment 4447: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6743, Text: So the child could be used as part of a manipulation.
Segment 4448: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6748, Text: Routinely.
Segment 4449: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6749, Text: That’s heartbreaking.
Segment 4450: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6750, Text: People weaponize children all the time and they do it with the permission of their own conscience because they genuinely believe I’m going to protect this person, this child, from this person, who by the way is a bad spouse, but that doesn’t mean they were a bad father or bad mother. You can be bad at being a spouse, but the skillset of a spouse and of a parent, it’s not necessarily the same. And I’ve seen people alienate children from a parent in such subtle ways, but they’re so powerful. And as a lawyer, it doesn’t matter what I know, it matters what I can prove. And It’s very hard to prove alienation because it’s usually a very subtle process.
Segment 4451: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6800, Text: And the example I always give to people is it’s a rare kind of crazy person that will say to a seven-year-old, “your dad is a bad person.” But this? “Hello? Here, it’s your dad.” You just said your dad’s a bad person. You just did it with your eyes, you did it with the expression on your face when you handed the phone to the kid, you told that kid your dad’s a bad person. You didn’t have to say it out loud. And that is something people are guilty of all the time. There’s a divorced couple, kid comes home and says, “Oh, I met mom’s new boyfriend.” And you go, “Oh yeah, that’s nice. Remember, he’s not your dad.”
Segment 4452: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6844, Text: Whoa, you just told that kid a whole bunch of information about how he’s supposed to feel about this person. Whereas, if you go, “That’s nice. Is he a nice guy? Oh, that’s great. I heard nice things. Yeah, I heard he likes bicycles. That’s cool. That’s really neat.” You just told this kid, it’s okay, you could like this person. It’s okay to like this person. It’s okay that your mom is with this person. And again, whatever you feel about your ex, your co-parent, usually you love your kid more than you hate your ex ideally.
Segment 4453: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6874, Text: Also, I wish people would, even without an apology, forgive each other. It goes back to the earlier discussion we had. I usually forgive people if there’s something in them, especially if we shared something. But even just if there’s something about them that’s beautiful, it’s great that they exist in the world. So I’m just grateful for that and I use that as the fuel of forgiveness.
Segment 4454: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6902, Text: I don’t know. To me, forgiveness is very often, it’s for me. When I let go of anger, I feel lighter. I think my heart enjoys peace. I mean, partly because I fight for a living. I work in the world of conflict. I jokingly used to say to my sons when they were teenagers, “I can only argue if you’ve paid. It’s not fair to the paying customers.” If I argue with you for free, that’s not fair.
Segment 4455: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6934, Text: But I think we’re talking about the incredibly wide range that a divorce can cost. And you were saying the cheapest one was the yellow-
Segment 4456: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6945, Text: Yeah, yellow pad. Two people, came to an agreement, write it up, make it legally binding, five grand maybe tops. But usually 3,500, 5 grand, that kind of vibe. Most expensive, millions, millions in counsel fees.
Segment 4457: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6960, Text: And that’s because of the duration, the complexity.
Segment 4458: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6962, Text: Yeah, duration, the complexity of issues. I have clients who’ve paid 2, 3 million in counsel fees to me.
Segment 4459: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6969, Text: So it’s like has to do custody or what’s the source of complexity?
Segment 4460: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6973, Text: It can be complex custody that requires a hearing, that requires expert testimony, dueling, mental health professionals, opining on the parenting. It can be a situation where emergency circumstances occur like where an individual tries to abscond to another country with the children and you have to bring them back under the Hague Convention.
Segment 4461: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6994, Text: Oh, wow.
Segment 4462: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6994, Text: On international child abduction.
Segment 4463: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6996, Text: Oh, wow.
Segment 4464: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=6997, Text: We’ve done some Hague cases. There are cases where people have very different facts. Before I came here today, a client of mine’s soon to be ex-husband who she’s in the middle of a door, he tested positive for cocaine on a hair follicle test, where it was said he was definitely not going to test positive, and he tested positive. So it was like we were scurrying now with okay, we got to get a motion filed, we got to suspend access, we got to protect the kids, we got to get in front of a judge, we got to think about what are the implications of this, because he was about to transition to an unsupervised parenting. This is the kind of stuff that can amp up the amount of work the lawyer has to do, which then translates to money. I get paid for my time and the time of my team. I have attorneys and paralegals who work for me. So when you have a team of lawyers working on a case, you can burn tens of thousands of dollars a day if it’s a big enough case.
Segment 4465: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7062, Text: There are also very complex financial cases. People move and hide money. The high net worth space is a different world. Like if an average person owns a home, they own a home in their name or their name with their spouse. A high net worth person owns an LLC that owns that home. That LLC is owned by a trust. They are a beneficial interested party in that trust. This is how some of my clients who make tens if not hundreds of millions of dollars a year pay less in taxes than a cop or a firefighter, because they have structures, and the structures that were designed for tax planning purposes then in a divorce become very tricky to unwind and to figure out wait, no, what is mine and what is not?
Segment 4466: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7125, Text: Well then, that takes us to the question of prenups. What’s your view on prenups, prenuptial agreements?
Segment 4467: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7130, Text: It’s not popular to quote Kanye West but, “If you ain’t no chump, holla, we want prenup, we want prenup.” I mean, that’s what he had to say meaning.
Segment 4468: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7139, Text: Meaning, prenup is a good idea.
Segment 4469: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7141, Text: Prenup is an excellent idea. A prenup is a contract between two people that binds their respective rights and obligations in the event of a divorce when it comes to financial issues. That’s all it is and there’s a lot of reasons to have them and there really aren’t any reasons not to have them other than the fact it requires an uncomfortable conversation.
Segment 4470: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7168, Text: So I mean, there’s a few questions here. First, do they work legally in general?
Segment 4471: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7173, Text: Yes. If they are crafted correctly, which is not that hard to do for a lawyer to do, I’m saying for a lawyer to do, because with the internet everybody thinks why would I spend $1,000, I can just Google prenuptial agreement and I can get one and then it’ll be…” That is a bad idea. It is like a will. If you’re going to have a document that binds your rights at that level, it’s worth… The most expensive prenup I’ve ever done was like three grand. That’s ridiculous. That’s not a lot of money. So there’s no reason you wouldn’t do it, but people still, people will still. I’ve had clients that have hundreds of thousands of dollars and they did their prenup downloading something from the internet and because of some imperfection, it doesn’t have the right what’s called acknowledgement, which is the section where the notary signs and it has to say that it was duly sworn before this person on this date, and if it doesn’t have that it’s invalid, it’s not binding.
Segment 4472: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7230, Text: So there are weird technicalities, but yeah, prenups are binding. As long as there’s been some minimal asset disclosure, which is easily done in a prenup, and as long as there’s not a language deficiency, meaning that the person who is reading it understands English to the level that they understand what they’re signing, and if they don’t that at least they’ve acknowledged in their native language that there is some opportunity for this to be translated for them, yeah, they’re binding. They’re presumptively binding. We live thankfully in a culture where people are allowed to enter into contracts about money.
Segment 4473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7267, Text: What are some prenups that you’ve seen that can be effective or that people converge towards in terms of what does an agreement look like? Because the popular conception is when there’s no prenup, both sides get half.
Segment 4474: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7286, Text: And that’s generally true that both sides get half, equitable distribution, which is what the law is called it’s, the law of equitable distribution. It’s not called the law of equal distribution for a reason, because it’s equitable, not equal. Now equitable is presumed to be equal, but there are exceptions to that presumption, and that’s where lawyers can get into fun and or trouble depending on how you view it. It’s where we make our money. We make our money arguing that the fair result will not be just a 50-50 split.
Segment 4475: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7320, Text: And so, there’s the very generic standard prenup, which is easy and I call that yours, mine, and ours. If it’s in your name, it’s yours, whether it’s an asset or a reliability. My name, it’s mine. Joint names, we split at 50-50. Simple, clean. And you go in to the marriage now knowing what the rules are. So if you get a bonus at work and you put it in your sole name, then it’s your separate property in the event you divorce. You go out and buy a boat and she doesn’t support you buying the boat. But the boat, you got a big loan on this boat, you’re responsible for that loan.
Segment 4476: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7360, Text: I like that because I like people having some control. I also like people having to have discussions. Well, why are we putting that bonus just in your bank account? Why wouldn’t we put it in the joint bank account? We should have that discussion while we’re married, not when we’re in a divorce lawyer’s office 10 years later, because we should be able to talk about those kinds of things. So what’s interesting about prenups is that somehow people think there’s something like it takes away from the romance of a marriage. But I’ve said it before and I’ll say it again, all marriages end, they end in death or divorce.
Segment 4477: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7399, Text: So having life insurance or having a will, it doesn’t mean you can’t wait to die, it doesn’t mean you’re looking forward to death, it doesn’t mean that you’re predicting your demise sometime imminently. It just means that you’re being realistic and honest. So when you marry and I don’t mean spiritually marrying, having a marriage ceremony, I mean legally marrying, you are making changes to your rights and obligations under law. That’s what you’re doing. Marriage from a legal standpoint, what we mean when we say I got married is a state agency. It’s been created by the state. This is a legal status that most people who are in it know nothing about. They just did the most legally significant thing they’re ever going to do other than dying. And they have no idea what rights and obligations it created in them. And the first time they’re going to get an education about it is in my office, that’s crazy.
Segment 4478: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7463, Text: When they get divorced.
Segment 4479: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7464, Text: That’s crazy.
Segment 4480: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7464, Text: And so, prenup is an opportunity to learn something about it at the start.
Segment 4481: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7469, Text: So first of all, whenever someone approaches me about prenups and that’s like four or five times a week probably depending on the season, right before wedding season, we get a lot.
Segment 4482: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7479, Text: When’s wedding season?
Segment 4483: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7480, Text: Well, it used to just be the summer. They say when you marry in June, you’re a bride all your life. That’s from some Rodgers and Hammerstein musical. Now, the fall is very big too. People love fall content, fall weddings, pretty pictures and things. Fall content.
Segment 4484: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7480, Text: It’s good on the gram.
Segment 4485: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7497, Text: Hashtag fall content.
Segment 4486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7497, Text: All right. That’s hashtag.
Segment 4487: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7498, Text: Listen, weddings is for the gram. I have to tell you, weddings is performative, man. See, the problem is though, it’s curated. So here’s us picking the cake, it’s not here’s us doing the prenup. You know how many people I’ve done prenups for that I’ve watched on their social media or them being interviewed by Andy Cohen on Bravo and saying, “Well no, we don’t have a prenup.” Yeah, you do. Yeah, you do. You do. It’s in my office. It’s in a folder. They have a prenup.
Segment 4488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7523, Text: Yeah, that’s beautiful.
Segment 4489: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7524, Text: But prenups are not published any place. They’re not filed with a court. They’re maintained by the two people that signed it and their lawyers. That’s it. So nobody has to admit that they have a prenup.
Segment 4490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7533, Text: Beautiful.
Segment 4491: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7535, Text: Yes, but there’s a certain problem with that insofar as a lot of people have prenups and we need to normalize prenups. There’s no reason not to normalize prenups. Until some famous people say, “Yeah, we have a prenup. We’re crazy about each other. That’s why we’re getting married. But yeah, look, we’re getting…” I don’t want to get a car accident but I got a seatbelt. You have it, just in case.
Segment 4492: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7561, Text: And I mean, what do you do if you’re running a company? What does that have to do with a prenup? You’re running a hundred billion dollar or trillion dollar company, Jeff Bezos. I suppose his marriage was before Amazon.
Segment 4493: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7578, Text: Yeah, his was before it was anything.
Segment 4494: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7580, Text: But how does that work in a prenup?
Segment 4495: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7582, Text: Well, no, actually it’s the same. What you’re doing with a prenup is you’re identifying how things will be classified in advance. So you’re creating a set of rules, and then you both can function under those rules during the marriage. So for a brief time, I taught a family law drafting class at a law school, and when we would do separation agreements and we would do pleadings, it was lots of fun. When we would do prenups, I would say to the students, “What’s the main thing you need when you’re doing a prenup?” And they would say, “Well, you need asset disclosure.” And I’d say, “Well, that’s not the main thing.” And they’d say, “Well, you need technical language.” They’d say, “Nope.” Main thing you need is a crystal ball. The main thing you need is the ability to see what’s going to happen in the future. Who’s going to have money, who’s not, who’s going to be successful, who isn’t, what people will inherit.
Segment 4496: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7638, Text: Problem is we don’t have that. We don’t have that. So what can we do? We can create tranches, we can create structures, we can create systems, and then people can live with those in mind. You enter the game knowing the rules. So you know if this is going to be a submission only event. You know if this is going to be no time limit. You know if we’re after a certain number of minutes, we’re going into points now. So I can work with that rule set and I’m going to amend my game based on that rule set. Same thing, same thing. You’re just going to say, “Look, what’s the rule set? Let’s agree on the rule set. And then, let’s conduct ourselves with the rule set in mind. Let’s plan the rule set in mind.” By the way, and if you’re going to cheat, you cheat with the rule set in mind. You know you’re cheating. You’re trying to get around the rule set.
Segment 4497: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7692, Text: When I do a consult for a prenup, the first thing I do is here’s what’s going to happen legally if you marry without a prenup. Here’s what happens to your rights and obligations. Then, what we can change with that, there’s almost no limit. You can amend anything you want to. The example I always give is there was a case that went up to the appellate court where a high net worth guy married a very beautiful woman and there was a provision in the prenuptial agreement that said for every 10 pounds she gained during the marriage, she would lose $10,000 a month in alimony if they divorced. Here’s her baseline weight as of the time of execution of this agreement. I wondered if she did what a wrestler does. Did she bulk up right before and then cut when she eventually got divorced? Is she in there in a sauna with the suit on? And the appellate court essentially said, “I don’t know why you married this person having had them make you sign this, but it’s binding, but it’s binding.”
Segment 4498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7758, Text: I wish somebody would do a contract like the rent for this place would be more expensive if I was fatter, and cheaper if I was skinnier, and that way I would have to weigh in and like the motivation.
Segment 4499: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7770, Text: Like some motivation on you.
Segment 4500: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7771, Text: Yeah, exactly. That kind of prenup is motivating.
Segment 4501: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7775, Text: Well, what’s his name? I think Tim Ferris says that about how he does, he said you should make bets with people. It’s like if you gain this much, I got to give you this amount of money. I think he says that in one of his early books.
Segment 4502: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7787, Text: And try to make a binding somehow, which is tough.
Segment 4503: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7790, Text: Yeah, I think when we create incentives of that kind, that’s why there was the No Nut November or No Shave November, sober, all those, it was a competition. When people make a competition of something, they gamify something, it makes it something that people are more likely to stick with. So I mean, I guess a prenup, it’d be interesting. The problem is there’s also, people put in prenups what’s called fidelity clauses.
Segment 4504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7816, Text: Oh.
Segment 4505: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7819, Text: Fidelity clauses. People still do these. I discourage people from doing them. The two things that people put in prenups that I discourage people from putting in prenups, but very often people still put in prenups even with my caveat is fidelity clauses and sunset clauses. So fidelity clauses is I’m waiving alimony, I’m waiving this, I’m waiving that. But if you cheat, I get a million bucks or I get this much alimony, I get this amount. And I know the intention is to disincentivize the person from cheating, it’s a deterrent to have them cheat, but all it really does is just creates an interesting legal battle for lawyers like how did you prove that they cheated or not?
Segment 4506: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7861, Text: Oh, right. Because what constitutes cheating also?
Segment 4507: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7865, Text: Right, is an emotional affair, and affair is oral sex. Cheating is… And by the way, how do you prove it? Well, I was in a hotel with her, but how do you prove that I had sex with her? And you’re opening a can of worms with that kind of a thing, but people sometimes still put them in. And sunset clauses. Sunset clauses is if we’re married X period of time, this goes away as if it never existed.
Segment 4508: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7893, Text: And why is that a bad idea?
Segment 4509: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7894, Text: The same reason the community property law in California is a bad idea. So the community property law is after a certain number of years, I think It’s seven, everything including your premarital property, all becomes marital property. And the idea of that was supposed to be that if you’ve been married that number of years, you’re in enough of a serious relationship now that everything is one unit, you’re one person. What it actually does is creates a very-
Segment 4510: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7920, Text: You’re one person. What it actually does is creates a very uncomfortable thought experiment that people have to have at the six-year mark, because you have to, now the honeymoon’s kind of over. You might have a kid or two and you go, “Okay, wait a minute. Am I so happy in this relationship that I’m willing to take all of my premarital assets and throw them in the pot right now? Because if not, I got six months to get divorced.” So if you say to someone, if you got married tomorrow and then you found a company that’s worth $100 million dollars, and under your prenup, that’s your separate property, but there’s a sunset clause that says that your prenup goes out the window in 15 years. Man, at year 14 and six months, you got to ask yourself some serious questions about where’s this relationship going to be in five, 10 years.
Segment 4511: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7977, Text: That’s brilliant. That’s why, kids, you pay for a lawyer. That’s it.
Segment 4512: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7981, Text: We get paid to see around corners. I get paid to be paranoid. I tell people that all the time.
Segment 4513: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=7986, Text: Okay, so you mentioned infidelity, you write in the book, which everybody should get. It’s a great book, it’s a great read, it’s a window into your soul. You, in this book that there’s five kinds of infidelity. Do you remember? Can you explain?
Segment 4514: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8000, Text: Yeah. I mean, what I wanted to say is that all infidelity is not the same, that there’s different kinds and some of them are more obvious than others. There’s the soulmate, that’s the one I think I see most often, which is a person meets another person or rekindles on social media or elsewhere, a reconnection with another person in their life and they go, “Oh my God, this is the person I’m supposed to be with. I’m in love. The heart wants what the heart wants like, I’m leaving you for this person. I have found my true love.” That’s one type and it’s an incredibly common type. And there are plenty of cautionary tales associated with that where people thought that they found their someone, and then it turns out it was no, it was just unfair. And a man who leaves his wife for his mistress just leaves a new job opportunity open.
Segment 4515: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8060, Text: And we should also mention that you talk about Facebook and Instagram.
Segment 4516: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8064, Text: Oh yes. If we were going to invent an infidelity generating machine, it would be called Facebook, which by the way is a function of the fact the book was written in 2019. I would now change it to Instagram.
Segment 4517: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8074, Text: Oh, because you said just Facebook?
Segment 4518: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8076, Text: Yes, but now if I had to rewrite it would be, if we were going to invent an infidelity generating machine, it would be called Meta. That would be what I’d write.
Segment 4519: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8082, Text: There you go.
Segment 4520: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8083, Text: Yeah.
Segment 4521: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8083, Text: Very tech forward.
Segment 4522: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8085, Text: It was a function of what Facebook, and I think Instagram also are, which is, it is a communication tool that has people looking into windows that I think are antagonistic to marriage. You’re looking into the lives of other people, you’re looking into the social lives of people that you meet casually. So there was a time where you would be at your son’s soccer practice and see the attractive mom across the way, and you wouldn’t really talk to her, interact with her. Or if you did, it would just be at practice. But now, we add on social media, those people, because for legitimate reasons, we need to maybe communicate about when practice is, or we want to message the person. But now it’s sort of an invitation to a connection and then it’s, a picture of her on vacation in a bikini. That’s very intriguing. And then you have a benign, “Oh, I saw you guys went on vacation. Where did you stay? Oh, was it good? Did you like that? Oh, that’s nice.”
Segment 4523: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8144, Text: And now we’re talking and now We’re having an interaction. And now this is how the spark of affairs begins. It’s usually, people don’t usually meet and go, “Would you like to potentially wreck your marriage? Yes. Would you? Oh my God, let’s do this.” It’s much more, it slowly happens. So when I talk about types of infidelity, the soulmate, the unexpected soulmate, this connection that you didn’t expect, “I didn’t expect to fall in love with this person, but I did. And the heart wants with the heart wants and I’m sorry.” That one’s tough. That one’s tough, because it’s an interesting distinction between men and women to some degree that when a man finds out his wife was cheating, the question is, “Did you fuck him?” And when a woman finds out that a man cheated, the question is, “Do you love her?” And those are different things.
Segment 4524: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8199, Text: I feel like there could be many and have been many books written on that very distinction.
Segment 4525: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8203, Text: There have, by much smarter people than me. But I think that the soulmate thing is very, very painful for a lot of my female clients. When a man says, “Listen, I found the one. I found the one and it’s not you.” That is really, really hard to get past. And even when it turned out to be true, I mean I’ve seen some people that it was an affair that turned into 20 plus year marriages, an unhappy marriage, and then a happy affair that turned into a very happy marriage. I’ve not seen… There’s not a formula. I’ve been doing it long enough now that I’ve seen permutations I never would’ve expected. So that’s one type of infidelity.
Segment 4526: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8257, Text: The other is what I call the push out of the closet, which is, and that I think happened more often earlier in my career. There have been tremendous strides, I think in the lesbian and gay community, including marriage equality obviously, where there’s a lot of change as to people accepting people as being gay or lesbian. And I think that there was a time where people were being in the closet was much more important. You were subject to professional scorn and all kinds of things if you were gay or lesbian. So people were sneaking around and having affairs with their same sex partners, and then they get caught. And then it really was a function of the fact that they were closeted. And again, that’s another kind of complicated dynamic, because I haven’t had that happen to me where a woman left me for a woman. But I’d like to think it would be easier for me.
Segment 4527: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8319, Text: Yeah.
Segment 4528: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8320, Text: Because if you left me for a man you’re saying, “I want one like you, but better than you.” Whereas if you leave me for a woman, well that’s a whole different set of equipment. I don’t have that. So I can’t… Okay, it’s not me. It’s you. It’s something you want that I can’t offer. We don’t serve that at this restaurant. So it’s okay, I get it. I mean there’s a betrayal, there’s a sadness, whatever, but it’s a different thing. The saddest type of infidelity, in my opinion is the mistake, which is someone just makes a mistake. People do dumb shit when it comes to sex. People just in a moment, they follow temptation. Their impulse control is poor, and they do something that doesn’t reflect their morality, or doesn’t reflect the depth of their feelings.
Segment 4529: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8381, Text: If you spent enough time in a room with people who’ve cheated in a relationship and are speaking candidly to you about it because you’re their lawyer, they’ll say to you very openly like, “No, I really love my wife, I really love my wife. I don’t know. I was just an idiot. I saw this bright shiny object and I went for it. I really wanted to sleep with that woman. I wanted to fuck her. I love my wife, I make love to my wife, I love my wife, but I just want to sleep with this one.” And we created a culture where one of those eradicates the other. That’s a whole nother discussion. Is there ethical non-monogamy? Should we, is marriage about who I have sex with, or is marriage a different kind of a partnership? Is it a pair bond that’s about building a life together, and where does monogamy fit into that? And people like Esther Perel, those are people who are making very intelligent discussions about that.
Segment 4530: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8448, Text: Yeah, that’s a complicated one. Just to actually just linger on that. How often have people with open marriages have been in your office?
Segment 4531: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8457, Text: Well, let’s see, and this is one of those from a research perspective, this would be flawed because I see, they’re in my office because their marriage is falling apart. So there may be lots of people having open relationships that don’t end up in a divorce lawyer’s office, so I’d never meet them. But I meet a lot of people, that that was the Hail Mary pass.
Segment 4532: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8481, Text: Sure.
Segment 4533: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8482, Text: I meet a lot of people that they tried that. But in retrospect it was a Hail Mary pass. It was like, “Look, we’ve just figured let’s try this. Maybe this will this’ll keep the glue together on this thing.” And I’ve also seen open relationships go wrong, where we agree We’re just going to have sexual connections with other people, or we’re going to bring other people into the bedroom. But together, we’re going to be together with other people or with another person. And then that connection of those two people, like you think it’s a soulmate all of a sudden now and it goes in this other, because again, is that novelty, it’s the reason why I don’t understand why people have threesomes. It’s kind of like when someone sings to you, I don’t know where to look. I don’t know where to look. If someone’s singing to me, I don’t know where to look. It feels weird, right? This is a conundrum.
Segment 4534: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8543, Text: Oh yeah.
Segment 4535: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8543, Text: I say this [inaudible 02:22:25] never, but that’s the reason I can’t go to strip clubs, I don’t know where to look. If I go to a strip club, you go to the strip club and there’s the part where the woman’s on the stage and she walks past each person who does a little thing, and then next person and then next little thing. So when she’s right in front of you, I like a woman’s face and I like a woman’s body. I like both of them. So I’m looking at the woman’s face and she’s very beautiful, but she’s naked and I think, “Oh, she’s naked. I should be looking at her naked body,” because obviously it’s almost rude not to because she’s naked in front of me, of course. So then I’m looking at her naked body, which is lovely to look at. But then I find myself going, “Oh my God, you’re just still, you should look at her face for God’s sakes.”
Segment 4536: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8586, Text: Then I look at your face and find myself having this whole thing in my head where I’m going like, “Oh my God, where am I supposed to look?” So I think a threesome with two women you don’t hardly know or you’re not with, that’s different. But a threesome with a long-term partner who you’re in a relationship with, and a new person, seems to me a very dangerous ground because you’re going to want to enjoy the novelty of this new person, but you’re going to have to spend time with this person after. So how much attention do you spend to the new novel exciting thing without creating the impression that you’re not interested in this? Because you’re my favorite person, but this is fun. So I want to just try this for a few. But then also I don’t want to forget about that. It just seems tricky.
Segment 4537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8639, Text: That analogy, by the way is brilliant. And also I guess it’s tricky because the consequences of mistakes are quite high. You’re going to have to talk about it.
Segment 4538: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8648, Text: Yeah, and there’s an easy way to misinterpret the data. So if I really like sleeping with my partner, but I get one chance to sleep with this other person, well of course I should indulge in that, because I can do this anytime. But this person, my partner might interpret that as, ” Oh, so you’re more interested in her than me,” because that voice in my partner that would be insecure might hear that. So why would you even open yourself up to that level of chaos?
Segment 4539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8682, Text: You seem to love chess in the courtroom. It’s a kind of intimate human chess, of sorts.
Segment 4540: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8688, Text: Yeah, no. That’s too high risk.
Segment 4541: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8690, Text: How did we get on threesomes? Oh, open marriages.
Segment 4542: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8693, Text: Well, how did we get on threesomes? I don’t know. I always wonder how people get on threesomes. I figure if one is fun, two must be better. If two is better, three must be better. Yeah, I think the way that this becomes an issue is, why would you have a non-monogamous relationship? What is it about your sex life with this person that’s not satisfying? And I think that that is the question that’s harder to ask yourself and to try to answer with your partner.
Segment 4543: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8723, Text: I mean, you’ve said that this idea of soulmates.
Segment 4544: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8725, Text: It’s great business.
Segment 4545: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8727, Text: It’s great for your business, but so a human being in a partnership can’t be everything. Is that true?
Segment 4546: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8737, Text: I think it’s unrealistic.
Segment 4547: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8738, Text: True Romance, right? The document that we keep referencing here.
Segment 4548: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8745, Text: I think it’s wonderful that we do sometimes now, people don’t get that reference anymore. I talk to people when I try to teach negotiation to young lawyers who come work for me, I tell them to watch the Gary Oldman scene where he offers them the Chinese food.
Segment 4549: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8761, Text: Yeah. Why is that scene the one that really?
Segment 4550: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8764, Text: Because it’s the best negotiating lesson I’ve ever heard in my life, where he comes in.
Segment 4551: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8770, Text: Just for the record.
Segment 4552: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8772, Text: Yeah. Gary Oldman plays a pimp and he owns, his girl is Patricia Arquette, right? And Christian Slater’s character, the protagonist is coming in to tell Gary Oldman that he no longer owns this girl, Alabama.
Segment 4553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8789, Text: Alabama.
Segment 4554: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8789, Text: Alabama is going to be with him now. And Gary Oldman is an amazing performance. And he’s sitting in a living room with a shotgun next to him, with armed guys around him watching television and eating Chinese food. And he’s got Chinese food laid out in front of him. And Christian Slater comes in and he says, “I need to talk to you about Alabama.” And Gary Oldman says, “Do you want some Chinese food?” And Christian Slater sort of taken aback by the question. He says, “No, I came to talk about Alabama. She’s with me now.” And he proceeds to tell him what his offer essentially is. And Gary Oldman says, “You know, you fucked up, right?”
Segment 4555: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8833, Text: In substance he says, “If you’d sat down and started eating my Chinese food, I would’ve thought who’s this guy, he didn’t have a care in the world, just sitting down eating my egg foo young. But instead you tried to be hard. And now I know you’re full of shit.” And so I think that scene summarizes how in negotiation, the more you enter into it with that, anytime I deal with another lawyer and they’re like, “Well, we’ll see you in court.” Okay, see you in court. Empty barrels make the most noise. You and I as people, who’ve been in the jiu-jitsu community, I know some dangerous people. I know FBI SWAT people. I know people that, they know how to do things to people. And they’re the calmest guys you ever meet in your life. You scuff their sneaker? “Oh yeah, don’t worry about man, it’s okay.” They’re quick to apology. They’re just chill.
Segment 4556: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8892, Text: What were we talking about?
Segment 4557: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8893, Text: We were talking about…
Segment 4558: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8895, Text: Oh wait, True Romance. Oh, the soulmate.
Segment 4559: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8899, Text: Yeah, soulmate. Yeah. Well, you’re saying that this idea that film underlying, there’s this current of they were made for each other. I think there’s a distinction between the feeling that someone is your missing puzzle piece, that you’re made for this person. I think what that just means is there’s a lot of overlapping beautiful connections. I love them intellectually. I love them sexually, I love them interpersonally. We have some shared history, we have some shared commonalities. We were raised in the same culture, raised in the same religion. We view, we have politically similar ideas. These are all, or we have totally opposite ones, but they’re complimentary. I’ve always joked that finding someone with complimentary pathologies, I’m obsessively disciplined. So having a partner who’s flexible and spontaneous is really good for me.
Segment 4560: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8952, Text: And also me being like, “No, no, no, come on, come back. We’re going to do this now. It’s time to actually do this now.” We’re good for each other. It’s barefoot in the park. It’s this idea of the yin and the yang. So, what I have an issue with is that the definition of soulmate that I think is sold to so many people now is this idea that if your partner is disappointing to you in any way, meaning they’re not the perfect travel companion, they’re not the perfect vocabulary companion, they’re not the perfect roommate, they’re not the perfect lover, they’re not… The odds of someone being all of those seems crazy to me. It’s infinitesimally small, and they don’t have to be everything.
Segment 4561: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=8998, Text: If I go to a restaurant and eat 10 courses, and one of them is kind of subpar and the other nine are the most amazing culinary experience I’ve ever had, how dare I say, “Well, that wasn’t the right restaurant.” What do you mean? That’s a great restaurant. What are you talking about? Of course there was one little thing. So I think it’s impossible to have someone never disappoint you. It’s impossible to have someone who never lets you down or doesn’t say and do the exact right thing at the exact right time, and to create the idea or expectation in anyone that your partner should never let you down, never disappoint you, never not know what to say is, I think crazy.
Segment 4562: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9042, Text: I find for myself, when someone, for example, loses someone, when someone loses a family member or a pet, I often say the same thing to the person. I’ll either talk to them or send them a text or call them and I’ll say, “I wish I knew the perfect thing to say, because I would say it right now.” But I know there isn’t, I don’t say that part. But I know there isn’t, there isn’t a perfect thing to say. But if there was a perfect thing to say, I would say it right now. Love to me is not that you never let this person down, it’s that you never want to let this person down. Love is a verb.
Segment 4563: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9081, Text: It’s this feeling of, I never want to disappoint you. I will disappoint you, but I never want to disappoint you. I will hurt you, but I never want to hurt you. When I hurt you, it will be my insecurity, my stupidity, my humanity that causes me to hurt you. But I will never intentionally hurt you. I will betray your trust. I’ll never intentionally betray your trust. I will, by my stupidity, say the wrong thing, or loose lip say something to someone that you didn’t want me to, but it won’t be intentional. I’ll always try to be on your team. That feels to me like a realistic thing.
Segment 4564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9120, Text: Yeah, the intention leads the way, but there’s some aspect of, just like the 10 course meal that over time there’s a kind of convergence towards perfection. And along the way, there’s the rose colored glasses where you see the beauty and everything. So it feels, it’s probably destructive just to really internalize the idea of soulmate. Because then any imperfections can make you doubt, can make you step away, can make you lose the connection. But it just feels like, I don’t know.
Segment 4565: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9157, Text: It’s too heavy. It just feels, I feel like when you see a couple that’s 90 years old and they’ve been together for 60 years, 70 years, there was of course a temptation to think about all the beauty that they’ve seen on that journey together. The children, the grandchildren, maybe the great-grandchildren, all the joy that they’ve seen, all the pain they’ve endured and struggled together. But they’ve also disappointed each other a whole bunch of times. Probably let each other down. They probably lied to each other a bunch. And to me, that is a beautiful thing. That is not, it’s great in spite of that. It’s great because of that, they still love each other even though they’ve been so flawed and imperfect, and they’re human and they still love each other, they still rode that thing together, because the reasons to do so were greater than the reasons to not.
Segment 4566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9218, Text: We’ve mentioned some of this, but I’d love to get your opinion on having seen things gone wrong, and having mentioned Amber Heard and Johnny Depp. How much fighting do you think is okay in a relationship, and how to resolve the fights such that they don’t escalate to that disconnection? Is there some wisdom you have for that? I imagine you’ve seen some epic fights.
Segment 4567: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9245, Text: Yeah, I’ve seen some crazy fights. Even on my phone, I have some recordings, because now there’s cameras everywhere. It’s like Nest cams and Ring cams. And so a lot of this gets recorded, and people have phones so readily available that they can record and the other person didn’t know it. And I listen to the way people speak to their… First of all, I listen to the way people speak to each other and I’m shocked. I listen to the way people speak to their romantic partner, to their spouse, and I’m blown away. I’m blown away.
Segment 4568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9278, Text: Disrespect or what?
Segment 4569: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9279, Text: Just disrespect, insults, profanity, just degradation, just brutality. And then, to then kind of go on the next day you kind of go on like nothing happened. I’m shocked by it. I mean, I listened to it and I think, if someone ever spoke to me that way, I don’t know that I could ever really feel deep connection to them freely. I would feel so betrayed that they’re just so brutal. I can’t imagine speaking to someone that way, saying you just such vicious insults to someone. But I understand that’s how some people communicate, perhaps. I guess the question of, how much fighting is too much fighting in the relationship is for me a bit like the question, how much sex is enough sex in the relationship?
Segment 4570: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9337, Text: It depends on the two people and their individual tastes. But what’s problematic is when there is a disconnect between the two people. I think it’s Annie Hall, it’s one of the Woody Allen films where Diane Keaton and Woody Allen are both talking to their respective therapists about the relationship, but it’s like a split screen. And she says, “I mean, we have sex all the time, we have sex like once a week.” And he goes, “We never have sex. We have sex like once a week.” And it’s funny because it’s true, it really is this, they both know the same data. But they’re interpreting that data set completely differently. And I think the question you have to start asking is, Steve Harvey actually once said something funny to me. He said that success is not where you are. Success is where you are in relation to where you started.
Segment 4571: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9402, Text: He says if success is where you are, Oprah’s got us all beat. Or maybe Elon’s got us all beat, I don’t know. But if it’s where you are versus where you started, because there’s a lot of people that started on second, and started on third, act like they hit a double. “Well, I was given 10 million but then I turned it into 100 million.” Well, the first million’s the hardest, so come on. But I think the question of how much sex were we having at the beginning of the relationship, that might be the wrong gauge. Because that’s like, we couldn’t keep our hands off each other and just, it’s novelty.
Segment 4572: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9435, Text: But, how much sex we’re having post children versus before the children, that might be worth looking at. How do we compare it? Am I overweight? Compared to what, when I was 20 and running marathons, or most 50-year-old men? I don’t know. What do you compare it to? So I think fighting, there are some people that I think they enjoy fighting, they enjoy argument. I know people that enjoy political debate. I don’t particularly enjoy political debate. Not that I’m not very interested in political concepts, economic concepts, I just argue for a living. So in my free time I don’t find argument that enjoyable when it’s intense, I find discussion more interesting.
Segment 4573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9484, Text: That’s so interesting, that you just keep the battle to that particular, to your main profession.
Segment 4574: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9491, Text: Sure.
Segment 4575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9491, Text: And everywhere else you want peace.
Segment 4576: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9492, Text: Well, did you ever Bobcat Goldthwait, the comedian?
Segment 4577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9496, Text: Yeah.
Segment 4578: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9496, Text: Very, very funny. And he had a whole second chapter as a director and a writer. But he has this, I saw an interview with him once where he said, “Yeah, I’m a comedian. I’ve been a comedian in a long time. People always come up to me and they’re like, oh, you’re a comedian. Do you want to hear a joke?” He’s like, ” Oh yeah, that’d be a real fucking treat. I haven’t heard jokes all day, all night for years. That would be a real special occasion.” Yes, I get it.
Segment 4579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9519, Text: Yeah. And I mean, a sadder story. I’ve been reading quite a bit about Robin Williams, and his wife would talk about how quiet and introspective, and thoughtful and intellectual he was, and not really that humorous in his private life.
Segment 4580: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9534, Text: But that may be a function of that it is enjoyable to be the other thing. One of the things I’ve always thought was very funny in relationships. My own relationships is, most women I know who have a husband who doesn’t wear a suit every day for a living. When their husband gets dressed up, they’re going to a wedding or something, they get like, “Oh my God, look at him.” And I wear a suit every day. On the weekends I don’t, I wear jeans and a black T-shirt. But the rest of the time I wear a suit. And I remember, I think this has been true in every relationship I’ve been in since I was a lawyer, including Mike’s wife. It was always like if I had on jeans and I wasn’t shaven, it was like, “Look at you.” It’s like, are you kidding me? Really? Whereas the suit, they wouldn’t even notice. Wouldn’t notice the suit.
Segment 4581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9595, Text: Sometimes the other thing.
Segment 4582: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9596, Text: Well, that’s what it is, it’s the novelty of the other thing. So I think that if you’re Robin Williams and You’re being shot out of a canon in terms of your performative style, and your energy and explosive, being quiet must be very refreshing. I imagine incredibly intelligent people must love just watching stupid humor, or having a dumb thing. It’s why some of the smartest people I know like really dumb shit. It’s why Rick and Morty, I think is brilliant because it’s both smart and dumb.
Segment 4583: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9627, Text: Yeah. It’s the perfect combination.
Segment 4584: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9628, Text: It really is. Yeah, I think it’s possibly the perfect show.
Segment 4585: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9633, Text: Is there advice you can give to somebody like me on how to interview well? How to do conversations well? Do you think there’s something transferable from the courtroom to this setting with complicated people?
Segment 4586: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9649, Text: Yeah, I think so. I think what can be learned about interviewing is the distillation. What is most important? When I hear a story that I have to present to a judge, the totality of someone’s parenting, the good of their parenting, the bad of their parenting, the good of the other parent, the bad of the other parent. I have to sort of boil down, what are the best examples? Because I can’t lay it all out. And then what greater principle do they speak to? The best jiu-jitsu teacher that I think I’ve had is Paul Shriner, and Paul doesn’t just teach you techniques, he’s teaching you ways of thinking about concepts in jiu-jitsu. And then, here are some techniques that illustrate that. John Danaher, from what I can see, does a lot of that as well. I think they’re like soulmates in the jiu-jitsu world.
Segment 4587: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9707, Text: Yeah, and then there’s that element that you spoke to, which is maybe considering the other side.
Segment 4588: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9715, Text: Always.
Segment 4589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9716, Text: Devil’s advocate kind of thing.
Segment 4590: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9718, Text: Yeah, I mean straw man, steel man stuff. You do a lot of that, and I think all the best interviewers do. But yeah, I think it’s really, really important to think about. I have to know the other side’s case much better than my own. I have to know, what are their defenses, what are their strengths? I have to map out a strategy that keeps those in mind, and that’s hard because early in my career I would attribute to the other side and intelligence and strategy that sometimes wasn’t applicable. I’ve learned there’s the simplest explanation is the accurate one, the Occam’s Razor. I think Sexton’s would be, never attribute to strategy that which could be attributed to stupidity or laziness.
Segment 4591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9771, Text: Yeah.
Segment 4592: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9772, Text: Because I have lots of adversaries that they’ll not file a motion I thought they were going to file and I’ll go, “Wait, why didn’t they file that tactically? What are they thinking I’m going to do? And what is that about?” And I would go, “Well, if I didn’t file it, why wouldn’t I file?” And the answer is they just didn’t think to file it, or they were too lazy to draft it or they went on vacation last week. So why they didn’t, and I’m driving myself crazy going, “There’s some tactical read, there must be.” So I think you have to look honestly and don’t attribute to the other side, your constitution. If I said that, I’d be saying it sarcastically. If you said it, maybe you weren’t saying it sarcastically. You have to think about the fact that we’re unique human beings who express themselves differently.
Segment 4593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9818, Text: And for you, the audience is usually the judge. Do you do jury?
Segment 4594: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9819, Text: Yeah. It’s the judge. No, we don’t do jury trials. That’s the interesting thing about family law attorneys, family law attorneys don’t do jury trials. We do bench trials. We just persuade, there’s a person in a black robe. That’s the only person I have to convince.
Segment 4595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9831, Text: Does the person in the black robe, do they have emotions? Are they human, or are they very…
Segment 4596: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9835, Text: They are human. They are all too human.
Segment 4597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9837, Text: Do they impose that humanity on you? Do you feel it?
Segment 4598: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9840, Text: Oh, yeah. Do you feel it? They’re human. They’re working their shit out.
Segment 4599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9848, Text: Okay.
Segment 4600: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9849, Text: They’re parents. They’re husbands and wives, and you’re talking about stuff they deal with. I had a woman on the stand, an expert witness on the stand who was talking about the emotional and physical abuse that was perpetrated on a seven-year-old, and this person had written a bunch of reports that were in evidence in this trial. Around day six or seven of the trial, and there’s all of this information in the record about this verbal abuse and mental abuse, and gaslighting and really intense stuff that this woman was doing to this seven year old. And the judge was vaguely paying attention for most of the time. And at some point the person says, ” Well, when a parent is abusing a child,” and the judge just interrupts, she goes, “Well, look…”
Segment 4601: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9900, Text: Well, when a parent is abusing a child and the judge just interrupts, she goes, “Well, look, do you think if a person spanks a child that that’s abuse?” She’s like, “Well, like a person in general?” By the way, if my adversary asks that question, I could object, but I can’t object when the judge asks a question. They get to rule on that objection. So I’m like, “Where is this going?” She’s like, “Well, no, I mean, spanking can be a form of abuse.” She’s like, “Right. But are you saying everybody who spanks…” I’m sitting here going, “What is going on in your house?”
Segment 4602: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9930, Text: Yeah, [inaudible 02:45:32].
Segment 4603: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9931, Text: What went on with your parents? Because you’re bringing some stuff here, this is not what you’re supposed to be. This is not your role. But there are good judges and bad judges and that’s a big, big deal.
Segment 4604: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9948, Text: I don’t have kids, so I have a certain perspective on the world. I really want to have a family and have kids. But I’ve noticed when I talk to people that have kids and gender matters also, fathers with daughters and so on, it changes the landscape of the conversation.
Segment 4605: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9971, Text: Sure does.
Segment 4606: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9972, Text: It’s like you’re no longer this intellectual that’s like, “Well, there’s this and there’s this.” It’s more like, “Go fuck yourself. Anything that with kids can burn it to the ground. I don’t care what the nuance is, if the little intellectual thing-
Segment 4607: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=9994, Text: Oh, you want to learn about this, represent someone who’s accused of child sexual abuse. I’ve had about a dozen of those cases, where I’ve represented someone who’s alleged to have perpetrated sexual abuse of a child. You are guilty until proven innocent. Let me tell you, as a lawyer, that is the toughest cases because you put sex and kids together and everyone loses their goddamn mind immediately. There’s a rush to judgment. There is a disregard for procedure. There is a confirmation bias. There’s a desire to be a protector. Again, all motivated and informed by really good things, the desire to protect the innocent, the desire to protect the vulnerable, but gang, no, we have these… I like living in a world that has due process. I like these rules. I like the rules of evidence. I like innocent until proven guilty. I like that. I’m not saying it’s perfect, but-
Segment 4608: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10058, Text: I’m so torn on it because I also like living in a world where people are so emotionally invested in connection to other humans.
Segment 4609: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10071, Text: Those two things aren’t mutually exclusive. They shouldn’t be.
Segment 4610: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10073, Text: I know, but if you dedicate yourself fully to the law, you might lose some of the humanity.
Segment 4611: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10079, Text: I don’t think you have to. I have to tell you, I once actually went off on a DA, on a district attorney who was very vehemently prosecuting a child sex abuse case that I was involved in. Thankfully, I came in very early in the case. So the accusation was made and I came in right away because very often you get this case there’ve been 15 interviews. This person’s been interviewed by police, by child protective services and it’s like they’re already so far down a hole they didn’t even know they dug themselves into. So I got in very early on and I just kept saying… She’s like, “Well, we’re going to do this. We’re going to do this.” I was like, “Wait, wait, wait, wait, wait, wait. We should both want this to be fair, done properly.”
Segment 4612: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10130, Text: There’s an expert, a well-respected expert who’s a clinical psychologist who their job is they’re a validation expert. So their job is to interview a child. They record the interviews with a hidden camera so that everyone can see they didn’t ask suggestive questioning. There are very stringent standards that they follow to prevent suggestive questioning or any of those kinds of things. I was saying, “Listen, no, no one should be interviewing this child other than this person, who’s a neutral qualified person.” I kept saying to the other side like, “Wait, no, no. See, this is the problem, you want to win. You’re a lawyer, you want to win. I want to win too, right? But we want to win fair.” That’s like saying, “I’m going into a boxing match, I want to win. So if the referee’s looking to the side, I’m going to kick the guy in the nuts.” Okay. Then you might’ve won, but you didn’t win boxing. You won some other thing.
Segment 4613: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10185, Text: I want to win a fair fight. I want to go in with the rules set, the law, the rules of evidence. I don’t want a judge who doesn’t understand evidence. I don’t want an adversary who plays it fast and loose with the rules. I want to go in and win a fair fight. That’s where when it comes our passion to protect the innocent, to emotionally connect, to feel deeply about children and protecting them, I don’t think that that’s antagonistic to… We always treat dandruff with decapitation in this culture and I don’t understand it and that’s what I like about the law. The law, there’s rules and there’s rules about procedure. And so, that’s our job is to bring out the truth using the rules and the procedure. I love that job.
Segment 4614: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10232, Text: But still there’s a human being in the judge, right?
Segment 4615: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10236, Text: That’s the problem.
Segment 4616: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10237, Text: It seems like a really hard job-
Segment 4617: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10239, Text: It’s a hard job. Yeah.
Segment 4618: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10240, Text: … because you have to be pay attention to the whole thing.
Segment 4619: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10242, Text: You have to pay attention to the whole thing and everyone is trying to persuade you and lie to you and everyone can keep their shit together in a court appearance most of the time. It takes a rare kind of crazy to blow up in a courtroom. So most of the time everybody looks really put together. Yeah, you got to have an amazing bullshit detector. I’m not saying they don’t have a really hard job. They have a really hard job. They have a way harder job than I have.
Segment 4620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10266, Text: What’s their source of ground truth? How do they sharpen the radar for bullshit?
Segment 4621: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10272, Text: I think that they’re assessing credibility, which is what you call it in the law, is something that I think you’re supposed to develop it on the job.
Segment 4622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10283, Text: Do you have the data of who was lying in the end or not?
Segment 4623: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10285, Text: No, not really. Not really. I mean, you can try to demonstrate. What I always tell clients, and this is the art of advocacy is I want to use examples of misrepresentations to show that this person’s a liar. I’m trying to extrapolate from the small, the large. I’m trying to say, “Here’s three times he lied, therefore he’s a liar,” when in fact we know human beings don’t really work that way, but I’ve seen people submarine, they just torpedo their entire case because they lied about some dumb shit, some dumb little thing. I say to them, “Why would you lie? Why did you lie about that?”
Segment 4624: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10334, Text: I had a case where a person was accused of child sexual abuse. On cross-examination, they were asked, “Did you have an affair with this babysitter?” They were like, “No, no, no, no, no.” And then it was shown through text messages and things, they clearly had an affair with the babysitter. I said, “Why did you lie?” They said, “Well, I didn’t want that to come out.” I said, “Right, but now you’re a liar. Did you molest your child? Because if the answer to that is no and now you destroyed your credibility because you didn’t want to admit that you slept with an adult woman. By the way, it would’ve been good for your case.” “What do you mean good for your case?” For you to say, “Yeah, I slept with her. I like sleeping with adult women. That’s how I am. I don’t sleep with children, much less my own.” So why would you lie?
Segment 4625: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10382, Text: And so, that concept is incredibly important. Judges, theoretically, they have to make very tough calls. I feel like It’s the most impotent place to just sit there and dispassionately listen and rule on objections. I just would be so frustrated because I’d want to get up and… I had to do jury duty once and it was like a horrific experience for me because I’m sitting there and-
Segment 4626: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10407, Text: You have no power. You’re just [inaudible 02:53:29].
Segment 4627: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10409, Text: Yeah, I’m just watching these two guys. I’m like, “Why did you ask that question that way? I would never have asked it that way. Why would you object? When you object, you bring more attention to it. What are you doing?” I’m watching both of them. It’s like watching a jiu-jitsu. Probably what it feel like for John Danaher to watch two white belts spar. “Why are you doing… Wow, my God, what are you doing? Why would you grab that? What are you thinking?” It’s frustrating. It’s frustrating to watch and as a judge, it must just be unbelievable.
Segment 4628: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10436, Text: So divorce lawyers sometimes get a bad rep. Is there a reason for this?
Segment 4629: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10442, Text: I mean, no one’s ever happy to be spending time with a divorce lawyer. If you have a criminal lawyer, they’re defending you against the maelstrom of injustice and false allegations. They’re protecting your freedom. Maybe you’re acquitted and then you’re like, “Oh, that person saved me.” You buy a house, that lawyer helps you get the house. You’re happy about that, sign the paperwork. You do a will, you help. They make you feel secure. At best, I’m a representative of a chapter in someone’s life that was very unpleasant.
Segment 4630: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10475, Text: I have a friend who’s a Julliard-trained classical pianist. He was having a humidification system installed in his home because his piano required a certain level of humidity and it was very expensive to install this humidification system. We went out to dinner and then we came back to his place and he said, “Man, this is the most depressing $15,000 I’ve ever spent.” I said, “Why?” He said, ” Because there’s nothing different. I spent $15,000 and I feel absolutely nothing different. My piano does, but I don’t.” You don’t have anything to show for it. You finished getting divorced, you don’t really have anything to show for it.
Segment 4631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10514, Text: At best it’s the same.
Segment 4632: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10517, Text: It’s one of the things I think that’s interesting about divorce is in our increasingly performative society, you can’t pretend you meant to get divorced. You can’t, like everything everybody does. “Well, I wrote that album for me. It didn’t matter that it was not going to be popular.” No, you wanted that album to be popular. Come on, you’re lying and that’s fine, but you’re lying. “Oh, I think my haircut came out great. I wanted it to look this fucked up.” No, you didn’t. You didn’t. You’re lying and that’s fine because we live in a society now where everybody’s just, “Oh yes, I meant to do that.” Okay.
Segment 4633: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10546, Text: Divorce? Nope, you got married. You break up in a relationship, not a marriage. “Okay. Well, we were only going to be together for a little while. It was never serious. We were having fun. That’s all it was. We were never going to be a happily believer after.” No, you got married. You got married guys. You got up there and you said forever and it didn’t go forever so you can’t bullshit anybody anymore. No, it didn’t go the way you thought it was going to go, didn’t go the way you signed on for. So now that that’s undeniable, what can we make it? What can we make it into? It can be beauty. The barns burned down, now I can see the moon. Let’s make it something. And so, for me, I think people look at a divorce lawyer and they just go, “Yeah, this is this horrible chapter and I associate you with it.”
Segment 4634: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10597, Text: Also, too, listen, some of the things we do, it’s difficult to simultaneously prevent and prepare for war. The things you do to protect your clients sometimes look like acts of aggression, but really they’re just trying to shore up a defense. And so, I get paid to be paranoid and I have to say to clients sometimes like, “Well, are you sure that they’re not doing this?” And then they go, “Well. I don’t know.” I go, “Well, let me inquire.” “Did you accuse me of that?” “No, no. I’m not accusing you. I’m just trying…” We get a reputation, divorce lawyers, as amping up conflict because we get paid for the conflict, right? It’s like if you get paid by the bullet, you’re going to start a lot of gunfights, right? It doesn’t really work that way with most good divorce lawyers. There are plenty of people that are bad lawyers and they stoke up conflict because it jacks up fees. They usually don’t do well. They don’t build a successful career because you live and die by your reputation.
Segment 4635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10658, Text: Yes, reputation is everything.
Segment 4636: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10660, Text: But good lawyers, like good experienced divorce lawyers, we do the whole, “Hey, listen, you’re going to say this, I’m going to say this. You’re going to do this, I’m going to do this. Let’s skip it. We’re going to end up here. We got Judge blah blah blah and you know what he’s going to do. He’s going to go right here. So why don’t we just agree right now to X, Y, Z? Sounds good. We’re done. We’re good.”
Segment 4637: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10681, Text: So you want to minimize the number of bullets.
Segment 4638: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10683, Text: It’s like Miyamoto Musashi. It’s like the two swordsmen who see each other and they just stand there at the edge and they see the whole fight in their minds and they know who won and who lost and they walk away. We do a lot of that. Okay. It’s like when you watch high level chess and someone resigns and you go, wait, “What happened?” You go, “No, no, the other guy won. It’s 15 moves from now, but he won and the other guy sees it, so now we’re done.”
Segment 4639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10714, Text: Can you speak to some recent high profile divorces? The most recent I saw is Kevin Costner.
Segment 4640: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10722, Text: Yeah, Kevin Costner is a great… I mean, I don’t know him. I’m not involved in the case.
Segment 4641: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10726, Text: By the way, Yellowstone is just so great.
Segment 4642: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10727, Text: Oh, it’s so good, right?
Segment 4643: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10728, Text: And I hope Matthew McConaughey, who I’ve gotten to know, I hope he does one of these shows. Yellowstone or anything else, he’s just-
Segment 4644: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10736, Text: Born for the role frankly.
Segment 4645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10738, Text: But anyway.
Segment 4646: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10738, Text: He’d be amazing in that. Yeah, your conversation with him was a great one. The Kevin Costner divorce is interesting because Kevin Costner had one of the most expensive from a distributive award perspective. He gave a huge payout to his first wife and then this time he had a prenup. It’s a very public showing of the fact that once bitten twice shy. He had a very public divorce that cost him a lot of assets in terms of the division of assets, and now it appears by all acknowledged reports that he had a prenuptial agreement that was well-crafted and enforceable. The argument now is over. What is child support? What is spousal support? What’s covered in the prenup and what isn’t?
Segment 4647: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10787, Text: So it seems like the prenup worked actually.
Segment 4648: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10789, Text: The prenup worked. Kevin Costner’s career, which has always been a steady career, I don’t know that in the Hollywood stock market that people would’ve bet on Yellowstone. I think you would’ve said, “Hey, the best years of that guy’s career are behind him.” How do you get better than Dances with Wolves and Robin Hood and all these big, big… The Bodyguard and then Yellowstone. It’s like, “Holy cow, did he knock that out of the park?” And he’s central to it? I mean, he knocked the skin off the ball. So I think that’s why prenups are important. You don’t know what your career’s going to do. You don’t know where it’s going to go. And so, he saved himself a lot of money. He also has a great lawyer. He has Laura Wasser. Laura Wasser’s L.A… Just a top professional, brilliant lawyer, even tempered but intense in the courtroom and just a smart, smart human being.
Segment 4649: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10844, Text: The thing I liked, just I haven’t been following it, but I saw a few comments he’s made and he refused to comment negatively about his spouse and just-
Segment 4650: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10855, Text: That’s smart.
Segment 4651: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10856, Text: But the way he said it, it wasn’t lawyer advice. It’s good lawyer advice probably, but he said it from the heart, which I always like. I like seeing that, where he refuses even the drama, even the public nature of it to throwing jabs or-
Segment 4652: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10875, Text: Well, Laura, his lawyer, is actually notorious for not speaking to the press about cases in an extended way and that’s smart move. I don’t speak about pending cases I’m involved in publicly and I discourage my clients from doing so. I can’t always stop them, but I discourage them from doing so. I don’t think there’s any good to come of it. There are lawyers who try to try things in the court of public opinion. To take it to the broader principle you just brought up, I think there is a lot of value in talking about your ex in a favorable way.
Segment 4653: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10910, Text: I have to say when I first got divorced many years ago, I went out on a date with a young woman. It was one of my first dates as a divorced man. She was a divorced woman. She’s a beautiful woman. We were having dinner and it was going quite well. It was one of those things where I was like, “Oh, I definitely want to see this girl again.” I said something about, “Oh, there’s going to be this thing at this museum. We should go.” She’s like, “Oh yeah, that’d be a lot of fun.” I’m like, “Yeah, we should, definitely. Maybe that’ll be next thing we do together.” She was like, “Yeah, we should go next weekend. The kids are with the asshole so we can go.” It was like you could hear that record scratch. I just went, “Oh yeah. No, this isn’t good. You’re referring to the father of your kids as the asshole? I’m walking into something here that I don’t know that I want to be involved in.”
Segment 4654: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=10958, Text: Matthew McConaughey, before he was married, if you look at his history, he dated some of the most beautiful women in Hollywood in their prime, and none of them ever talked bad about him in the press. They all were like, ” Oh my god, he’s such a great guy. He’s such a great guy.” I always wondered how do you… He got out of all of those relationships without a scratch on him. When you’d watch an interview with him, they would say, “So you dated Penelope Cruz,” and he’d go, “Penelope, that’s just a special lady. What a special lady. She’s just a wonderful… What a wonderful woman. I’m just so blessed to have the time with her. What a beautiful, wonderful woman.”
Segment 4655: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11012, Text: I would think to myself, I’m like, “You’re a genius.” He’s a genius because he never came off as petty, spiteful, bitter, any of that. He just came off as just dignified, strong, smart, self-assured. It left the viewer with the impression that when he was looking off and basically he’s probably just thinking about some wonderful time he had with her and you think to yourself like, “God, that guy. He just became cooler and cooler.” Whereas if he got into the whole, “Oh yeah, that was ugly and then this happened,” nobody wants to hear it. It’s awful.
Segment 4656: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11052, Text: The funny thing about him just having interacted with him a bunch, I don’t think… He’s in the Rogan school of thought, I think, that I don’t see him ever having a fight. Now his parents were, as he’s spoken about a bunch, nonstop fighting. They got divorced and remarried and just insane.
Segment 4657: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11070, Text: And they were volatile.
Segment 4658: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11071, Text: Yeah, very. It depend on swinging the other way. He just seems cool as a cucumber always.
Segment 4659: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11079, Text: Just lets it roll off. But even if It’s internally not rolling off, there is value in just rising above it in your discourse.
Segment 4660: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11094, Text: That’s true. Yes. Yes.
Segment 4661: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11097, Text: You lie to your children. People say this to me all the time. Clients, they’re like, “Why did you tell your child that dad had an affair?” “Well, I’m not going to lie to my kids.” Fuck you. Yes, you are. You lie to your kids all the time. “Mommy, are you going to die someday?” “Yes, babe, I’m going to die and Daddy’s going to die. And then someday the earth’s going to hurl into the sun. We’re all going to die. Sweet dreams.” You lie to your kids all the time. “What’s wrong with me?” “We don’t know What’s wrong with you. We’re going to take you to the doctor and hopefully it’s nothing serious and you won’t die.” You lie to your kids all the time. You tell them that Santa Claus exists when he doesn’t, whatever.
Segment 4662: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11131, Text: So to say, “I’m not going to lie to my kids,” you lie to your kids all the time. You don’t like your husband, that’s okay. You don’t like your ex-husband, but it’s their father so just grin. “Oh, Daddy took me to meet his new girlfriend, Kiki.” “Oh, that’s nice. Did you guys have a good time?” “Good. Oh yeah. And she helped me do my hair and she did my makeup.” Listen, I’m sure that’s burning you inside, but you go, “Oh, that’s great,” because why? You love your kids.
Segment 4663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11156, Text: Well, I mean, again, McConaughey has a way bottom with that. He basically says, “Never lie, but a little bullshit is okay.”
Segment 4664: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11164, Text: Sure. Yeah.
Segment 4665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11168, Text: Tom Waits, that song Lied To Me, “You got to lie to me baby.” Honesty is a funny thing.
Segment 4666: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11176, Text: Tom Waits also believes that God’s away on business.
Segment 4667: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11178, Text: I think his words, man-
Segment 4668: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11181, Text: “Who are the ones that we left in charge? Killers, thieves and lawyers,” that’s a Tom Waits quote.
Segment 4669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11187, Text: Well, it must be true then.
Segment 4670: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11188, Text: Yeah.
Segment 4671: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11189, Text: I don’t know how many limbs I have, but I will give all of them to talk to Tom. He’s a very private person.
Segment 4672: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11198, Text: I feel like he’s the musical equivalent of Cormac McCarthy. Even if you get the interview, you’re not, I don’t think, going to get in there.
Segment 4673: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11206, Text: Honestly, I don’t think you want to. You’ve seen his public interviews over the years with Letterman and I think he is the poetry.
Segment 4674: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11217, Text: I would put Tom Waits, Cormac McCarthy, Maynard James Keenan, these are artists that I think they want the art to speak for itself. They would like to be lessened. I remember early, early days of Tool that he could not have been less interested in the spotlight to the point where I think it was almost to the detriment of the band early on. There’s no surprise that those are three artists that I think are unbelievable and in a category of their own and that you hear their performance. You can give me a page of a Cormac McCarthy novel and I’ll know it’s a Cormac McCarthy novel. A few notes of Maynard James Keenan or Tom Wait’s voice, you know that that’s them.
Segment 4675: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11274, Text: Yes, genius. Genius hides from the spotlight, but it doesn’t stop me from feeling sad about it, but anyway.
Segment 4676: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11281, Text: Yeah, that does. I would like to hear that interview/
Segment 4677: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11283, Text: She’s the girl that got away.
Segment 4678: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11284, Text: Yeah. Yeah.
Segment 4679: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11286, Text: I’m just standing outside of that girl’s house with a blue box.
Segment 4680: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11289, Text: With a sign. Yeah, just playing In Your Eyes with Peter Gabriel. Yeah.
Segment 4681: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11294, Text: Yeah. Anyway, what is it? Lie To Me. This whole idea of honesty in relationships is interesting. I mean, clerks with the blowjobs. I don’t know how to phrase it eloquently, but there’s stuff you should be honest about and there’s stuff maybe you don’t need to be honest about.
Segment 4682: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11315, Text: So in the law, it is illegal to commit fraud. Fraud is a material misrepresentation of fact, but the law specifically says you are permitted to engage in “mere puffery.”
Segment 4683: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11331, Text: Nice.
Segment 4684: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11331, Text: Puffery.
Segment 4685: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11332, Text: Puffery.
Segment 4686: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11333, Text: That’s the term that was used for it, puffery. Puffery is when you are inflating something. You’re being hyperbolic, but people wouldn’t necessarily think you’re telling the truth. If I say to you, “This bottle of water was held by Elvis and that’s why you should pay me $50 for it,” that’s fraud. But if I say, “This water was drank by the finest people. Presidents drink this water,” now this is puffery. And so, advertising, marketing is based on puffery. It’s not fraud. When it’s fraud, it crosses the line.
Segment 4687: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11373, Text: So I think there’s a difference between honesty and candor, right? So in relationships, being honest is good. Being totally candid is probably not a great idea. It’s indelicate to be totally candid about some things. If a woman you’re in romantic relationship with says to you, “Do I look good in this dress?” and they don’t, or “Do I look fat in this?” that’s a better way. Any heterosexual man who’s ever been in a relationship has had that question asked of him, “Do I look fat in this? Does this make my butt look big or whatever? Do I look fat in this?” If you go, “Yes,” that’s indelicate. It’s honest, but it’s indelicate and it’s almost mean, right? If you say no, but it’s true, she doesn’t look good in that, the concern she sees is a legitimate concern, do you lie and go, “No. No, you look great in that. It’s great, da-da-da-da-da”? That’s not a good thing either.
Segment 4688: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11439, Text: So, what do you say? “That blue dress you have really compliments your body in a way that one doesn’t. The cut of that dress is such that it doesn’t flatter you.” “I see what you’re saying.” Now, it’s the dress, it’s not you babe, but I’m telling you the truth. I’m addressing your concern. This is the distinction. Don’t material misrepresent the facts. Don’t steer people down roads that you know that that’s not how it’s going to go, right? So it’s like if the woman says I love you and you don’t love her, don’t say I love you back. You do the like, “Oh, I have very strong feelings for you as well.” Or there has to be some middle ground. You don’t just pretend you didn’t hear them.
Segment 4689: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11487, Text: Yeah. I mean, I guess all of it requires skill, just like you described. I think just being honest in quotes is not enough.
Segment 4690: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11496, Text: Well, it’s not a specific enough instruction. I mean, that’s the problem. See, when you write a relationship book, which I never intended to do, people come to you and say, “What are the things I should do to help my relationship, or what is the cause of divorce?” You go, “Well, disconnection.” But what do you mean by that? Or like, “How do I improve my relationship?” Pay more attention. Make small gestures. “Okay. What does that even mean? What do you mean?” Acts of love. You should show your partner that you love them more often. “What do you mean? What I say? What I do? We should have more sex? What are you at? What are you saying?”
Segment 4691: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11533, Text: People want measurable, specific things. So that’s why I tried in my book to be very specific about things you can do, things you shouldn’t do, and they’re practical suggestions, like leaving a note. I talk a lot about leaving a note. If you’re dating someone or you’re living with them or you’re in a serious relationship, send a text, leave a note. Every day just some little thing that just tells them how much you like them. This is a low cost, high value move, doesn’t take much and it’s a practical thing. But when we speak in these broader axioms, these broader concepts that people just don’t have any idea how to practically apply.
Segment 4692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11574, Text: I can’t wait to listen to the audiobook where you talk about managing marital finances is like anal sex, which your mastery of the metaphor touches one’s heart and soul. You’re Shakespeare of the 21st century, really.
Segment 4693: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11590, Text: I don’t know that Shakespeare would’ve brought anal up in that context, but I appreciate it. Yeah. Yeah. My thesis there or my point there was proceed carefully and have discussion in advance and don’t just spring it on someone and realize that if this goes wrong it will go catastrophically wrong. So, good communication is important. Yeah, I don’t think it’s something you should just dive into unless you’re prepared for that to have potentially a very negative impact.
Segment 4694: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11628, Text: Finances is one of the sources of a huge amount of stress in relationships, which is-
Segment 4695: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11633, Text: Tremendous. Because it’s about value, I think. I mean, it’s aside from having painful conversations about what you tried to do and were able to do or what your impulse control was in terms of what you spent money on. There’s the conversation and then there’s underneath the conversation. There’s gender stuff about men feeling the need to be a provider. There’s gender stuff of men or women thinking material goods will fill the void and buying things and then creating stress on their partner. There’s the very human desire to make things seem effortless so your spouse doesn’t feel any stress when in fact it’s causing tremendous financial stress. And then when the dam breaks, it breaks hard. So yeah, there’s a lot. Finance is tricky stuff. You could probably be wonderful, romantic and sexual partners and have very different styles of how you handle your finances. How you handle your finances is informed by not only your individual psychology, but also how you were raised and how your family taught you about finance and how you should conduct your finances.
Segment 4696: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11705, Text: And there’s interesting power dynamics in play.
Segment 4697: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11707, Text: Tremendously. Yeah. Those are very tricky because the standard of living of a couple becomes important in a divorce, but sometimes this toxic standard of living that created toxic levels of stress is one of the causes of the divorce. And so, they’re asking the court to maintain a financial obligation on you, that is the reason why the marriage fell apart and that feels like a particularly insulting form of indignity.
Segment 4698: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11746, Text: Well, you’re a fascinating human being on many levels, but you’re also exceptionally productive. You’ve talked to me about waking up early. We’ve met today at 11:00 AM and for you that’s what? Late afternoon, I suppose. We had to negotiate and come to an agreement because I went to bed at 4:00 AM.
Segment 4699: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11765, Text: And I was up. I get up at 4:00 every day, so now I hear-
Segment 4700: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11766, Text: You woke up at 4:00 every day.
Segment 4701: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11769, Text: It’s three o’clock local time, so I woke up at 3:00 local time.
Segment 4702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11772, Text: Nice.
Segment 4703: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11772, Text: Yeah, I wake up at 4:00 naturally though. My body just wakes up.
Segment 4704: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11775, Text: Oh, wow. That’s fascinating.
Segment 4705: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11776, Text: And wakes up full on this speed.
Segment 4706: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11778, Text: Wow.
Segment 4707: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11779, Text: My most productive writing and speaking is from 4:00 AM until noon or 1:00.
Segment 4708: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11786, Text: So can you take me through a perfectly productive day?
Segment 4709: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11791, Text: I wake up at 4:00 AM very naturally. I wish I didn’t, but I do check my phone first thing because I want to see if any emergencies came in from a client overnight.
Segment 4710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11801, Text: So work emergencies.
Segment 4711: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11802, Text: Yeah, work-related emergencies. It is a divorce lawyer… Our definition of emergency can be very serious. It’s people absconding with a child. It’s a police being involved in a domestic violence incident. It can be time-sensitive things. When someone is hiring a divorce lawyer, I think they want someone responsive. My clients have my cell phone number. I go to bed early because I get up early and so I go to sleep by 8:00 PM latest. I don’t think I’ve seen 9:00 PM even on New Year’s Eve.
Segment 4712: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11836, Text: So I wake up at 4:00. I check my phone, check my email. Usually, even if there’s something that’s time-sensitive, it’s usually not so time-sensitive that it needs to be responded to at 4:00 AM because most other normal people are asleep. I have espresso, black espresso, which I enjoy very much. And then I work out and that’s some days going to be weights. A lot of days it’s just going to be cardio. I’ve changed my habits now that I’m in my early 50s. It used to be much more intensive weight training and deadlifts and stuff like that, and then I herniated my L5-S1. So 485 was my max deadlift and now I don’t hardly do deadlifts.
Segment 4713: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11873, Text: Well, you can still relive the past glory.
Segment 4714: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11876, Text: I do. I have some pictures and videos.
Segment 4715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11876, Text: You have pictures?
Segment 4716: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11878, Text: I have videos. I have videos of me putting 485 for three, which-
Segment 4717: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11881, Text: In stories, when you talk about it, you can exaggerate how much-
Segment 4718: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11880, Text: … five for three, which is-
Segment 4719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11881, Text: In stories, when you talk about it, you can exaggerate how much you’ve actually lifted.
Segment 4720: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11884, Text: That’s true, but then you can’t pack it up. See, I’m very evidence-based. So if I don’t have a photo or video of it, it’s just puffing, mere puffery at that point, but I work out. Then I try to work out for a good hour. I do that partly because of stress. I think when I don’t work out, it’s difficult. I had a group of guys that I would do jujitsu with at 5:00 AM. They were mostly law enforcement. They were cops who would either be starting a shift, or coming off of a night shift. We would train together, just do an open mat, and it was at 5:00 AM till 6:00, and that was heaven. I love training jujitsu first thing in the morning if I can.
Segment 4721: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11922, Text: Then I always do either a sauna or steam for 20 minutes, half an hour. Then I do a cold plunge, or if I don’t have access to a cold plunge, a cold shower. Then I have breakfast, and it’s usually a very uncontroversial simple breakfast. I like to eat. I eat slow carb Tim Ferriss type style. Then I get right to work. I try to do my drafting early in the day, prenups, motions, things like that from, let’s say, six or seven until 9:00, 9:30, which is when court begins.
Segment 4722: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11957, Text: So, drafting is like writing up different documents.
Segment 4723: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11960, Text: Right. Writing prenups, writing separation agreements, writing settlement proposals, writing motions for the court, pretrial memos, which is research that I want to present to a judge that supports my arguments. I do drafting. I review documents that the attorneys who work for me have drafted and refined them. Then court is usually from 9:00 until noon. If we’re on trial, then it’s a whole different pace, because trials… The lunch break isn’t really a lunch break. You’re preparing the afternoon’s witnesses, and you’re trying to do damage control on what happened in the morning. But if it’s just court conferences like most cases, there’s conferences.
Segment 4724: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=11996, Text: Conferences, as you go in, you make oral argument, but you don’t have witnesses on the stand. You’re not taking testimony. It’s like everybody’s just shouting allegations back and forth, and making temporary arguments pretrial. It’s kind of the foreplay of the trial.
Segment 4725: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12006, Text: Is that exhausting by the way?
Segment 4726: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12011, Text: It’s exhausting when you’re done with it. While you’re doing it, it’s exhilarating. I always say that I never sleep as poorly as the night before a trial, and I never sleep as well as the night I finished a trial. Because when I am on trial, I am speaking, listening, watching the judge closely to see what they’re reacting to, and when they’re paying attention or not paying attention, watching opposing counsel and the opposing party like, “When is the opposing party writing a little note to their lawyer to show it to them? What is the opposing counsel objecting to?” My client is trying to pass me notes half the time.
Segment 4727: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12049, Text: While I’m speaking and making my arguments, I’m trying to adjust what I’m doing strategically based on the objections that the judge is ruling on. So, I’m so hyperstimulated on trial that when you finish, you can’t even talk. You’re gone. Your brain is jello. Conferences is harder because at least with a trial, there’s a singularity of focus. With a trial, it’s just one case, and they have all my attention. The problem is then on the lunch break, all the other cases that I’ve been ignoring for the last several hours while I was on trial, they all have stuff going on. So, it’s like, “Hey, where’s that settlement proposal on this? Hey, she just did this. We need to file a motion.”
Segment 4728: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12089, Text: So now it’s like, “Okay, I have an hour to eat and to answer all of this in some preliminary way to delegate some responsibilities. Then I got to go back in and put 100% of my focus on this other case again.” So, you find yourself in a place. That’s why I’m very disciplined is you find yourself in a place where I live my whole life in six-minute increments, tenths of an hour, because we bill in tenths of an hour. So, everything I do, it’s like 0.2, 0.4, 0.6, and I’m logging time throughout the day.
Segment 4729: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12117, Text: That’s fascinating.
Segment 4730: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12118, Text: You find yourself at the end of the day. My son is a lawyer, my older son. He’s a district attorney, and I’m very proud of him. He gets to put bad guys in jail, and he is very smart, and he’s doing a great job. He just about a year ago. When he graduated from law school, we were very close, and we were talking, and he said… We were just talking about the career in the law that he was about to embark on. I said to him, “You know, the feeling at the end of the day when all your homework or all your work is done, and you just go, “Okay, it’s all done now, and I’m going to go home.” You’ll never have that feeling ever again ever. You’re just going to everyday go, “All right, it’s enough. It’s enough. I got to get out of here.”
Segment 4731: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12173, Text: Because with every one of these cases, you could stay up 24 hours focusing just on it. So, you have to have the discipline to go, “No, that’s it. I’m done for now. I’ve done what I could do today, and now I’m going to sit and read for a half an hour. I’m going to watch this show for a half an hour. I’m going to have this meal,” because It’s never done. So, that’s challenging. That’s a hard part of this job, but I think my discipline helps with that. Then like I said, I finished my day around 5:30, 6: 00. I have something to eat, and I try to wind down a little, and I’m usually in bed by 7:30, and asleep by 8:00.
Segment 4732: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12219, Text: You mentioned jujitsu. You’re brown belt. What role has jujitsu played in your life?
Segment 4733: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12226, Text: I love jujitsu. I trained martial arts from the time I was a little kid. I think I was seven or eight. I took up Okinawan Goju karate, and I did judo. It was always part of my life. Then I got to college and grad school, and I didn’t have time for it, and I didn’t do it so much. Then I got divorced. I was quite young still when I got divorced, and I had two young kids. I thought, “Well, I can grow a goatee, and buy a convertible, and do the thing you’re supposed to do, and you’re a dude with kids close to middle age, or I can try to do something more productive.” So I said, “Well, maybe I’ll go back to martial arts.” So, I took up Muay Thai kickboxing, and they had a jujitsu class at the same school after the Muay Thai class.
Segment 4734: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12272, Text: I had been around the orbit of jujitsu having been my kids took karate, and there was jujitsu there. It was a Gracie Academy. I stayed for a jujitsu class, and I had 120 pound girl ragdoll me, because I just knew nothing about grappling. I remember just going, “Well, I got to learn what this is,” and that was it. I just dove into it. My first professor was Louis Vintaloro in New Jersey. He’s a Royler Gracie black belt, great teacher, taught me amazing fundamentals, took me all the way up to purple belt. Then right after I got my purple belt, I moved to the city. I moved to Manhattan. I actually chose my apartment based on its proximity to Marcelo Garcia, and I moved to West Chelsea, because it was a short walk to Marcelo’s academy.
Segment 4735: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12322, Text: My core jujitsu was up to purple belt. It was Louis Vintaloro, and then it’s been Marcelo, and Marcelo, Paul Shriner who’s really phenomenal at his academy. All the people at his academy, I mean, are all phenomenal. I mean, Bernardo [inaudible 03:25:37] was there for a period of time that I was there and before he went to Boston. Marcos Tinoco was like his lasso guard stuff. He was at Marcelo’s for a long time, and what a teacher. I mean, my lack of skill at jujitsu is not based on a lack of quality instruction. It’s based on an inability to retain the information for very long.
Segment 4736: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12360, Text: For me, that’s one of the most reliable place I can go to humble myself.
Segment 4737: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12365, Text: I love jujitsu. I love the progressive humility that it drives home constantly. I love the impossibility of perfecting it, although Gordon Ryan’s probably come close, and Marcelo’s probably come close to perfecting it.
Segment 4738: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12382, Text: Let me ask you since you mentioned Gordon Ryan. So, apparently some close with Gordon, and there’s, I am sure in Austin, just this jujitsu scene. It’s incredible.
Segment 4739: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12394, Text: It’s like jujitsu mecca.
Segment 4740: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12395, Text: This is the Mecca.
Segment 4741: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12396, Text: I’m actually seeing John Donaher this evening,
Segment 4742: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12400, Text: I mean, this-
Segment 4743: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12402, Text: This is amazing.
Segment 4744: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12402, Text: It’s a truly special place. But anyway, apparently, long ago, you mentioned Jersey.
Segment 4745: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12409, Text: Yes.
Segment 4746: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12409, Text: There’s a bit of a conflict between you and Gordon, and you mentioned to me offline that you love him and just how much respect you have for him as an athlete and so on. But can you explain why is this-
Segment 4747: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12424, Text: I’m actually glad I have that. It’s funny that you bring it up, and of all the… We’re talking about all these heavy topics, and this is probably the one that I find the most actually emotional. Gordon’s, I think, a very young man still. He’s probably in his 20s or early 30s. It’s hard to imagine that because he’s accomplished so much as an athlete and as a business person, but there was a time not that long ago, I think it was eight or nine years ago, where he was just a young guy on his way up. He’s only, I think, a couple years older than my oldest son. Through a series of circumstances, jujitsu wasn’t… It’s really exploded in the last 10 years, but there were not as many people sponsoring “super fights.” There really weren’t jujitsu super fights being sponsored at Jersey and New York in particular.
Segment 4748: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12477, Text: I got involved in sponsoring some jujitsu super fights. I also got involved in sponsoring some jujitsu athletes. Gordon was a part of the Danaher Death Squad. I was friends with Eddie Cummings. I’m still friends with Eddie. I was friends with John. I’m still friends with John, but I didn’t really know Gordon. I actually don’t know that I’ve still ever met… I don’t think I’ve ever met Gordon. I’ve been in the same room as him, but there was a fight that… I had sponsored some other fights with this particular promoter, and they asked me to sponsor one. It didn’t involve anyone from Marcelo’s, but it involved Gordon. He was one of the people.
Segment 4749: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12519, Text: I liked John very much, and I liked everybody in the Danaher Death Squad. I like watching them compete, and I thought, “I think John’s just brilliant.” I mean, everyone at Marcelo’s has such respect for John and for everyone and the stuff they were doing when they were the… Early days of that Danaher Death squad, Eddie Cummings, his leg locks. It just blew the whole game up. It just was a whole nother thing. It was insane such innovation. Gordon at the time, he was online. I’m much older than that. I’m in my early 50s, and that’s not, I guess, chronologically that much older, but generationally, I think it’s quite a bit different.
Segment 4750: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12561, Text: Gordon was smack talking about a guy who I was sponsor of, who I knew and who I knew was a very good athlete, and had been through difficult things in his life. Gordon just said some nasty things about him. It falls into the category of totally appropriate smack talking, looking at it now and looking at what Gordon became, which is he’s someone who talks trash. It’s part of his brand is to talk trash. I see now that that’s like a Muhammad Ali thing, but at the time, I just didn’t see it as what it was. Although it doesn’t excuse it, my mother was dying. I was not at my best. I was having a hard time, and Gordon had spoken ill of this person. I got upset, and I reached out to John and to Tom DeBlass.
Segment 4751: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12612, Text: I said to them, “Hey, could you tell this guy to knock it off? Don’t talk about this person who I sponsor if I’m sponsoring his fight. I don’t even know this Gordon Ryan kid, and I’m sponsoring his fight. He should say thank you. Don’t talk bad about a person who I financially sponsor. That’s not cool.” I think on Facebook, he wrote some comments, and then I wrote some comments back, and I was incredibly obnoxious. Very soon after, I felt really gross, because I was an adult, and I was talking to a young person this way, who’s on their way up, who’s a little older than one of my kids. I just said these obnoxious things to him, and I felt really like, “That’s gross.” But I’d never really thought much about it again.
Segment 4752: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12665, Text: I watched his star rise, and I was very… I mean, who is not impressed by Gordon Ryan? Everyone at our academy was always very thrilled to see him rise. I’ve stayed friends with John. Every time Gordon would have a big victory, I would always text John and be like… Because Gordon’s victories are John’s victories too. They have such a great bond. All the people in his orbit are all people that I respect and like. I just would say, “Hey listen, congratulations and please pass on my congratulations to Gordon,” but we don’t know each other. I Don’t have his number. I have no way to contact him to apologize to him.
Segment 4753: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12698, Text: But if Gordon hears this, I am profoundly sorry. I don’t say that because I’m trying to get in your good graces. I don’t know that we’ll ever meet each other, but that was an unbelievably wrong, stupid thing to say to a young person.
Segment 4754: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12716, Text: Well, thank you for saying that. This warms my heart in general.
Segment 4755: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12721, Text: So, you talk to a divorce lawyer, and it warms your heart. Look at that.
Segment 4756: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12723, Text: Well speaking of which, you’re romantic actually. What role… You’ve seen love break down completely. What role does love play in the human condition?
Segment 4757: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12739, Text: I mean, it’s everything, right? Love is romantic. Wars are fought for romantic love. Empires fall because of romantic love. It takes down kings. It takes down… We’re all just struggling for it. We’re all just chasing it. We’re all chasing the dragon. It’s like the rush. We all are… So, it’s huge. It’s huge. I mean, sex and love, which I like to believe are in some way connected, and love and romance, which again I like to believe are in some way connected. I think it’s huge. I think It’s a… Look, I’ve always thought most of what men do, including me, we do to get laid on some level. You want to be successful. Why? So, you can have money. Why? So you can have nice things so that you can attract attractive members of the opposite sex.
Segment 4758: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12802, Text: A lot of things come down to that. Even for men like red-pilled men who are like, “I don’t care about women.” Well, you talk about them an awful lot. For someone that’s not interested in women, you sure are in the orbit of women who you’re telling how much you don’t care about women, which feels like you’re doing that to attract a certain kind of woman, which I get. More power to you, but a person who worships an idol and a person who destroys an idol are both idolaters.
Segment 4759: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12831, Text: Yes.
Segment 4760: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12832, Text: So if all you’re talking about is how you don’t need women, you’re talking about women an awful lot. So, it’s just such a splinter in people’s mind, relationships, breakups, and it’s such a great equalizer. I mean, you’re spending some time in the rarefied air now of big celebrity people. I remember when I started out as a lawyer just doing the regular, the cop and the teacher with a 401k, and they didn’t have any assets. I remember thinking like, “Well someday if I represent celebrities or wealthy CEOs, it’ll be different. They’ll be smarter. They’ll be different.” It’s just the same-
Segment 4761: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12872, Text: It’s the same.
Segment 4762: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12874, Text: … weird, petty, shit, the same infidelity, the same-
Segment 4763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12878, Text: The same kind of insecurities, the same kind of jealousy, the same kind of fights. It all-
Segment 4764: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12884, Text: It’s all the same, but it is, and it’s all the same insecurity, sadness. It’s the same desire to be validated like mommy issues, daddy issues, like intimacy issues, and it’s all the same stuff. Just because you’re really good at other things… I’ve represented professional athletes who are phenomenal world-class doctors, business people, and they suck at relationships, no better than anybody else. There’s no connection between the skills that made you a good entrepreneur and the skills that made you a good spouse or partner. I’m sure there’s some overlap like patience is good, and thinking strategically is probably good, but I’m just humbled by how we’re called to it still.
Segment 4765: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12940, Text: Even when we lose and even when our greatest pains were caused by our desire to love and be loved in a romantic sense, we just keep putting the money on the table and playing. We won’t just quit. We just keep going.
Segment 4766: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12954, Text: The whole mess of it is worth it.
Segment 4767: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12956, Text: I mean, I guess so… It’s calling us. I don’t know if it’s worth it or not. That’s a value judgment, but we don’t stop. I don’t know a lot of people that they played the hand. They lost and they went, “Well, no more of that game for me. I’m not a good poker player. I’m not playing poker anymore.” I know people who’ve done that. I know people that are like, “Listen, I don’t drink. I am allergic. I break out in handcuffs and hospital bills. I’m not drinking anymore,” but I don’t know people that are like, “Man, that relationship, I screwed that up, or I got screwed on that one. I’m not doing that anymore.”
Segment 4768: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=12993, Text: You can say that. Everybody says that, “I’m through with love. I’m done.” They’re not. They keep going. They’ll go up again.
Segment 4769: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13002, Text: Never going to fall in love again, and then a few weeks later-
Segment 4770: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13006, Text: I got job security, man. I got job security. People are not going to stop walking down that aisle. They are not going to stop having kids with people that they probably should have thought through whether they would have kids with that person or not.
Segment 4771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13020, Text: I’m glad they are. I’m glad they’re taking that leap. I’m glad they’ve taken that risk. It’s this whole beautiful mess that we’re all a part of. It’s like taking that risk, taking that leap of vulnerabilities of what this whole thing is about.
Segment 4772: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13033, Text: And what a danger if we didn’t. You hear about people like Alexander Hamilton, or you hear about people who they were born of circumstances that these two people should never have had a kid, and then they did. That kid changes the world and moves the dial forward. What a great mistake. What a great… You can’t ever say it’s a mistake. What an amazing thing that happened. I think that that’s… One of the things I like about divorce as a practice and as almost looking at it like a spiritual practice, I think you just don’t know what is a blessing in the world. You just don’t know. I’ve spoken about this before publicly, and he does frequently. My father’s an alcoholic. My father’s been in recovery now for seven years, I think, but he was a bad alcoholic Vietnam veteran my whole life, and only got sober when I was in my 40s.
Segment 4773: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13103, Text: A lot of the personality characteristics I have are consistent with those of adult children of alcoholics, desire for control and control issues, a lot of those things. I love my life. I’m having a great time. If I died tomorrow, man, I did more, learned more, earned more, loved more than I ever dreamed. So, I’m so glad my dad was an alcoholic. If you said to me, “How do you raise kids?” I wouldn’t say, “Well, you definitely want to be an alcoholic, because your kid’s going to get a lot of really good discipline lessons from that experience.” No, I wouldn’t want that for… But it’s born. All these wonderful things were born of this awful situation.
Segment 4774: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13153, Text: So, I think divorce is the same thing. We make these mistakes, but they’re not really… I often have to say to my clients when they’re like, “Oh, I wish I’d never married this person,” I’m like, “You love your kids, right? Your kids are half that person. They would not be the organism they are without that person’s DNA. So, you can’t regret being with that person if you love your kids, because those kids don’t exist without that person.” I don’t know how we refocus on that. I don’t know. Maybe we give anyone going through a… I’ve actually had a theory, which I’ve not said out loud, but I’ll say it to you, because it’s just us talking.
Segment 4775: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13198, Text: I think if we could figure out a way to take a divorcing couple that is interested in potentially mediating, and put them in a setting where we could give them both psilocybin, a good dose, like two and a half, three grams, and have them do individual sessions with controlled setting with a guide, and have them do that inner work, and then have them do some kind of a session together after they’ve had that experience, that psychedelic experience, I actually think you could do transformative divorce work, because I have found myself and certainly the many people that I’ve talked to who’ve had psilocybin experiences in particular, but any psychedelic experience, many of the empathogens or even MDMA… MDMA is an empathogen.
Segment 4776: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13261, Text: If we brought that space and the divorce and conflict resolution space together, that psychopharmacological intervention on empathy, one’s empathy receptors or one’s connectivity, I think that could be radically transforming. It would be logistically an absolute nightmare. It would never get done from a legal standpoint, but man, I think sometimes that if… Because I think the more that you can bring people to the awareness of connection that comes from many people’s psychedelic experiences, I think they could then extrapolate that into their understanding of the conflict and disconnect they’re having with their partner.
Segment 4777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13312, Text: So really lean into the, “Use this brink of divorce as a catalyst for doing a lot of soul-searching, a lot of growth together.”
Segment 4778: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13323, Text: Well, that was what appealed to me about it, I mean, before I started doing it is it was this idea that this is a opportunity for radical reinvention. It was an opportunity for people to say, “Okay, now what?” I didn’t expect that now what, and it was to be part of the architecture of that. I didn’t look at it like I’m helping demolish the building. It was like I’m tearing down the building, so we can build the new one, which I hope is filled with joy and abundance and peace and love and real love, real satisfaction. My ex-wife is married for over a decade now to a phenomenal guy who is perfect for her, and he’s nothing like me by the way.
Segment 4779: Speaker: , Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13371, Text: If you met him, and you’ve met both of us, you’d go, “Well, no one could love both of these guys.” It’s like, “If you like this flavor, you wouldn’t like this flavor.” I’m impatient, fast talking. Skip to the end, “We got to land this plane. Come on.” He’s a therapist. He’s chill. He’s patient, and they’re perfect together. I can say that as someone who loves her and loved her and knows her or knew her. I think if we can radically view honestly without jealousy, without the sense of, “Look at it, and just go, “Yeah. Yeah, okay, this is the love this person needed.” That doesn’t mean my love sucks. It just means it wasn’t the right one for this person. There’s a lid for every pot. She found her lid. I want her to find her lid. That’s good.
Segment 4780: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13427, Text: There’s billions of pots out there, and we just need to match them with the proper lid.
Segment 4781: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13430, Text: Yeah, not hit each other over the head with them all day long.
Segment 4782: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13433, Text: Man, this is such a romantic few hours we’ve got to spend together. There’s even a candle burning over there.
Segment 4783: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13440, Text: Is there? Oh, that’s lovely.
Segment 4784: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13442, Text: All right, brother, thanks so much, James.
Segment 4785: Speaker: James Sexton, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13443, Text: Thank you. Thanks for having me.
Segment 4786: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=fUEjCXpOjPY&t=13445, Text: Thanks for listening to this conversation with James Sexton. To support this podcast, please check out our sponsors in the description. Now, let me leave you with some words from Rumi. Your task is not to seek for love, but merely to seek and find all the barriers within yourself that you have built against it. Thank you for listening and hope to see you next time.
Segment 1: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=0, Text: I hope with my books I’m saying, “This isn’t a how-to guide, but this is somebody you can walk alongside.” You can see Einstein growing up Jewish in Germany. You can see Jennifer Doudna growing up or as an outsider, or Leonardo da Vinci or Elon Musk, in really violent South Africa with a psychologically difficult father, and getting off the train when he goes to an anti-apartheid concert with his brother and there’s a man with a knife sticking out of his head, and they step into the pool of blood and it’s sticky on their soles. This causes scars that last the rest of your life. The question is not how do you avoid getting scarred, it’s how do you deal with it.
Segment 2: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=56, Text: The following is a conversation with Walter Isaacson, one of the greatest biography writers ever, having written incredible books on Albert Einstein, Steve Jobs, Leonardo da Vinci, Jennifer Doudna, Benjamin Franklin, Henry Kissinger, and now a new one on Elon Musk. We talked for hours, on and off the mic. I’m sure we’ll talk many more times. Walter is a truly special writer, thinker, observer, and human being.
Segment 3: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=85, Text: I highly recommend people read his new book on Elon. I’m sure there will be short-term controversy, but in the long term, I think it will inspire millions of young people, especially with difficult childhoods, with hardship in their surroundings or in their own minds, to take on the hardest problems in the world and to build solutions to those problems, no matter how impossible the odds. In this conversation, Walter and I cover all of his books, and use personal stories from them to speak to the bigger principles of striving for greatness in science, in tech, engineering, art, politics and life.
Segment 4: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=125, Text: There are many things in the new Elon book that I felt are best saved for when I speak to Elon directly again on this podcast, which will be soon enough. Perhaps it’s also good to mention here that my friendships, like with Elon, nor any other influence like money, access, fame, power, will never result in me sacrificing my integrity, ever. I do like to celebrate the good in people, to empathize and to understand, but I also like to call people out on their bullshit with respect and with compassion. If I fail, I fail due to a lack of skill, not a lack of integrity. I’ll work hard to improve. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Walter Isaacson. What is the role of a difficult childhood in the lives of great men and women, great minds? Is it a requirement, is it a catalyst, or is it just a simple coincidence of fate?
Segment 5: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=191, Text: Well, it’s not a requirement. Some people with happy childhoods do quite well, but it certainly is true that a lot of really driven people are driven because they’re harnessing the demons of their childhood. Even Barack Obama’s sentence in his memoirs, which is, I think, “Every successful man is either trying to live up to the expectations of his father or live down the sins of his father.” For Elon it’s especially true, because he had both a violent and difficult childhood and a very psychologically problematic father. He’s got those demons dancing around in his head, and by harnessing them, it’s part of the reason that he does riskier, more adventurous, wilder things than maybe I would ever do.
Segment 6: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=242, Text: You’ve written that Elon talked about his father, and that at times it felt like mental torture, the interaction with him during his childhood. Can you describe some of the things you’ve learned?
Segment 7: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=256, Text: Yeah. Well, Elon and Kimbal would tell me that, for example, when Elon got bullied on the playground, and one day was pushed down some concrete steps and had his face pummeled so badly that Kimbal said, “I couldn’t really recognize him,” and he was in the hospital for almost a week, but when he came home, Elon had to stand in front of his father, and his father berated him for more than an hour, and said he was stupid and took the side of the person who had beaten him.
Segment 8: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=288, Text: That’s probably one of the more traumatic events of Elon’s life.
Segment 9: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=291, Text: Yes, and there’s also Veldskool, which is a sort of paramilitary camp that young South African boys got sent to, and at one point he was scrawny. He was very bad at picking up social cues and emotional cues, he talks about being Asperger’s, and so he gets traumatized at a camp like that. The second time he went, he’d gotten bigger. He had shot up to almost six feet and he learned a little bit of judo, and he realized that if he was getting beaten up, it might hurt him, but he would just punch the person in the nose as hard as possible, so that sense of always punching back has also been ingrained in Elon.
Segment 10: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=333, Text: I spent a lot of time talking to Errol Musk, his father. Elon doesn’t talk to Errol Musk anymore, his father, nor does Kimbal. It’s been years, and Errol doesn’t even have Elon’s email, so a lot of times Errol will be sending me emails. Errol had one of those Jekyll-and-Hyde personalities. He was a great mind of engineering and especially material science. Knew how to build a wilderness camp in South Africa using mica and how it would not conduct the heat, but he also would go into these dark periods in which he would just be psychologically abusive.
Segment 11: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=378, Text: Of course, Maye Musk says to me … his mother, who divorced Errol early on … said, “The danger for Elon is that he becomes his father.” Every now and then … you’ve been with him so much, Lex, and you know him well … he’ll even talk to you about the demons, about Diablo dancing in his head. I mean, he gets it, he’s self-aware, but you’ve probably seen him at times where those demons take over and he goes really dark and really quiet. Grimes says, “I can tell a minute or two in advance when demon mode’s about to happen,” and he’ll go a bit dark. I was here at Austin once at dinner with a group, and you could tell suddenly something had triggered him and he was going to go dark. I’ve watched it in meetings, where somebody will say, “We can’t make that part for less than $200,” or, “No, that’s wrong,” and he’ll berate them, and then he snaps out of it. You know that too, the huge snap-out, where suddenly he’s showing you a Monty Python skit on his phone and he’s joking about things. I think coming out of the childhood, there were just many facets, maybe even many personalities … the engineering mode, the silly mode, the charismatic mode, the visionary mode … but also the demon in dark mode.
Segment 12: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=463, Text: A quote you cited about Elon’s really stood out to me. I forget who it was from, but, “Inside the man, he’s still there as a child, the child standing in front of his dad.”
Segment 13: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=473, Text: That was Talulah, his second wife, and she’s great. She’s an English actress. They’ve been married twice, actually. Tallulah said that’s just him from his childhood. He’s a drama addict. Kimbal says that as well. I asked why, and Tallulah said, “For him, love and family are associated with those psychological torments, and in many ways he’ll channel.” I mean, Tallulah would be with him in 2008 when the company was going bad or whatever it may have been or later, and he would be so stressed he would vomit, and then he would channel things that his father had said, use phrases his father had said to him. She told me, “Deep inside the man is this man-child, still standing in front of his father.”
Segment 14: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=531, Text: To what degree is that true for many of us, do you think?
Segment 15: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=535, Text: I think it’s true, but in many different ways. I’ll say something personal, which is I was blessed … and perhaps it’s a bit of a downside too … with the fact that I had the greatest father you could ever imagine, and mother. They were the kindest people you’d ever want to meet. I grew up in a magical place in New Orleans. My dad was an engineer, an electrical engineer, and he was always kind. Perhaps I’m not quite as driven or as crazed. I don’t have to prove things, so I get to write about Elon Musk.
Segment 16: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=570, Text: I get to write about Einstein or Steve Jobs or Leonardo DaVinci, who as you know, was totally torn by demons and had different difficult childhood situations, not even legitimized by his father. Sometimes those of us who are lucky enough to have really gentle, sweet childhoods, we grow up with fewer demons, but we grow up with fewer drives, and we end up maybe being Boswell and not being Dr. Johnson. We end up being the observer, not being the doer. I always respect those who are in the arena.
Segment 17: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=613, Text: You don’t see yourself as a man in the arena?
Segment 18: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=616, Text: I’ve had a gentle, sweet career, and I’ve got to cover really interesting people, but I’ve never shot off a rocket that might someday get to Mars. I’ve never moved us into the era of electric vehicles. I’ve never stayed up all night on the factory floor. I don’t have quite those, either the drives or the addiction to risk. I mean, Elon’s addicted to risk. He’s addicted to adventure. Me, if I see something that’s risky, I spend some time calculating, “Okay, upside/downside here.” That’s another reason that people like Elon Musk get stuff done, and people like me write about the Elon Musks.
Segment 19: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=669, Text: One other aspect of this, given a difficult childhood, whether it’s Elon or DaVinci, I wonder if there’s some wisdom, some advice almost that you can draw, that you can give to people with difficult childhoods.
Segment 20: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=689, Text: I think all of us have demons, even those of us who grew up in a magical part of New Orleans with sweet parents. We all have demons, and rule one in life is harness your demons. Know that you’re ambitious or not ambitious or you’re lazy or whatever. Leonardo da Vinci knew he was a procrastinator. I think it’s useful to know what’s eating at you, know how to harness it. Also, know what you’re good at. I’ll take Musk as another example.
Segment 21: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=730, Text: I’m a little bit more like Kimbal Musk than Elon. I maybe got overendowed with the empathy gene. What does that mean? Well, it means that I was okay when I ran Time Magazine. It was a group about 150 people on the editorial floors, and I knew them all and we had a jolly time. When I went to CNN, I was not very good at being a manager or an executive of an organization. I cared a little bit too much that people didn’t get annoyed at me or mad at me.
Segment 22: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=767, Text: Elon said that about John McNeil, for example, who was president of Tesla. It’s in the book. I talked to John McNeil a long time, and he says, “Elon just would fire people, be really rough on people. He didn’t have the empathy for the people in front of him.” Elon says, “Yeah, that’s right, and John McNeil couldn’t fire people. He cared more about pleasing the people in front of him than pleasing the entire enterprise or getting things done.”
Segment 23: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=796, Text: Being overendowed with a desire to please people can make you less tough of a manager, and that doesn’t mean there aren’t great people who are overendowed. Ben Franklin, overendowed with the desire to please people. The worst criticism of him from John Adams and others was that he was insinuating, which meant he was always trying to get people to like him, but that turned out to be a good thing. When they can’t figure out the big state/little state issue at the Constitutional Convention, when they can’t figure out the Treaty of Paris, whatever it is, he brings people together, and that is his superpower.
Segment 24: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=839, Text: To get back to the lessons, you asked, and the first was harness your demons, the second is to know your strengths and your superpower. My superpower is definitely not being a tough manager. After running CNN for a while, I said, “Okay, I think I’ve proven I don’t really enjoy this or know how to do this well. Do I have other talents? Yeah, I think I have the talent to observe people really closely, to write about it in a straight but I hope interesting narrative style.” That’s a power. It’s totally different from running an organization.
Segment 25: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=878, Text: It took me until three years of running CNN that I realized I’m not cut to be an executive in really high-intense situations. Elon Musk is cut to be an executive in highly intense situations, so much so that when things get less intense … when they actually are making enough cars and rockets are going up and landing … he thinks of something else, so he can surge and have more intensity. He’s addicted to intensity, and that’s his superpower, which is a lot greater than the superpower of being a good observer.
Segment 26: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=918, Text: I think also, to build on that, it’s not just addiction to risk and drama. There’s always a big mission above it. I would say it’s an empathy towards people in the big picture, humanity.
Segment 27: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=939, Text: It’s an empathy towards humanity more than the empathy towards the three or four humans who might be sitting in the conference room with you, and that’s a big deal, and you see that in a lot of people. You see it Bill Gates or Larry Summers, Elon Musk. They always have empathy for these great goals of humanity, and at times they can be clueless about the emotions of the people in front of them or callous sometimes.
Segment 28: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=972, Text: Musk, as you said, is driven by mission more than any person I’ve ever seen, and it’s not only mission, it’s like cosmic missions, meaning he’s got three really big missions. One is to make humans a spacefaring civilization, make us multi-planetary, or get us to Mars. Number two is to bring us into the era of sustainable energy, to bring us into the era of electric vehicles and solar roofs and battery packs. Third is to make sure that artificial intelligence is safe and is aligned with human values.
Segment 29: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1014, Text: Every now and then, I’d talk to him and we’d be talking about Starlink satellites or whatever, or he would be pushing the people in front of him at SpaceX and saying, “If you do this, we’ll never get to Mars in our lifetime,” and then he would give the lecture of how important it was for human consciousness to get to Mars in our lifetime. I’m thinking, “Okay, this is the pep talk of somebody trying to inspire a team, or maybe it’s the type of pontification you do on a podcast.” On the 20th time I watched him, I realized, “Okay, I believe it. He actually is driven by this.”
Segment 30: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1051, Text: He is frustrated and angry that, because of this particular minor engineering decision, the big mission is not going to be accomplished? It’s not a pep talk, it’s a literal frustration?
Segment 31: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1064, Text: An impatience, a frustration, and it’s also just probably the most deeply ingrained thing in him is his mission. He joked at one point to me about how much he loved reading comics as a kid, and he said, “All the people in the comic books, they’re trying to save the world, but they’re wearing their underpants on the outside and they look ridiculous.” Then he paused and said, “But they are trying to save the world.” Whether it’s Starlink in Ukraine or Starship going to Mars or trying to get a global new Tesla, I think he’s got this epic sense of the role he’s going to play in helping humanity on big things, and like the characters in the comic books, it’s sometimes ridiculous, but it also is sometimes true.
Segment 32: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1123, Text: When I was reading this part of the book, I was thinking of all the young people who are struggling in this way, and I think a lot of people are in different ways, whether they grow up without a father, whether they grow up with physical, emotional, mental abuse or demons of any kind, as you talked about. It’s really painful to read, but also really damn inspiring.
Segment 33: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1146, Text: Thanks.
Segment 34: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1147, Text: That if you walk side by side with those demons, if you don’t let that pain break you or somehow channel it, if you can put it this way, that you can achieve. You can do great things in this world.
Segment 35: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1163, Text: Well, that’s an epic view of why we write biography, which is more epic than I had even thought of, so I say thank you, because in some ways what you’re trying to do is say, “Okay, I mean, Leonardo, you talk about being a misfit. He’s born illegitimate in the village of Vinci, and he’s gay and he’s left-handed and he’s distracted, and his father won’t legitimize him. Then he wanders off to the town of Florence, and he becomes the greatest artist and engineer of that part of the Renaissance.
Segment 36: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1205, Text: I hope this book inspires. Jennifer Doudna, the gene editing pioneer who helps discover CRISPR, the gene editing tool, which in my book, The Code Breaker, she grew up feeling like a misfit in Hawaii in a Polynesian village, being the only white person, and also trying to live up to a father who pushed her. If people can read the books … and I should have said about Jennifer Doudna, my point was that she was told by her school guidance counselor, “No, girls don’t do science. Science is not for girls. You’re not going to do math or science.” It pushes her to say, “All right, I’m going to do math and science.”
Segment 37: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1247, Text: Just to interrupt real quick, but Jennifer Doudna, you’ve written an amazing book about her. A Nobel Prize winner, CRISPR developer, just incredible. One of the great scientists in the 21st century,
Segment 38: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1258, Text: Right, and I’m talking about when Jennifer Doudna was young and she felt really, really out of place, like you and me and a lot of people when they’re feeling that way, they read books. They curl up with a book. Her father drops a book on her bed called The Double Helix, the book by James Watson on the discovery of the structure of DNA by him and Rosalind Franklin and Francis Crick, and she realizes, “Oh, my God, girls can become scientists. My school guidance counselor is wrong.”
Segment 39: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1293, Text: I think books … like she read this book, and even if it’s a comic book like Elon Musk read … books can sometimes inspire you. Every one of my books is about people who were totally innovative, who weren’t just smart, because none of us are going to be able to match Einstein in mental processing power, but we can be as curious as he was and creative and think out of the box the way he did, or as Steve Jobs put it, think different.
Segment 40: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1327, Text: I hope with my books I’m saying, “This isn’t a how-to guide, but this is somebody you can walk alongside.” You can see Einstein growing up Jewish in Germany. You can see Jennifer Doudna growing up or as an outsider, or Leonardo da Vinci or Elon Musk, in really violent South Africa with a psychologically difficult father, and getting off the train when he goes to an anti-apartheid concert with his brother and there’s a man with a knife sticking out of his head, and they step into the pool of blood and it’s sticky on their soles. This causes scars that last the rest of your life. The question is not how do you avoid getting scarred, it’s how do you deal with it.
Segment 41: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1386, Text: It’s hard to pick my favorite of your biographies, but Einstein, I mean, you really paint a picture of another … I don’t want to call him a misfit … but a person who doesn’t necessarily have a standard trajectory through life of success.
Segment 42: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1405, Text: Absolutely.
Segment 43: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1406, Text: That’s extremely inspiring. I don’t know exactly what question to ask. There’s a million.
Segment 44: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1412, Text: I’ll talk about the misfit for a second, because we talked about Leonardo being that way. Einstein’s Jewish in Germany, at a time when it starts getting difficult. He’s slow in learning how to talk and he’s a visual thinker, so he’s always daydreaming and imagining things. The first time he applies to the Zurich Polytech … because he runs away from the German education system because it’s too much learning by rote … he gets rejected by the Zurich Polytech.
Segment 45: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1442, Text: Now, it’s the second-best school in Zurich, and they’re rejecting Einstein. I tried to find, but couldn’t, the name of the admissions counselor at the Zurich Polytech, like, “You rejected Einstein?” Then he doesn’t finish in the top half of his class. Once he does and he goes to graduate school, they don’t accept his dissertation, so he can’t get a job. He’s not teaching. He even tries about 14 different high schools at Gymnasium to get a job, and they won’t take him.
Segment 46: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1472, Text: He’s a third-class examiner in the Swiss patent office in 1905, third class because they’ve rejected his doctoral dissertation, so he can’t be second class or first class. He doesn’t have a doctoral degree, and yet he’s sitting there on the stool in the patent office in 1905, and writes three papers that totally transform science. If you’re thinking about being misunderstood or unappreciated, in 1906, he’s still a third-class patent examiner. In 1907, he still is. It takes until 1909 before people realize that this notion of the Theory of Relativity might be correct and it might upend all of Newtonian physics.
Segment 47: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1515, Text: How is it possible for three of the greatest papers in the history of science to be written in one year by this one person? Is there some insights, wisdoms you draw?
Segment 48: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1526, Text: Plus he had a day job as a patent examiner, and there’s really three papers but there’s also an addendum, because once you figure out quantum theory and then you figure out relativity, and you’re understanding Maxwell’s equations and the speed of light, he does a little addendum. That’s the most famous equation in all of physics, which is E equals MC squared, so it’s a pretty good year.
Segment 49: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1551, Text: It partly starts because he’s a visual thinker, and I think it was helpful that he was at the patent office, rather than being the acolyte of some professor at the academy where he was supposed to follow the rules. At the patent office, they’re doing devices to synchronize clocks, because the Swiss have just gone on Standard times zones, and Swiss people, as you know, tend to be rather Swiss. They care, if it strikes the hour in Basel, it should do the same in Bern at the exact incident.
Segment 50: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1581, Text: You have to send a light signal between two distant clocks, and he’s visualizing what’s it look like to ride alongside a light beam. He says, “Well, if you catch up with it, if you go almost as fast, it’ll look stationary,” but Maxwell’s equations don’t allow for that. He said, “It was making my palms sweat that I was so worried.” He finally figures out, because he’s looking at these devices to synchronize clocks, that if you’re traveling really, really fast, what looks synchronous to you or synchronized to you is different than for somebody traveling really fast in the other direction. He makes a mental leap that the speed of light’s always constant, but time is relative depending on your state of motion. It was that type of out-of-the-box thinking, those leaps, that made 1905 his miracle year.
Segment 51: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1632, Text: Likewise with Musk. I mean, after General Motors and Ford, everybody gives up on electric vehicles. To just say, “I know how we’re going to have a path to change the entire trajectory of the world into the era of electric vehicles.” Then when he comes back from Russia, where he tried to buy a little rocket ship so he could send a experimental greenhouse to Mars, and they were poking fun of him and actually spit on him at one point in a drunken lunch.
Segment 52: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1665, Text: This is very fortuitous, because on the ride back home on the plane, on the Delta Airlines flight, he’s doing the calculations of how much materials, how much metal, how much fuel. How much would it really cost? He’s visualizing things that other people would just say is impossible. It’s what Steve Jobs’s friends called the reality distortion field, and it drove people crazy. It drove them mad, but it also drove them to do things they didn’t think they would be able to do.
Segment 53: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1700, Text: You said visual thinking. I wonder if you’ve seen parallels of the different styles and kinds of thinking that operate the minds of these people. Is there parallels you see between Elon, Steve Jobs, Einstein, DaVinci, specifically in how they think?
Segment 54: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1724, Text: I think they were all visual thinkers, perhaps coming from slight handicaps as children, meaning Leonardo was left-handed and a little bit dyslexic, I think. Certainly Einstein had echolalia. He would repeat things. He was slow in learning to talk. I think visualizing helps a lot. With Musk, I see it all the time when I’m walking the factory lines with him or in product development, where he’ll look at, say, the heat shield under the Raptor engine of a Starship booster, and he’ll say, “Why does it have to be this way? Couldn’t we trim it this way or make it … or even get rid of this part of it?” He can visualize the material science.
Segment 55: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1773, Text: There’s small anecdotes in my book, but at one point he’s on the Tesla line and they’re trying to get 5,000 cars a week in 2018. It’s a life-or-death situation. He’s looking at the machines that are bolting something to the chassis, and he insists that Drew … not Drew, that Lars Moravy, one of his great lieutenants, come, and they have to summon him, and he says, “Why are there six bolts here?
Segment 56: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1802, Text: Lars and others explained, “Well, for the crash test or anything else, the pressure would be in this way, so you have to,” and they were blah, blah, blah, blah, blah. He said, “No. If you visualize it, you’ll see if there’s a crash, the force would go this way and that way, and it could be done with four bolts.” Now, that sounds risky, and they go test it and they engineer it, but it turns out to be right. I know that seems minor, but I could give you 500 of those, where in any given day he’s visualizing the physics of an engineering or manufacturing problem.
Segment 57: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1842, Text: That sounds pretty mundane, but for me, if you say what makes him special, there’s the mission-driven thing. I’d give you a lot of reasons, but one of the reasons is he cares not just about the design of the product, but visualizing the manufacturing of the product, the machine that makes the machine, and that’s what we failed to do in America for the past 40 years. We outsourced so much manufacturing. I don’t think you can be a good innovator if you don’t know how to make the stuff you’re designing. That’s why Musk puts his designers’ desks right next to the assembly lines in the factories, so that they have to visualize what they drew as it becomes the physical object.
Segment 58: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1890, Text: Understanding everything, from the physics all the way up to the software? It’s like end to end.
Segment 59: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1895, Text: Well, having an end-to-end control is important. Certainly with Steve Jobs. I’m looking at my iPhone here. It’s a big deal. That hardware only works with Apple software, and for a while the iTunes store only worked. He has an end-to-end that makes it like a Zen garden in Kyoto. Very carefully curated, but a thing of beauty. For Musk when he first was at Tesla …
Segment 60: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1920, Text: For Musk when he first was at Tesla and before he was the CEO, when he was just the executive chairman and basically the finance person, person funding it, they were outsourcing everything. They were making the batteries in Japan and the battery pack would be at some barbecue shop in Thailand and got sent to the Lotus factory in England to be put into a Lotus Elise chassis and then… That was a nightmare. You did not have end to end control of the manufacturing process. So he goes to the other extreme. He gets a factory in Fremont from Toyota and he wants to do everything in-house. The software in-house, the painting in-house, the battery. He makes his own batteries. And I think that end-to-end control is part of his personality, but it’s also what allows Tesla to be innovative.
Segment 61: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=1983, Text: Yeah, I got to see and understand in detail one example of that, which is the development of the brain of the car in autopilot going from Mobile Eye to in-house building the autopilot system to basically getting rid of all sensors that are not rich in data to make it AI friendly, saying that we can do it all with vision. And like you said, removing some of the bolts. So sometimes it’s small things, but sometimes it’s really big things like getting rid of radar.
Segment 62: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2021, Text: Well, vision only, getting rid of radar is huge and everybody’s against it. They’re still fighting it a bit. They’re still trying to do it next generation some form of radar. But it gets back to the first principles. We’re talking about visualizing. Well, he starts with the first principles. And the first principles are physics involve things like, well, humans drive with only visual input. They don’t have radar, they don’t have LiDAR, they don’t have sonar, and so there is no reason in the laws of physics that make it so that vision only won’t be successful in creating self-driving. Now, that becomes an article of faith to him and he gets a lot of pushback. And he’s by the way, not been that successful in meeting his deadlines of getting self-driving, he’s way too optimistic. But it was at first principles of get rid of unnecessary things.
Segment 63: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2084, Text: Now you would think, LiDAR, why not use it? Why not use a crutch? It’s like, yeah, we can do things vision only, but when I look at the stars at night I’ll use a telescope too. Well, you could use LiDAR, but you can’t do millions of cars that way at scale. At a certain point you have to make it not only a good product but a product that goes to scale. And you can’t make it based on maps like Google Maps because it’ll never be able to then drive from New Orleans to Slidell where I want to go when it’s too hot in New Orleans.
Segment 64: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2117, Text: Take for example, full self drive. He has been obsessed with what he calls the robotaxi. We’re going to build the next generation car without a steering wheel, without pedals because it’s going to be full self-drive. You just summon it, you won’t need to drive it. Well over and over again, all these people I’ve told you about, Lars Moravy and Drew Baglino and others, they’re saying, okay, fine, that sounds really good, but it ain’t happened yet. We need to build a $25,000 mass market global car that’s just normal with a steering wheel. And yeah, he finally turned around a few months ago and said, let’s do it.
Segment 65: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2159, Text: And then he starts focusing on how’s the assembly line going to work? How are we going to do it and make it the same platform for Robotaxi, so you’re going to have the same assembly line. Likewise for full self-drive, they were doing it by coding hundreds of thousands of lines of code that would say things like, if you see a red light stop, if there’s a blinking light, if there two yellow lines do this. If there’s a bike lane, do this, if there’s a crosswalk, do that.
Segment 66: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2185, Text: Well, that’s really hard to do. Now he’s doing it through artificial intelligence and machine learning only. FSD 12 will be based on the billion or so frames from Tesla each week of Tesla drivers and saying, what happened when a human was in this situation? What did the human do? And let’s only pick the best humans, the five star drivers, the Uber drivers, as Elon says. And so that’s him changing his mind and going to first principles but saying, all right, I’m even going to change full self-driving so there’s not rules based, it becomes AI based, just like ChatGPT doesn’t try to answer your question, who are the five best popes or something by study. ChatGPT does it by having ingested billions of pieces of writing that people have done. This will be AI, but real world done by ingesting video.
Segment 67: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2246, Text: Sometimes it feels like he and others that are building things in this world successfully are basically confidently exploring a dark room with a very confident ambitious vision of what that room actually looks like. They’re just walking straight into the darkness. There’s no painful toys or legos on the ground. I’m just going to walk. I know exactly how far the wall is, and then very quickly willing to adjust as they run into, they step on the Lego and their body is filled with a lot of pain. What I mean by that is there’s this kind of evolution that seems to happen where you discover really good ideas along the way that allow you to pivot.
Segment 68: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2294, Text: To me since a few years ago when you could see with Andrei Karpathy, the software 2.0 evolution of autopilot, it became obvious to me that this is not about the car. This is about Optimus, the robot. This is like if we look back a hundred years from now, the car will be remembered as a cool car, nice transportation, but the autopilot won’t be the thing that controls the car. It’ll be the thing that allows embodied AI systems to understand the world, so broadly. And so that kind of approach. And you kind of stumble into it, will Tesla be a car company? Will it be an AI company? Will it be a robotics company? Will it be a home robotics company? Will it be an energy company? And then you kind of slowly discover this as you confidently push forward with a vision. So it’s interesting to watch that kind of evolution as long as it’s backed by this confidence.
Segment 69: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2362, Text: There are a couple of things that are required for that. One is being adventurous. One doesn’t enter a dark room without a flashlight and a map unless you’re a risk-taker, unless you’re adventurous. The second is to have iterative brain cycles where you can process information and do a feedback loop and make it work. The third, and this is what we failed to do a lot in the United States and perhaps around the world, is when you take risks, you have to realize you’re going to blow things up. First three rockets, the Falcon Rockets that Musk does, they blow up. Even Starship, three and a half minutes, but then it blows up the first time. So I think Boeing and NASA and others have become unwilling to enter your dark room without knowing exactly where the exit is and the lighted path to the exit.
Segment 70: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2421, Text: And the people who created America, whenever they came over, whether the Mayflower, refugees from the Nazis, they took a lot of risks to get here. And now I think we have more referees than we have risk-takers, more lawyers and regulators and others saying, you can’t do that, that’s too risky than people willing to innovate, and you need both. I think you’re also right on 50, a hundred years from now, what Musk will be most remembered for besides space travel is real world AI. Not just Optimus the robot, but Optimus the robot and the self-driving car. They’re pretty much the same. They’re using GPU clusters or dojo chips or whatever it may be to process real world data. We all got, and you did on your podcast, quite excited about large language model, generative predictive text AI. That’s fine, especially if you want to chit-chat with your chatbot. But the holy grail is artificial general intelligence and the tough part of that is real world AI and that’s where Optimus, the robot or full self-drive are I think far ahead of anybody else.
Segment 71: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2517, Text: Well, I like how you said chitchat. I would say for one of the greatest writers ever, it’s funny you spoke about language and the mastery of languages as merely chitchat. People have fallen in love over some words. People have gone to wars over some words. I think words have a lot of power. It’s actually an interesting question where the wisdom of the world, the wisdom of humanity is in the words or is it in visuals, is it in the physical? I don’t really-
Segment 72: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2549, Text: It’s in mathematics.
Segment 73: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2550, Text: Maybe it all boils down to math and in the end, this kind of discussion about real world AI versus language is all the same. Maybe. I’ve gotten a chance to hang out quite a bit in the Metaverse with Mr. Mark Zuckerberg recently, and boy is the realism in there. The thing that’s coming up in the future is incredible. I got scanned in Pittsburgh for 10 hours into the Metaverse and there’s a virtual version of me and I got to hang out with that virtual version.
Segment 74: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2589, Text: Do you like yourself?
Segment 75: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2590, Text: Well, I never like myself. But it was easier to like that other guy, that was interesting.
Segment 76: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2599, Text: Did he like you?
Segment 77: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2601, Text: He didn’t seem to care much.
Segment 78: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2603, Text: That’s the lack of the empathy.
Segment 79: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2607, Text: But it made me start to question even more than before, well, how important is this physical reality? Because I got to see myself and other people in that metaverse, the details of the face, all the things that you think maybe if you look at yourself in the mirror are imperfections, all this kind of stuff of stuff. When I was looking at myself and at others, all those things are beautiful and it was real and it was intense and it was scary because you’re like, well, are you allowed to murder people in the metaverse? What are you allowed to do? Because you can replicate a lot of those things and you start to question what are the fundamental things that make life worth living here as we know as humans.
Segment 80: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2661, Text: Have you talked to Elon about his views of we’re living in a simulation maybe and how you would figure out if that’s true?
Segment 81: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2668, Text: Yes, there’s a constant lighthearted but also a serious sense that this is all a bit of a game.
Segment 82: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2676, Text: One of my theories on Elon, a minor theory, is that he read Hitchhiker’s Guide to the Galaxy once too often. And as you know, there’s a scene in there that says that there’s a theory about the universe that if anybody ever discovers the secrets of meanings of the universe, it will be replaced by an even more complex universe. And then the next line Douglas Adams writes is, and there’s another theory that this has already happened, so I’m not trying to get my head around that, but I know that Elon Musk tries to.
Segment 83: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2711, Text: Well, there’s a humor to that.
Segment 84: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2713, Text: There’s an enormous humor to Hitchhiker’s Guide. I really think that helped Musk out of the darkest of his periods to have sort of the sense of fun of figuring out what life is all about.
Segment 85: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2725, Text: I wonder if as a small aside we could say just having gotten to know Elon very well, the silliness, the willingness to engage in the absurdity of it all and have fun. What is that? Is that just a cork of personality or is that a fundamental aspect of a human who’s running six plus companies?
Segment 86: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2748, Text: Well, it’s a release valve just like video games and Polytopia and Elden Ring are release valves for him. And he does have an explosive sense of humor as you know. And the weird thing is when he makes the abrupt transition from dark demon mode and you’re in a conference room and he has really become upset about something and not only there dark vibes, but there’s dark words emanating and he’s saying, your resignation will be accepted if you… et cetera. And then something pops and he pulls out his phone and pulls up a Bonnie Python’s skit like the School of Silly Walks or whichever John Cleese it was. And he starts laughing again and things break. So it’s almost as if he has different modes, the emulation of human mode, the engineering mode, the darkened demon mode, and certainly there is the silly and giddy mode.
Segment 87: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2813, Text: Yeah, you’ve actually opened the Elon book with the quotes from Elon and from Steve Jobs. So Elon’s quote is to anyone I’ve offended, I just want to say, this is on SNL, I just want to say I reinvented electric cars and I’m sending people to Mars on a rocket ship. Did you also think I was going to be a chill normal dude? And then the quote from Steve Jobs of course is the people who are crazy enough to think they can change the world are the ones who do. So what do you think is the role of the old madness and genius? What do you think the role of crazy in this?
Segment 88: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2850, Text: Well, first of all, let’s both stipulate that Musk is crazy at times, I mean. And then let’s figure out, and I try to do it through storytelling, not through highfalutin preaching, where that craziness works. Give me a story, tell me an anecdote, tell me where he is crazy. And the almost final example, AI, but him shooting off Starship for the first time and between an aborted countdown in the shoot off he goes to Miami to an ad sales conference and meets Linda Yaccarino for the first time, makes her the CEO. I mean there’s a very impulsiveness to him. Then he flies back, they launch Starship.
Segment 89: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2897, Text: And you realize that there’s a drive and there’re demons and there’s also craziness and you sometimes want to pull those out. You want to take away his phone so he doesn’t tweet at 3:00 AM. You want to say quit being so crazy. But then you realize there’s a wonderful line of Shakespeare in measure for measure at the very end. He says, even the best are molded out of faults. And so you take the faults of Musk, for example, which includes a craziness that can be endearing but also a craziness that’s just like effing crazy as well as this drive and demon mode. I don’t know that you can take that strand out of the fabric and the fabric remains whole.
Segment 90: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2952, Text: I wonder sometimes it saddens me that we live in a society that doesn’t celebrate even the darker aspects of crazy and acknowledging that it all comes in one package. It’s the man in the arena versus the critic.
Segment 91: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2968, Text: And the man in the arena versus the regulator to make it more prosaic.
Segment 92: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2975, Text: Well, let me ask about not just the crazy but the cruelty. So you’ve written when reporting as Steve Jobs, Woz told you that the big question to ask was did he have to be so mean, so rough and cruel, so drama addicted, what is this answer for Steve Jobs? Did he have to be so cruel?
Segment 93: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=2996, Text: For Jobs, I asked Woz at the end of my reporting because that’s what he said at the beginning. We’re doing the launch of I think the iPad 2, it may have been. Steve is emaciated because he’s been sick. And so I say to Woz, what’s the answer to your question? And he said, well, if I had been running Apple, I would’ve been nicer to everybody. Everybody got stock options. We’ve been like a family. And then I don’t know if you know Woz, he was like a teddy bear. He paused, he smiled and he said, but if I had been running Apple, I don’t think we would’ve done the Macintosh or the iPhone. So yeah, you have to sometimes be rough. And Jobs said the same thing that Musk said to me, which is he said, people like you love wearing velvet gloves. Now, I don’t know that I’ve worn velvet gloves often. But you like people to like you, like to sweet talk things, your sugarcoat things.
Segment 94: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3055, Text: He says, I’m just a working class kid and I don’t have that luxury. If something sucks, I got to tell people it sucks or I got a team of B players. Well, Musk is that way as well. And it gets back to what I said earlier, which is yeah, I probably would wear velvet gloves if I could find them at my haberdasher, and I do try to sugarcoat things. But when I was running CNN, it needed to be reshaped, it needed to be broken, it needed to have certain things blown up, and I didn’t do it. So bad on me, but it made me realize, okay, I’ll just write about the people who can do it.
Segment 95: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3096, Text: Well, that thing of saying, I think probably both of them, but Elon certainly saying things like that is the stupidest thing I’ve ever heard.
Segment 96: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3104, Text: By the way I’ve heard Jeff Bezos say that, I’ve heard Bill Gates say that, I’ve heard Steve Jobs say it. I’ve heard Steve Jobs say it about a smoothie. They were making it a whole food or something. I mean people, they used the word stupid really often. And you know who else used it? Errol Musk. He kept baking Elon stand in front of him and saying, that’s the stupidest thing, you’re the stupidest person, you’ll never amount to anything. I don’t know as John McNeil, the president of Tesla said, do you have to be that way? Probably not. There are a lot of successful people who are much kinder, but it’s sometimes necessary to be much more brutal and honest, brutally honest, I would say, than people like who win Boss of the Year trophies.
Segment 97: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3164, Text: Well, as you said, this kind of idea did also send a signal, this idea of Steve Jobs of a-players, it did send a signal to everybody. It was a kind of encouragement to the people that are all in.
Segment 98: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3177, Text: Right, and that happened at Twitter when we went to Twitter headquarters the day before the takeover, he was having Andrew and James, his two young cousins and other people from the autopilot team going over lines of code and Musk himself sat there with a laptop on the second floor of the building looking at the lines of code that had been written by Twitter engineers and they decided they were going to fire 85% of them because they had to be all in. And this notion of psychological safety and mental days off and working remotely. He said either… And then it came up, actually one of his, I think it was one of the cousins or maybe Ross Nordine came up with the idea of let’s not be so rough and just fire all these people. Let’s ask them, do you really want to be all in because this is going to be hardcore, it’s going to be intense, you get to choose. But by midnight tonight, we want you to check the box. I’m hardcore all in. I’ll be there in person. I’ll work as much. Or that’s not for me. I’ve got a family, I’ve got work balance. And you got different type of people that way in different stages of their life. I was a little bit more hardcore and all in when I was in my twenties than when I was in my fifties.
Segment 99: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3256, Text: And you write about this, this really nice idea actually that there’s two camps and you find out… I wonder how true this is, it rings true. That you can just ask people, which camp are you in? Are you the kind of person that prizes themselves that enjoy staying up till 2:00 AM programming or whatever, or do you see the value of work-life balance, all this kind of stuff? And it’s interesting, I mean people probably divide themselves in different stages of life and you could just ask them and it makes sense for certain companies at certain stages of their development to be like, we only want hardcore people.
Segment 100: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3297, Text: Or teams, it doesn’t even have to be a whole company. And you’re right, it goes back to what I was saying about rule. The first secret is sort of know thyself. Obviously it comes from Plato and everything comes from Plato and Socrates, but and decide in this stage of my life, do I want to be a hackathon all in all night and change the world or do I want to bring wisdom and stability but also have balance? I think it’s good to have different companies with different styles. The problem was Twitter was at almost one extreme with yoga studios and mental health days off and enshrining psychological safety as one of the mantras that people should never feel psychologically threatened. And I remember the bitter laugh he unleashed when he kept hearing that word. He said, no, I like the words hardcore. I like intensity. I like a intense sense of urgency as our operating principle. Well, yeah, there’re people that way as well. So know who you are and know what type of team you want to build.
Segment 101: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3369, Text: Versus psychological safety and too many birds everywhere.
Segment 102: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3373, Text: Oh yeah. A lot of times Musk did things and I go, what the hell? Among them was changing the name Twitter and getting rid of the birds? Man, it’s a lot invested in that brand. But when I watched him, he thought, okay, these sweet little chirpy birds tweeting away in the name Twitter. It’s not hardcore, it’s not intense. And so for better and for worse, I think he’s taking acts into the hardcore realm with people who post hardcore things with people with hardcore views. It’s not a polite play pen for the blue checked anointed elite. And I thought, okay, this is going to be bad. The whole thing’s going to fall apart. Well, it has had problems, but the hardcore intensity of it’s also meant that there’s new things happening there. So it’s very Elon Musk to not like the sweetness of birds chirping and tweeting and saying, I want something more hardcore.
Segment 103: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3445, Text: As you’ve written in referring to the previous Twitter CEO, Elon said Twitter needs a fire breathing dragon. I think this is a good opportunity to maybe go through some of the memorable moments of the Twitter saga as you’ve written about extensively in your book from the early days of considering the acquisition to how it went through to the details of like you mentioned, the engineering teams.
Segment 104: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3473, Text: Well, at the beginning of 2022, he was riding high, but as we say, he’s a drama addict, he doesn’t like to coast. And Tesla sold a million vehicles, I think 33 boosters, Falcon Nines have been shot up and landed safely in the past few months, and he was the richest person on earth and Times person of the year. And yet he’d said, I still want to put all my chips back on the table. I want to keep taking risks. I don’t want to savor things. He had sold all of his houses. So he starts secretly buying shares of Twitter. January, February, March. Becomes public at a certain point he has to declare it. And we were here in Austin at Gigafactory on the mezzanine and he was trying to figure out, well, where do I go from here? And at that time, this is early April, they were going to offer him a board seat and he was going to do a standstill agreement and stop at 10% or something.
Segment 105: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3542, Text: I remember we were standing around, it was Luke Nozik, whom you know well, Ken Howery, some of his friends on that mezzanine here. And all afternoon and then late into the evening at dinner is like, should we do this? And I didn’t say anything, I’m just the observer, but everybody else is saying, excuse me, why do you want to own Twitter? And Griffin, his son joined at dinner and May for some reason was in town. And everybody says, no, we don’t use Twitter. Why would you do that? And May said, well, I use Twitter.
Segment 106: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3576, Text: And it is almost like, okay, the demographics are people my age or May’s age. And so it looked like he wasn’t going to pursue it. They offered him a board seat and then he went off to Hawaii to Larry Ellison’s house, which he sometimes uses. He was meeting a friend, Angela Bassett, an actress, and instead of enjoying three days of vacation, he just became supercharged and started firing off text messages, including the fire breathing dragon one, I think he used that phrase a few times that Parag wasn’t the person who was going to take Twitter to a new level.
Segment 107: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3621, Text: And then by the time he gets to Vancouver where Grimes meets him, they stay up all night playing Elden Ring. He was doing a Ted Talk. And then at 5:30 he finishes playing the Elden Ring and sends out that I’ve made an offer. Even when he comes back, people are trying to intervene and say, excuse me, why are you doing it? And so it was a rocky period between late April and October when the deal closes. And people ask me all the time, well, did he want to get out of the deal? I said, which Elon are you talking about at what time of day? Because there’ll be times in the morning when he’d say, oh, the Delaware court’s going to force me to do it, it’s horrible. Talk to his lawyers. You can win this case. Get me out of it.
Segment 108: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3667, Text: He met here in Austin with three or four investment bankers, Blair Efron at Center View, Bob Steele at Perella Weinberg, and they offered him options, do you want to get out? Do you want to stay in? Do you want to reduce the price? And I think he was mercurial. There were times he would text me or say to me, this is going to be great. It’s going to be the accelerant to do x.com the way we thought about 20 years ago. And so it’s not until they finally tell them at the beginning of October, right when Optimus the robot is being unveiled in California actually, that the lawyer is saying, you’re not going to probably win this case, better go through with the deal. And by then he’s not only made his peace with it, he’s kind of happy with it at times.
Segment 109: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3717, Text: Eventually the deal is going to close on, I think a Friday morning, I have it in the book, and we’re there on Thursday and he’s wandering around looking at the Stay Woke t-shirts and psychological safety lingo they’re all using. And he and his lawyers and bankers hatched a plan to do a flash close. And the reason for that was if they closed the deal after the markets had closed for the day and he could send a letter to Parag and to others firing them, quote, for cause, and this’ll be something the courts will have to figure out, then he could save 200 million or so. And it was both the money, but for him, a matter, I won’t say of principle, but of, Hey, they misled me about the numbers. I got forced into doing it, so I’m going to try this jujitsu maneuver and be able to get some money out of them.
Segment 110: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3780, Text: Then when he takes over, it’s kind of a wild scene, him trying to decide in three different rounds how to get the staff down to 15% of what it was him deciding on Christmas Eve after he’d been at a meeting where they told him, we can’t get rid of that Sacramento server farm because it’s needed for redundancy. And he says, no, it’s not. And he’s flying here to Austin and young James says, why don’t we just do it ourselves? He turns the plane around, they land in Sacramento and he pulls them out himself. So it was a manic period.
Segment 111: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3815, Text: We should also say that underneath of that, there was a running desire to, or a consideration to perhaps start a new company to build a social media company from scratch.
Segment 112: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3828, Text: Well, Kimball wanted to do that, and Kimball here at a wonderful restaurant in Austin at lunch is like, Hey, why are you buying Twitter? Let’s start one from scratch and do it on the blockchain. Now, it took them a while and you can argue it one way or the other.
Segment 113: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3840, Text: Now, it took him a while and you can argue it one way or the other, to come to the conclusion that the blockchain was not fast enough in responsive time enough to be able to handle a billion tweets in a day or so. He gets mad when they keep trying to get them to talk to Sam Bankman-Fried, who’s trying to say, “I’ll invest, but we have to do it on the blockchain.” Kimball is still in favor of starting a new one and doing it on blockchain-based. In retrospect, I think starting a new media company would’ve been better. He wouldn’t have had the baggage or the legacy that he’s breaking now in breaking the way Twitter had been. But it’s hard to have hundreds of millions of true users, not just trolls, and start from scratch as others have found. There’s Mastodon and Blue Sky and Threads. Threads even had a base, so it would’ve been hard.
Segment 114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3903, Text: Yeah, and to do that in the way he did requires another part that you write about with the Three Musketeers and the whole engineering, the firing and the bringing in the engineers to try to go hardcore, so there’s a lot of interesting questions to ask there. But high level, can you just comment about that part of the saga, which is, bringing in the engineers and seeing what can we do here?
Segment 115: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3931, Text: Right. He brought in the engineers and figured that the amount of people doing Tesla full self-driving autopilot and all the software there was about 1/10 of what was doing software for Twitter. He said, “This can’t be the case,” and he fired 85% in three different rounds. The first was just firing people because they looked at the coding, and they had a team of people from Tesla’s autopilot team grading the codes of all that was written in the past year or so. Then he fired people who didn’t seem to be totally all in or loyal, and then another round of layoffs.
Segment 116: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=3974, Text: So at each step of the way, almost everybody said, “That’s enough, it’s going to destroy things,” from Alex Sparrow, his lawyer, to Jared Birchall, it’s like, “Whoa, whoa, whoa.” Even Andrew and James, the young cousins who are tasked with making a list and figuring out who’s good or bad, say, “We’ve done enough, we’re going to be in real trouble.” They were partly right. There was degradation of the service some, but not as much as half the services I use half the time. I wake up each morning and hit the app and okay, still there.
Segment 117: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4017, Text: What do you think? Was that too much?
Segment 118: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4019, Text: I think that he has an algorithm that we mentioned earlier that begins with question every requirement, but it’s up to is delete, delete, delete, delete every part there. Then a corollary to that is if you don’t end up adding back 20% of what you deleted, then you didn’t delete enough in the first round ’cause you were too timid. Well, so you asked me did he overdo it? He probably overdid it by 20%, which is his formula, and they’re probably trying to hire people now to keep things going.
Segment 119: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4054, Text: But it sends a strong signal to people that are hired back or the people that are still there, the APIs, yeah-
Segment 120: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4060, Text: Yeah, and what Steve Jobs and many other great leaders felt, and certainly Bezos, and certainly in the early days of Microsoft, Bill Gates, it was hardcore only A players.
Segment 121: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4072, Text: So how much of Elon’s success would you say, Elon’s and Steve Jobs’ success is the hiring and managing of great teams?
Segment 122: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4079, Text: When I asked Steve Jobs at one point, “What was the best product you ever created?” I thought he’d say maybe the Macintosh or maybe the iPhone. He said, “No, those products are hard. The best thing I ever created was the team that made those products, and that’s the hard part is creating a team,” and he did, from Jony Ive to Tim Cook and Eddie Cue and Phil Schiller. Elon has done a good job bringing in people, Gywnne Shotwell, obviously, Linda Yaccarino. She can navigate through the current crises, certainly stellar people at SpaceX like Mark Juncosa, and then at Tesla, like Drew Baglino and Lars Moravy and Tom Zhu and many others.
Segment 123: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4134, Text: He’s not as much of a team collaborator as say, Benjamin Franklin, who by the way, that’s the best team ever created, which is the founders. You had to have really smart people like Jefferson and Madison and really passionate people like John Adams and his cousin, Samuel, and really a guy of high rectitude like Washington. But you also needed a Ben Franklin who could bring everybody together and forge a team out of them and make them compromise with each other. Musk is a magnet for awesome talent.
Segment 124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4168, Text: Magnet, interesting. But there’s the priorities of hiring based on excellence, trustworthiness and drive. These are things you’ve described throughout the book. There’s a pretty concrete and rigorous set of ideas based on which the hiring is done.
Segment 125: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4190, Text: Oh, yeah. He has a very good spidey intuitive sense, just looking at people, not looking at them, but studying them, who could be good. One of his ways of operating is what he calls a skip-level meeting. Let’s take a very specific thing, like the Raptor engine, which is powering the Starship, and it wasn’t going well. It looked like a spaghetti bush, and it was going to be hard to manufacture, and he got rid of the people who were in charge of that team. I remember that he spent a couple of months doing what he calls skip-level, which means instead of meeting with his direct reports on the Raptor team, he would meet with the people one level below them. So he would skip a level and meet with them. I just asked them what they’re doing and I drill them with questions and he said, “This is how I figure out who’s going to emerge.” He said it was particularly difficult. I was sitting in those meetings ’cause people were wearing masks.
Segment 126: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4259, Text: It was during the height of COVID, and he said it made it a little bit harder for him because he has to get the input. But I watched as a young kid, dreadlocks, named Jacob McKenzie, he’s in the book, is sitting there. He’s a bit like you, engineering mindset, speaks in a bit of a monotone. Musk would ask a question and he would give an answer, and the answer would be very straightforward. He didn’t get rattled, he was like this. Musk said one day called him up at 3:00 AM, well, I won’t say 3:00 AM, but after midnight said, “You still around?” Jake said, “Yeah, I’m still at work.” He said, “Okay, I’m going to make you in charge of the team building Raptor,” and that was like a big surprise. But Jacob McKenzie has now gotten a version of Raptor and where they’re building them at least one a week and they’re pretty awesome. That’s where his talent, Musk’s talent, for finding the right person and promoting them, that’s where it is.
Segment 127: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4325, Text: Promoting it in a way where it’s like, “Here’s the ball. Here, catch,” and you run with it. I’ve interacted with quite a few folks from even just the Model X all throughout where people on paper don’t seem like they would be able to run the thing, and they run it extremely successfully.
Segment 128: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4346, Text: He does it wrong sometimes. He’s had a horrible track record with the solar roof division, wonderful guy named Brian Dow. I really liked him. When they were doing the battery factory surge in Nevada, Musk got rid of two or three people in. There’s Brian Dow can do, can do, can stays up all night, and he gets promoted and runs it. So finally Musk goes through two or three people running the solar roof division, finally calls up Brian Dow. I was sitting in Musk’s house in Boca Chica, that little tiny two bedroom he has, and he offers Brian Dow the job of running solar roof.
Segment 129: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4386, Text: Brian there, “Okay, can do, can do.” Two or three times, Musk insisted that they install a solar roof in one of those houses in Boca Chica. This is this tiny village at the south end of Texas. Late at night, I’d have to climb up to the top of the roof on these ladders and stand on this peaked roof as Musk is there saying, “Why do we need four screws to put in this single leg?” Brian was just sweating and doing everything, but then after a couple of months it wasn’t going well and boom! Musk just fired him. So I always try to learn what is it that makes those who stay thrive?
Segment 130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4431, Text: What’s the lesson there? What do you think?
Segment 131: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4433, Text: Well, I think it’s self-knowledge, like an Andy Krebs or others. They say, “I am hardcore. I really want to get a rocket to Mars, and that’s more important than anything else.” One of the people, I think it’s Tim Zaman. I hope when he hears this, I’m getting the right person, who took time, was working for Tesla Autopilot. It was just so intense, he took some time off and then went to another company. He said, “I was burned out at Tesla, but then I was bored at the next place. So I called,” I think it was, “Ashok at Tesla, said, ‘Can I come back?'” He said, ” Sure.” He said, “I learned about myself I’d rather be burned out than bored.”
Segment 132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4475, Text: That’s a good line. Well, can you just linger on one of the three that seem interesting to you in terms of excellence, trustworthiness, and drive? Which one do you think is the most important and the hardest to get at? The trustworthiness is an interesting one. Are you ride or die kind of thing?
Segment 133: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4493, Text: Yeah, I think that especially when it came to taking over Twitter, he thought half the people there were disloyal, and he was wrong. About 2/3 were disloyal, not just half. It was how do we weeded out those? He did something and made the Firing Squad, I call it, or the Musketeers I think is my nickname for them, which is the young cousins and two or three other people, he made them look at the Slack messages everybody at Twitter had posted, and they went through hundreds of Slack messages. So if anybody posted on the internal slack, ” That jerk Elon Musk is going to take over and I’m afraid that he’s a maniac or something,” they would be on the list because they want all-in loyal. They did not look at private Slack messages.
Segment 134: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4545, Text: I guess people who are posting on a corporate Slack board should be aware that your company can look at them. But that’s more than I would’ve done or most people would’ve done, and so that was to figure out who’s deeply committed and loyal. I think that was mainly the case at Twitter. He doesn’t sitting around at SpaceX saying, “Who’s loyal to me? At other places, it’s excellence, but that’s pretty well a given. Everybody is like a Mark Juncosa just whip smart. Its, “Are you hardcore and all in?” Especially if you’re going to have to move to this spit of a town in the south tip of Texas called Boca Chica, you got to be all in.
Segment 135: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4592, Text: Yeah, and that’s the drive, the last piece. So you, in terms of collaborating, one of the great teams of all time, Ben Franklin, I like that. I thought it was The Beatles, but Ben Franklin is pretty good.
Segment 136: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4605, Text: Oh, no, no, no.
Segment 137: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4606, Text: I’m sorry.
Segment 138: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4606, Text: Yeah.
Segment 139: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4607, Text: Sorry to offend you so [inaudible 01:16:48]
Segment 140: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4608, Text: Read the Constitution and read Abbey Road, look at Abbey Road, they’re both good, but they’re in a different league.
Segment 141: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4613, Text: Yeah, a different league. Okay. So one of the many things that comes to mind with Ben Franklin is incredible time management. Is there’s something you could say about Ben Franklin and about Steve Jobs? I think interesting with Elon is that he, as you write, runs six companies, seven, it depends how you count with Starlink ’cause its own thing. I don’t know. What can you say about these people in terms of time management?
Segment 142: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4644, Text: Well, Musk is in a league of his own in the way he does it. First of all, Steve Jobs had to run Pixar and Apple for a while, but Musk every couple of hours is switching his mindset from how to implant the Neuralink chip and what will the robot that implants it in the brain look like and how fast can we make it move? Then the heat shield on the Raptor or switching to human imitation, machine learning, full self-drive. On the night that the Twitter board agreed to the deal, this is huge around the world. I’m sure you remember like, “Musk buys Twitter.” It wasn’t when the deal closed, it was when Twitter accepted his offer. I thought, “Okay,” but then he went to Boca Chica, to South Texas and spent time fixating on, if I remember correctly, a valve in the Raptor engine that had a methane leak issue and what were the possible ways to fix it. All the engineers in that room, I assume, or thinking about, “This guy just bought Twitter, should we say something?”
Segment 143: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4728, Text: Then he goes with Kimball to a roadside joint in Brownsville and just sits in the front and listens to music with nobody noticing really him being there. One of his strengths and sort of weaknesses in a way is in a given day, he’ll focus serially, sequentially, on many different things. He will worry about uploading video on to X.com or the payment system and then immediately switch over to some issue with the FAA giving a permit for Starship or with how to deal with Starlink and the CIA. When he’s focused on any of these things, you cannot distract him.
Segment 144: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4781, Text: It’s not like he’s also thinking about, “I’m dealing with Starlink, but I’ve got to also worry about the Tesla decision on the new $25,000 car.” Now, he’ll in between these sessions, process information, then let off steam. For better or worse, he lets off steam by either playing a friend in Polyopia or fire off some tweets, which is often not a healthy thing, but it’s a release for him. I once said he was a great multitasker and that was a mistake, people corrected me. He’s a serial tasker, which means focuses intensely on a task for an hour, almost has a, what do they call it at restaurants where they give you a-
Segment 145: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4830, Text: Pallet cleanser.
Segment 146: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4831, Text: … pallet cleanser? He does some pallet cleanser with Polytopia and then focuses on the next task.
Segment 147: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4838, Text: Is there some wisdom about time management that you can draw from that?
Segment 148: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4842, Text: There’s some things that these people do and you say, “Okay, I can be that way. I can be more curious. I can question every rule and regulation.” I just don’t think anybody should try to emulate Musk’s time management style because it takes a certain set of teams who know how to deal with everything else other than the thing he’s focusing on and a certain mind that can shift just like his moods can shift. You and I go through transitions, and also if I’m thinking about what I’m going to say on this podcast, I’m also thinking about the email my daughter just sent about a house that she’s looking, and I’m multitasking. He doesn’t actually do that. He single tasks sequentially with a focus that’s hardcore.
Segment 149: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4893, Text: I don’t know. I think there’s wisdom to draw from that to first of all, he frankly, makes me feel that way, that there’s a lot of hours in the day. There’s a lot of minutes in the day. There’s no excuse not to get a lot done, and that requires just an extreme focus, an extreme focus and an urgency.
Segment 150: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4914, Text: I think the fierce urgency that drives him is important, and it’s sometimes genned up, like I say, the fierce urgency of getting to Mars. On a Friday night at the launchpad in Boca Chica at 10:00 PM there are only a few people working ’cause it’s a Friday night, they’re not supposed to launch for another eight months, and he orders a surge. He says, “I want 200 people here by tomorrow working on this pad. We have to have a fierce sense of urgency or we will never get to Mars.”
Segment 151: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4951, Text: That sense of urgency is also a vibrancy that’s really taking on life fully. To me, that’s the lesson is even the mundane can be full of this just richness, and you just have to really take it in intensely. So like the switching enables that kind of intensity ’cause most of us can’t hold that intensity in any one task for prolonged period of time. Maybe that’s also a lesson.
Segment 152: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4985, Text: Right. I guess it goes back to also know who you are, meaning-
Segment 153: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4989, Text: Know who you are.
Segment 154: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=4989, Text: … there are people who can focus intensely, and there are people who can see patterns across many things. Look, Leonardo da Vinci, he was not all that focused. He was easily distracted.
Segment 155: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5003, Text: Procrastinated.
Segment 156: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5004, Text: It’s why he has more unfinished paintings than finished paintings in his canon. But his ability to see patterns across nature and to, in some ways, process procrastinate, be distracted, that helped him some. But Musk is not that way, and every few months there’s a new surge. You don’t know where it’ll be, but you’ll be on solar roofs and all of a sudden, we’ll have a surge and there has to be 100 solar roofs built, or this has to be done by tomorrow or make a Starship dome by dawn and surge and do it. There are people who are built that way. It is inspiring, but also let’s appreciate that there are people who can be really good but also can savor the success, savor the moment, savor the quiet sometimes. Musk’s big failing is he can’t savor the moment or success, and that’s the flip side of hardcore intensity
Segment 157: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5080, Text: In Innovators, another book of yours that I love, you write about individuals and about groups. So one of the questions the book addresses is, is it individuals or is it groups that turn the tides of history?
Segment 158: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5095, Text: When Henry Kissinger was on the shuttle missions for the Middle East piece, this is the first book I ever wrote, he said, “When I was a professor at Harvard, I thought that history was determined by great forces and groups of people. But when I see it up close, I see what a difference an individual can make.” He’s talking about Sadat and Golda Meir or probably talking about himself too, or at least in his mind. We biographers have this dirty secret that we know. We distort history a bit by making the narrative too driven by an individual, but sometimes it is driven by an individual. Musk is a case like that. Sometimes, as I did with The Innovators, there’s teams and people who build on each other and Gordon Moore and Bob Noyce then getting Andy Grove and doing the microchip, which then comes out and Wozniak and Jobs find it at some electronic store and they decide to build the Apple. So sometimes they are flows of forces and groups of people.
Segment 159: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5166, Text: I guess I err a little bit on the side of looking at what a Steve Jobs and Elon Musk and Albert Einstein can do. I also try to figure out if they hadn’t been around, would the forces of history and the groups of people have done it without them? That’s a good historical question, as somebody who loves history. You think about special relativity, one of the 1905 papers. Even after he writes it, it’s four years before people truly get what he’s saying, which is, “It’s not just how you observe time is relative, it’s time itself is relative.” On the general theory, which he does a decade later, I’m not sure we would gotten that yet. What about moving us into the era of an iPhone and which it’s so beautiful that you can’t live without 1,000 songs in your pocket, email and the internet in your pocket and a phone? There are a lot of brain-dead people from Panasonic to Motorola who didn’t get that, and it may have been a while.
Segment 160: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5233, Text: I certainly think it’s true of the era of electric vehicles. Jim and Ford, all the great people there, they crushed the Bolt, and I mean that literally. They ended up smashing them because they decided to discontinue it. Likewise, nobody was sending up rockets. Our space shuttle was about to be grounded 12 years ago. So Musk does things, and there’ll be people who say and read the book… Well, if they read the book, they’ll see the full story, but they’ll say, “It wasn’t Musk who did Tesla, it was Martin Eberherd or Marc Tarpenning.” No, no. There were people who had helped create the shells of companies and other things, and they were all deserved to be called co-founders. But the guy who actually gets us to a million electric vehicles a year is Elon Musk, and without him, I don’t think we… Look, if anybody five years from now buys a car that’s gasoline powered, we’ll think, “That’s quaint. That’s odd.” Suddenly, we’ve changed. We’re not going to do it. 90% of that is Elon Musk.
Segment 161: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5306, Text: We’re all mortal. When and how do you think Elon will retire from the insanely productive schedule he’s on now?
Segment 162: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5315, Text: I would think that he would hate to retire. I think that he can’t live without the pressure, the drama, the all-in feeling. It’s never been anything that seemed to have crossed his mind. He’s never said, “Maybe I love Larry Ellison’s house on the beach in Hawaii. Maybe I should spend time in doing.” Instead, he says things like, “I learned early on that vacations will kill you.” He goes on vacation at one point, and they oust him from PayPal. Then he goes to Africa at one point, he gets malaria. He says, “I’ve learned vacations kill you.”
Segment 163: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5357, Text: Lesson learned. Well, it’s interesting because the projects are 100+ year projects, many of these.
Segment 164: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5364, Text: One of the weird things is watching him think incredibly long term. One of the meetings every week early on when I was watching him was Mars colonizer. We did through a two-hour meeting about what would the governance structure be on Mars? What would people wear? How would the robots work and would there be democracy or should there be a different form of governance? I’m sitting there saying, ” What are they doing? What are they talking about? They’re trying to build rocket ships and everything else. They are worrying about the governance structure of Mars?” Likewise, whenever he’s in a tense moment, like there’s a rocket’s about to be launched, he’ll start asking people about something in the way future, like the new elite engine or something.
Segment 165: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5423, Text: “If we’re going to build that, do we have enough materials ready to order?” Or, I don’t know, he’ll just ask questions. Like when he’s building robo taxi, the global car, the $25,000 inexpensive global car, that’s not a total passion. He was talked into doing that. His passion is robotaxis, but his passion is how are we going to make this factory to do a million cars a year? So even the robotaxi is a longer range vision. He’s been touting it since 2016, but there are no robotaxis. Waymo may be doing a little experiment on it, but there’s not cars being manufactured without steering wheels that are going to take over the highways yet. So he’s always looking way into the future is my point.
Segment 166: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5477, Text: I just hope that there’s a lot of da Vincis and Steve Jobs and Einsteins and Elon Musks that carry the flame forward.
Segment 167: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5488, Text: That’s one of the reasons you write books about these people is so that if you’re a young woman in a school where you’re not being told to do science and you read The Code Breaker about Jennifer Doudna, you say, “Okay, I can be that.” When you say, “Oh, maybe I’ll be a regulator,” or you say, “Oh, no, maybe I’ll be the person who pushes the boundaries, who pushes the lines, who pushes as Steve Jobs said, the human race.”
Segment 168: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5517, Text: Well, let me ask you about your mind, your genius, your process?
Segment 169: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5524, Text: I’ll give you two out of three.
Segment 170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5525, Text: All right. Take me through your process of writing a biography, the full of it. Not just writing a biography, but understanding deeply, which your books have done for the human story and the bigger ideas underlying the human story. So you’ve written biographies both of individuals, which are hardly individuals, it’s a really big complex picture and biographies of ideas that involve individuals.
Segment 171: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5559, Text: Well, step one for me is trying to figure out how the mind works. What causes Einstein to make that leap, for Elon Musk to say stainless steel while he’s looking at a carbon fiber rocket? Or how do you make the mental leap? Because I write about smart people, smart people are a dime a dozen. They don’t usually amount to much. You have to be creative, imaginative, to think different, as Jobs would say. So what makes people creative? What makes them take imaginative leaps? That’s the key question you got to ask. You also ask the questions like you’ve asked earlier, which is, what demons are dangling in their head, and how do they harness them into drives? So you look at all that, and you try to observe really carefully the person.
Segment 172: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5609, Text: One of the more mundane things I do is a lot of writers try to give you a lot of their opinions and preach or whatever. As this mentor said two people types come out, preachers, storytellers, to be a storyteller. I try, whenever I’m trying to convey a thought, there’s six magic words that I almost should have written on a card pinned above my desk, which is, “Let me tell you a story.” So if somebody says, “How does Elon Musk figure out good talent?” As you did, I think, “Well, let me tell you the story. I’ll tell you the story of Jake McKenzie,” or this is not something I invented.
Segment 173: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5665, Text: This is way the good Lord does it in the Bible, has the best opening lead sentence ever, “In the beginning,” comma, and then it’s stories. Secondly, to pick up on that lead sentence, “In the beginning,” make it chronological. Everybody in the 40th year of their life has grown from the 39th year and the 38th year, and so you want to show how people evolve and grow. I had the greatest of all nonfiction narrative editors, Alice Mayhew at Simon Schuster, who among other things, created All the President’s Men with Woodward and Bernstein. But she had a note she’d put in the margins of my books, that was a tickta, and it meant, “All things in good time. Keep it chronological. If it’s good enough for the Bible, it’s good enough for you.”
Segment 174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5716, Text: Interesting. To me, that’s a small note, but to you it’s extremely important.
Segment 175: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5721, Text: Because it’s the framework for how you structure things, but also how you understand things, which is if you keep it a chronological narrative, then you’re showing how a person has grown from one experience you’ve talked about to the next one. That moral growth, creative growth, risk-taking, growth, wisdom, that’s the essences of creativity, but you can’t do it… There’s a term buildings woman, which is a book that carries a narrative and tells how people learn something. I’m a big believer in narrative. If you-
Segment 176: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5760, Text: People learn something. I’m a big believer in narrative. If you are an academic, you sometimes, not today, but in like 20 years ago, 30 years ago, there were two things you thought were bad. One was having a great person theory of history in which you decided to do biography. I had a great professor when I was in college. Her name was Doris Kerns. She later married Dick Goodwin and when she was going for tenure at the university, wrote a biography of Lyndon Johnson & the American Dream, and they denied her tenure because it was beneath the dignity of the academy to write history through one person.
Segment 177: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5806, Text: That’s great. It opened up the field of biography to us non-academics, starting with David McCullough, Bob Caro, but maybe John Meacham and myself are in a new generation, and certainly there’s a generation coming after us. But the second thing besides telling it through people, which is the academy tended to disdain what they called imposing a narrative in which you made it storytelling because that meant you were leaving things out and making it into a narrative. Well, that’s how we form our views of the world.
Segment 178: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5850, Text: Well, let me ask you this question. In terms of gathering and understanding, how much of it is one observing and how much of it is interviews?
Segment 179: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5864, Text: Yeah, and obviously depends on the subject. With a Ben Franklin, it’s all based on archives and every, of course, we have 40 volumes of letters he wrote. That was the good old days when every day you’d write 20 letters. The Musk book is based much more on observation than almost any of my books, because he opened up in a way that was breathtaking to me. Even when he would be sitting blank polytopia or seething at other people, he’d have me just sitting there watching. I spent a lot of time with Jennifer Doudner at her side. I went to her lab and edited a human gene and with a pipette and a test tube.
Segment 180: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5908, Text: But I would say I spent 30 hours with her. I can count a hundred hours or more just observing Musk. And I’m not sure that any biographer, perhaps since Boswell took on Dr. Johnson has ever had quite as much up close meaning five feet away at all times access and because of that I’ll go back to what I said a moment ago. I try to get out of the way of the story. It’s not about me, it’s not about… I try to just say, “Okay, here’s what happened. Here’s this story. Here’s what happened the night he came in to Twitter for the first time,” and let you form your own judgment.
Segment 181: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5958, Text: What about the interviews? You’ve had a lot of conversations. You give acknowledgement to the people you’ve done interviews with. Well, one, I have to ask as an aspiring interviewer myself, how?
Segment 182: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=5976, Text: People love to talk. People just love, you know that. And I’ve had 140, maybe 150 people, they’re all listed in the back. One of the little things that people won’t notice, but I’ll say it now, is all of them are on the record. Getting them to talk is easy. They all want to talk about Musk, but then at a certain point say, I don’t put anonymous quotes in my book, I cite things. I say if you’re tough enough and you’ve gone through this, and a lot of times it takes two or three calls back, somebody will tell me a story say, oh, no, no, no, I don’t [inaudible 01:40:11]. But I think it’s important to know where everything came from. And with Musk it’s, I had that from the very beginning because I was a Time Magazine reporter. I’d worked reporter for the Times Picayune or New Orleans.
Segment 183: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6026, Text: First day on the job, I had to go cover a murder. And I phoned in the story from a payphone and my editor, the city editor, said, “Well, did you talk to the family?” I went, “No, Billy, I mean the family, the daughter just got…” He said, go knock on the door. I knocked on the door. An hour later, they were still talking. They were bringing out her yearbooks. Lesson one, I learned people want to talk if you’re willing to just listen, and whether it be Henry Kissinger, you just push the button and say Kissinger, and people tell you the stories all the way through Elon Musk, everybody talked, everybody in his family, everybody he fired, everybody. I think it’s important to listen to people. And the other thing I learned as a reporter, back when I was covering politics in New Hampshire in the early campaigns, I learned from two or three great reporters, a guy named David Broder and Tim Russert, the late NBC guy.
Segment 184: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6082, Text: They do what was called door knocking. You just walk in a neighborhood, knock on a door and asked people about the election. But they said here’s the secret. Don’t ask any leading questions. Don’t have any premise. Just say, “Hey, I’m trying to figure out this election. What’s going on? What do you think?” And then stay silent. With Musk a third secret, you know this well, he’ll go silent at times, sometimes a minute, two minutes, four minutes. Don’t try to fill the silences. If you’re a listener, you got to learn, okay, he’s not said anything for four minutes. I can outlast him.
Segment 185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6123, Text: It’s tough, as humans it’s very tough. Respecting the silence is really, really difficult. Speaking of demons, when there’s silence, all the demons show up in my head.
Segment 186: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6133, Text: Oh dear.
Segment 187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6134, Text: The fear I think is if I don’t say anything is boring, and if I say something, it’s going to be stupid. And that the basic engine that just keeps running, not on the podcast, well on the podcast, but also in human interaction. And so I think there’s that nervous energy when interacting with people.
Segment 188: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6151, Text: You can never go wrong by staying silent if there’s nothing you have to say. Not something I’ve mastered, but I do when I’m a reporter, try to master that, which is don’t ask complex questions, don’t interject and when somebody hasn’t fully answered the question, don’t say, well, let me, you know I haven’t fully… You just stay silent. And then they’ll keep talking.
Segment 189: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6182, Text: Just give them a chance to keep talking, even if they’ve kind of finished, you still.
Segment 190: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6186, Text: Yeah. Sometimes if they haven’t given you enough, instead of following up, I’ll just nod and keep waiting.
Segment 191: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6193, Text: You’re making it sound simple. Is there a secret to getting people to open up more?
Segment 192: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6198, Text: I’m somewhat lucky because I started off working for a daily newspaper and people back then they wanted to talk to the newspaper reporter.
Segment 193: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6210, Text: But you also have a way about you. I feel like you have a cowboy in a saloon. You just kind of want to talk. Like there’s a draw to, I don’t know what it is. I don’t know if it’s developed or you’re born with it, but it feels like I want to tell you a story of some sort.
Segment 194: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6226, Text: Good, tell me a story. A couple things. I did learn to be more quiet. I’m sure I know when I was younger or even I’ll see videos of me at news things where I’m always trying to interject a question and so you learn to be quieter sometimes. I haven’t mastered it. I haven’t learned it enough. You learn to be naturally curious. Many reporters today when they ask a question or either trying to play gotcha or trying to get a news scoop or trying to gig something that can make a lead. And if you actually are curious and you really want to know the answer to a question, then people can tell that you asked it because you want the answer, not because you’re playing a game with them.
Segment 195: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6290, Text: I’m sure some of them off the record, some of them on the record, you had maybe just some incredible conversations. I was going to say some of the greatest conversations ever, but who knows? Some of the best conversations ever are probably somewhere in South America between two drunk people that we never get to hear. So I don’t know, but is there advice you can give from what you’ve learned to somebody like me on how to have good conversation, especially when it’s recorded?
Segment 196: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6321, Text: Well, to be actually curious. Every question you’ve asked me is because I think you actually want to know the answer, and you’ve done your homework to be open and not to have an agenda. We all suffer from there being too many agendas in the world today.
Segment 197: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6341, Text: Yeah. So that’s just genuine curiosity. But there’s something when you talk about just one-on-one interaction, whether it’s Elon or Steve Jobs or there’s something beautiful about that person’s mind, and it feels like it’s possible to reveal that, to discover that together efficiently and that’s kind of the goal of a conversation.
Segment 198: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6371, Text: Well, look, you are amongst the top podcasters and interviewers in the world today. You have an earnestness to you. Ben Franklin is the person who taught me by reading him the most about on conversation. He wrote a wonderful essay on that. It includes on silence, but it includes trying to ask sincere questions rather than get a point across. It’s somewhat Socratic, but whenever he wondered or wanted to start a Fireman’s Corps in Philadelphia, he would go to his group that he called the Leather Apron Club, and they would pose a question, why don’t we have it? What would it take? What would be good? And then the second part is to make sure that you listen. And if somebody has even just the germ of an idea, give them credit for it. As Joe said, the real problem is this. And I do think that if I’m in situations and I just mean even at dinner or something, I’m with somebody, I’m usually curious and the conversation will proceed with questions.
Segment 199: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6466, Text: And I guess it’s also because I’m pretty interested in what anybody’s doing, whoever I happen to be with. And so that’s a talent you have, which is, you’re pretty genuine in your interests. There are people like Benjamin Franklin, like the, I’ll say Charlie Rose, even though he’s in disfavor who are interested in huge number of subjects, and I think that helps as well to be interested in basketball and opera and physics and metaphysics. That was a Ben Franklin. That was a Leonardo trick, which is they wanted to know everything you could possibly know about every subject knowable.
Segment 200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6509, Text: But there’s a different aspect of this, which is that I would love to hear how you’ve solved it or if you’ve faced it, that you’re certainly disarming. See, I’m like peppering you with compliments here, trying to get you to open-
Segment 201: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6525, Text: That’s a very disarming method.
Segment 202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6526, Text: Yeah. I’ve recently talked to Benjamin Netanyahu, we’ll talk again. We unfortunately, because of scheduling and complexities only had one hour, which is very difficult, very difficult with the charismatic politician.
Segment 203: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6538, Text: He’s the prime minister.
Segment 204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6539, Text: I understand this, but he’s also a charismatic talker, which is very difficult to break through in one hour. But there, people have built up walls, whether it’s because of demons or because of they’re politicians, and so they have agendas and narratives and so on. And so to break through those, I wonder if there’s some advice, some wisdom you’ve learned on how to wear down through water or whatever method the walls that we’ve built up as individuals.
Segment 205: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6573, Text: You call it disarming, which I don’t know that I am, but disarming basically means you’re taking down their shields also. And you know when people have a shield and you try to give them comfort. I had zero of that problem with Elon Musk. It was disarming to me, which is I kept waiting to say, okay, he’s not going to, they’ve got a shell or he won’t do that. But he was almost crazily open and did not seem to want to be spinning or hiding or faking things. And I’ve been lucky. Doudna was that way. Steve Jobs was that way. But you have to put in time too. In other words, you can’t say, okay, there’s a one-hour interview and I’m going to break down every wall. It’s like on your fifth visit.
Segment 206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6638, Text: Yes. Well, actually, there’s one of the things that my situation, you learn, fifth visit is very nice, but sometimes you don’t get a fifth visit. Sometimes it’s just the first date. And I think what it boils down to, and we said disarming, but there’s something about this person that you trust. I think a lot of it just boils down to trust in some deep human way. I think with many other people I’ve spoken with, sometimes the trust happens after the interview, which is really sad because it’s like, oh man.
Segment 207: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6673, Text: I’ve never been in your situation where I have a show. I usually have-
Segment 208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6679, Text: Second-
Segment 209: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6679, Text: … mini cracks at the wheel. Yes, I’m not a first date person.
Segment 210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6683, Text: Yeah, Yeah. Yeah. Well, you know.
Segment 211: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6685, Text: But then I’m lucky. I say lucky, but I’m in print.
Segment 212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6685, Text: I understand.
Segment 213: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6688, Text: Print is a couple thousand year old medium, but there are those of us who love it.
Segment 214: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6695, Text: Well, the nature of the podcast medium is that I’m a one night stand kind of girl. Let me ask you about objectivity. You followed Elon and you follow Steve, like you’ve, I don’t even know if you would say your friend. You have to be careful with words like that, because there’s an intimacy and how do you remain objective. Do you want to remain objective while telling a deeply human story?
Segment 215: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6723, Text: Yeah, I want to be honest, which I think is akin to being objective. I try to keep in mind who am I writing for? I’m not writing for Elon Musk, as I say, I haven’t sent him the book. I don’t know if he, don’t think he’s read it yet. I’ve got one person I’m writing for, the open-minded reader. And if I can put in a story and say, well, that will piss off the subject, or that will really make the subject happy, that’s irrelevant, or I try to make that a minor consideration. It’s, will the reader have a better understanding because I’ve put this story in the book?
Segment 216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6777, Text: I’m a bit of a romantic. So to me, even your Einstein book had lessons on romance and relationships.
Segment 217: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6787, Text: Ooh, dear.
Segment 218: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6789, Text: So how important are romantic relationships to the success of great men, great women, great minds?
Segment 219: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6795, Text: Well, sometimes people who affect the course of humanity have better relationships with humanity than they do with the humans sitting around them. Einstein had two interesting relationships with wives. Mileva, his first wife was a sounding board and helped with the mathematics of the special relativity paper in particular. But he didn’t treat her well. He made her sign a letter that she wouldn’t interrupt him. She wouldn’t… And finally, when she wanted a divorce, he couldn’t afford it because he was still a patent clerk. And so he offered her a deal, which is I think totally amazing. He said, one of these days one of those papers from 1905 is going to win the Nobel Prize. If we get a divorce, I’ll give you the money.
Segment 220: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6856, Text: That was a lot of money back then, like a million dollars now or something. And she’s smart, she’s a scientist. She consults with a few other scientists, and after a week or so, she takes the bet. It’s not until what, 1919, that he wins his Nobel Prize and she gets all the money. She buys three apartment buildings in Zurich. With his second wife, Elsa, it was more a partnership of convenience. It was not a romantic love, but he knew, and that’s sometimes what people need in life is just a partner. Somebody who’s going to handle the stuff you’re not going to handle. So I guess if you look at my books, they’re not great inspiring guides to personal relationships.
Segment 221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6906, Text: Let me ask you about actually the process of writing itself. When you’ve observed, when you’ve listened, when you’ve collected all the information, what’s maybe even just the silly mundane question of what do you eat for breakfast before you start writing? When do you write?
Segment 222: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6923, Text: First of all, breakfast is not my favorite meal. And those people who tell you that you have to start with a hardy breakfast, I look askance.
Segment 223: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6923, Text: Yes.
Segment 224: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6934, Text: And morning is not my favorite day part so I write at night and because I love narrative, it’s easy to structure a book, which is I can make a outline that if I printed it out or notes would be a hundred pages, but everything’s in order. In other words, if there’s a burning man and he’s coming back from grimes and then there’s a solar roof thing, and then there’s something, I put it all in order day by day as an outline. And that disciplines me when I’m starting to write to follow the mantra from Alice Mayhew, my first editor, which is all things in good time.
Segment 225: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=6980, Text: Don’t get ahead of the story, don’t have to flash back. And then after you get it so that it’s all chronological and those things, then you have to do some clustering. You have to say, okay, we’re going to do the decision to do Starship or to build a factory in Texas or to whatever. And then you sometimes have the organizational problem of, yeah, and that gets us all the way up to here. Do I keep that in that chapter or do I wait until later when it’s better chronologically? But those are easy.
Segment 226: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7017, Text: Well, what about the actual process of telling the story?
Segment 227: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7022, Text: Well, that’s the mantra I mentioned earlier, which is whenever I get pause or I don’t know how to say something, I just say, let me tell you a story. And then I find the actual anecdote, the story, the tale that encompasses what I’m trying to convey. And then I don’t say what I’m trying to convey. I don’t have a transition sentence that says Elon sometimes changes his mind so often he couldn’t remember whether he had changed his mind. You don’t need transition sentences. You just say, all right, here’s the point I need to make next and so you start with a sentence that says, one day in January in the factory in Texas comma.
Segment 228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7071, Text: Well, one of the things I’d love to ask you is for advice for young people. To me, first advice would be to read biographies in the sense because they help you understand of all the different ways you can live a life well lived. But from having written biographies, having studied so many great men and women, what advice could you give to people of how to live this life?
Segment 229: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7103, Text: Well, I keep going back to the classics and Plato and Aristotle and Socrates, and I guess it’s Plato’s maxim but he may be quoting Socrates that the unexamined life is not worth living. And it gets back to the know thyself and other things, which is you don’t have to figure out what is the big meaning of it all, but you have to figure out why you’re doing what you’re doing and that requires something that I did not have enough of when I was young, which is self-awareness and examining every motive, everything I do.
Segment 230: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7147, Text: Where does the examination lead you? Is it to a shift in life trajectory?
Segment 231: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7159, Text: It’s not for me sort of, all right, I’ve now decided having been a journalist, I’ll run a think tank or I’ll run a network or I’ll write a bio. It is actually something that’s more useful on an hourly basis. Why am I about to say that to somebody or why am I going to do this particular act? What’s my true motive here? And also in the broader sense to learn as I did after a couple of years at CNN, my examination of my life is that I’m not great at running complex organizations. I’m not great as a manager. Given the choice I’d rather somebody else have to manage me than me have to manage people.
Segment 232: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7211, Text: But it took me a while to figure that out. And I was probably too ambitious when I was young and at Time Magazine, that was when I was green and well, that was when I was in my salad days and green in judgment, and it was like chasing the next level at Time Incorporated whatever it might be. And then one day I caught the brass ring and I became an editor and then the top editor. And after a while I realized that wasn’t really totally what I’m suited to be, especially when I got put in charge of CNN. All young people are almost by definition in their salad days and green in judgment. But you learn what’s motivating you and then you learn to ask, but is that really what I want? Should I be careful of what I’m wishing for?
Segment 233: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7273, Text: One of the big examinations you can do is the fact that you and everybody dies one day. How much you Walter Isaacson think about death? Are you afraid of it?
Segment 234: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7286, Text: No, and I don’t think about it a lot, but I do think about Steve Jobs as, let me tell you a story, which is the wonderful Steve Jobs story of I think after he was diagnosed, but before it was public. And he gave both a Stanford talk, but other things in which he said, the fact that we are going to die gives you focus and gives you meaning. If you’re going to live… And Elon Musk has said that to me, which is a lot of the tech bros out in the Silicon Valley that looking for ways to live forever, I can think Musk says of nothing worse. We read the myth of Sisyphus and we know how bad it is to be condemned to eternal life. So there was in Ancient Greece, the person who walked behind the king and said, memento mori, remember you’re going to die. And it kept people from losing it a bit.
Segment 235: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7349, Text: Do you think about legacy?
Segment 236: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7350, Text: The lucky thing about being a biographer is that you know what your legacy is. There’s going to be a shelf and it’ll be of interesting people and you’ll have inspired a 17 year old biology student somewhere to be the next great biochemist or somebody to start a company like Elon Musk. And what I think more about, I won’t say giving back, that’s such a trite thing. I moved back to New Orleans for a reason. First of all, the hurricane hit and after Katrina I was asked to be vice chair of the Recovery Authority and I realized everything I’ve got going for me, it all comes from this beautiful gem of a troubled city. The wonderful high school I went to, the wonderful streets where I learned to ride a bike and it’s got challenges. I’m never going to solve challenges at the grand global level, but I can go back home and say, part of my legacy is going to be, I tried to pay it back to my hometown even by teaching at Tulane, which I don’t do as a favor.
Segment 237: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7433, Text: I enjoy the hell out of it, but it’s like, all right, I’m part of a community. And I think we lose that in America because people who are lonely are lonely because they’re not part of a community. But I’ve got all my high school kids, they’re friends, they’re all still in New Orleans. I’ve got my family, but I also have Tulane, institutions in New Orleans that have been there forever. And if I can get involved in helping the school system in New Orleans, of helping the youth empowerment programs, of helping the innovation center at Tulane, I was even on the City Planning Commission, which worries about zoning ordinances for short- term rentals. Go figure.
Segment 238: Speaker: , Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7473, Text: But it was like no, immerse myself in my community because my community was just so awesomely good at allowing me to become who I became and has trouble year by year, hurricane by hurricane, making sure that each new generation can be creative and it’s a city of creativity from jazz to the food, to the architecture. So when I think of, I won’t say legacy, but what am I going to do to pay it forward, which is a lower level way of saying legacy, I pay it forward by going back to the place where I began and trying to know it for the first time. That was a ripoff of a T.S. Eliot line. I don’t want you to think I thought of that one.
Segment 239: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7523, Text: Always cite your sources. I appreciate it.
Segment 240: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7524, Text: T.S. Eliot, if you ever need to figure it out, the four quartets, it’s that part at the end which is, “We shall not cease from exploration and the end of all of our exploring will be to return to the place where we started and know it for the first time. Through the unknown but half remembered gate.” It’s just beautiful. And that’s been an inspiration of what do you do in, I guess if it’s a Shakespeare play, you’d call it act five. Well, you go back to the place where you came and-
Segment 241: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7561, Text: See for yourself.
Segment 242: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7561, Text: … so you don’t sit there worrying about legacy, but you’ll sit there saying, how do I make sure that somebody else can have a magical trajectory starting in New Orleans?
Segment 243: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7574, Text: Well, to me, you’re one of the greatest storytellers of all time. I’ve been a huge fan.
Segment 244: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7579, Text: That’s definitely not true, but it’s so sweet of you. You see, you can be-
Segment 245: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7582, Text: Brutally interrupting. From, I think probably Ben Franklin so far, I don’t know how many years, 15 years, Einstein, all the way through today has just been a huge fan of yours, and you’re one of the people that I thought surely would not lower themselves to appear and have a conversation with me, and it’s just a giant gift to me.
Segment 246: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7609, Text: Hey I flew into Austin for this because I am a big fan and especially a big fan because you take people seriously and you care.
Segment 247: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7618, Text: Thank you a thousand times. Thank you for respecting me and for inspiring just millions of people with your stories. Again, an incredible storyteller, incredible human, and thank you for talking today.
Segment 248: Speaker: Walter Isaacson, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7629, Text: Thank you, Lex.
Segment 249: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=aGOV5R7M1Js&t=7631, Text: Thanks for listening to this conversation with Walter Isaacson. To support this podcast please check out our sponsors in the description. And now let me leave you with one of my favorite quotes from Carl Young. “People will do anything, no matter how absurd, in order to avoid facing their own souls. One does not become enlightened by imagining figures of light, but by making the darkness conscious.” Thank you for listening and hope to see you next time.
Segment 250: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=0, Text: Whenever we start a new project, it has to have these ingredients of simultaneous complexity. It has to be novel in terms of the synthetic biology, material science, robotics, engineering, all of these elements that are discipline based or rooted must be novel. If you can combine novelty in synthetic biology with a novelty in robotics, with a novelty in material science, with a novelty in computational design, you are bound to create something novel.
Segment 251: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=30, Text: The following is a conversation with Neri Oxman, an engineer, scientist, designer, architect, artist, and one of the kindest, most thoughtful and brilliant human beings I’ve ever gotten to know. For a long time, she led the mediated matter group at MIT that did research and built incredible stuff at the intersection of computational design, digital fabrication, material science, and synthetic biology, doing so at all scales from the microscale to the building scale. Now she’s continuing this work at a very new company for now called Oxman, looking to revolutionize how humans design and build products working with nature, not against it.
Segment 252: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=73, Text: On a personal note, let me say that Neri has for a long time been a friend and someone who in my darker moments, has always been there with a note of kindness and support. I am forever grateful to her. She’s a brilliant and a beautiful human being. Oh, and she also brought me a present, War and Peace by Tolstoy and Meditations by Marcus Aurelius. It doesn’t get better than that. This is the Lex Friedman podcast to support it. Please check out our sponsors in the description. And now, dear friends, here’s Neri Oxman. Let’s start with the universe. Do you ever think of the universe as a kind of machine that designs beautiful things at multiple scales?
Segment 253: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=116, Text: I do. And I think of nature in that way in general. In the context of design, specifically, I think of nature as everything that isn’t anthropomass, everything that is not produced by humankind, the birds and the rocks and everything in between, fungi, elephants, whales.
Segment 254: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=139, Text: Do you think there’s an intricate ways in which there’s a connection between humans and nature?
Segment 255: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=144, Text: Yes, and we’re looking for it. I think that let’s say from the beginning of mankind going back 200,000 years, the products that we have designed have separated us from nature. And it’s ironic that the things that we designed and produced as humankind, those are exactly the things that separated us. Before that we were totally and completely connected, and I want to return to that world.
Segment 256: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=174, Text: But bring the tools of engineering and computation to it.
Segment 257: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=177, Text: Yes. Yes. I absolutely believe that there is so much to nature that we still have not leveraged, and we still have not understood and we still haven’t. And so much of our work is designed, but a lot of it is science is unveiling and finding new truths about the natural world that we were not aware before. Everybody talks about intelligence these days, but I like to think that nature has kind of wisdom that exists beyond intelligence or above intelligence, and it’s that wisdom that we’re trying to tap into through technology. If you think about humans versus nature, at least in the realm, at least in the context of definition of nature, is everything, but anthropomass.
Segment 258: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=229, Text: And I’m using Ron Milo, who is an incredible professor from the Weizmann Institute who came up with this definition of Anthropo mass in 2020 when he identified that 2020 was the crossover year when anthropomass exceeded biomass on the planet. So all of the design goods that we have created and brought into the world now outweigh all of the biomass, including of course, all plastics and wearables, building cities, but also asphalt and concrete, all outweigh the scale of the biomass. And actually that was a moment. You know how in life there are moments that be a handful of moments that get you to course correct. And it was a Zoom conversation with Ron, and that was a moment for me when I realized that that imbalance, now we’ve superseded the biomass on the planet, here do we go from here?
Segment 259: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=290, Text: And you’ve heard the expression more phones than bones and the anthropomass and the anthropocene and the technosphere sort of outweighing the biosphere. But now we are really trying to look at is there a way in which all things technosphere are designed as if they’re part of the biosphere? Meaning if you could today grow instead of build everything and anything, if you could grow an iPhone, if you could grow a car, what would that world look like? Where the touring test for, I call this material ecology approach, but this notion that everything material, everything that you design in the physical universe can be read and written to as or thought of or perceived of as nature grown.
Segment 260: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=346, Text: That’s sort of the touring test for the company or at least that’s how I started. I thought, well grow everything. That’s sort of the slogan. Let’s grow everything. And if we grow everything, is there a world in which driving a car is better for nature than a world in which there are no cars? Is it possible that a world in which you build buildings in cities, that those buildings in cities actually augment and heal nature as opposed to their absence? Is there a world in which we now go back to that kind of synergy between nature and humans where you cannot separate between grown and made? And it doesn’t even matter.
Segment 261: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=396, Text: Is there a good term for the intersection between biomass and anthropomass, things that are grown?
Segment 262: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=396, Text: Yeah. So in 2005 I called this material ecology. I thought, what if all things materials would be considered part of the ecology and would have a positive impact on the ecology where we work together to help each other? All things nature, all things human. And again, you can say that that wisdom in nature exists in fungi. Many mushroom lovers always contest my thesis here saying, “Well, we have the mushroom network and we have the mother trees and they’re all connected, and why don’t we just simply hack into mushrooms?” Well, first of all, yes, they’re connected, but that network stops when there is a physical gap. That network does not necessarily enable the whales in the Dominican to connect with an olive tree in Israel to connect with a weeping willow in Montana.
Segment 263: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=448, Text: And that’s sort of a world that I’m dreaming about. What does it mean for nature to have access to the cloud? The kind of bandwidth that we’re talking about, sort of think Neuralink for nature. Since the first computer, and you know this by heart probably better than I do, but we’re both MIT lifers. We today have computational power that is one trillion times the power that we had in those times. We have 26.5 trillion times the bandwidth and 11.5 quintillion times the memory, which is incredible. So humankind since the first computer has approached and accessed such incredible bandwidth, and we’re asking, what if nature had that bandwidth? So beyond genes and evolution, if there was a way to augment nature and allow it access to the world of bits, what does nature look like now? And can nature make decisions for herself as opposed to being guided and guarded and abused by humankind?
Segment 264: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=525, Text: So nature has this inherent wisdom that you spoke to, but you’re also referring to augmenting that inherent wisdom with something like a large language model.
Segment 265: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=536, Text: Exactly.
Segment 266: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=536, Text: So compress human knowledge, but also maintain whatever is that intricate wisdom that allows plants, bacteria, fungi to grow incredible things at arbitrary scales, adapting to whatever environment and just surviving and thriving no matter where, no matter how.
Segment 267: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=554, Text: Exactly. So I think of it as large molecule models and those large molecule models, of course, large language models are based on Google and search engines and so on and so forth. And we don’t have this data currently. And the part of our mission is to do just that, trying to quantify and understand the language that exists across all kingdoms of life, across all five kingdoms of life. And if we can understand that language, is there a way for us to first make sense of it, find logic in it, and then generate certain computational tools that empower nature to build better crops, to increase the level of biodiversity? In the company we’re constantly asking, what does nature want? What does nature want from a compute view?
Segment 268: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=611, Text: If it knew it, what could aid it in whatever the heck it’s wanting to do.
Segment 269: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=616, Text: So we keep coming back to this answer of nature wants to increase information, but decrease entropy. So find order, but constantly increase the information scale. And this is true for what our work also tries to do because we’re constantly trying to fight against the dimensional mismatch between things made and things grown. And as designers, we are educated to think in X, Y, and Z and that’s pretty much where architectural education ends and biological education begins.
Segment 270: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=651, Text: So in reducing that dimensional mismatch, we’re missing out on opportunities to create things made as if grown. But in the natural environment, we’re asking, can we provide nature with these extra dimensions? And again, I’m not sure what nature wants, but I’m curious as to what happens when you provide these tools to the natural environments. Obviously with responsibility, obviously with control, obviously with ethics and moral code, but is there a world in which nature can help fix itself using those tools?
Segment 271: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=686, Text: And by the way, we’re talking about a company called Oxman.
Segment 272: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=690, Text: Yeah. Just a few words about the team.
Segment 273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=693, Text: Yeah. What kind of humans work at a place like this? They’re trying to figure out what nature wants.
Segment 274: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=697, Text: I think they’re first like you, they’re humanists first. They come from different disciplines and different disciplinary backgrounds. And just as an example, we have a brilliant designer who is just a mathematical genius and a computer scientist and a mechanical engineer who is trained as a synthetic biologist. And now we’re hiring a microbiologist and a chemist, architects of course, and designers, roboticist. So really it’s arc, two of each.
Segment 275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=733, Text: And always dancing between this line of the artificial, the synthetic, and the real, what’s the term for it? And the natural
Segment 276: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=741, Text: Yeah, the built and the grown nature and culture, technology and biology, but we’re constantly seeking to ask how can we build, design and deploy products in three scales? The molecular scale, which I briefly hinted to. And there in the molecular scale we’re really looking to understand whether there’s a universal language to nature and what that language is. And then build a tool that I think and dream of it is the iPhone for nature. If nature had an iPhone, what would that iPhone look like?
Segment 277: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=779, Text: Does that mean creating an interface between nature and the computational tools we have?
Segment 278: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=787, Text: Exactly. It goes back to that 11.5 quintillion times the bandwidth that humans have now arrived at, and giving that to nature and seeing what happens there can animals actually use this interface to know that they need to run away from fire? Can plants use this interface to increase the rate of photosynthesis in the presence of a smoke cloud? Can they do this quote-unqoute “automatically” without a kind of a top-down brute force policy-based method that’s authored and deployed by humans? And so this work really relates to that interface with the natural world. And then there’s a second area in the company which focuses on growing products. And here we’re focusing on a single product that starts from CO2. It becomes a product. It’s consumed, it’s used, it’s worn by a human, and then it goes back to the soil and it grows an edible fruit plant.
Segment 279: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=853, Text: So we’re talking about from CO2 to fruit.
Segment 280: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=853, Text: Yeah. It starts from CO2 and it ends with something that you can literally eat. So the world’s first entirely biodegradable, biocompatible, bio renewable product.
Segment 281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=864, Text: That’s grown.
Segment 282: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=865, Text: Yes, either using plant matter or using bacteria, but we are really looking at carbon recycling technologies that start with methane or wastewater and end with this wonderful reincarnation of a thing that doesn’t need to end up in a composting site, but can just be thrown into the ground and grow olive and find peace. And there’s a lot of textile based work out there that is focused on one single element in this long chain like, oh, let’s create leather out of mycelium, or let’s create textile out of cellulose, but then it stops there and you get to assembling the shoe or the wearable and you need a little bit of glue, and you need a little bit of this material and a little bit of that material to make it water resistant and then it’s over.
Segment 283: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=916, Text: That’s one thing that we’re trying to solve for is how to create a product that is materially, computationally, robotically, novel, and goes through all of these phases from the creation, from this carbon recycling technology to the product, to literally, how do you think about reinventing an industry that is focused on assembly and putting things together and using humans to do that? Can that happen just using robots and microbes? And that’s it.
Segment 284: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=948, Text: And doing it end to end. I would love to see what this factory looks like.
Segment 285: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=954, Text: And the factory is great too. I’m very, very excited. In October we’ll share first renditions of some of this work and in February we’ll invite you to the lab.
Segment 286: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=965, Text: I’m there. I’ve already applied. I haven’t heard back. I don’t understand. Okay. Just before we get to number three, it’d be amazing to just talk about what it takes with robotic arms or in general, the whole process of how to build a life form stuff you’ve done in the past, maybe stuff you’re doing now, how to use bacteria, this kind of synthetic biology, how to grow stuff by leveraging bacteria? Is there examples from the past and explain?
Segment 287: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=991, Text: Yes. And just take a step back over the 10 years, the mediated matter group, which was my group at MIT, has sort of dedicated itself to bio-based design would be a suitcase word, but thinking about that synergy between nature and culture, biology and technology. And we attempted to build a suite of embodiments, let’s say that they ended up in amazing museums and amazing shows, and we wrote patents and papers on them, but they were still N of ones. Again, the challenge, as you say, was to grow them, and we classified them into fibers, cellular solids, biopolymers, pigments.
Segment 288: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1033, Text: And in each of the examples, although the material was different, sometimes we used fibers, sometimes we used silk with silkworms and honey with bees and or comb as the structural material, with vespers we used synthetically engineered bacteria to produce pigments, although the materials were different and the hero organisms were different, the philosophy was always the same. The approach was really an approach of computational templating. That templating allowed us to create templates for the natural environment where nature and technology could duet, could dance together to create these products.
Segment 289: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1068, Text: So just a few examples with silk pavilion, we’ve had a couple of pavilions made of silk, and the second one, which was the bigger one, which ended up at the Museum of Modern Art with my friend, an incredible mentor, Paul Antonelli, that pavilion was six meter tall and it was produced by silkworms. And there we had different types of templates. There were physical templates that were basically just these water soluble meshes upon which the silkworms were spinning and then there were environmental templates, which was a robot basically applying variation of environmental conditions such as heat and light to guide the movement of the silkworm.
Segment 290: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1109, Text: You’re saying so many amazing things, and I’m trying not to interrupt you, but one of the things you’ve learned by observing, by doing science on these is that the environment defines the shape that they create or contributes or intricately plays with the shape they create. And that’s one of the ways you can get to guide their work is by defining that environment. By the way, you said hero organism, which is an epic term. That means whatever is the biological living system that’s doing the creation.
Segment 291: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1141, Text: And that’s what’s happening in pharma and biomaterials and by the way, precision ag and new food design technologies as people are betting on a hero organism, is sort of how I think of it. And the hero organism is sometimes it’s the palm oil or it’s the mycelium. There’s a lot of mushrooms around for good and bad, and it’s cellulose or it’s fake bananas or the workhorse E. Coli. But these hero organisms are being betted on as the… What’s the one answer that solves everything hitchhiker’s guide?
Segment 292: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1178, Text: 42.
Segment 293: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1180, Text: 42.
Segment 294: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1182, Text: Yeah. These are sort of the 42s of the enchanted new universe. And back at MIT, we said, instead of betting on all of these organisms, let’s approach them as almost movement in a symphony and let’s kind of lean into what we can learn from each of these organisms in the context of building a project in an architectural scale. And those usually were pavilions.
Segment 295: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1205, Text: And then the computational templating is the way you guide the work of this. How many did you say? 17,000?
Segment 296: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1215, Text: 17,532. So each of these silkworms threads are about one mile in distance, and they’re beautiful. And just thinking about the amount of material, it’s a bit like thinking about the length of capillary vessels that grow in your belly when you’re pregnant to feed that incredible new life form. Just nature is amazing. But back to the silkworms, I think I had three months to build this incredible pavilion, but we couldn’t figure out how. We were thinking of emulating the process of how a silkworm goes about building its incredible architecture. This cocoon over the period of 24 to 72 hours, and it builds a cocoon basically to protect itself.
Segment 297: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1263, Text: It’s a beautiful form of architecture, and it uses pretty much just two materials, two chemical compounds ceresin and fibrin. The ceresin is sort of the glue of the cocoon, the fibrin is the fiber based material of the cocoon and through fibers and glue. And that’s true for so many systems in nature, lots of fiber and glue. And that architecture allows them to metamorphosize. And in the process they vary the properties of that silk thread, so it’s stiffer or softer depending on where it is in the section of the cocoon. And so we were trying to emulate this robotically with a 3D printer that was six axis KUKA arm one of these baby KUKAs.
Segment 298: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1306, Text: And we’re trying to emulate that process computationally and build something very large when one of my students now, a brilliant industrial engineer, roboticist on my team, Marcus said, “Well, we were just playing with those silkworms and enjoying their presence when we realized that if they’re placed on a desk or a horizontal surface, they will go about creating their cocoon only the cocoon would be flat because they’re constantly looking for a vertical post in order to use that post as an anchor to spin the cocoon. But in the absence of that post on surfaces that are less than 21 millimeters and flat they will spin flat patches and we said, “Aha, let’s work with them to produce this dome as a set of flat patches.”
Segment 299: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1362, Text: And a silkworm mind you is quite an egocentric creature. And actually the furthest you go, you move forward in evolution by natural selection, the more egoism you find in creatures. So when you think about termites, their material sophistication is actually very primitive, but they have incredible ability to communicate and connect with each other. So if you think about entire all of nature, let’s say all of living systems as a matrix that runs across two axes one is material sophistication, which is terribly relevant for designers, and the other is communication. The termites ace on communication, but their material sophistication is crap.
Segment 300: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1411, Text: It’s just saliva and feces and some soil particles that are built to create these incredible termite mounds, the scale that when compared to human skyscrapers transcend all of buildable scales, at least in terms of what we have today in architectural practice just relative to the size of the termite. But when you look at the silkworm, the silkworm has zero connection and communication across silkworms. They were not designed to connect and communicate with each other. They’re sort of a human design species because the domesticated silk moth creates the cocoon.
Segment 301: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1448, Text: We then produce the silk of it and then it dies. So it has dysfunctional wings, it cannot fly. And that’s another problem that the sericulture industry has is, why did we in the first place, author this organism 4,000 years ago that is unable to fly and is just there to basically live to serve a human need, which is textiles? And so here we were fascinated by the computational kind of biology dimension of silkworms, but along the way… By the way, this is great. I never get to tell the full story. So great.
Segment 302: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1487, Text: I’ve enjoyed this so much.
Segment 303: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1491, Text: People say, “Oh, speak in [inaudible 00:24:54] paragraphs. They’re way too long.” And this is wonderful. This is like heaven.
Segment 304: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1498, Text: [inaudible 00:24:58] paragraphs. You’re dropping so many good lines. I love it for that.
Segment 305: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1502, Text: But really those silkworms, yes, they’re not designed to be like humans. They’re not designed to connect, communicate, and build things that are bigger than themselves through connection and communication.
Segment 306: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1517, Text: So what happens when you add 17,000 of them communicating effectively?
Segment 307: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1517, Text: That’s a really great question. What happens is that at some point, the templating strategies, and as you said correctly, there were geometrical, templating, material templating, environmental templating, chemical templating if you’re using pheromones to guide the movement of bees in the absence of a queen where you have a robotic queen.
Segment 308: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1538, Text: Robotic queen.
Segment 309: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1539, Text: But whenever you have these templating strategies, you have sort of control over nature, but the question is there a world in which we can move from templating, from providing these computational material and immaterial physical and molecular platforms that guide nature, almost guiding a product almost like a gardener to a problem or an opportunity of emergence where that biological organism assumes agency by virtue of accessing the robotic code and saying, now I own the code. I get to do what I want with this code. Let me show you what this pavilion may look like or this product may look like?
Segment 310: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1578, Text: And I think one of the exciting moments for us is when we realized that these robotic platforms that were designed initially as templates actually inspired, if I may, a kind of a collaboration and cooperation between silkworms that are not a swarm based organism. They’re not like the bees and the termites. They don’t work together and they don’t have social orders amongst them, the queen and the drones, et cetera. They’re all the same in a way. And here, what was so exciting for us is that these computational and fabrication technologies enable the silkworm to sort of hop from the branch in ecology of worms to the branch in ecology of maybe human-like intelligence where they could connect and communicate by virtue of feeling or rubbing against each other in an area that was hotter or colder.
Segment 311: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1639, Text: And so the product that we got at the end, the variation of density of fiber and the distribution of the fiber and the transparency, the product at the end seems like it was produced by a swarm silk community, but of course it wasn’t. It’s a bunch of biological agents working together to assemble this thing. That’s really, really fascinating to us. How can technology augment or enable a swarm like behavior and creatures that have not been designed to work as swarms?
Segment 312: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1673, Text: So how do you construct a computational template from which a certain kind of thing emerges? How can you predict what emerges, I suppose?
Segment 313: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1685, Text: So if you can predict it doesn’t count as emergence, actually.
Segment 314: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1692, Text: That’s a deeply poetic line.
Segment 315: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1693, Text: We can talk about it. It’s a bit exaggerated, doesn’t count. Speaking of emergence, an empowerment, because we’re constantly moving between those as if they’re equals on the team and one of them, Christopher shared with me a mathematically equation for what does it mean to empower nature and what does empowerment in nature look like? And that relates to emergence. And we can go back to emergence in a few moments, but I want to say it so that I know that I’ve learned it and if I’ve learned it I can use it later.
Segment 316: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1734, Text: And maybe you’ll figure something out as you say it also.
Segment 317: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1737, Text: Of course, Christopher is the master here, but really we were thinking again, what does nature want? Nature wants to increase the information dimension and reduce entropy. What do we want? We kind of want the same thing. We want more, but we want order. And this goes back to your conversation with Joscha about stochastic versus deterministic languages or processes. His definition or the definition he found was that an agent is empowered if the entropy of the distribution of all of its states it’s high while the entropy of the distribution of a single state given a choice, given an action is low. Meaning it’s that kind of duality between opportunity like starting like this and going like this, opening and closing. And this really, I think is analogous to human empowerment, given infinite wide array of choices. What is the choice that you make to enable, to empower, to provide you with the agency that you need?
Segment 318: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1819, Text: And how much does that making that choice actually control the trajectory of the system? That’s really nice. So this applies to all the kinds of systems you’re talking about.
Segment 319: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1828, Text: And the cool thing is it can apply to a human on an individual basis or a silkworm or a bee or a microbe that has agency or by virtue of a template, but it also applies to a community of organisms like the bees. And so we’ve done a lot of work sort of moving from, you’ve asked how to grow things. So we’ve grown things using co fabrication where we’re digitally fabricating with other organisms that live across the various kingdoms of life and those were silkworms and bees. And with bees, which we’ve sent to outer space and returned healthily and they were reproductive.
Segment 320: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1875, Text: Okay, you’re going to have to tell that story. You’re going to have to talk about the robotic queen and the pheromones. Come on.
Segment 321: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1880, Text: So we built what we called a synthetic apiary and the synthetic apiary was designed as an environment that was a perpetual spring environment for the bees of Massachusetts. They go on hibernation, of course, during the winter season, and then we lose 80% of them or more during that period. We’re thinking, okay, what if we created this environment where before you template, before you can design with, you have to design for? You have to create this space of mutualism space of sort of shared connection between you and the organism. And with bees it started as the synthetic apiary. And we have proven that curated environment where we designed the space with high levels of control of temperature, humidity, and light and we’ve proven that they were reproductive and alive. And we realized, wow, this environment that we created can help augment bees in the winter season in any city around the world where bees survive and thrive in the summer and spring seasons. And could this be a kind of new urban typology, an architectural typology of symbiosis, of mutualism between organisms and humans?
Segment 322: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=1957, Text: By the way, the synthetic API was in a co-op nearby Somerville. We had robots. Our team schlepped there every day with our tools and machines and we made it happen. And the neighbors were very happy, and they got to get a ton of honey at the end of the winter. And those bees, of course, were released into the wild at the end of the winter alive and kicking. So then in order to actually experiment with the robotic queen and idea or concept, we had to prove obviously that we can create this space for bees. And then after that, we had this amazing opportunity to send the bees to space on Blue Shepherd Mission that is part of Blue Origin, and we of course said, “Yes, we’ll take a slot.”
Segment 323: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2004, Text: We said, “Okay, can we outdo NASA?” So NASA in 1982 had an experiment where they sent bees to outer space. The bees returned, they were not reproductive and some of them died. And we thought, “Well, is there a way in which we can create a life support system, almost like a small mini biolab of a queen and her retinue that would be sent in this Blue Origin New Shepherd mission in this one cell?” And so if the synthetic apiary was an architectural project, in this case, this second synthetic apiary was a product. It was so from an architectural controlled environment to a product scale controlled environment.
Segment 324: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2048, Text: And this biolab, this life support system for bees, was designed to provide the bees with all the conditions that they needed. And we looked at that time at the Nasonov pheromone that the queen uses to guide the other bees, and we looked at pheromones that are associated with a bee, and thinking of those pheromones being released inside the capsule that goes to outer space. They returned back to the media lab roof and those bees were alive and kicking and reproductive, and they continued to create comb. It ended with a beautiful nature paper that the team and I published together. We gave them gold nanoparticles and silver nanoparticles because we were interested if bees recycle wax, it was known forever that-
Segment 325: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2103, Text: Bees recycle wax. It was known forever that bees do not recycle the wax. And by feeding them these gold nanoparticles, we were able to prove that the bees actually do recycle the wax. The reason I’m bringing this forward is because we don’t view ourselves as designers of consumable products and architectural environments only, but we love that moment where these technologies… And by the way, every one of these projects that we created involve the creation of a new technology, whether it be a glass printer or the spinning robot or the life support system for the bee colony. They all involved a technology that was associated with the project, and I never, ever, ever want to let that part go because I love technology so much.
Segment 326: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2154, Text: But also another element of this is that always, these projects, if they’re great, they reveal new knowledge about, or new science about the topic that you’re investigating, be it silkworms or bees or glass. That’s why I say, I always tell my team it should be at MoMA and the cover of Nature or Science at the same time. We don’t separate between the art and the science, it’s one of the same.
Segment 327: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2181, Text: So as you’re creating the art, you’re going to learn something about these organisms or something about these materials. Is there something that stands out to you about these hero organisms like bees, silkworms? You mentioned E. coli has its pros and cons, this bacteria. What have you learned, small or big, that’s interesting about these organisms?
Segment 328: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2201, Text: Yeah, that’s a beautiful question. What have I learned? I’ve learned that… We also worked with shrimp shells with a glow. How we built this tower on the roof of SF MoMa, which by a couple of months ago until it was on the roof, we’ve shown this structure completely biodegrade into the… Well, not completely, but almost completely biodegrade to the soil. And this notion that a product or an organism or part of that organism can reincarnate is very, very moving thought to me, because I want to believe that I believe in reincarnation.
Segment 329: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2244, Text: I want to believe that I believe. I want to believe.
Segment 330: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2245, Text: Yeah, that’s my relationship with God. I like to believe in believing. Most great things in life are second derivatives of things, but that’s part of another conversation.
Segment 331: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2258, Text: I feel like that’s a quote that’s going to take weeks to really internalize.
Segment 332: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2263, Text: That notion of, I want you to want, or I need you to need. There’s always something, a deeper truth behind what is on the surface. So I like to go to the second and tertiary derivative of things and discover new truths about them through that. But what have I learned about organisms-
Segment 333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2285, Text: And why don’t you like E. coli?
Segment 334: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2287, Text: I like E. coli, and a lot of the work that we’ve done was not possible without our working on E. coli or other workhorse organisms, like cyanobacteria.
Segment 335: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2299, Text: How are bacteria used?
Segment 336: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2300, Text: Death masks. The death masks.
Segment 337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2304, Text: So what are death masks?
Segment 338: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2304, Text: We did this project called Vespers, and those were basically death masks. That was set as a process for designing a living product. What happens? I remember looking at Beethoven’s death mask and Agamemnon’s death mask and just studying how they were created. And really they were geometrically attuned to the face of the dead, and what we wanted to do is create a death mask that was not based on the shape of the wearer, but rather was based on their legacy and their biology. And maybe we could harness a few stem cells there for future generations or contain the last breath. Lazarus, which preceded Vespers, was a project where we designed a mask to contain a single breath, the last breath of the wearer. And again, if I had access to these technologies today, I would totally reincorporate my grandmother’s last breath in a product. So it was like an air memento.
Segment 339: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2371, Text: So with Vespers, we actually used E. coli to create pigmented masks, masks whose pigments would be recreated at the surface of the mask. And I’m skipping over a lot of content, but basically there were 15 masks and they were created as three sets, the masks of the past, the masks of the present, and the masks of the future. They were five, five, and five, and the masks of the past were based on ornaments and they were embedded with natural minerals like gold. Yes, yes, yes, exactly-
Segment 340: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2412, Text: And we’re looking at pictures of these and they’re gorgeous.
Segment 341: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2416, Text: Yes, yes.
Segment 342: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2416, Text: Extremely delicate and interesting fractal patterns that are symmetrical.
Segment 343: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2424, Text: They look symmetrical, but they’re not. We intended for you to be tricked and think that they’re all symmetrical, but-
Segment 344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2432, Text: There’s imperfections.
Segment 345: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2433, Text: There are imperfections by design. All of these forms and shapes and distribution of matter that you’re looking at was entirely designed using a computational program. None of it is manual. But long story short, the first collection is about the surface of the mask. And the second collection, which you’re looking at, is about the volume of the mask and what happens to the mask when all the colors from the surface, yes, enter the volume of the mask inside, create pockets and channels to guide life through them. They were incorporated with pigment-producing living organisms, and then those organisms were templated to recreate the patterns of the original death masks. And so life recycles and re-begins, and so on and so forth. The past meets the future, the future meets the past. From the surface to the volume, from death to life, to death to life, to death to life. And that again, is a recurring theme in the projects that we take on.
Segment 346: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2499, Text: But from a technological perspective, what was interesting is that we embedded chemical signals in the jet, in the printer, and those chemical signals basically interacted with the pigment-producing bacteria, in this case E. coli, that were introduced on the surface of the mask. And those interactions between the chemical signals inside the resins and the bacteria at the surface of the mask, at the resolution that is native to the printer, in this case, 20 microns per voxel, allowed us to compute the exact patterns that we wanted to achieve. And we thought, “Well, if we can do this with pigments, can we do this with antibiotics? If we can do this with antibiotics, could we do it with melanin? And what are the implications?” Again, this is a platform technology. Now that we have it, what are the actual real-world implications and potential applications for this technology?
Segment 347: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2561, Text: We started a new area, one of my students, Rachael, her PhD thesis was titled after this new class of materials that we created through this project, Vespers, Hybrid Living Materials, HLMs. And these hybrid living materials really paved the way towards a whole other set of products that we’ve designed, like the work that we did with melanin for the Mandela pavilion that we presented at SF MoMa. Where again, we’re using the same principles of templating, in this case not silkworms and not bees, but we’re templating bacteria at a much, much, much more finer resolution. And now instead of templating using a robot, we’re templating using a printer.
Segment 348: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2612, Text: But compute is very, very much part of it. And what’s nice about bacteria, of course, is that from an ethical perspective I think there’s a range. So at the end of the silk pavilion, I got an email from professor in Japan who has been working on transgenic silk and said, “Well, if you did amazing silk pavilion, why don’t we create glow in the light silk dresses?” And in order to create this glow in the light silk, we need to apply jeans that are taken from a spider to a silkworm. And this is what is known as a transgenic operation. And we said no. And that was for us a clear decision that, no, we will work with these organisms as long as we know that what we are doing with them is not only better for humans, but it’s also better for them.
Segment 349: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2671, Text: And again, just to remind you, I forget the exact number, but it’s around 1,000 cocoons per a single shirt that are exterminated in India and China, in those sericulture industries that are being abused. Now, yes, this organism was designed to serve the human species and maybe it’s time to retire that conception of organisms that are designed for a human-centric world or human-centric set of applications. I don’t feel the same way about E. coli, not that I’m organism agnostic, but still I believe there’s so much for us to do on this planet with bacteria.
Segment 350: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2726, Text: And so in general, your design principle is to grow cool stuff as a byproduct of the organism flourishing. So not using the organism-
Segment 351: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2736, Text: Yes. The win-win, the synergy.
Segment 352: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2737, Text: Win-win.
Segment 353: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2738, Text: A whole that’s bigger than the sum of its parts.
Segment 354: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2740, Text: It’s interesting. It just feels like a gray area, where genetic modification of an organism, it just feels like… I don’t know. If you genetically modified me to make me glow in the light, I kind of like it.
Segment 355: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2759, Text: I think you have enough of an aura.
Segment 356: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2760, Text: All right, thank you. I was just fishing for compliments. Thank you. I appreciate the-
Segment 357: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2766, Text: But you’re absolutely right. And by the way, the gray area is where some of us like to live and like to thrive, and that’s okay. And thank goodness that there’s so many of us that like the black and white and that thrive in the black and white. My husband is a good example for that.
Segment 358: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2781, Text: Well, but just to clarify, in this case you are also trying to thrive in the black and white in that you’re saying the silkworm is a beautiful, wonderful creature. Let us not modify it. Is that the idea? Or is it okay to modify a little bit as long as we can see that it benefits the organism as well as the final creation?
Segment 359: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2802, Text: With silkworms, absolutely let’s not modify it genetically. Let’s not modify it genetically. And then some. Because why did we get there to begin with 4,000 years ago in the Silk Road? And we should never get to a point where we evolve life for the service of mankind at the risk of these wonderful creatures across the across the kingdom of life. I don’t think about the same kind of ethical range when I think about bacteria.
Segment 360: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2835, Text: Nevertheless, bacteria are pretty wonderful organisms.
Segment 361: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2838, Text: I’m moving to my second cup here.
Segment 362: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2841, Text: Take two, because things are getting serious now.
Segment 363: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2843, Text: Bacteria are. Yeah, for sure.
Segment 364: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2845, Text: Let’s give bacteria all the love they deserve. We wouldn’t be here without them. They were here for, I don’t know what it is, like a billion years before anything else showed up.
Segment 365: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2852, Text: But in a way, if you think about it, they create the matter that we consume and then reincarnate, or dissolved into the soil and then creates a tree, and then that tree creates more bacteria. And then that bacteria could… Again, again. That’s why I like to think about not recycling, but reincarnating, because that assumes, imparting upon nature that dimension of agency and maybe awareness. But yeah, lots of really interesting work happening with bacteria. Directed evolution is one of them. We’re looking at directed evolution. So high-throughput directed evolution of bacteria for the production of products. And again, those products can be a shoe, wearables, biomaterials, therapeutics.
Segment 366: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2906, Text: And doing that direction computationally?
Segment 367: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2907, Text: Totally computationally, obviously in the lab with the hero organism, the hero bacteria. And what’s happening today, in equal microbial synthetic biology, synthetic biology that lends itself to ecology. And again, all of these fields are coming together. It’s such a wonderful time to be a designer. I can’t think of a better time to be a designer in this world. But with high-throughput directed evolution… And I should say that the physical space in our new lab will have these capsules which we have designed. They are designed like growth chambers or grow rooms, and in those grow rooms we can basically program top-down environmental templating, top-down environmental control of lights, humidity, light, et cetera. Sorry, light, humidity and temperature while doing bottom-up genetic regulation. So it is a wet lab, but in that wet lab you could do at the same time, genetic modulation, regulation and environmental templating.
Segment 368: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=2979, Text: And then, again, the idea is that in one of those capsules maybe we grow transparent wood, and in another capsule, transparent wood for architectural application. Another capsule, we grow a shoe, and in another capsule we look at that large language model that we talked about. And there was a particular technology associated with that, which we’re hoping to reveal to the world in February. And in each of those capsules is basically a high-throughput computational environment, like a breadboard, think of a physical breadboard environment that has access to oxygen and nitrogen and CO2 and nutritional dispensing, and these little capsules could be stressed. They’re sort of ecology in a box, and they could be stressed to produce the food of the future or the products of the future or the construction materials of the future. Food is a very interesting one, obviously because of food insecurity and the issues that we have around both in terms of food insecurity, but also in terms of the future of food and what will remain after we can’t eat plants and animals anymore, and all we can eat is these false bananas and insects as our protein source.
Segment 369: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3056, Text: So there we’re thinking, can we design these capsules to stress an environment and see how that environment behaves? Think about a biodiversity chamber, kind of a time capsule that is designed as a biodiversity chamber where you can program the exact temperature, humidity, and light combination to emulate the environment from the past. So Ohio, 1981, December 31st at 5:00 AM in the morning, what did tomatoes taste like? To all the way in the future, 200 years ago, these are the environmental inputs, these are some genetic regulations that I’m testing and what might the food of the future or the products of the future or the construction materials of the future feel like, taste like, behave like, et cetera. And so these capsules are designed as part of a lab. That’s why it’s been taking us such a long time to get to this point, because we started designing them in 2019, and they’re currently, literally as I speak to you, under construction.
Segment 370: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3122, Text: How well is it understood how to do this dance of controlling these different variables in order for various kinds of growth to happen?
Segment 371: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3130, Text: It’s not. It’s never been done before and these capsules have never been designed before. So when we first decided these are going to be environmental capsules, people thought we were crazy. “What are you building? What are you making?” So the answer is that we don’t know. But we know that there has never been a space like this where you have basically a wet lab and a grow room at that resolution, at that granularity of control over organisms. There is a reason why there is this incredible evolution of products in the software space. The hardware space, that’s a more limiting space because of the physical infrastructure that we have to test and experiment with things. So we really wanted to push on creating a wet lab that is novel in every possible way. What could you create in it? You could create the future. You could create an environment of plants talking to each other with a robotic referee. And you could set an objective function.
Segment 372: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3200, Text: And let’s say for the transaction-driven individuals in the world, let’s say their objective function is carbon sequestration. And all of those plants are implemented with a gaming engine and they have these reward system and they’re constantly needing to optimize the way in which they carbon sequest. We weed out the bad guys, we leave the good guys, and we end up with this ideal ecology of carbon sequestering heroes that connect and communicate with each other. And once we have that model, this biodiversity chamber, we send it out into the field and we see what happens in nature. And that’s sort of what I’m talking about, augmenting plants with that extra dimension of bandwidth that they do not have. Just last week I came across a paper that discusses the in vivo neurons that are augmented with a pong game. And in a dish they basically present sentience and the beginning of awareness.
Segment 373: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3277, Text: Which is wonderful that you could actually take these neurons from a mouse brain, and you have the electrical circuits and the physiological circuits that enable these cells to connect and communicate, and together arrive at swarm situation that allows them to act as a system that is not only perceived to be sentient, but is actually sentient. Michael Levine calls this gentle material, material that has agency. This is of interest to us because, again, this is emergence post-templating. You template until you don’t need to template anymore because the system has its own rules. What we don’t want to happen with AGI, we want to happen with synthetic biology. What we don’t want to happen online and software with language, we want for it to happen with bio-based materials. Because that will get us closer to growing things as opposed to assembly and mechanically putting them together with toxic materials and compounds.
Segment 374: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3343, Text: If I can ask a pothead question for a second, you mentioned just like the silkworms, the individualist silkworms got to actually learn how to collaborate or actually to collaborate in a swarm like way. You’re talking about getting plants to communicate in some interesting way based on an objective function. Is it possible to have some kind of interface between another kind of organisms, humans, and nature? So like a human to have a conversation with a plant?
Segment 375: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3374, Text: There already is. You know that when we cut freshly cut grass, I love the smell, but actually it’s a smell of distress that the leaves of grass are communicating to each other. The grass, when it’s cut emits green leaf volatiles, GLVs. And those GLVs are basically one leaf of grass communicating to another leaf of grass, “Be careful. Mind you, you’re about to be cut.” These incredible life forms are communicating using a different language than ours. We use language models, they use molecular models. At the moment where we can parse, we can decode these molecular moments is when we can start having a conversation with plants.
Segment 376: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3417, Text: Now, of course there is a lot of work around plant neurobiology. It’s a real thing. Plants do not have a nervous system, but they have something akin to a nervous system. It has kind of a ecological intelligence that is focused on a particular timescale, and the timescale is very, very slow, slow, slow, slow timescale. So it is when we can melt these timescales and connect with these plants in terms of the content of the language, in this case molecules, the duration of the language, and we can start having a conversation, if not simply to understand what is happening in the plant kingdom.
Segment 377: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3458, Text: Precision agriculture, I promise to you, will look very, very different. Because right now we are using drones to take photos of crops, of corn, that look bad. And when we take that photo, it’s already too late. But if we understand these molecular footprints and things that they are trying to say, distress that they are trying to communicate, then we could of course predict the physiological, biological behavior of these crops, both for their own self perpetuation, but also for the foods and the pharma and the type of molecules that we’re seeking to grow for the benefit of humanity. And so these languages that we are attempting now to quantify and qualify, will really help us not only better nature and help nature in its striving to surviving, but also help us design better wines and better foods and better medicine and better products, again, across all scales, across all application domains.
Segment 378: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3521, Text: Is there intricacies to understanding the timescales, like you mentioned, at which these communications, these languages operate? Is there something different between the way humans communicate and the way plants communicate in terms of time?
Segment 379: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3536, Text: Remember when we started the conversation talking about definitions in the context of design and then in the context of being? That question requires, I think a kind of a shift, a humility. That requires a humility towards nature, understanding that it operates on different scales. We recently discovered that the molecular footprint of a rose, or of a plant in general during nighttime, is different than its molecular footprint during daytime. So these are circadian rhythms that are associated with what kind of molecules these plants emit given stresses, and given there’s a reason why a jasmine field smells so, so delicious and 4:00 AM in the morning. There’s peace and rest amongst the plants. And you have to tune into that time dimension of the plant kingdom, and that of course requires all this humility, where in a single capsule, to design a biodiversity chamber, it will take years, not months, and definitely not days to see these products.
Segment 380: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3613, Text: And also, that humility in design comes from simply looking at how we are today as a civilization, how we use and abuse nature. Just think of all these Christmas trees. These Christmas trees, they take years to grow. We use them for one night, the holiest night of the year, and then we let them go. And think about in nature to design a “product,” an organism spends energy and time and thoughtfulness and many, many, many years, and I’m thinking about the redwoods, to grow these channels, these cellulose layers and channels and reach these incredible heights. Takes sometimes hundreds of years, sometimes thousands of years. Am I afraid of building a company that designs products in the scale of thousands of years? No, I’m not.
Segment 381: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3668, Text: And the way of being in the physical world today is really not in tune with the time dimension of the natural world at all, and that needs to change. And that’s obviously very, very hard to do in a community of human beings that is, at least in the Western world, that is based on capitalism. And so here, the wonderful challenge that we have ahead of us is, how do we impart upon the capitalist movement? We know that we need to produce now products that will enter the real world and be shared and used by others, and still benefit the natural world while benefiting humans? And that’s a wonderful challenge to have.
Segment 382: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3715, Text: So, integrate technology with nature, and that’s a really difficult problem. I see parallels here with another company of Neuralink, which is basically like, I think you mentioned, Neuralink for nature. That there are short-term products you can come up with, but it’s ultimately a long-term challenge of how do you integrate the machine with this creation of nature, this intricate, complex creation of nature, which is the human brain. And then you’re speaking more generally, nature.
Segment 383: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3749, Text: You know how every company has an image? Like this one single image that embodies the spirit of the company? And I think for Neuralink it was, to me, that chimpanzee playing a video game. It was just unbelievable. But with plants, there potentially is a set of molecules that impacts or inspires, I like that word, the plant to behave or act in a certain way, and allows still the plan the possibility of deciding where it or she or he wants to go. Which is why our first product for this molecular space is going to be a functionalized fragrance. So here we’re thinking about the future of fragrances and the future of fragrances and flavors.
Segment 384: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3803, Text: These products in the industry as we know it today, are designed totally for a human-centric use and enjoyment and indulgence and luxury. They’re used on the body for the sake of, I don’t know, attraction and feeling good and smelling good. And we were asking ourselves, is there a world in which a fragrance can be not a functional fragrance? Because you could claim that all fragrances are functional. But is there a world in which the fragrance becomes functionalized, is, again, imparted upon or given agency to connect with another organism? Is there a world in which you and I can go down to your garden and use a perfume that will interact with the rose garden downstairs? I’ve just been enamored with the statements that are being made in the media around, “Oh, this is completely biologically-derived fragrance and it’s bio-based.”
Segment 385: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3868, Text: But when you look into the fragrance and you understand that in order to get to this bio-derived fragrance, you blew through 10,000 bushes of rose to create 5 mL of a rose fragrance. And all these 10,000 bushes of rose, they take space, they take water management, and so much waste. Is this really what we want the future of our agriculture and molecular goods to look like? And so when we did the Aguahoja pavilion on the roof of SF MoMa, we calculated that for that pavilion we had 40,000 calories embedded into this pavilion that was made of shrimp shells and chitosan and apple skins and cellulose from tree pulp. And we calculated that overall the structure had 40,000 calories. Interesting way to think about a structure, from the point of view of calories. But as you left the gallery, you saw these three clocks that were so beautifully designed by Felix on our team, and these clocks measured temperature and humidity, and we connected them to a weather channel so that we could directly look at how the pavilion was biodegrading in real-time.
Segment 386: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3940, Text: And in our calculations, I say this long-winded description of the pavilion to say that in the calculation, we incorporated how much electricity we used for our computers, for the 3D printers that printed the pavilion. And these were called energy calculations, energy end materials. And when you think about a product and you think about a shoe or a chair or a perfume or a building, you don’t stop at the object. You want to go all the way to the system. Again, instead of designing objects or singular embodiments of the will of the designer, you’re really tapping into an entire system that is interconnected.
Segment 387: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=3986, Text: And if you look at the energy budget that characterize the project Aguahoja, it traverses the entire planet. Some of these shrimp shells were brought from places in the world we haven’t thought of, in terms of the apples and the shrimp shells and the tree pulp. And so going back to fragrances, it’s really, really important to understand the product in the context of the ecological system from which it’s sourced, and how it’s designed. And that is the kind of thinking that is not only desired, but is required if we are to achieve synergy between humanity and nature.
Segment 388: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4026, Text: And it’s interesting, because the system-level thinking is almost always going to take you to the entire earth, to considering the entire earth ecosystem.
Segment 389: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4033, Text: Which is why it’s important to have a left brain and a right brain competing for attention. And intimacy [inaudible 01:07:19]. Yes.
Segment 390: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4039, Text: Yeah. You mentioned a fragrance that sends out a message to the environment, essentially.
Segment 391: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4047, Text: A message in a bottle. Yeah.
Segment 392: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4049, Text: A message in a bottle. So you can go to a rose garden and trick the rose garden to think it’s 4:00 AM, essentially?
Segment 393: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4056, Text: You could if you wanted to, but maybe that is-
Segment 394: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4058, Text: Not trick. Trick is such a bad word.
Segment 395: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4060, Text: Right. Right.
Segment 396: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4061, Text: Inspire.
Segment 397: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4063, Text: Inspire I like. I like the idea of providing nature with a choice, which is why I love that elegant mathematical equation of empowerment and agency.
Segment 398: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4073, Text: Empower the rose garden to create a romantic moment for the wearer of the fragrance.
Segment 399: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4080, Text: But now again you’re, again, all of this to go back to that human-centric notion of romance. But maybe there’s another way to do romance that we haven’t yet explored. And maybe there’s a way to tap into what happens to the rose when it’s dreaming. Assuming that plants are sentient and assuming that we can tap into that sentient, what can we discover about what does the rose want? What does it actually want and what does it need? And what are the rose’s dreams?
Segment 400: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4121, Text: But do you think there’s some correlation in terms of romance, in terms of the word you sometimes use, magic? Is there some similarities in what humans want and what roses want and what nature wants?
Segment 401: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4133, Text: I think so. I think there is. And if I did not think so, oh my goodness, this would not be a nice world to live in. I think we all want love. I recently read this beautiful letter that was written by Einstein to his daughter. Einstein asked his daughter to wait 20 years until she reveals these letters, and so she did. It’s just one of the most beautiful letters I’ve ever read from a father to his daughter. And the letter overall is imbued with a sense of remorse or maybe even feelings of sadness. And there is some kind of melancholy note in the letter where Einstein regrets not having spent enough time with his daughter, having focused on the theory of general relativity and changing the world. And then he goes on to talk about this beautiful and elegant equation of E=MC^2. And he tells his daughter that he believes that love is actually the force that shapes the universe because it is like-
Segment 402: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4203, Text: Is actually the force that shapes the universe because it is like gravity, right? It attracts people. It is like light. It brings people together and connects between people, and it’s all empowering. And so if you multiply it by the speed of light, you could really change the world for the better. And call me a romanticist. I know you are too, which is why I so love being here. I believe in this. I totally and utterly believe in…
Segment 403: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4234, Text: In love. By the way, let me just excerpt from Einstein’s letter. “There’s an extremely powerful force that so far science has not found a formal explanation to. It’s a force that includes and governs all others and is even behind any phenomena operating in the universe and has not yet been identified by us. This universal force is love.” He also, the last paragraph in the letter, as you’ve mentioned, ” I deeply regret not having been able to express what is in my heart, which has quietly beaten for you all my life. Maybe it’s too late to apologize, but as time is relative,” that jokes to Einstein, “I need to tell you that I love you and thanks to you I have reached the ultimate answer. Your father, Albert Einstein.” By that regret, I deeply regret not having been able to express what is in my heart. Maybe that’s a universal regret, filling your days with busyness and silly pursuits and not sitting down and expressing that.
Segment 404: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4303, Text: But it is everything. It is everything. It is why I love that expression, and I forget who said this, but I love my daughter more than evolution required, and I feel the same way towards my other half. And I feel that when you find that connection, everything and anything is possible and it’s a very, very, very magical moment. So I believe in love and I believe in the one.
Segment 405: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4347, Text: It might be the same thing, it might be a different thing, but let me ask you a ridiculously big philosophical question about beauty. Dostoevsky said Beauty will save the world in The Idiot, one of my favorite books of his. What is beauty to you? You’ve created through this intersection of engineering and nature, you have created some incredibly beautiful things. What do you think is beauty?
Segment 406: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4375, Text: That’s a beautiful question.
Segment 407: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4377, Text: Maybe it is connected to the love question.
Segment 408: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4379, Text: It is connected to the love question. Of course, everything is connected to the love question. To me, beauty is agency. To me, something that has agency, it is beautiful. There is this special quote from Buckminster Fuller, which I cannot remember word for word but I remember the concept, which goes something like this. When I work on a problem, I never think about beauty. But when I’m done solving the problem and I look at what I’ve created and it’s not beautiful, I know that I was wrong.
Segment 409: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4417, Text: Okay, yeah.
Segment 410: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4418, Text: It’s kind of an agency that speaks to the “objective function” of the creation, right? Whether for Bucky it’s useless or useful.
Segment 411: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4429, Text: So this idea of empowerment that you talked about, it’s fundamentally connected to it.
Segment 412: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4432, Text: Comes back to that, yeah.
Segment 413: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4434, Text: What’s the difference that you hinted at between empowerment and emergence? Is emergence completely lacks control and empowerment is more controlled? There’s an agent making decisions? Is there an interesting distinction there?
Segment 414: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4456, Text: Yes. I think empowerment is a force with direction. It has directionality to it. Emergence is, I believe, multi-directional. Again, that depends on the application. Emergence is perhaps in terms of a material definition, is a tropic spirit. When empowerment, the end is a tropic counterpart, I think they overlap because I think that empowerment is a way of inspiring emergence. I think emergence does not happen without empowerment, but empowerment can happen without emergence.
Segment 415: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4505, Text: Do you think of emergence as the loss of control? When you’re thinking about these capsules and then the things they create, is emergence of things not a desirable conclusion?
Segment 416: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4519, Text: I love that question because to some of us, the loss of control is control. In design, we’re used to extreme levels of control over form and the shape of a thing and how it behaves and how it functions. And that’s something we’ve inherited from the industrial revolution. But with nature, there is this diversity that happens without necessarily having a reward function, right? This is good or bad. Things just happen and some of them happen to have wings and some of them happen to have scales, and you end up with this incredible potential for diversity. So I think the future of design is in that soft control, is in the ability to design highly controlled systems that enable the loss of control.
Segment 417: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4574, Text: And creativity is very much part of this because creativity is all about letting go and beginning again and beginning again and beginning again. And when you cannot let go, you cannot be creative and you can’t find novelty. But I think that letting go is a moment that enables empowerment, agency, creativity, emergence, and they’re all connected. They sort of associate themselves with definition of destiny or the inevitable. A good friend of mine shared with me elegant definition of fate, which is the ratio of who you are and who you want to be.
Segment 418: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4621, Text: Ratio of who you are, who want to be.
Segment 419: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4624, Text: Exactly. And that sort of ends up defining you and those tools, I think when you let go, you sort of find, you give peace to your will, to a sense of will. And so I think that’s very, very important in design, but also in life.
Segment 420: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4643, Text: She said this fate is the ratio of…
Segment 421: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4645, Text: Who you are and who you want to be.
Segment 422: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4647, Text: Who you want to be. Do you think there’s something to this whole manifestation thing like focusing on a vision of what you want the world to become and in that focusing you manifest it? Like Paula Coelho said in the Alchemist, “when you want something, all the universe conspires in helping you to achieve it.” Is there something to that?
Segment 423: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4668, Text: I think so, yes. And I always think of what I do as the culmination of energy, information, and matter and how to direct energy, information, and matter in the design of a thing or in the design of a life. I think living is very much a process of channeling these energies to where they need to go. I think that the manifestation or part of that manifestation is the pointing to the moon in order to get to the moon. And that’s why manifestation is also directional. It has that vector quality to it that I think of agency as.
Segment 424: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4711, Text: Have you in your own life. Has there been things you’ve done where you kind of direct that energy information and matter in a way that opens up?
Segment 425: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4721, Text: New possibilities?
Segment 426: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4722, Text: Yeah. I mean, you’ve also said somewhere, I’m probably misquoting, that many things, you, Neri, are many things and you become new things every 10 years or so.
Segment 427: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4736, Text: Oh, I did say that somewhere, that every decade you’ve sort of switched.
Segment 428: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4740, Text: That was a previous Neri that said that.
Segment 429: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4743, Text: Yeah, I did say sometime ago that you have to sort of reboot every 10 years to keep creative and keep inventive and keep fresh.
Segment 430: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4752, Text: Is there are things you’ve done in your life where just doors opened?
Segment 431: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4760, Text: I think everything, everything, everything good I’ve found in my life has been found in that way of letting go and suspending my sense of disbelief. And often you will find me say to the team, suspend your disbelief. I don’t care that this is impossible. Let’s assume it is. Where does it take us? And that suspension of disbelief is absolutely part and parcel of the creative act. I did so when I was in medical school, I was in Hadassah and in the Hebrew University, and I remember I left medical school for architecture the day my grandmother passed away. And that was a moment of relief and that was a door that was closing that opened other opportunities. But that of course required letting go of the great vision of becoming a doctor and letting go of the dream of being surrounded by wonderful patients and the science of medicine and the research associated with that science. And letting go of that dream to accomplish another.
Segment 432: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4843, Text: And it has happened throughout my life in different ways. MIT was another experience like that where people pointed at me as the designer for whom the academic currency is not necessarily the citation index. And of course in order to get tenure at MIT, you have to look at the citation index. But for me it was not that. It was manifesting our work in shows and writing papers and writing patents and creating a celebration around the work. And I never saw a distinction between those ways of being. I also think that another kind of way of being or a modality of being that I found helpful is Viktor Frankl wrote this incredible book, Men’s Search for Meaning after the Holocaust. And he writes, different people pursue life for different reasons. According to Freud, the goal of life is to find pleasure and according to Adlers, to find power.
Segment 433: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4914, Text: And for Viktor Frankl, it was about finding meaning. And when you let go of the titles and the disciplines and the boundaries and the expectations and the perception, you are elevated to this really special, yes, spiritual, but definitely very, very creative plane where you can sort of start anew, look at the world through the lens of a bacterium or a robot, or look at ecology through the lens of chemistry and look at chemistry through the lens of robotics and look at robotics through the lens of microbial ecologies and so on and so forth. And I feel that kind of rebooting not every 10 years, but every minute, every breath, is very, very important for a creative life and for just maintaining this fresh mind to reboot, reboot, to begin again with every breath, begin again. And that can be confusing some. For my team members, I like to change my mind. It’s who I am, it’s how I think, it’s how I operate.
Segment 434: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=4991, Text: And they’ll come and we found another technique or another technology that’s interesting and we thought that we were working on this functionalized fragrance, but now there’s another opportunity and let’s go there. And to me, I would much rather live life, like if I had to pick sort of my favorite Broadway show to enter and live through, it would be Into The Woods. It’s not a specific fairytale. It’s not the Sleeping Beauty or Little Red Riding Hood or Rapunzel, it’s all of them. It’s sort of moving into the forest and seeing this wonder and getting close and learning about that and then moving to another wonder. And life is really about tying all of these little fairytales together in work and also in life.
Segment 435: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5046, Text: Unafraid to leap into the unknown?
Segment 436: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5047, Text: Unafraid to leap into the unknown.
Segment 437: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5048, Text: Speaking of MIT, you got a tenure at MIT and then you leaped to New York and started a new company that with a vision that doesn’t span a couple of years, but centuries.
Segment 438: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5061, Text: I did. It was my destiny to start a company. And do I have mornings when I wake up and I ask myself what the hell am I doing? Yes, I have those mornings.
Segment 439: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5072, Text: What do you do with those mornings, by the way?
Segment 440: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5073, Text: I embrace them and I find gratitude and I say to myself, thank goodness. I am so lucky to have the ability to be frustrated in this way. So I really, really embrace these frustrations and I take them, I wrap them in a bubble and I look at it on the outside of my aware mind and I laugh at them, I smile at them.
Segment 441: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5111, Text: If I could return actually to the question of beauty for a second, I forgot to ask you something. You mentioned imperfection in the death masks. What role does imperfection play in our conception of beauty? What role does imperfection play in nature? There’s this Japanese aesthetics concept of wabi-sabi, which basically embraces imperfection. Nothing lasts, nothing is finished, and nothing is perfect. What do you think of that?
Segment 442: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5145, Text: I totally agree that change is the only permanence. That imperfection is there if only to signal that we are part of a bigger thing than ourselves, that we are on a journey, that things are in movement. And if they were perfect, of course, when things are perfect, it is just so boring. We end up with stereotypes. And as humans, but I think just in general as living beings, we’re here to find meaning and that meaning cannot be found without struggle and without seeking to, not to perfect, but to build towards something better. When I was a child, my mother who I love so much, always explained to me how important it is to fall and to fail and to fight and to argue, and that there is a way, that there’s a culture to failing and to imperfection. So I think it is necessary for something beautiful to be imperfect and it is a sign of nature because nothing in nature is perfect.
Segment 443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5229, Text: What about human relations? You mentioned finding love. Are the flaws in humans, imperfection in humans, a component of love? What role do you think the flaws play?
Segment 444: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5243, Text: That’s a really profound question. I think the flaws are there to present a vulnerability, and those flaws are a sign of those vulnerabilities. And I think love is very, very gentle, right? Love with Bill, we often talk about between the two of us, about what drives all human behavior. And for him it’s incentive, as you might expect, and he will repeat this sentence to me, oh, incentive drives all human behavior. But I would say to me it’s love, very much so. And I think flaws are part of that because flaws are a sign of that vulnerability, whether physical, whether emotional vulnerability, and these vulnerabilities, they either tear us apart or they bring us together.
Segment 445: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5316, Text: The vulnerability is what is the glue. I think that the vulnerability enables connection. The connection is the glue, and that connection enables accessing a higher ground as a community as opposed to as an individual. So if there is a society of the mind, or if there are higher levels of awareness that can be accessed in community as opposed to again, going to the silkworm, as opposed to on the individual level, I think that those occur through the flaws and the vulnerabilities. And without them we cannot find connection, community. And without community, we can’t build what we have built as a civilization for the past hundreds of thousands of years. So I think not only are they beautiful, but they have a functional role in building civilizations.
Segment 446: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5372, Text: Yeah, there’s a sense in which love requires vulnerability and maybe love is the leap into that vulnerability.
Segment 447: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5380, Text: And I think yes, I think a flaw, think about it physically, I’m thinking about a brick that’s flawed, but in a way I think of a flaw as an increased surface area.
Segment 448: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5402, Text: That’s a good line. That’s a good line.
Segment 449: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5403, Text: A surface area that physically or emotionally, right, it sort of introduces this whole new dimension to a human or a brick. And because you have more surface area, you can use mortar and build a home. And yeah, I think of it as accessing this additional dimension of surface area that could be used for good or bad to connect, to communicate, to collaborate. It makes me think of that quote from this incredible movie I’ve watched years ago, Particle Fever, I think it was called, documentary about the large hadron collider, an incredible film, where they talk about the things that are least important for our survival are the things that make us human. Like the pure romantic act or the notion of, and Viktor Frankl talks about that too.
Segment 450: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5461, Text: He talks about feeling the sun on his arms as he is working the soil in two degrees Fahrenheit without clothes. And the officer berates him and says, what have you done? Have you been a businessman before you came here to the camp? And he says, I was a doctor. And he said, you must’ve made a lot of money as a doctor. And he said, all my work I’ve done for free, I’ve been helping the poor. But he keeps his humility and he keeps his modesty and he keeps his preservation of the spirit. And he says the things that actually make him able to, or made him able to outlive the terrible experience in the Holocaust was really cherishing this moment when the sun hits his skin or when he can eat a grain of rice, a single grain of rice. So I think cherishing is a very important part of living a meaningful life, being able to cherish those simple things
Segment 451: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5550, Text: To notice them and to-
Segment 452: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5552, Text: To notice them, to pay attention to them in the moment, and I do this now more than ever.
Segment 453: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5562, Text: Bakowski has this poem called Nirvana where it tells a story of a young man on a bus going through North Carolina or something like this, and they stop off in a cafe and there’s a waitress and he talks about that he notices the magic, something indescribable, he just notices the magic of it. And he gets back on the bus with the rest of the passengers. And none of them seem to have noticed the magic. And I think if you just allow yourself to pause, just to feel whatever that is, maybe ultimately it’s a kind of gratitude for, I don’t know what it is. I’m sure it’s just chemicals in the brain, but it is just so incredible to be alive and noticing that and appreciating that and being one in that with others.
Segment 454: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5618, Text: Yes. Yes. And that goes back to the fireplace, right to the first technology. What was the first technology? It was fire, first technology to have built community. And it emerged out of a vulnerability of wanting to stay away from the cold and be warm together. And of course, that fire is associated with not only with comfort and the ability to form bio relevant nutrients in our food and provide heat and comfort, but also spirits and a kind of way to enter a spiritual moment, to enter a moment that can only be experienced in a community as a form of a meditative moment. There is a lot to be said about light. Light is, I think, an important part of these moments of, I think it’s a real thing. I really truly believe that we’re born with an aura surface area that is measurable. I think we’re born into the world with an aura. And how do we channel that really ends up sort of defining the light in our lives.
Segment 455: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5724, Text: Do you think we’re all lonely? Do you think there’s loneliness in us humans?
Segment 456: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5726, Text: Oh yes, yes. Loneliness is part, yes. I think we all have that loneliness, whether we’re willing to access that loneliness and look at it in the eye or completely, completely avoid it or deny it.
Segment 457: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5744, Text: It feels like it’s some kind of foundation for longing and longing leads to this combination of vulnerability and connection with others.
Segment 458: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5755, Text: Yes.
Segment 459: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5756, Text: It feels like that’s a really important part of being human as being lonely.
Segment 460: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5759, Text: Very. We are born into this world alone. Again, being alone and being lonely are two different things and you can be together, but be lonely and you can be alone but not be lonely at all. We often joke, Bill and I, that he cannot be lonely. He cannot deal with being by himself. He always needs people around him. And I strive, long, must have creative solitude, must find pockets of solitude and loneliness in order to find creativity and reconnect with myself. So loneliness is a recipe for community in my opinion. And I think those things compliment each other. And they’re synergetic, absolutely. The yin and yang of togetherness. And they allow you, I think, to reset and to tune in to that ratio we talked about of who you are and who you want to be.
Segment 461: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5827, Text: If you go to this place of creative solitude, what’s your creative process? Is there something you’ve noticed about what you do that leads to good work?
Segment 462: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5838, Text: I love to be able not only to lose focus, but kind of to focus on the peripheral view and to allow different things to occur at once. So I will often, in my loneliness journeys, I will often listen to Leonard Bernstein. Anything I can find online by Lenny Bernstein, it’s reading a nature paper, it’s War and Peace. It’s really revisiting all the texts that are so timeless for me with opportunities that are very, very timely. And I think for me, the creative process is really about bringing timeless problems or concepts together with timely technologies to observe them. I remember when we did the Mandela Pavilion, we read Moby Dick, the whiteness of the whale, the albino, the different the other, and that got us to work on melanin and melanine also is sort of an output from the death mass. So it’s lots of things happening at the same time and really allowing them to come together to form this view about the world through the lens of a spirit being or a living being or a material. And then focus on the world through the lens of that material.
Segment 463: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5921, Text: The glasswork was another project like that where we were fascinated by glass because obviously it’s superb material for architecture, but we created this new glass printing technology for the first time that was shedding light on the biomechanics of fluid glass, the math and the physics of which was never done before, which was so exciting to us, but revealing new knowledge about the world through technology. That’s one theme. The reincarnation between things, material and immaterial. That’s another theme. Lenny Bernstein, War and Peace, Tolstoy.
Segment 464: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5958, Text: You’ve tweeted a Tolstoy quote from War and Peace, as of course you would. Everything I know, I know because of love.
Segment 465: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5967, Text: Yeah, I love this quote.
Segment 466: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5968, Text: So you use these kind of inspirations to focus you and then find the actual idea in the periphery.
Segment 467: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=5979, Text: Yes. And then connect them with whatever it is that we’re working on, whether it’s high throughput, directed evolution of bacteria, whether it’s recreating that Garden of Eden in the capsule and what it looks like, the food of the future. It is a little bit like directing a film. Creating a new project is a bit like creating a film. And you have these heroes, you have these characters and you put them together and there is a narrative and there’s a story. Whenever we start a new project, it has to have these ingredients of simultaneous complexity. It has to be novel in terms of the synthetic biology, material science, robotics, engineering, all of these elements that are discipline based or rooted must be novel.
Segment 468: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6031, Text: If you can combine novelty in synthetic biology with a novelty in robotics, with a novelty in material science, with a novelty in computational design, you are bound to create something novel, period. And that’s how I run the company and that’s how I pick the people. And so that’s another very, very important ingredient of the cutting edge across multiple disciplines that come together. And then in the background, in the periphery, there is all these messages, the whispers of the ancient oldies, right? The Beethoven’s and the Picassos.
Segment 469: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6065, Text: So Beethoven’s always whispering to you.
Segment 470: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6067, Text: Yeah. How could one not include Beethoven in the whispers?
Segment 471: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6071, Text: I’m going to ask you about Beethoven and the Evgeny Kissin you’ve mentioned because I’ve played piano my whole life. I obviously know a lot of Beethoven and it’s one of the private things for me, I suppose, because don’t think I’ve ever publicly played piano.-
Segment 472: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6085, Text: By the way. Me too.
Segment 473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6085, Text: I mean at night-
Segment 474: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6090, Text: I play in private only.
Segment 475: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6092, Text: People sometimes even with guitar, people ask me, can you play something? And it just feels like certain things are
Segment 476: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6098, Text: Are meant to be done-
Segment 477: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6099, Text: Privately. Yeah, it’s weird. I mean it’s a difficult, and some of the times I have performed publicly, it is an ultimate leap in vulnerability. It’s very, very, very difficult for me. And I’m sure, I know it’s not for a lot of people, but it is for me. Anyway, we’ll return to that. But since you’ve mentioned combination of novelty across multiple disciplines and that’s what you seek when you build teams or pick people you work with, I just wanted to linger on this idea of what kind of humans are you looking for in this endeavor that you’re taking on, this fascinating thing that you’ve been talking about. One of the things somewhere else, a previous version, version 5.7 of Neri said somewhere that there’s four fields that are combined to create this intersection of biology and engineering work, and it’s computational design, additive manufacturing, material engineering, synthetic biology. I’m sure there’s others, but how do you find these humans? Machine learnings in the mix.
Segment 478: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6165, Text: I manifest and they come, there are a few approaches to-
Segment 479: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6170, Text: Manifest.
Segment 480: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6173, Text: They show up.
Segment 481: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6175, Text: Okay.
Segment 482: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6175, Text: Send your message upon the water. I mean those job descriptions that you saw, the first ones I wrote by myself, and you find interesting people and brilliant people when you look, we talked about second derivative. When you look under and under and under. And if you look deep enough and specialized enough and if you allow yourself to look at the cracks, at the flaws, at the cracks between disciplines and between skills, you find really, really interesting diamonds in the rough. And so I like for those job descriptions to be those messages in a bottle that bring those really interesting people our way. I mean, they have to have humility. They have to have a shine in their eye. They have to be hungry and foolish, as Steve Jobs so famously said.
Segment 483: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6229, Text: A friend of mine who’s a dean of well-known architectural school said today, architects don’t want to be architects. Architects don’t look up to the starchitects as role models. Starchitects are no longer role models. Architects want to build by virtue of not building. Architects want, she said, we’re back in the sixties when we think about architecture back in the hippie movement, I think that in a way they have to be somewhat of a hippie, somewhat of a kind of jack of all trades, master of all.
Segment 484: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6266, Text: And yet with humility.
Segment 485: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6267, Text: And yet with humility. Now that is hard to find and that is why when I start an interview, I talk about childhood memories and I asked about music and I ask about connection. And through these interviews you can learn a lot about a person’s future by spending time hearing them talk about their past.
Segment 486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6292, Text: Do you find that educational, like PhDs versus, what’s the life trajectory? Yours is an interesting life trajectory too. What’s the life trajectory that leads to the…
Segment 487: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6303, Text: What’s the life trajectory that leads to the kind of person that would work with you?
Segment 488: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6307, Text: It’s people who have ideally had industry experience and know what it’s like to be in the quote unquote real world. They’re dreamers that are addicted to reality as opposed to realists that are addicted to dreams, meaning they have that innocence in them, they have the hunger, they have the idealism without being entitled and with understanding the systems that govern our world and understanding how to utilize these systems as Trojan horses to bring those values into the world. There are individuals who feel comfortable in this friction between highly wondrous and dreamy and incredible fantasy renditions of what the world could be and extremely brilliant skills in terms of their disciplinary background. PhD with industrial experience in a certain field or a double major in two fields that make no sense whatsoever in their combination.
Segment 489: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6377, Text: I love it. Yeah.
Segment 490: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6377, Text: Are things that really, really attract me.
Segment 491: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6379, Text: Especially the span, the technology biology gap.
Segment 492: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6384, Text: Yes. Technology, biology, nature, culture. I mean, the secret to one thing is through the lens of another. And I always believe in that kind of translational design ability to be able to see something through the lens of another and always allows you to think again, begin again, reestablish, redefine, suspend your disbelief, revisit. And when you revisit enough times like a hundred times or 200 times and you revisit the same question through the lens of any possible discipline and any possible scenario, eventually you get to the truth.
Segment 493: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6419, Text: I have to ask you, because you work at the interplay of the machine and the natural world, is there a good definition for you of what is life? What is a living organism?
Segment 494: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6435, Text: I think 440 million years ago, there were all these plants, the cyanobacteria I believe actually. That was the first extinction. There were five extinctions. We are apparently the sixth. We are in the eye of the storm. We are in the sixth extinction. We are going to be extinct as we speak. I mean, death is upon us whether we want to admit it or not.
Segment 495: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6462, Text: And actually they found in Argentina and in various places around the world, they found these spores of the first plants that existed on the planet. And they emerged out of these … Cyanobacteria were the first of course, and then they found these spore based plants. And because they didn’t have seeds there were only spores. The spores became sort of the fossils by which we’ve come to known of their existence. And because of these spores, we know that this first extinction existed.
Segment 496: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6498, Text: But this extinction is actually what enabled plants to resurrect. The death of these first plants, because they clinked to the rocks and they generated a ton of phosphorus that went into the ocean by clinging to the rocks 60 times more phosphorus than without them. And then all this phosphorus basically choked the oceans and made them super cold and without oxygen, anoxic. And then we lost the plant kingdom, and then because of the death of these first plants, they actually enriched the soil and created nutrients for these new plants to come to the planet. And those planets had more sophisticated vein systems and they were moving beyond spores to seeded plants, et cetera, and flowering plants. And so in a way, one mass extinction or the division period led to life as we know it. And where would we be without plants in a way?
Segment 497: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6571, Text: I think that death is very much part of life and through that definition, that kind of planetary wide definition in the context of hundreds of millions of years, life gains a completely new light. And that’s when the particles become a wave, where humans, we are not alone and we are here because of those plants. I think death is very much part of life. In the context of the redwood tree, perhaps life is defined as 10 generations. And through the lens of a bacteria, perhaps life is defined as a millisecond. And perhaps through the lens of an AGI, life is defined as all of human civilization. And so I think it really is a question of this timescale again, the timescale and the organism, the life form that’s asking the question through which we can answer, what is life?
Segment 498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6636, Text: What do you think about this? If we think of ourselves in the eye of the storm of another extinction, the natural question to ask here is you have all of nature and then you have this new human creation that is currently being termed artificial intelligence. How does your work play with the possibility of a future super intelligent ecosystem, an AGI that either joins or supersedes humans?
Segment 499: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6673, Text: I’m glad you asked this question.
Segment 500: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6675, Text: And are you hopeful or terrified?
Segment 501: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6677, Text: Both. I’m hopeful and terrified. I did watch your interview with Eliezer Yudkowsky and I loved it
Segment 502: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6685, Text: Because you were scared or because you were excited or because there was a [inaudible 01:51:29]?
Segment 503: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6688, Text: First of all, I was both. Totally scared, shamed, excited, and totally also inspired because he’s just such an incredible thinker. And I can agree or disagree with what he says, but I just found his way of thinking about AGI and the perils of humanity as a result.
Segment 504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6713, Text: There’s an inevitability to what he’s saying. His advice to young people is that prepare for a short life. He thinks it’s very almost simple. It’s almost common sense that AGI would get rid of humans, that he can’t imagine a trajectory eventually that leads to a place that doesn’t have AGI kill all humans. There’s just too many trajectories where a super intelligent systems gets rid of humans and in the near term. And so that clarity of thinking is very sobering. To me, maybe it is to you as well, it’s super inspiring because I think he’s wrong, but it’s like you almost want to prove him wrong. It’s like, “No, we humans are a clever bunch. We’re going to find a way.”
Segment 505: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6768, Text: It is a bit like jumping into super cold water. It’s sort of a kind of fist in your face. It wakes you up. And I like these moments so much, and he was able to bring that moment to life, even though I think a mother can never think that way ever. And it’s a little bit like that notion of I love her more than evolution requires.
Segment 506: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6794, Text: On your question about AGI and nature, look, I think we’ve been through a lot in terms of to get here, we sort of moved from data, the ability to collect information to knowledge, the ability to use this information for utility, from knowledge to intelligence. And what is intelligence? It’s the ability to problem solve and adapt and translate. That’s sort of from data to information to knowledge. I think the next frontier is wisdom. And what is wisdom? Wisdom is the ability to have or find insight about the world and from wisdom to spiritual awareness, which sort of transcends wisdom and is able to chart the world into new territory.
Segment 507: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6838, Text: But I think what is interesting about AGI is that it is sort of almost like a self recursive thing, because it’s like a washing machine of a third derivative Wikipedia. It uses kind of language to create language, to create language, to create language.
Segment 508: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6855, Text: It feels like novelty is being constantly created. It doesn’t feel like it’s regurgitating.
Segment 509: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6860, Text: And that’s so fascinating because these are not the stochastic parrots. This is sort of a new form of emergence perhaps of novelty as you say, that exists by virtue of using old things to create new things.
Segment 510: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6878, Text: But it’s not as if the AGI has self-awareness. Maybe. Maybe it has, but as far as I can tell, it’s not as if AGI has approached consciousness or sentience just yet. It’s probably getting there. But the language appears to present itself as if there is sentience there, but it doesn’t. But I think that’s the problem at the point where this AGI sounds like me and speaks like me and behaves like me and feels like me and breathes like me and my daughter knows the AGI to be me as sort of the end of everything is the end of human agency.
Segment 511: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6923, Text: But what is the end of human agency to humans I think is the beginning of agency to nature. Because if you take all of this agency, if you take all of these language models that can summarize all of human civilization and consciousness and then upload that to nature and have nature now deal with that world of consciousness that it never had access to.
Segment 512: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=6949, Text: Maybe through Eliezer’s lens, the sort of short-lived human becomes sort of a very long-lived humanlike, sentient, weeping willow. Maybe that’s the end in the beginning. And maybe on the more optimistic side for us humans, it’s a different form of existence where everything we create and everything we consume and everything we process is all made out of six elements and that’s it. And there’s only those six elements and not 118 elements. And it’s all the stuff of biology plus some fair amount of bits, genes, and atoms. A lot of Beethoven.
Segment 513: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7004, Text: A lot of Beethoven. I think the idea of connecting AGI to nature through your work is really fascinating. Sort of unlocking this incredible machinery of intelligence that is AGI and connecting it to the incredible machinery of wisdom that is nature has evolved through billions of years of pretty crazy intense evolution.
Segment 514: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7035, Text: Exactly. Again, I’m going back to directed evolution. Unlike this sort of high throughput brute force approach, if there is a way to utilize this synergy for diversity and diversification, what happens if you ask a ChatGPT question, but it takes 10,000 years to answer that question? What does that look like when you completely switch the timescale and you can afford the time to answer the question? And again, I don’t know, but that world to me is possibly amazing.
Segment 515: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7090, Text: Because when we start to think about timescales like this, just looking at earth, all the possible trajectories it might take of this living organism that is earth, do you think there’s others like it? Do you think there’s other planets with life forms on them that are just doing their thing in this kind of way?
Segment 516: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7106, Text: Planets.
Segment 517: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7107, Text: Because in what you’re doing, you’re directly playing with what’s possible with life, lifelike things. That kind of maps the question of, well, what kind of other things are possible elsewhere? Do you think there’s other worlds full of life, full of alien life out there?
Segment 518: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7130, Text: I’ve studied the calculations that point towards the verdict that the possibility of life in and around us is very, very low. We are a chosen planet in a way. There’s water and there’s love. What else do you need? And that sort of very peculiar juxtaposition of conditions, the oxygen, the water, the carbon again, is in a way a miracle given the massive extinctions that we’ve been through as life forms.
Segment 519: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7173, Text: And that said, I cannot believe that there is no other life form. I want to believe more than I know that yes, that there are life forms in the white fountain that is the black hole, that there are these life forms that are light years away from us, that are forming other forms of life forces.
Segment 520: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7205, Text: I’m much more worried about probably the thing that you’re working on, which is that there’s all kinds of life around us that we’re not communicating with.
Segment 521: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7217, Text: Yes.
Segment 522: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7218, Text: That there’s aliens in a sense all around us that we’re not seeing, that we’re not talking to, that we’re not communicating. Because that to me just seems the more likely situation.
Segment 523: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7230, Text: That they’re here.
Segment 524: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7231, Text: That they’re here, they’re all around us in different forms, that there’s a thing that connects all of us, all of living beings across the universe, and we’re just beginning to understand any of it. And I feel like that’s the important problem is I feel like you can get there with the tools of science today by just studying life on earth. Unlock some really fundamental things that maybe you can start to answer questions about what is consciousness? Maybe this thing that we’ve been saying about love, but honestly, in a serious way. And then you’ll start to understand that there is alien life all out there, and it’s much more complicated and interesting than we kind of realize as opposed to looking to exactly human-like things. It’s the variety of life that’s possible is just almost endless.
Segment 525: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7288, Text: I totally agree with you. I think again, define alien, right?
Segment 526: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7296, Text: Yeah. Define intelligence, define life.
Segment 527: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7299, Text: Right. And Marvin Minsky used to say, “Intelligence is a suitcase word.” It’s a word so big. It’s a word like sustainability, and it’s a word like rock and roll. And suitcase words are always very, very dangerous.
Segment 528: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7315, Text: Speaking of rock and roll, you’ve mentioned music and you mentioned Beethoven a bunch of times. You’ve also tweeted about you getting Kiss in performance and so on. What can you say about the role of music in your life?
Segment 529: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7329, Text: I love music. I always wondered why is it that plastic arts, meaning architecture and sculpture and painting, can’t get us to cry and music gets us to cry so quickly and connect so quickly? And no wonder that plants also respond to music, but that is at the top of the creative pyramid in my opinion.
Segment 530: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7353, Text: It’s a weird mystery that we’re so connected to music. Well, by the way, to push back, a good bridge will make me cry.
Segment 531: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7361, Text: It’s true. And I will say when I visited the Segreta Familia, I had that kind of spiritual reverence towards that spatial experience and being in that space and feeling the intention and the space and appreciating every little gesture. It’s true. It is the universal language. It’s the language of waves. It’s the language of the waves, not the language of the particles. It is the universal language, I believe, and that is definitely one of my loves.
Segment 532: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7396, Text: And you said that if you weren’t doing what you were doing now, perhaps you would be a film director. I have to ask, what do you think is the best film of all time? Maybe top three?
Segment 533: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7410, Text: Maybe The Godfather.
Segment 534: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7413, Text: Godfather, okay.
Segment 535: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7414, Text: The Godfather is definitely up there. Francis Coppola is one of my heroes.
Segment 536: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7419, Text: Have you met him?
Segment 537: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7420, Text: I have met him, yes. Yes, yes. We were very lucky to work with him on his new film, Megalopolis, which is coming out I hope in 2024. And think about the cities of the future in the context of new materials and the unity between nature and culture. Godfather is definitely up there.
Segment 538: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7442, Text: 2001 is up there. I would watch that film again and again and again. It’s incredible. The last scene in Odyssey 2001, just watch the last scene of 2001, then listen to Yudkowsky, and then go to the garden. And that’s pretty much the end in the beginning.
Segment 539: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7467, Text: But that scene, that last scene from 2001 is everything. It says so much with so little and it’s sort of the embodiment I believe, of ambivalence. And there’s opportunity to believe in the beginning of humankind, the end of humankind, the planet, child star or star child of the future. Was there a death? Was there an reincarnation? That final scene to me is something that I go back to and study, and every time there is a different reading of that scene that inspires me. That scene, and then the first scene in The Godfather, still one of the best scenes of all times, sort of a portrait of America, the ideals and values that are brought from Italy.
Segment 540: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7523, Text: A family of loyalty.
Segment 541: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7525, Text: Yes.
Segment 542: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7526, Text: Of values of how different values are constructed.
Segment 543: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7529, Text: Yes. Loyalty and the human spirit and how Coppola celebrates the human spirit through the most simple gestures in language and acting. And I think in Kubrick you see this highly curated and controlled and manicured vision of creating a film. And with Francis, it’s like an Italian feast. It’s like anything can happen at any moment in time. And just being on the set with him is an experience I’ll take with me to my grave. It’s very, very, very special.
Segment 544: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7572, Text: And you said music is also part of that, of creating a feeling in the movies?
Segment 545: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7573, Text: Yeah, actually The Godfather, that tune-
Segment 546: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7581, Text: That makes me emotional every time on some weird level.
Segment 547: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7585, Text: Yeah. It’s one of these tunes I’m sure that if you play it to a Jasmine, you’ll get the best scent of all times. But I think with that particular tune, I learned staccato as something very, very happy and joyous. And then made into this stretched in time and became kind of the refrain of nostalgia and melancholy and loyalty and all of these values that ride on top of this one single tune.
Segment 548: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7625, Text: And you can play it in all kinds of different ways. I’ve played it on guitar and all kinds of different ways. And I think in Godfather III, the son plays it on guitar to the father. I think this happens in movies, but sometimes a melody, and it has a simple melody, you can just like-
Segment 549: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7642, Text: And the Straus melody in 2001. And when you juxtapose this melodies with this scene, you get this, again, hole that’s bigger than some of its parts where you get this moment, I think. These are the moments I would send with the next Voyager to outer space. The Godfather in 2001 would definitely beyond that golden record.
Segment 550: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7674, Text: You are an incredibly successful scientist, engineer, architect, artist, designer. You’ve mentored a lot of successful people. Can you give advice to young people listening to this of how to have a successful career and how to have a successful life?
Segment 551: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7694, Text: Look, I think there’s this beautiful line in Sheltering Sky. How many times have you seen a full moon in your life and actually took the time to ingest and explore and reflect upon the full moon? Probably 20, I believe he says.
Segment 552: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7715, Text: I spend time with a full moon. I take my time with a full moon and I pay attention to a full moon. And I think paying attention to the seasons and taking time to appreciate the little things, the simple things is what makes a meaningful life. I was very lucky to have grown up in a home that taught me this way of being. My parents, my grandmother, who played a very important role in my growing up. And that ability to pay attention and to be present is so, so, so, so … I could not emphasize it enough, is so crucial.
Segment 553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7779, Text: And be grateful.
Segment 554: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7780, Text: And be grateful. I think gratitude and presence, appreciation are really the most important things in life.
Segment 555: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7793, Text: If you could take a short tangent about your grandmother who’s played a big role in your life, what do you remember? What lessons have you learned from her?
Segment 556: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7805, Text: She had this blanket that she would give me every time I came back from school and say, “Do your homework here and meet with your friends here.” And it was always in her garden. And her garden in my mind was ginormous. But when last I went there and saw the site, which has now become the site for another tall building, it was a tiny, tiny little garden that to me, seemed so large when I was growing up because it had everything. It had fig trees, it had olive trees, it had mushrooms, it had the blanket. I would do my homework there. It was everything. And I needed nothing else. And that was my Garden of Eden. That was my childhood being.
Segment 557: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7853, Text: And we would lie on the blanket and look at the clouds and reflect upon the shapes of the clouds and study the shapes of the plants, and there was a lot of wonder in that childhood with her. And she taught me the importance of wonder in an eternal childhood and living adulthood as a child. And so I am very, very grateful for that. I think it is the sense of wonder, the speaking up was always something that she adhered to, to speak up your truth, to be straightforward, to be positive.
Segment 558: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7902, Text: These are things that I also got from my mom. And from my mom, the sense of humor. She had the best sense of humor that I could think of and was just a joy to be around. And my father taught me everything. My father taught me everything I know. My mom taught me everything I feel.
Segment 559: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7922, Text: That’s a good way to put it.
Segment 560: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7922, Text: My grandma taught me everything I insight.
Segment 561: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7928, Text: Well, I see the sense of wonder that just carries through everything you do. So I think you make your grandmother proud.
Segment 562: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7937, Text: Well, what about advice for how to have a career? You’ve had a very interesting career and a successful career, but not an easy one. You took a few leaps.
Segment 563: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7949, Text: I did take a few leaps and they were uncomfortable. And I’ll never forget, I think we were listening to a Rolling Stone song in the kitchen, and my dad was actually born in Boston. He’s American. He said, “I started to have sort of these second thoughts about continuing my education in Israel, and I was on my way to London to the Architectural Association to do my diploma studies there.” And he looked at me and he said, “Get out of here kiddo. You got to get out of here. You’ve outgrown where you’re at. You need to move forward.”
Segment 564: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=7996, Text: Another thing he had taught me, the feeling of discomfort. As you say, the feeling of loneliness and discomfort is imperative to growth. Growth is painful. Period. Any form of growth is difficult and painful. Birth is difficult and painful, and it is really, really important to place yourself in situations of discomfort. I like to be in a room where everyone in the room is more intelligent than me. I like to be in that kind of state where the people that I surround myself with are orders of magnitude more intelligent than I am. And I can say that that is true of all of my team members, and that’s the intellectual discomfort that I feed off of. The same is true for physical exertion. You got to put yourself in these uncomfortable situations in order to grow, in order to find comfort.
Segment 565: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8059, Text: And then on the other hand is love, is finding love and finding this other human that compliments you and that makes you a better version of the one you are and even of the one you want to be. But with gratitude and attention and love, you can go so, so far.
Segment 566: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8091, Text: To the younger generation, I don’t speak of a career. I never thought of my work as my career, ever. And there was this constant entanglement between life and work and love and longing and being and mothering. It’s all the same. And I appreciate that to some people that doesn’t work in their arrangement of will versus comfort versus the reality. But for me, it has always worked. I think to the younger generation, I say, don’t think of your career. A career is something that is imposed upon you. Think of your calling. That’s something that’s innately and directionally moves you, and it’s something that transcends a career.
Segment 567: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8147, Text: Similarly, you can think about the difference between learning versus being educated. Being educated is something that’s given to you that’s external, that’s being imposed, that’s top down imposed, whereas learning is something that comes from within. It’s also the difference between joy and happiness. Many times I’m sad and I’m still joyous. And it’s very, very important to understand the difference between these externally perceived success paths and internally driven value-based ways of being in the world.
Segment 568: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8182, Text: And together, when we combine the broken puzzle, let’s say, of substance and vulnerability, we get this bigger gestalt, this wondrous world of a future that is peaceful, that is wholesome, and that proposes or advocates for that kind of synergy that we’ve been talking about throughout. But it’s all fun.
Segment 569: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8221, Text: Well, thank you for this incredible conversation. Thank you for all the work you’re doing.
Segment 570: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8225, Text: Thank you.
Segment 571: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8226, Text: And I just have to say that thank you for noticing me and listening to me. You’re somebody from just today and from our exchanges before this, there’s a sense where you care about me as a human being, which I could tell you care about other humans. Thank you for doing that. Thank you for having empathy and just really listening and noticing me that I exist. Thank you for that. I’ve been a huge fan of your work, been a huge fan of who you are as a human being. It’s just an honor that you would sit with me. Thank you.
Segment 572: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8260, Text: Thank you so much, Lex. I feel the same way. I’ll just say the same.
Segment 573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8266, Text: And I look forward to hearing the response to my job application that I’ve submitted.
Segment 574: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8270, Text: Oh, you’re accepted.
Segment 575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8271, Text: Oh, damn. All right, excellent.
Segment 576: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8273, Text: We all speak of you all the time.
Segment 577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8275, Text: Thank you so much.
Segment 578: Speaker: Neri Oxman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8275, Text: Thank you, Lex.
Segment 579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8276, Text: Thank you, Neri. Thank you.
Segment 580: Speaker: , Timestamp: https://youtube.com/watch?v=XbPHojL_61U&t=8278, Text: Thanks for listening to this conversation with Neri Oxman. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Leo Tolstoy, “Everything I know, I know because of love.” Thank you for listening. I hope to see you next time.
Segment 581: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=0, Text: Listen, when it comes to romantic relationships, if it’s not a 100% in you, it ain’t happening. And I’ve never seen a violation of that statement where it’s like, “Yeah, it’s mostly good.” And this is like the negotiations, already it’s doomed. And that doesn’t mean someone has to be perfect. The relationship has to be perfect, but it’s got to feel a 100% inside, like yes, yes, and yes.
Segment 582: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=29, Text: The following is a conversation with my dear friend Andrew Huberman, his fourth time on this podcast. It’s my birthday, so this is a special birthday episode of sorts. Andrew flew down to Austin just to wish me a happy birthday, and we decided to do a podcast last second. We literally talked for hours beforehand and a long time after late into the night. He’s one of my favorite human beings, brilliant scientists, incredible teacher, and a loyal friend. I’m grateful for Andrew. I’m grateful for good friends, for all the support and love I’ve gotten over the past few years. I’m truly grateful for this life, for the years, the days, the minutes, the seconds I’ve gotten to live on this beautiful earth of ours. I really don’t want to leave just yet. I think I’d really like to stick around. I love you all. This is the Lex Fridman podcast. And now, dear friends, here’s Andrew Huberman.
Segment 583: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=90, Text: I’m trying to run a little bit more.
Segment 584: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=94, Text: Are you losing weight?
Segment 585: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=95, Text: I’m not trying to lose weight, but I always do the same fitness routine after 30 years. Basically lift three days a week, run three days a week, but one of the runs is the long run, one of them is medium, one of them is a sprint type thing. So what I’ve decided to do this year was just extend the duration of the long run. And I like being mobile. I never want to be so heavy that I can’t move. I want to be able to go out and run 10 miles if I have to so sometimes I do. And I want to be able to sprint if I have to. So sometimes I do.
Segment 586: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=130, Text: And lifting in objects feels good. It feels good to train like a lazy bear and just lift heavy objects. But I’ve also started training with lighter weights and higher repetitions and for three month cycles, and it gives your joints a rest. Yeah, so I think it also is interesting to see how training differently changes your cognition. That’s probably hormone related, hormones downstream of training heavy versus hormones downstream of training a little bit lighter. I think my cognition is better when I’m doing more cardio and when the repetition ranges are a little bit or higher, which is not to say that people who lift heavy are dumb, but there is a… Because there’s real value in lifting heavy.
Segment 587: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=175, Text: There’s a lot of angry people listening to this right now.
Segment 588: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=177, Text: No, no, no. But lifting heavy and then taking three to five minutes rest is far and away a different challenge than running hard for 90 minutes. That’s a tough thing, just like getting in an ice bath. People say, “Oh, well, how is that any different than working out?” Well, there are a lot of differences, but one of them is that it’s very acute stress, within one second you’re stressed. So I think subjecting the body to a bunch of different types of stressors in space and time is really valuable. So yeah, I’ve been playing with the variables in a pre systematic way.
Segment 589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=210, Text: Well, I like long and slow like you said, the impact it has on my cognition.
Segment 590: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=217, Text: Yeah, the wordlessness of it, the way it seems to clean out the clutter.
Segment 591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=226, Text: Yeah.
Segment 592: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=227, Text: It can take away that hyperfocus and put you more in a relaxed focus for sure.
Segment 593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=233, Text: Well, for me, it brings the clutter to the surface at first. Like all these thoughts come in there, and then they dissipate. I got knee barred pretty hard. That’s when somebody tries to break your knee.
Segment 594: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=244, Text: What a knee bar? They try and break your knee?
Segment 595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=244, Text: Yeah.
Segment 596: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=246, Text: Oh, so you tap so they-
Segment 597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=247, Text: Yeah. Yeah. So it’s hyperextend the knee in that direction, they got knee barred pretty hard. So in ways I don’t understand, it kind of hurts to run. I don’t understand what’s happening behind there. I need to investigate this. Basically the hamstringing flex, like curling, your leg hurts a little bit, and that results in this weird, dull, but sometimes extremely sharp pain in the back of the knee. So I’m working through this anyway, but walking doesn’t hurt.
Segment 598: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=278, Text: So I’ve been playing around with walking recently for two hours and thinking because I know a lot of smart people throughout history, I have walked and thought, and you have to play with things that have worked for others, not just to exercise, but to integrate this very light kind of prolonged exercise into a productive life. So they do all their thinking while they walk. It’s like a meditative type of walking, and it’s really interesting. It really works.
Segment 599: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=309, Text: Yeah. The practice I’ve been doing a lot more of lately is I walk while reading a book in the yard. I’ll just pace back and forth or walk in a circle.
Segment 600: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=318, Text: Audiobook, or are you talking about anything-
Segment 601: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=320, Text: No hard copy.
Segment 602: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=320, Text: Well, you just holding.
Segment 603: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=322, Text: I’m holding the book and I’m walking and I’m reading, and I usually have a pen and I’m underlining. I have this whole system like underlining, stars, exclamation points, goes back to university of what things I’ll go back to which things I export to notes and that kind of thing. But from the beginning when I opened my lab at that time in San Diego before I moved back to Stanford, I would have meetings with my students or postdocs by just walking in the field behind the lab. And I’d bring my bulldog Costello, bulldog Mastiff at the time, and he was a slow walker. So these were slow walks, but I can think much more clearly that way. There’s a Nobel Prize winning professor at Columbia University School of Medicine, Richard Axel, who won the Nobel Prize, co-won Nobel Prize with Linda Buck for the discovery of the molecular basis of olfaction.
Segment 604: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=369, Text: And he walks in, voice dictates his papers. And now with Rev or these other, maybe there are better ones than Rev, where you can convert audio files into text very quickly and then edit from there. So I will often voice dictate first drafts and things like that. And I totally agree on the long runs, the walks, the integrating that with cognitive work, harder to do with sprints and then the gym. You weight train?
Segment 605: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=396, Text: Yeah.
Segment 606: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=396, Text: You just seem naturally strong and thicker jointed. It’s true, it’s true.
Segment 607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=400, Text: Yeah.
Segment 608: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=401, Text: I mean, we did the one very beginner because I’m a very beginner of jiu jitsu class together, and as I mentioned then, but if people missed it, Lexus freakishly strong.
Segment 609: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=412, Text: I think I was born genetically to hug people.
Segment 610: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=415, Text: Oh, like Costello.
Segment 611: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=416, Text: Exactly.
Segment 612: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=417, Text: You guys have a certain similarity. He had wrists like it’s like you know. You and Jocko and Costello have these wrists and elbows that are super thick. And then when you look around, you see tremendous variation. Some people have the wrist width of a Whippet or Woody Allen, and then other people like you or Jocko. There’s this one Jocko video or thing on GQ or something. Have you seen the comments on Jocko, These are the Best?
Segment 613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=441, Text: No.
Segment 614: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=442, Text: The comments, I love the comments on YouTube because occasionally they’re funny because. The best is when Jocko was born, the doctor looked at his parents and said, “It’s a man.”
Segment 615: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=455, Text: It’s like Chuck Norris type comments.
Segment 616: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=456, Text: Oh yeah. Those are great. That’s what I miss about Rogan being on YouTube with the full-length episode. Oh, that comment.
Segment 617: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=462, Text: So this is technically a birthday podcast. What do you love most about getting older?
Segment 618: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=470, Text: It’s like the confirmation that comes from getting more and more data, which basically says, ” Yeah, the first time you thought that thing, it was actually right because the second, third and fourth and fifth time, it turned out the exact same way.” In other words, there have been a few times in my life where I did not feel easy about something. I felt a signal for my body, “This is not good.” And I didn’t trust it early on, but I knew it was there.
Segment 619: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=505, Text: And then two or three bad experiences later, I’m able to say, “Ah, every single time there was a signal from the body informing my mind, this is not good.” Now the reverse has also been true that there’ve been a number of instances in which I feel there sort of immediate delight, and there’s this almost astonishingly simple experience of feeling comfortable with somebody or at peace with something or delighted at an experience. And it turns out literally all of those experiences and people turned out to be experiences and people that are still in my life and that I still delight in every day. In other words, what’s great about getting older is that you stop questioning the signals that come from, I think deeper recesses of your nervous system to say, “Hey, this is not good,” or, “Hey, this is great, more of this.” Whereas I think in my teens, my twenties, my thirties, I’m almost 48, I’ll be 48 next month.
Segment 620: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=574, Text: I didn’t trust, I didn’t listen. I actually put a lot of work into overriding those signals and learning to fight through them, thinking that somehow that was making me tougher or somehow that was making me smarter. When in fact, in the end, those people that you meet that are difficult or there are other names for it, like in the end, you’re like, “That person’s a piece of shit,” or, “This person is amazing and they’re really wonderful.” And I felt that from the go.
Segment 621: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=603, Text: So you’ve learned to trust your gut versus the influences of other people’s opinions?
Segment 622: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=609, Text: I’ve learned to trust my gut versus the forebrain over analysis, overriding the gut. Other people often in my life have had great optics. I’ve benefited tremendously from an early age of being in a large community. It’s been mostly guys, but I have some close female friends and always have as well who will tell me, “That’s a bad decision,” or, “This person not so good,” or, “Be careful,” or, “They’re great,” or, “That’s great.” So oftentimes my community and the people around me have been more aligned with the correct choice than not.
Segment 623: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=644, Text: Is it really?
Segment 624: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=645, Text: Yes.
Segment 625: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=645, Text: Really? When you were younger like friends, parents and so on.
Segment 626: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=650, Text: I don’t recall ever really listening to my parents that much. I grew up in… We don’t have to go back to my childhood thing-
Segment 627: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=650, Text: My fault Andrew.
Segment 628: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=656, Text: … but my sense was that… Thank you. I learned that recently in a psilocybin journey, my first high dose psilocybin journey, which was-
Segment 629: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=666, Text: Welcome back.
Segment 630: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=666, Text: … done with a clinician. Thank you very much. Thank you. I was worried there for a second at one point. “Am I not coming back?” But in any event, yeah, I grew up with some wild kids. I would say about a third of my friends from childhood are dead or in jail, about a third have gone on to do tremendously impressive things, start companies, excellent athletes, academics, scientists, and clinicians. And then about a third are living their lives as more typical. I just mean that they are happy family people with jobs that they mainly serve the function to make money. They’re not into their career for career’s sake.
Segment 631: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=709, Text: So some of my friends early on gave me some bad ideas, but most of the time my bad ideas came from overriding the signals that I knew that my body, and I would say my body and brain were telling me to obey, and I say body and brain is that there’s this brain region, the insula, which does many things, but it represents our sense of internal sensation and interoception. And I was talking to Paul Conte about this, who as you know, I respect tremendously. I think he’s one of the smartest people I’ve ever met. I think for different reasons. He and Marc Andreessen are some of the smartest people I’ve ever met. But Paul’s level of insight into the human psyche is absolutely astounding. And he says the opposite of what most people say about the brain, which is most people say, “Oh, the supercomputer of the brain is the forebrain.”
Segment 632: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=768, Text: It’s like a monkey brain with a extra real estate put on there. And the forebrain is what makes us human and gives us our superpowers. Paul has said, and he’s done a whole series on mental health that’s coming out from our podcast in September, so this is not an attempt to plug that, but he’ll elaborate on [inaudible 00:13:08].
Segment 633: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=788, Text: Wait, you’re doing a thing with Paul?
Segment 634: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=789, Text: We already did. Yeah.
Segment 635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=789, Text: Oh, nice.
Segment 636: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=790, Text: So Paul Conte, he and I sat down, he did a four episode series on mental health. This is not mental illness mental health, about how to explore one’s own subconscious, explore the self, build and cultivate the generative drive. You’ll learn more about what that is from him. He’s far more eloquent and clearer than I am, and he provides essentially a set of steps to explore the self that does not require that you work with a therapist.
Segment 637: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=819, Text: This is self-exploration that is rooted in psychiatry, it’s rooted in neuroscience, and I don’t think this information exists anywhere else. I’m not aware that it exists anywhere else. And he essentially distills it all down to one eight and a half by 11 sheet, which we provide for people. And he says there, I don’t want to give too much away because I would detract from what he does so beautifully, but if I tried and I wouldn’t have accomplish it anyway.
Segment 638: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=849, Text: But he said, and I believe that the subconscious is the supercomputer of the brain. All the stuff working underneath our conscious awareness that’s driving our feelings and what we think are the decisions that we’ve thought through so carefully. And that only by exploring the subconscious and understanding it a little bit, can we actually improve ourselves over time and I agree. I think that so the mistake is to think that thinking can override it all. It’s a certain style of introspection and thinking that allows us to read the signals from our body, read the signals from our brain, integrate the knowledge that we’re collecting about ourselves, and to use all that in ways that are really adaptive and generative for us.
Segment 639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=896, Text: What do you think is there in that subconscious? What do you think of the Jungian and shadow? What’s there?
Segment 640: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=903, Text: There’s this idea, as you’re familiar with too. I’m sure that this Jungian idea that we all have all things inside of us, that all of us have the capacity to be evil, to be good, et cetera, but that some people express one or the other to a greater extent. But he also mentioned that there’s a unique category of people, maybe 2 to 5% of people that don’t just have all things inside of them, but they actually spend a lot of time exploring a lot of those things. The darker recesses, the shadows, their own shadows.
Segment 641: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=931, Text: I’m somebody who’s drawn to goodness and to light and to joy and all those things like anybody else. But I think maybe it was part of how I grew up. Maybe it was the crowd I was with, but then again, even when I started spending more time with academics and scientists, I mean you see shadows in other ways, right? You see pure ambition with no passion. I recall a colleague in San Diego who it was very clear to me did not actually care about understanding the brain, but understanding the brain was just his avenue to exercise ambition. And if you gave him something else to work on, he’d work on that.
Segment 642: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=972, Text: In fact, he did. He left and he worked on something else, and I realized he has no passion for understanding the brain like I assumed all scientists do, certainly why I went into it. But some people, it’s just raw ambition. It’s about winning. It doesn’t even matter what they win, which to me is crazy. But I think that’s a shadow that some people explore, not one I’ve explored. I think the shadow parts of us are very important to come to understand and look better to understand them and know that they’re there and work with them than to not acknowledge their presence and have them surface in the form of addictions or behaviors that damage us in other people.
Segment 643: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1012, Text: So one of the processes for achieving mental health is to bring those things to the surface. So fish the subconscious mind.
Segment 644: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1018, Text: Yes, and Paul describes 10 cupboards that one can look into for exploring the self. There’s the structure of self and the function of self. Again, this will all be spelled out in this series in a lot of detail. Also in terms of its relational aspect between people, how to pick good partners and good relationship. It gets really into this from a very different perspective. Yeah, fascinating stuff. I was just sitting there. I will say this, that four episode series with Paul is at least to date, the most important work I’ve ever been involved in in all of my career because it’s very clear that we are not taught how to explore our subconscious and that very few people actually understand how to do that. Even most psychiatrists, he mentioned something about psychiatrists. If you’re a cardiothoracic surgeon or something like that and 50% of your patients die, you’re considered a bad cardiothoracic surgeon.
Segment 645: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1073, Text: But with no disrespect to psychiatrists, there are some excellent psychiatrists out there. There are also a lot of terrible psychiatrists out there because unless all of their patients commit suicide or half commit suicide, they can treat for a long time without it becoming visible that they’re not so good at their craft. Now, he’s superb at his craft, and I think he would say that yes, exploring some shadows, but also just understanding the self, really understanding like, “Who am I? And what’s important? What are my ambitions? What are my strivings?” Again, I’m lifting from some of the things that he’ll describe exactly how to do this. People do not spend enough time addressing those questions, and as a consequence, they discover what resides in their subconscious through the sometimes bad, hopefully also good, but manifestations of their actions.
Segment 646: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1130, Text: We are driven by this huge 90% of our real estate that is not visible to our conscious awareness. And we need to understand that. I’ve talked about this before. I’ve done therapy twice a week since I was a kid. I had to as a condition of being let back in school. I found a way to either through insurance or even when I didn’t have insurance, I took an extra job writing for Thrasher Magazine when I was a postdoc so I could pay for therapy at a discount because I didn’t make much money as a postdoc.
Segment 647: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1160, Text: I mean, I think for me, it’s as important as going to the gym and people think it’s just ruminating on problems, or getting… No, no, no. If you work with somebody really good, they’re forcing you to ask questions about who you really are, what you really want. It’s not just about support, but there should be support. There should be rapport, but then it’s also, there should be insight, right? Most people who get therapy, they’re getting support, there’s rapport, but insight is not easy to arrive at, and a really good psychologist or psychiatrist can help you arrive at deep insights that transform your entire life.
Segment 648: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1196, Text: Well, sometimes when I look inside and I do this often exploring who you truly are, you come to this question, do I accept… Once you see parts, do I accept this or do I fix this? Is this who you are fundamentally, and it will always be this way, or is this a problem to be fixed? For example, one of the things, especially recently, but in general over time I’ve discovered about myself probably has roots in childhood, probably has roots in a lot of things, is I deeply value loyalty maybe more than the average person. And so when there’s disloyalty, it can be painful to me. And so this is who I am, and so do I have to relax a bit? Do I have to fix this part or is this who you are? And there’s a million, that’s one little…
Segment 649: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1253, Text: I think loyalty is a good thing to cling to, provided that when loyalty is broken, that it doesn’t disrupt too many other areas of your life. But it depends also on whose disrupting that loyalty, if it’s a coworker versus a romantic partner versus your exclusive romantic partner, depending on the structure of your romantic partner life. I mean, I have always experienced extreme joy and feelings of safety and trust in my friendships. Again, mostly male friendships, but female friendships too, which is only to say that they were mostly male friendships. The female friendships have also been very loyal. So getting backstabbed is not something I’m familiar with. And yeah, I love being crewed up.
Segment 650: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1303, Text: Yeah. No, for sure. And I’m with you and you and I very much have the same values on this, but that’s one little thing. And then there’s many other things like I’m extremely self-critical and I look at myself as I’m regularly very self-critical, a self-critical engine in my brain. And I talked to actually Paul about this, I think on the podcast quite a bit. And he’s saying, “This is a really bad thing. You need to fix this. You need to be able to be regularly very positive about yourself.” And I kept disagreeing with him, “No, this is who I am,” and he seems to work. Don’t mess with a thing that seems to be working. It’s fine.
Segment 651: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1344, Text: I oscillate between being really grateful and really self-critical. But then you have to figure out what is it? Maybe there’s a deeper root thing. Maybe there’s an insecurity in there somewhere that has to do with childhood and then you’re trying to prove something to somebody from your childhood, this kind of thing.
Segment 652: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1359, Text: Well, a couple of things that I think are hopefully valuable for people here. One is one way to destroy your life is to spend time trying to control your or somebody else’s past. So much of our destructive behavior and thinking comes from wanting something that we saw or did or heard to not be true, rather than really working with that and getting close to what it really was. Sometimes those things are even traumatic, and we need to really get close to them and for them to move through us. And there are a bunch of different ways to do that with support from others and hopefully, but sometimes on our own as well.
Segment 653: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1403, Text: I don’t think we can rewire our deep preferences and what we find despicable or joyful. I do think that it’s really a question of what allows us peace. Can you be at peace with the fact that you’re very self-critical? And enjoy that, get some distance from it, have a sense of humor about it, or is it driving you in a way that’s keeping you awake at night and forcing you back to the table to do work in a way that feels self-flagellating and doesn’t feel good?
Segment 654: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1432, Text: Can you get that humility and awareness of your one’s flaws? And I think that that can create, this word space sounds very new, edgy, like get space from it. You can have a sense of humor about how neurotic we can all be. I mean, neurotic isn’t actually a bad term in the classic sense of the psychologists and psychiatrists, the freudians. So that the best case is to be neurotic, to actually see one’s own issues and work with them. Whereas psychotic is the other way to be, which is obviously not good. So I think the question whether or not to work on something or to just accept it as part of ourselves, I think really depends if we feel like it’s holding us back or not. And I think you’re asking perhaps the most profound question about being a human, which is what do you do with your body? What do you do with your mind?
Segment 655: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1485, Text: I mean, it’s also a question. We started off talking about fitness a little bit just for whatever reason. Do I need to run an ultra marathon? I don’t feel like I need to. David Goggins does and does a whole lot more than that. So that for him, that’s important. For me, it’s not important to do that. I don’t think he does it just so he can run the ultras. There’s clearly something else in there for him. And guys like Cam Hanes and tremendous respect for what they do and how they do it. Does one need to make their body more muscular, stronger, more endurance, more flexibility? Do you need to read harder books? I think doing hard things feels good. I know it feels good. I know that the worst I feel, the worst way to feel is when I’m procrastinating and I don’t do something.
Segment 656: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1543, Text: And then whenever I do something and I complete it and I break through that point where it was hard and then I’m doing it at the end, I actually feel like I was infused with some sort of super chemical. And who knows if it’s probably a cocktail of endogenously made chemicals. But I think it is good to do hard things, but you have to be careful not to destroy your body, your mind in the process. And I think it’s about whether or not you can achieve peace. Can you sleep well at night?
Segment 657: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1569, Text: Stress isn’t bad if you can sleep well at night, you can be stressed all day, go, go, go, go, go, go, go. And it’ll optimize your focus. But can you fall asleep and stay deeply asleep at night? Being in a hard relationship. Some people say that’s not good. Other people like can you be at peace in that? And I think we all have different RPM. We all kind of idle at different RPM and some people are big mellow Costello and others need more friction in order to feel at peace. But I think ultimately what we want is to feel at peace.
Segment 658: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1607, Text: Yeah, I’ve been through some really low points over the past couple of years, and I think the reason could be boiled down to the fact that I haven’t been able to find a place of peace, a place or people or moments that give deep inner peace. And I think you put it really beautifully. You have to figure out, given who you are, the various characteristics of your mind, all the things, all the contents of the cupboards, how to get space from it. And ultimately one good representation of that is to be able to laugh at all of it, whatever’s going on inside your mind to be able to step back and just kind of chuckle at the beauty and the absurdity of the whole thing.
Segment 659: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1656, Text: Yeah, and keep going. There’s this beautiful, as I mentioned, it seems like every podcast lately. I’m a huge Rancid fan. Mostly I just think Tim Armstrong’s writing is pure poetry and whether or not you like the music or not. And he’s written music for a lot of other people too. He doesn’t advertise that much because he’s humble but-
Segment 660: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1677, Text: By the way, I went to a show of theirs like 20 years ago.
Segment 661: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1679, Text: Oh, yeah. I’m going to see them in Boston, September 18th. I’m literally flying there for… Where I’ll take the train up from New York. I’m going to meet a friend of mine named Jim Thiebaud, who’s a guy who owns a lot of companies, the skateboard industry. We’re meeting there, a couple of little kids to go see them play amazing, amazing people, amazing music.
Segment 662: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1698, Text: Very intense.
Segment 663: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1699, Text: Very intense, but embodies all the different emotions. That’s why I love it. They have some love songs, they have some hate songs, they have some in. But going back to what you said, I think there’s a song, the first song on Indestructible album. I think he’s just talking about shock and disbelief of discovering things about people that were close to you. And I won’t sing it, but nor I wouldn’t dare. But there’s this one lyric that’s really stuck in my mind ever since that album came out in 2003, which is that, “Nothing’s what it seems so I just sit here laughing. I’m going to keep going on. I can’t get distracted.” There is this piece of like, you got to learn how to push out the disturbing stuff sometimes and go forward. And I remember hearing that lyric and then writing it down. And that was a time where my undergraduate advisor, who was a mentor and a father to me, blew his head off in the bathtub like three weeks before.
Segment 664: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1766, Text: And then my graduate advisor, who I was working for at that time, who I loved and adored, was really like a mother to me. I knew her when she was pregnant with her two kids, died at 50, breast cancer. And then my postdoc advisor, first day of work at Stanford as a faculty member sitting across the table like this from him, had a heart attack right in front of me, died of pancreatic cancer at the end of 2017. And I remember just thinking, going back to that song there over and over and where people would… Yeah, I haven’t had many betrayals in life. I’ve had a few. But just thinking or seeing something or learning something about something, you just say you can’t believe it. And I mentioned that lyric off, that first song, Indestructible on that album because it’s just the raw emotion of like, “I can’t believe this. What I just saw is so disturbing, but I have to just keep going forward.”
Segment 665: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1817, Text: There are certain things that we really do need to push not just into our periphery, but off into the gutter and keep going. And that’s a hard thing to learn how to do. But if you’re going to be functional in life, you have to. And actually just to get at this issue of do I change or do I embrace this aspect of self? About six months, it was April of this last year, I did some intense work around some things that were really challenging to me. And I did it alone, and it may have involved some medicine, and I expected to get peace through this. I was like, “I’m going to let go of it.” And I spent 11 hours just getting more and more frustrated and angry about this thing that I was trying to resolve.
Segment 666: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1862, Text: And I was so unbelievably disappointed that I couldn’t get that relief. And I was like, “What is this? This is not how this is supposed to work. I’m supposed to feel peace. The clouds are supposed to lift.” And so a week went by and then another half week went by, and then someone whose opinion I trust very much. I explained this to them because I was getting a little concerned like, “What’s going on? This is worse, not better.” And they said, ” This is very simple. You have a giant blind spot, which is your sense of justice, Andrew, and your sense of anger are linked like an iron rod and you need to relax it.” And as they said that, I felt the anger dissipate. And so there was something that I think it is true. I have a very strong sense of justice and my sense of anger then at least was very strongly linked to it.
Segment 667: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1918, Text: So it’s great to have a sense of justice, right? I hate to see people wrong. I absolutely do. And I’m human. I’m sure I’ve wronged people in my life. I know I have. They’ve told me, I’ve tried to apologize and reconcile where possible. Still have a lot of work to do. But where I see injustice, it draws in my sense of anger in a way that I think is just eating me up. But it was only in hearing that link that I wasn’t aware of before. It was in my subconscious, obviously. Did I feel the relaxation? There’s no amount of plant medicine or MDMA or any kind of chemical you can take that’s naturally just going to dissipate what’s hard for oneself if one embraces that or if one chooses to do it through just talk therapy or journaling or friends or introspection or all of the above. There needs to be an awareness of the things that we’re just not aware of.
Segment 668: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=1971, Text: So I think the answer to your question, do you embrace or do you fight these aspects of self is? I think you get in your subconscious through good work with somebody skilled. And sometimes that involves the tools I just mentioned in various combinations and you figure it out. You figure out if it’s serving you. Obviously it was not bringing me peace. My sense of justice was undermining my sense of peace. And so in understanding this link… Now, I would say, in understanding this link between justice and anger, now I think it’s a little bit more of you know, it’s not like a Twizzler stick bendy, but at least it’s not like an iron rod. When I see somebody wronged, I mean it used to just… Like immediately.
Segment 669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2013, Text: But you’re able to step back now. To me, the ultimate place to reach is laughter.
Segment 670: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2022, Text: I just sit here laughing. Exactly. That’s the lyric. I can’t believe it. “So I just sit here laughing. Can’t get distracted,” Just at some point but the problem I think in just laughing at something like that gives you distance, but the question is, do you stop engaging with it at that point? I experienced this…
Segment 671: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2040, Text: … to stop engaging with it at that point. I experienced this… I mean, recently I got to see how sometimes I’ll see something that’s just like, “What? This is crazy,” so I just laugh. But then, I continue to engage in it and it’s taking me off course. And so, there is a place where… I mean, I realize this is probably a kid show too so I want to keep it G-rated. But at some point, for certain things, it makes sense to go, “Fuck that.”
Segment 672: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2067, Text: But also, laugh at yourself for saying, “Fuck that.”
Segment 673: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2071, Text: Yeah. And then, move on. So the question is do you get stuck or do you move on?
Segment 674: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2076, Text: Sure, sure. But there’s a lightness of being that comes with laughter. I mean, I’ve gotten-
Segment 675: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2079, Text: Sure.
Segment 676: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2080, Text: As you know, I spent the day with Elon today. He just gave me this burnt hair. Do you know what this is?
Segment 677: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2086, Text: I have no idea.
Segment 678: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2087, Text: I’m sure there’s actually… There should be a Huberman Lab episode on this. It’s a cologne that’s burnt hair and it’s supposedly a really intense smell and it is.
Segment 679: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2096, Text: Give me a smell.
Segment 680: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2096, Text: Please, it’s not going to leave your nose.
Segment 681: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2098, Text: That’s okay. Well, that’s okay. I’ll whiff it as if I were working a chemical in the lab-
Segment 682: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2102, Text: You have to actually spray it on yourself because I don’t know if you can-
Segment 683: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2104, Text: So I’m reading an amazing book called An Immense World by Ed Yong. He won a Pulitzer for We Contain Multitudes or something like that, I think is the title of the other book. And the first chapter is all about olfaction and the incredible power that olfaction has. That smells terrible. I don’t even-
Segment 684: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2122, Text: And it doesn’t leave you. For those listening, it doesn’t quite smell terrible. It’s just intense and it stays with you. This, to me, represents just laughing at the absurdity of it all so-
Segment 685: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2137, Text: I have to ask, so you were rolling jiu jitsu?
Segment 686: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2138, Text: Yeah. We’re training. Yeah.
Segment 687: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2140, Text: So is that fight between Elon and Zuck actually going to happen?
Segment 688: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2145, Text: I think Elon is a huge believer of this idea of the most entertaining outcome is the most likely and there is almost the sense that there’s not a free will. And the universe has a deterministic gravitational field pulling towards the most fun and he’s just a player in that game. So from that perspective, I think it seems like something like that is inevitable.
Segment 689: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2174, Text: Like a little scrap in the parking lot of Facebook or something like that?
Segment 690: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2177, Text: Exactly.
Segment 691: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2178, Text: Sorry, Meta. But it looks like they’re training for real and Zuck has competed, right, in jiu jitsu?
Segment 692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2183, Text: So I think he is approaching it as a sport, Elon is approaching it as a spectacle. And I mean, the way he talks about it, he’s a huge fan of history. He talks about all the warriors that have fought throughout history. Look, he wants to really do it at the Coliseum. And the Coliseum is for 400 years, there’s so much great writing about this, I think over 400,000 people have died in the Coliseum, gladiators.
Segment 693: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2212, Text: So this is this historic place that sheds so much blood, so much fear, so much anticipation of battle, all of this. So he loves this kind of spectacle and also, the meme of it, the hilarious absurdity of it. The two tech CEOs are battling it out on sand in a place where gladiators fought to the death and then bears and lions ate prisoners as part of the execution process.
Segment 694: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2241, Text: Well, it’s also going to be an instance where Mark Zuckerberg and Elon Musk exchange bodily fluids. They bleed. That’s one of the things about fighting. I think it was in that book. It’s a great book. Fighter’s Heart, where he talks about the sort of the intimacy of sparring. I only rolled jiu jitsu with you once but there was a period of time where I boxed which I don’t recommend.
Segment 695: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2263, Text: I got hit. I hit some guys and definitely got hit back. I’d spar on Wednesday nights when I lived on San Diego. And when you spar with somebody, even if they hurt you, especially if they hurt you, you see that person afterwards and there’s an intimacy, right? It was in that book, Fighter’s Heart, where he explains, you’re exchanging bodily fluids with a stranger and you’re in your primitive mind and so there’s an intimacy there that persists so-
Segment 696: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2293, Text: Well, you go together through a process of fear, anxiety like-
Segment 697: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2298, Text: Yeah. When they get you, you nod. I mean, you watch somebody catch somebody. Not so much in professional fighting, but if people are sparring, they catch you, you acknowledge that they caught you like, “He got me there.”
Segment 698: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2309, Text: And on the flip side of that, so we trained and then after that, we played Diablo 4.
Segment 699: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2314, Text: I don’t know what that is. I don’t play video games. I’m sorry.
Segment 700: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2317, Text: But it’s a video game, so it’s a pretty intense combat in the video… You’re fighting demons and dragons-
Segment 701: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2325, Text: Oh, okay. Last video game I played was Mike Tyson’s Punch-Out!!
Segment 702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2328, Text: There you go. That’s pretty close.
Segment 703: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2329, Text: I met him recently. I went on his podcast.
Segment 704: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2331, Text: You went… Wait.
Segment 705: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2332, Text: It hasn’t come out yet.
Segment 706: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2332, Text: Oh, it hasn’t come out? Okay.
Segment 707: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2334, Text: Yeah. I asked Mike… His kids are great. They came in there. They’re super smart kids. Goodness gracious. They ask great questions. I asked Mike what he did with the piece of Evander’s ear that he bit off.
Segment 708: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2348, Text: Did he remember?
Segment 709: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2349, Text: Yeah. He’s like, “I gave it back to him.”
Segment 710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2349, Text: Here you go. Sorry about that.
Segment 711: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2354, Text: He sells edibles that are in the shape of ears with a little bite out of it. Yeah. His life has been incredible. He’s intimate. Yeah. His family, you get the sense that they’re really a great family. They’re really-
Segment 712: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2370, Text: Mike Tyson?
Segment 713: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2370, Text: Mm-hmm.
Segment 714: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2371, Text: That’s a heck of a journey right there of a man.
Segment 715: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2373, Text: Yeah. My now friend, Tim Armstrong, like I said, lead singer from Rancid. He put it best. He said that Mike Tyson’s life is Shakespearean, down, up, down, up and just that the arcs of his life are just… Sort of an only in America kind of tale too, right?
Segment 716: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2392, Text: So speaking of Shakespeare, I’ve recently gotten to know Neri Oxman who’s this incredible scientist that works at the intersection of nature and engineering and she reminded me of this Anna Akhmatova line. This is this great Soviet poet that I really love from over a century ago that each of our lives is a Shakespearean drama raised to the thousand degree. So I have to ask, why do you think humans are attracted to this kind of Shakespearean drama? Is there some aspect we’ve been talking about the subconscious mind that pulls us towards the drama, even though the place of mental health is peace?
Segment 717: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2438, Text: Yes and yes.
Segment 718: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2439, Text: Do you have some of that?
Segment 719: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2441, Text: Draw towards-
Segment 720: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2442, Text: Drama?
Segment 721: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2442, Text: Drama? Yeah.
Segment 722: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2445, Text: If you look at the empirical data.
Segment 723: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2446, Text: Yes, I mean… Right. If I look at the empirical data, I mean, I think about who I chose to work for as an undergraduate, right? I was a… Barely finished high school, finally get to college, barely… This is really embarrassing and not something to aspire to. I was thrown out of the dorms for fighting-
Segment 724: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2465, Text: Nice.
Segment 725: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2465, Text: Barely passed my classes. The girlfriend and I split up. I mean, I was living in a squat, got into a big fight. I was getting in trouble with the law. I eventually got my act together, go back to school, start working for somebody. Who do I choose to work for? A guy who’s an ex-navy guy who smokes cigarettes in the fume hood, drinks coffee, and we’re injecting rats with MDMA. And I was drawn to the personality, his energy, but I also… He was a great scientist, worked out a lot on a thermal regulation in the brain and more.
Segment 726: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2498, Text: Go to graduate school, I’m working for somebody, and decide that working in her laboratory wasn’t quite right for me. So I’m literally sneaking into the laboratory next door and working for the woman next door because I liked the relationships that she had to a certain set of questions and she was a quirky person. So drawn to drama but drawn to… I like characters. I like people that have texture. And I’m not drawn to raw ambition, I’m drawn to people that seem to have a real passion for what they do and a uniqueness to them that I… Not kind of, I’ll just say how it is. I can feel their heart for what they do and I’m drawn to that and that can be good.
Segment 727: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2540, Text: It’s the same reason I went to work for Ben Barris as a post-doc. It wasn’t because he was the first transgender member of the National Academy of Sciences, that was just a feature of who he was. I loved how he loved glial. He would talk about these cells like they were the most enchanting things that he’d ever seen in his life. And I was like, “This is the biggest nerd I’ve ever met and I love him.” I think I’m drawn to that.
Segment 728: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2562, Text: This is another thing that Conti elaborates on quite a bit more in the series on mental health coming out. But there are different drives within us, there are aggressive drives. Not always for fighting but for intense interaction. I mean, look at Twitter. Look at some of the… People clearly have an aggressive drive. There’s also a pleasure drive. Some people also have a strong pleasure drive. They want to experience pleasure through food, through sex, through friendship, through adventure. But I think the Shakespearean drama is the drama of the different drives in different ratios in different people.
Segment 729: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2601, Text: I know somebody and she’s incredibly kind. Has an extremely high pleasure drive, loves taking great care of herself and people around her through food and through retreats and through all these things and makes spaces beautiful everywhere she goes. And gifts these things that are just so unbelievably feminine and incredible. These gifts to people and then kind and thoughtful about what they like. And then.. But I would say, very little aggressive drive from my read.
Segment 730: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2633, Text: And then, I know other people who just have a ton of aggressive drive and very little pressure drive and I think… So there’s this alchemy that exists where people have these things in different ratios. And then, you blend in the differences in the chromosomes and differences in hormones and differences in personal history and what you end up with is a species that creates incredible recipes of drama but also peace, also relief from drama, contentment.
Segment 731: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2661, Text: I mean, I realize this isn’t the exact topic of the question. But someone I know very dearly, actually an ex-girlfriend of mine, long- term partner of mine, sent me something recently and I think it hit the nail on the head. Which is that ideally for a man, they eventually settle where they find and feel peace, where they feel peaceful, where they can be themselves and feel peaceful. Now, I’m sure there’s an equivalent or mirror image of that for women but this particular post that she sent was about men and I totally agree.
Segment 732: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2694, Text: And so, it isn’t always that we’re seeking friction. But for periods of our life, we seek friction, drama, adventure, excitement, fights, and doing hard, hard things. And then I think at some point, I’m certainly coming to this point now where it’s like, “Yeah. That’s all great and checked a lot of boxes.” But I had a lot of close calls, flew really close to the sun on a lot of things with life and limb and heart and spirit and some people close to us didn’t make it. And sometimes, not making it means the career they wanted went off a cliff or their health went off a cliff or their life went off a cliff. But I think that there’s also the Shakespearean drama of the characters that exit the play and are living their lives happily in the backdrop. It just doesn’t make for as much entertainment.
Segment 733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2749, Text: That’s one other thing, you could say, is the benefit of getting older is finding the Shakespearean drama less appealing or finding the joy in the peace.
Segment 734: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2761, Text: Yeah. Definitely. I mean, I think there’s real peace with age. I think the other thing is this notion of checking boxes is a real thing, for me anyway. I have a morning meditation that I do. Well, I wake up now, I get my sunlight, I hydrate, I use the bathroom. I do all the things that I talk about. I’ve started a practice of prayer in the last year which is new-ish for me which is we could talk about-
Segment 735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2787, Text: In the morning?
Segment 736: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2787, Text: Yeah.
Segment 737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2788, Text: Can you talk about it a little bit?
Segment 738: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2789, Text: Sure. Yeah. And then, I have a meditation that I do that actually is where I think through with the different roles that I play. So I start very basic. I say, “Okay. I’m an animal,” like we are biologically animals, human. “I’m a man. I’m a scientist. I’m a teacher. I’m a friend. I’m a brother. I’m a son,” I have this list and I think about the different roles that I have and the roles that I still want in my life going forward that I haven’t yet fulfilled. It just takes me… It’s an inventory of where I’ve been, where I’m at, and where I’m going as they say. And I don’t know why I do it but I started doing it this last year, I think, because it helps me understand just how many different contexts I have to exist in and remind myself that there’s still more that I haven’t done that I’m excited about.
Segment 739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2844, Text: So within each of those contexts, there’s things that you want to accomplish to define that.
Segment 740: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2850, Text: Yeah, and I’m ambitious so I think… I’m a brother. I have an older sister and I love her tremendously and I think, “I want to be the best brother I can be to her,” which means maybe a call, maybe just we do an annual trip together for our birthdays. Our birthdays are close together. We always go to New York for our birthdays and we’ve gone for the last three, four years. It’s like really reminding myself of that role not because I’ll forget, but because I have all these other roles I’ll get pulled into.
Segment 741: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2873, Text: I say the first one, “I’m an animal,” because I have to remember that I have a body that needs care like any of us. I need sleep, I need food, I need hydration, I need… That I’m human, that the brain of a human is marvelously complex but also marvelously self-defeating at times. And so, I’m thinking about these things in the context of the different roles. And the whole thing takes about four or five minutes and I just find it brings me a certain amount of clarity that then allows me to ratchet into the day.
Segment 742: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2902, Text: The prayer piece, I think I’ve been reluctant to talk about until now because I don’t believe in pushing religion on people. And I think that… And I’m not, it’s a highly individual thing and I do believe that one can be an atheist and still pray or agnostic and still pray. But for me, it really came about through understanding that there are certain aspects of myself that I just couldn’t resolve on my own. And no matter how much therapy, no matter how much… And I haven’t done a lot of it. But no matter how much plant medicine or other forms of medicine or exercise or podcasting or science or friendship or any of that, I was just not going to resolve.
Segment 743: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2957, Text: And so, I started this because a male friend said, “Prayer is powerful,” and I said, “Well, how?” And he said, “I don’t know how but it can allow you to get outside yourself. Let you give up control and at the same time, take control.” I don’t even like saying take control. But the whole notion is that… And again, forgive me, but there’s no other way to say it. The whole notion is that God works through us. Whatever God is to you, he, him, her, life force, nature, whatever it is to you, that it works through us.
Segment 744: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=2999, Text: And so, I do a prayer. I’ll just describe it where I make an ask to help remove my character defects. I pray to God to help remove my character defects so that I can show up better in all the roles of my life and do good work which for me is learning and teaching. And so you might say, “Well, how is that different than a meditation?” Well, I’m acknowledging that there is something bigger than me, bigger than nature as I understand it, that I cannot understand or control nor do I want to, and I’m just giving over to that. And does that make me less of a scientist? I sure as hell hope not. I certainly know… There’s the head of our neurosciences at Stanford until recently. You should talk to him directly about it. Bill Newsome has talked about his religious life.
Segment 745: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3052, Text: For me, it’s really a way of getting outside myself and then understanding how I fit into this bigger picture. And the character defects part is real, right? I’m a human. I have defects. I got a lot of flaws in me like anybody and trying to acknowledge them and asking for help in removing them. Not magically but through right action, through my right action. So I do that every morning.
Segment 746: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3083, Text: And I have to say that it’s helped. It’s helped a lot. It’s helped me be better to myself, be better to other people. I still make mistakes but it’s becoming a bigger part of my life. And I never thought I’d talk like this but I think it’s clear to me that if we don’t believe in something… Again, it doesn’t have to be traditional, standardized religion, but if we don’t believe in something bigger than ourselves, we, at some level, will self-destruct. I really think so.
Segment 747: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3124, Text: And it’s powerful in a way that all the other stuff, meditation and all the tools, is not because it’s really operating at a much deeper and bigger level. Yeah. I think that’s all I can talk about it. Mostly because I’m still working out. The scientists in me wants to understand how it works and I want to understand. And the point is to just go, for lack of a better language for it, “There’s a higher power than me and what I can control. I’m giving up control on certain things.” And somehow, that restores a sense of agency for right action and better action.
Segment 748: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3166, Text: I think perhaps a part of that is just the humility that comes with acknowledging there’s something bigger and more powerful than you.
Segment 749: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3173, Text: And that you can’t control everything. I mean, you go through life as a hard driving person, forward center of mass. I remember being that way since I was little. It’s like in Legos. I’m like, “I’m going to make all the Legos.” I was like, on the weekends, learning about medieval weapons and then giving lectures about it in class when I was five or six years old or learning about tropical fish and cataloging all of them at the store. And then, organizing it and making my dad drive me or my mom drive me in some fish store and then spending all my time there until they throw me out. All of that. But I also remember my entire life, I would secretly pray when things were good and things weren’t good. But mostly, when things weren’t good because it’s important to pray. For me, it’s important to pray each morning regardless.
Segment 750: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3215, Text: But when things weren’t right, I couldn’t make sense of them, I would secretly pray. But I felt ashamed of that for whatever reason. And then, it was once in college, I distinctly remember I was having a hard time with a number of things and I took a run down to SAN Speech. It was at UC Santa Barbara. And I remember I was like, “I don’t know if I even have the right to do this but I’m just praying,” and I just prayed for the ability to be as brutally honest with myself and with other people as I possibly could be about a particular situation I was in at that time.
Segment 751: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3253, Text: I mean, I think now it’s probably safe to say I’d gone off to college because of a high school girlfriend. Essentially, she was my family. Frankly, more than my biological family was at a certain stage of life and we’d reached a point where we were diverging and it was incredibly painful. It was like losing everything I had. And it was like, “What do I do? How do I manage this?” I was ready to quit and join the fire service just to support us so that we could move forward and it was just…
Segment 752: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3282, Text: But praying, just saying, “I can’t figure this out on my own.” It’s like, “I can’t figure this out on my own,” and how frustrating that no number of friends could tell me and inner wisdom couldn’t tell me. And eventually, it led me to the right answers. She and I are friendly friends to this day. She’s happily married with a child and we’re on good terms. But I think it’s a scary thing but it’s the best thing when you just, “I can’t control all of this.” And asking for help, I think is also the piece. You’re not asking for some magic hand to come down and take care of it but you’re asking for the help to come through you so that your body is used to do these right works, right action.
Segment 753: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3324, Text: Isn’t it interesting that this secret thing that you’re almost embarrassed by, that you did as a child is something you… It’s another thing you do as you get older, is you realize those things are part of you and it’s actually a beautiful thing.
Segment 754: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3336, Text: Yeah. A lot of the content of the podcast is deep academic content and we talk about everything from eating disorders to bipolar disorder to depression, a lot of different topics. But the tools or the protocols, as we say, the sunlight viewing and all the rest, a lot of that stuff is just stuff I wish I had known when I was in graduate school. If I’d known to go outside every once in a while and get some sunlight, not just stay in the lab, I might not have hit a really tough round of depression when I was a post-doc and working twice as hard.
Segment 755: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3369, Text: And when my body would break down or I’d get sick a lot, I don’t get sick much anymore. Occasionally, about once every 18 months to two years, I’ll get something. But I used to break my foot skateboarding all the time, I couldn’t understand. What’s wrong with my body? I’m getting injured. I can’t do what everyone else can. Now, I developed more slowly. I had a long arc of puberty so that was part of it. I was still developing.
Segment 756: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3391, Text: But how to get your body stronger, how to build endurance, no one told me. The information wasn’t there. So a lot of what I put out there is the information that I wish I had. Because once I had it, I was like, “Wow.” A, this stuff really works. B, it’s grounded in something real. Sometimes, certain protocols are a combination of animal and human studies, sometimes clinical trials. Sometimes there’s some mechanistic conjecture for some, not all, I always make clear which. But in the end, figuring out how things work so that we can be happier, healthier, more productive, suffer less, reduce the suffering of the world. And I think that… Well, I’ll just say thank you for asking about the prayer piece. Again, I’m not pushing or even encouraging it on anyone. I’ve just found it to be tremendously useful for me.
Segment 757: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3453, Text: I mean, about prayer in general. You said information and figuring out how to get stronger, healthier, smarter, all those kinds of things. A part of me believes that deeply. You can gain a lot of knowledge and wisdom through learning. But a part of me believes that all the wisdom I need was there when I was 11 and 12 years old.
Segment 758: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3477, Text: And then, it got cluttered over. Well, listen, I can’t wait for you and Conti to talk again. Because when he gets going about the subconscious and the amount of this that sits below the surface like an iceberg. And the fact that when we’re kids, we’re not obscuring a lot of that subconscious as much. And sometimes, that can look a little more primitive. I mean, a kid that’s disappointed will let you know. A kid that’s excited will let you know and you feel that raw exuberance or that raw dismayal.
Segment 759: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3512, Text: And I think that as we grow older, we learn to cover that stuff up. We wear masks and we have to, to be functional. I don’t think we all want to go around just being completely raw. But as you said, as you get older, you get to this point where you go, “Eh. What are we really trying to protect anyway?”
Segment 760: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3533, Text: I mean, I have this theory that certainly my experience has taught me that a lot of people but I’ll talk about men because that’s what I know best, whether or not they show up strong or not, that they’re really afraid of being weak. They’re just afraid… Sometimes, the strength is even a way to try and not be weak which is different than being strong for its own sake. I’m not just talking about physical strength. I’m talking about intellectual strength. I’m talking about money. I’m talking about expressing drive. I’ve been watching this series a little bit of Chimp Empire.
Segment 761: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3574, Text: Oh, yeah.
Segment 762: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3575, Text: So Chimp Empire is amazing, right? They have the head chimp. He’s not the head chimp but the alpha in the group and he’s getting older. And so, what does he do? Every once in a while, he goes on these vigor displays. He goes and he grabs a branch. He starts breaking them. He starts thrashing them. And he’s incredibly strong and they’re all watching. I mean, I immediately think of people like they’re deadlifting on Instagram and I just think, “Displays of vigor.” This is just the primate showing displays of vigor. Now, what’s interesting is that he’s doing that specifically to say, “Hey, I still have what it takes to lead this troop.” Then there are the ones that are subordinate to him but not so far behind-
Segment 763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3618, Text: It seems to be that there’s a very clear numerical ranking.
Segment 764: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3621, Text: There is.
Segment 765: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3622, Text: Like it’s clear who’s the Number 2, Number 3-
Segment 766: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3624, Text: Oh, yeah.
Segment 767: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3624, Text: I mean, probably-
Segment 768: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3625, Text: Who gets to mate first, who gets to eat first, this exists in other animal societies too but Bob Sapolsky would be a great person to talk about this with because he knows obviously tremendous amount about it and I know just the top contour. But yeah, so Number 2, 3, and 4 males are aware that he’s doing these vigor displays. But they’re also aware because in primate evolution, they got some extra forebrain too. Not as much as us but they got some. And they’re aware that the vigor displays are displays that… Because they’ve done them as well in a different context, might not just be displays of vigor but might also be an insurance policy against people seeing weakness.
Segment 769: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3664, Text: So now, they start using that prefrontal cortex to do some interesting things. So in primate world, if a male is friendly with another male, wants to affiliate with him and say, “Hey, I’m backing you,” they’ll go over and they’ll pick off the little parasites and eat them. And so, the grooming is extremely important. In fact, if they want to ostracize or kill one of the members of their troop, they will just leave it alone. No one will groom it. And then, there’s actually a really disturbing sequence in that show of then the parasites start to eat away on their skin. They get infections. They have issues. No one will mate with them. They have other issues as well and can potentially die.
Segment 770: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3704, Text: So the interesting thing is Number 2 and 3 start to line up a strategy to groom this guy but they are actually thinking about overtaking the entire troop setting in a new alpha. But the current alpha did that to get where he is so he knows that they’re doing this grooming thing, but they might not be sincere about the grooming. So what does he do? He takes the whole troop on a raid to another troop and sees who will fight for him and who won’t.
Segment 771: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3734, Text: This is advanced contracting of behavior for a species that normally we don’t think of as sophisticated as us. So it’s very interesting and it gets to something that I hope we’ll have an opportunity to talk about because it’s something that I’m obsessed with lately, is this notion of overt versus covert contracts, right? There are overt contracts where you exchange work for money or you exchange any number of things in an overt way. But then, there are covert contracts, and those take on a very different form and always lead to, in my belief, bad things.
Segment 772: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3767, Text: Well, how much of human and chimp relationships are overt versus covert?
Segment 773: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3773, Text: Well, here’s one thing that we know is true. Dogs and humans, the dog to human relationship is 100% overt. They don’t manipulate you. Now, you could say they do in the sense that they learn that if they look a certain way or roll on their back, they get food. But there’s no banking of that behavior for a future date where then they’re going to undermine you and take your position so in that sense. Dogs can be a little bit manipulative in some sense.
Segment 774: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3803, Text: But now, okay. So overt contract would be we both want to do some work together, we’re going to make some money, you get X percentage, I get X percentage. It’s overt. Covert contract which is, in my opinion, always bad, would be we’re going to do some work together, you’re going to get a percentage of money, I’m going to get a percentage of money. Could look just like the overt contract but secretly, I’m resentful that I got the percentage that I got. So what I start doing is covertly taking something else. What do I take? Maybe I take the opportunity to jab you verbally every once in a while. Maybe I take the opportunity to show up late. Maybe I take the opportunity to get to know one of your coworkers so that I might start a business with them. That’s covert contracting.
Segment 775: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3854, Text: And you see this sometimes in romantic relationships. One person, we won’t set the male or female in any direction here and just say it’s, “I’ll make you feel powerful if you make me feel desired.” Okay. Great. There’s nothing explicitly wrong about that contract if they both know and they both agree. But what if it’s, “I’ll do that but I’ll have kids with you so you feel powerful. You’ll have kids with me so I feel desired. But secretly, I don’t want to do that,” or one person says, “I don’t want to do that,” or both don’t. So what they end up doing is saying, “Okay. So I expect something else. I expect you to do certain things for me,” or, “I expect you to pay for certain things for me.”
Segment 776: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3893, Text: Covert contracts are the signature of everything bad. Overt contracts are the signature of all things good. And I think about this a lot because I’ve seen a lot of examples of this. I’ve… Like anyone, we participate in these things whether or not we want to or not and the thing that gets transacted the most is… Well, I should say the things that get transacted the most are the overt things. You’ll see money, time, sex, property, whatever it happens to be, information. But what ends up happening is that when people, I believe, don’t feel safe, they feel threatened in some way, like they don’t feel safe in a certain interaction, what they do is they start taking something else while still engaging in the exchange. And I’ll tell you, if there’s one thing about human nature that’s bad, it’s that feature.
Segment 777: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3957, Text: Why that feature? Or, “Is it a bug or a feature?” as you engineers like to say. I think it’s because we were allocated a certain extra amount of prefrontal cortex that makes us more sophisticated than a dog, more sophisticated than a chimpanzee, but they do it too. And it’s because it’s often harder, in the short term, to deal with the real sense of, “This is scary. This feels threatening,” than it is to play out all the iterations. It takes a lot of brain work. You’re playing chess and go simultaneously trying to figure out where things are going to end up and we just don’t know.
Segment 778: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=3997, Text: So it’s a way, I think, of creating a false sense of certainty. But I’ll tell you, covert contracts, the only certainty is that it’s going to end badly. The question is, how badly? Conversely, overt contracts always end well, always. The problem with overt contracts is that you can’t be certain that the other person is not engaging in a covert contract. You can only take responsibility for your own contracting.
Segment 779: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4021, Text: Well, one of the challenges of being human is looking at another human being and figuring out their way of being, their behavior, which of the two types of contracts it represents because they look awfully the same on the surface. And one of the challenges of being human, the decision we all make is, are you somebody that takes a leap of trust and trust other humans and are willing to take the hurt or are you going to be cynical and skeptical and avoid most interactions until they, over a long period of time, prove your trust?
Segment 780: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4057, Text: Yeah. I never liked the phrase history repeats itself when it comes to humans because it doesn’t apply if the people or the person is actively working to resolve their own flaws. I do think that if people are willing to do dedicated, introspective work, go into their subconscious, do the hard work, have hard conversations, and get better at hard conversations, something that I’m-
Segment 781: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4080, Text: Have hard conversations and get better at hard conversations, something that I’m constantly trying to get better at. I think people can change, but they have to want to change.
Segment 782: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4089, Text: It does seem like, deep down, we all can tell the difference between overt and covert. We have a good sense. I think one of the benefits of having this characteristic of mine, where I value loyalty, I’ve been extremely fortunate to spend most of my life in overt relationships and I think that creates a really fulfilling life.
Segment 783: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4111, Text: But there’s also this thing that maybe we’re in this portion of the podcast now, but I’ve experienced this-
Segment 784: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4116, Text: I should say that this is late at night, we’re talking about.
Segment 785: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4118, Text: That’s right, certainly late for me, but I’m two hours… I came in today on… I’m still in California time.
Segment 786: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4123, Text: And we should also say that you came here to wish me a happy birthday. [inaudible 01:08:46].
Segment 787: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4127, Text: I did. I did and-
Segment 788: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4128, Text: And the podcast is just a fun, last-minute thing I suggested.
Segment 789: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4131, Text: Yeah, some close friends of yours have arranged a dinner that I’m really looking forward to. I won’t say which night, but it’s the next couple of nights. Your circadian clock is one of the most robust features of your biology. I know you can be nocturnal or you can be diurnal. We know you’re mostly nocturnal, certain times of the year Lex, but there are very, very few people can get away with no sleep. Very few people can get away with a chaotic sleep-wake schedule. So you have to obey a 24-hour, AKA circadian, rhythm if you want to remain healthy of mind and body. We also have to acknowledge that aging is in linear, right? So-
Segment 790: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4174, Text: What do you mean?
Segment 791: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4174, Text: Well, the degree of change between years 35 and 40, is not going to be the degree of change between 40 and 45. But I will say this, I’m 48 and I feel better in every aspect of my psychology and biology now, than I did when I was in my twenties. Yeah, quality of thought, time spent, physically, I can do what I did then, which probably says more about what I could do then than what I can do now. But if you keep training, you can continue to get better. The key is to not get injured, and I’ve never trained super hard. I’ve trained hard, but I’ve been cautious to not, for instance, weight train more than two days in a row. I do a split which is basically three days a week, and the other day’s a run, take one full day off, take a week off every 12 to 16 weeks. I’ve not been the guy hurling the heaviest weights or running the furthest distance, but I have been the guy who’s continuing to do it when a lot of my friends are talking about knee injuries, talking about-
Segment 792: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4236, Text: Hey. Hey. Hey, hey.
Segment 793: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4236, Text: I’m just…
Segment 794: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4237, Text: [inaudible 01:10:37], I-
Segment 795: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4238, Text: But of course, with sport you can’t account for everything the same way you can with fitness, and I have to acknowledge that. Unless one is powerlifting, weightlifting and running, you can get hurt, but it’s not like skateboarding where, if you’re going for it, you’re going to get hurt. That’s just, you’re landing on concrete and with jujitsu, people are trying to hurt you so that you say stop.
Segment 796: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4263, Text: No, but [inaudible 01:11:04]-
Segment 797: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4263, Text: So with a sport it’s different, and these days, I don’t really do a sport any longer. I work out to stay fit. I used to continue to do sports, but I kept getting hurt and frankly now, a rolled ankle… I may put out a little small skateboard part in 2024 because people have been saying, “We want to see the kickflip.” Then I’ll just say, “Well, I’ll do a heel flip instead, but okay.” I might put out a little part because some of the guys that work on our podcast are from DC. I think by now, I should at least do it just to show I’m not making it up, and I probably will. But I think doing a sport is different. That’s how you get hurt-
Segment 798: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4306, Text: [inaudible 01:11:46].
Segment 799: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4305, Text: Overuse and doing an actual sport, and so hat tip to those who do an actual sport.
Segment 800: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4313, Text: And that’s a difficult decision a lot of people have to make. I have to make with jiujitsu, for example, if you just look empirically. I’ve trained really hard from all my life, in grappling sports and fighting sports and all this kind of stuff, and I’ve avoided injury for the most part. And I would say, I would attribute that to training a lot. Sounds counterintuitive, but training well and safely and correctly, keeping good form saying, “No,” when I need to say no, but training a lot, and taking it seriously. Now when it’s training, it’s really a side thing, I find that the injuries becomes a higher and higher probability.
Segment 801: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4354, Text: But when you’re just doing it every once in a while?
Segment 802: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4355, Text: Every once in a while.
Segment 803: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4356, Text: Yeah. I think you said something really important, the saying, “No.” The times I have gotten hurt training, is when someone’s like, “Hey, let’s hop on this workout together,” and it becomes, let’s challenge each other to do something outrageous. Sometimes that can be fun though. I went up to Cam Hanes’ gym and he does these very high repetition weight workouts that are in circuit form. I was sore for two weeks, but I learned a lot and didn’t get injured, and yes, we ate bow-hunted elk afterwards.
Segment 804: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4385, Text: Nice.
Segment 805: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4386, Text: Yeah.
Segment 806: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4386, Text: But the injury has been a really difficult psychological thing for me because… So I’ve injured my pinky finger, I’ve injured my knee.
Segment 807: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4396, Text: Yeah, your kitchen is filled with splints.
Segment 808: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4398, Text: Splints. I’m trying to figure out-
Segment 809: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4404, Text: It’s like if you look in Lex’s kitchen, there’s some really good snacks, I had some right before. He’s very good about keeping cold drinks in the fridge and all the water has element in it, which is great.
Segment 810: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4415, Text: Yeah, yeah.
Segment 811: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4416, Text: I love that. But then there’s a whole hospital’s worth of splints.
Segment 812: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4421, Text: Yeah, I’m trying to figure it out. So here’s the thing, you… The finger pop out like this, right? Pinky finger. I’m trying to figure out how do I splint in such a way that I can still program, still play guitar, but protect this torque motion that creates a huge amount of pain. And so [inaudible 01:13:58]-
Segment 813: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4438, Text: [inaudible 01:13:58] you have a jiujitsu injury.
Segment 814: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4439, Text: Jiujitsu, but it’s probably more like a skateboarding-style injury, which is, it’s unexpected in a silly-
Segment 815: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4449, Text: It’s a thing that happens in a second. I didn’t break my foot doing anything important.
Segment 816: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4453, Text: Yeah.
Segment 817: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4453, Text: I broke my fifth metatarpal stepping off a curb.
Segment 818: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4458, Text: Yep.
Segment 819: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4459, Text: So that’s why they’re called accidents. If you get hurt doing something awesome, that’s a trophy that you have to work through. It’s part of your payment to the universe. If you get hurt stepping off a curb or doing something stupid, it’s called a stupid accident.
Segment 820: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4479, Text: Since we brought up Chimp Empire, let me ask you about relationships. I think we’ve talked about relationships.
Segment 821: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4484, Text: Yeah, I only date Homo sapiens.
Segment 822: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4485, Text: Homo sapiens.
Segment 823: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4486, Text: It’s the morning meditation.
Segment 824: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4489, Text: The night is still young. You are human. No, but you are also animal. Don’t sell yourself short.
Segment 825: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4495, Text: No, I always say listen, any discussion on the Huberman Lab Podcast, about sexual health or anything, will always the critical fours: consensual, age appropriate, context appropriate, species appropriate.
Segment 826: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4506, Text: Species appropriate, wow. Can I just tell you about sexual selection? I’ve been watching Life in Color: With David Attenborough. I’ve been watching a lot of nature documentaries. Talking about inner peace, it brings me so much peace to watch nature, at its worst and at its best. So Life in Color is a series on Netflix where it presents some of the most colorful animals on earth, and tells their story of how they got there through natural selection. So you have the peacock with the feathers and it’s just such incredible colors. The peacock has these tail feathers, the male, that are gigantic and they’re super colorful and they’re these eyes on it. It’s not eyes, it’s eye-like areas. And they wiggle their ass to show the tail, they wiggle the tails.
Segment 827: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4555, Text: The eyespots, they’re called.
Segment 828: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4556, Text: The eyespots, yes. Thank you. You know this probably way better than me, I’m just quoting David Attenborough.
Segment 829: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4556, Text: No, no, please continue.
Segment 830: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4562, Text: But it’s just, I’m watching this and then the female is as boring looking as… She has no colors or nothing, but she’s standing there bored, just seeing this entire display. And I’m just wondering the entirety of life on earth… Well, not the entirety. Post bacteria, is like, at least in part, maybe in large part, can be described through this process of natural selection, of sexual selection. So dudes fighting and then women selecting. It seems like, just the entirety of that series shows some incredible birds and insects and shrimp. They’re all beautiful and colorful, and just-
Segment 831: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4606, Text: Mantis shrimp.
Segment 832: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4606, Text: Mantis shrimp. They’re incredible, and it’s all about getting laid. It’s fascinating. There’s nothing like watching that and Chimp Empire to make you realize, we humans, that’s the same thing. That’s all we’re doing. And all the beautiful variety, all the bridges and the buildings and the rockets and the internet, all of that is, at least in part, a product of this kind of showing off for each other. And all the wars and all of this… Anyway, I’m not sure wat I’m asking. Oh, relationships.
Segment 833: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4642, Text: Well, right, before you ask about relationships, I think what’s clear is that every species, it seems, animal species, wants to make more of itself and protect its young.
Segment 834: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4658, Text: Well, the protect its young, is non-obvious.
Segment 835: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4661, Text: So not destroy enough of itself that it can’t get more to reproductive competent age. I think that we healthy people have a natural reflex to protect children.
Segment 836: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4680, Text: Well, I don’t know that-
Segment 837: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4680, Text: And those that can’t-
Segment 838: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4683, Text: Wait a minute. Wait, wait, wait a minute. I’ve seen enough animals that are murdering the children of some other-
Segment 839: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4686, Text: Sure, there’s even siblicide. First of all, I just want to say that I was delighted in your delight, around animal kingdom stuff, because this is a favorite theme of mine as well. But there’s, for instance, some fascinating data on, for instance, for those that grew up on farms, they’ll be familiar with freemartins. You know about freemartins? They’re cows that have multiple calves inside them, and there’s a situation in which the calves will, if there’s more than one inside, will secrete chemicals that will hormonally castrate the calf next to them, so they can’t reproduce. So already in the womb they are fighting for future resources. That’s how early this stuff can start. So it’s chemical warfare in the womb, against the siblings. Sometimes there’s outright siblicide. Siblings are born, they kill one another. This also becomes biblical stories, right? There are instances of cuttlefish, beautiful cephalopods like octopuses, and that is the plural as we made clear.
Segment 840: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4752, Text: Yeah, it’s a meme on the internet.
Segment 841: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4755, Text: Oh, yeah? That became a meme, our little discussion two years ago.
Segment 842: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4758, Text: Yeah, it spread pretty quick.
Segment 843: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4759, Text: Oh, yeah.
Segment 844: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4759, Text: And now we just resurfaced it. [inaudible 01:19:22].
Segment 845: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4762, Text: The dismay in your voice is so amusing. In any event, the male cuttlefish will disguise themselves as female cuttlefish, infiltrate the female cuttlefish group, and then mate with them, all sorts of types of covert operations.
Segment 846: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4782, Text: Yep, there we go.
Segment 847: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4782, Text: So I think that…
Segment 848: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4786, Text: Callbacks.
Segment 849: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4786, Text: It’s like a drinking game, where every time we say covert contract, in this episode, you have to take a shot of espresso. Please don’t do that. You’d be dead by the end. [inaudible 01:19:56].
Segment 850: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4796, Text: So it actually is just a small tangent, it does make me wonder how much intelligence covert contracts require. It seems like not much. If you can do it in the animal kingdom, there’s some kind of instinctual… It is based perhaps in fear.
Segment 851: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4810, Text: Yeah, it could be simple algorithm. If there’s some ambiguity about numbers and I’m not with these guys, and then flip to the alternate strategy. I actually have a story about this that I think is relevant. I used to have cuttlefish in my lab in San Diego. We went and got them from a guy out in the desert. We put them in the lab. It was amazing. And they had a postdoc who was studying prey capture in cuttlefish. They have a very ballistic, extremely rapid strike and grab of the shrimp, and we were using high-speed cameras to characterize all this. Looking at binocular, they normally have their eyes on the side of their head, when they see something they want to eat the eyes translocate to the front, which allows them stereopsis death perception, allows them to strike. We were doing some unilateral eye removals they would miss, et cetera.
Segment 852: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4856, Text: Okay, this has to do with eyespots. This was during a government shutdown period where the ghost shrimp that they normally feed eat on, that we would ship in from the gulf down here, weren’t available to us. So we had to get different shrimp. And what we noticed was the cuttlefish normally would just sneak up on the shrimp. We learned this by data collection. And if the shrimp was facing them, they would do this thing with their tentacles of enchanting the shrimp. And if the shrimp wasn’t facing them, they wouldn’t do it and they would ballistically grab it and eat them.
Segment 853: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4893, Text: Well, when we got these new shrimp, the new shrimp had eyespots on their tails and then the cuttlefish would do this attempt to enchant, regardless of the position of the ghost shrimp. So what does that mean? Okay, well, it means that there’s some sort of algorithm in the cuttlefish’s mind that says, “Okay, if you see two spots, move your tentacles.” So it can be, as you pointed out, it can be a fairly simple operation, but it looks diabolical. It looks cunning, but all it is strategy B.
Segment 854: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4923, Text: Yeah, but it’s still somehow emerged. I don’t think that-
Segment 855: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4930, Text: Success-
Segment 856: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4931, Text: … calling it an algorithm doesn’t… I feel like-
Segment 857: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4933, Text: Well, there’s a circuit there that gets implemented in a certain context, but that circuit had to evolve.
Segment 858: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4939, Text: You do realize, super intelligent AI will look at us humans and we’ll say the exact thing. There’s a circuit in there that evolved to do this, the algorithm A and algorithm B, and it’s trivial. And to us humans, it’s fancy and beautiful, and we write poetry about it, but it’s just trivial.
Segment 859: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=4956, Text: Because we don’t understand the subconscious. Because that AI algorithm cannot see into what it can’t see. It doesn’t understand the under workings of what allows all of this conversation stuff to manifest. And we can’t even see it, how could AI see it? Maybe it will, maybe AI will solve and give us access to our subconscious. Maybe your AI friend or coach, like I think Andreessen and others are arguing is going to happen at some point, is going to say, “Hey Lex, you’re making decisions lately that are not good for you, but it’s because of this algorithm that you picked up in childhood, that if you don’t state your explicit needs upfront, you’re not going to get what you want. So why do it? From now on, you need to actually make a list of every absolutely outrageous thing that you want, no matter how outrageous, and communicate that immediately, and that will work.”
Segment 860: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5011, Text: We’re talking about cuttlefish and sexual selection, and then we went into some… Where did we go? Then you said you were excited.
Segment 861: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5018, Text: Well, I was excited… Well, you were just saying what about these covert contracts, [inaudible 01:23:43] animals do them.
Segment 862: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5024, Text: Yes, [inaudible 01:23:44].
Segment 863: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5023, Text: I think it’s simple contextual engagement of a neural circuit, which is not just nerd speak for saying they do a different strategy. It’s saying that there has to be a circuit there, hardwired circuit, maybe learned, but probably hardwired, that can be engaged, right? You can’t build neural machinery in a moment, you need to build that circuit over time. What is building it over time? You select for it. The cuttlefish that did not have that alternate context-driven circuit, didn’t survive when all the shrimp that they normally eat disappear, and the eyespotted shrimp showed up. And there were a couple that had some miswiring. This is why mutation… Right, X-Men stuff is real. They had a mutation that had some alternate wiring and that wiring got selected for, it became a mutation that was adaptive as opposed to maladaptive.
Segment 864: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5073, Text: This is something people don’t often understand about genetics, is that it only takes a few generations to devolve a trait, make it worse, but it takes a long time to evolve an adaptive trait. There are exceptions to that, but most often that’s true. So a species needs a lot of generations. We are hopefully still evolving as a species. And it takes a long time, to evolve more adaptive traits, but doesn’t take long to devolve adaptive traits, so that you’re getting sicker or you’re not functioning as well. So choose your mate wisely, and that’s perhaps the good segue into sexual selection in humans.
Segment 865: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5113, Text: [inaudible 01:25:13]. I could tell you you’re good at this. Why did I bring up sexual selection, is good relationships, so sexual selection in humans. I don’t think you’ve done an episode on relationships.
Segment 866: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5125, Text: No, I did an episode on attachment but not on relationships.
Segment 867: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5131, Text: Right.
Segment 868: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5131, Text: The series with Conti includes one episode of the four that’s all about relational understanding, and how to select a mate based on matching of drives and-
Segment 869: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5143, Text: All the demons inside the subconscious, how to match demons that they dance well together or what?
Segment 870: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5149, Text: And how generative two people are.
Segment 871: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5152, Text: What does that mean?
Segment 872: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5152, Text: Means how… The way he explains it is, how devoted to creating growth within the context of the family, the relationship, with work.
Segment 873: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5162, Text: Well, let me ask you about mating rituals and how to find such a relationship. You’re really big on friendships, on the value of friendships.
Segment 874: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5162, Text: I am.
Segment 875: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5173, Text: And that I think extends itself into one of the deepest kinds of friendships you can have, which is a romantic relationship. What mistakes, successes and wisdom can you impart?
Segment 876: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5190, Text: Well, I’ve certainly made some mistakes. I’ve also made some good choices in this realm. First of all, we have to define what sort of relationship we’re talking about. If one is looking for a life partner, potentially somebody to establish family with, with or without kids, with or without pets, right? Families can take different forms. I certainly experienced being a family in a prior relationship, where it was the two of us and our two dogs, and it was family. We had our little family. I think, based on my experience, and based on input from friends, who themselves have very successful relationships, I must say, I’ve got friends who are in long-term, monogamous, very happy relationships, where there seems to be a lot of love, a lot of laughter, a lot of challenge and a lot of growth. And both people, it seems, really want to be there and enjoy being there.
Segment 877: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5261, Text: Just to pause on that, one thing to do, I think, by way of advice, is listen to people who are in long-term successful relationships. That seems dumb, but we both know and are friends with Joe Rogan, who’s been in a long-term, really great relationship and he’s been an inspiration to me. So you take advice from that guy.
Segment 878: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5283, Text: Definitely, and several members of my podcast team are in excellent relationships. I think one of the things that rings true, over and over again, in the advice and in my experience, is find someone who’s really a great friend, build a really great friendship with that person. Now obviously not just a friend, if we’re talking romantic relationship, and of course sex is super important, but it should be a part of that particular relationship, alongside or meshed with, the friendship. Can it be a majority of the positive exchange? I suppose it could, but I think the friendship piece is extremely important, because what’s required in a successful relationship, clearly is joy in being together, trust, a desire to share experience, both mundane and more adventurous, support each other, acceptance, a real, maybe even admiration, but certainly delight, in being with the person.
Segment 879: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5358, Text: Earlier we were talking about peace, and I think that that sense of peace comes from knowing that the person you’re in friendship with, or that you’re in romantic relationship, or ideally both, because let’s assume the best romantic relationship includes a friendship component with that person. It’s like you just really delight in their presence, even if it’s a quiet presence. And you delight in seeing them delight in things, that’s clear.
Segment 880: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5385, Text: Mm-hmm.
Segment 881: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5386, Text: The trust piece is huge and that’s where people start, we don’t want to focus on what works, not what doesn’t work, but that’s where, I think, people start engaging in these covert contracts. They’re afraid of being betrayed, so they betray. They’re afraid of giving up too much vulnerability, so they hide their vulnerability, or in the worst cases, they feign vulnerability.
Segment 882: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5412, Text: Mm-hmm.
Segment 883: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5413, Text: Again, that’s a covert contract that just simply undermines everything. It becomes one plus one equals two minus one to infinity. Conversely, I think if people can have really hard conversations, this is something I’ve had to work really hard on in recent years, that I’m still working hard on. But the friendship piece seems to be the thing that rises to the top, when I talk to friends who are in these great relationships, it’s like they have so much respect and love and joy in being with their friend. It’s the person that they want to spend as much of their non-working, non-platonic friendship time with, and the person that they want to experience things with and share things with. And it sounds so canned and cliche nowadays, but I think if you step back and examine how most people go about finding a relationship, like, oh, am I attracted? Of course physical attraction is important and other forms of attraction too, and they enter through that portal, which makes sense. That’s the mating dance, that’s the peacock situation. That’s hopefully not the cuttlefish situation.
Segment 884: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5479, Text: But I think that there seems to be a history of people close to me getting into great relationships, where they were friends for a while first or maybe didn’t sleep together right away, that they actually intentionally deferred on that. This has not been my habit or my experience. I’ve gone the more, I think typical, like, oh, there’s an attraction, like this person, there’s an interest. You explore all dimensions of relationship really quickly except perhaps the moving in part and the having kids part, which because it’s a bigger step, harder to undo without more severe consequences. But I think that whole take it slow thing, I don’t think is about getting to know someone slowly, I think it’s about that physical piece, because that does change the nature of the relationship. And I think it’s because it gets right into the more hardwired, primitive circuitry around our feelings of safety, vulnerability.
Segment 885: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5541, Text: There’s something about romantic and sexual interactions, where it’s almost like it’s assets and liabilities, right?
Segment 886: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5551, Text: Mm-hmm.
Segment 887: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5551, Text: Where people are trying to figure out how much to engage their time and their energy and multiple people. I’m talking about from both sides, male, female or whatever sides, but where it’s like assets and liabilities. And that’s where it starts getting into those complicated contracts early on, I think. And so maybe that’s why if a really great friendship and admiration is established first, even if people are romantically and sexually attracted to one another, then that piece can be added in a little bit later, in a way that really just seals up the whole thing, and then who knows, maybe they spend 90% of their time having sex. I don’t know. That’s not for me to say or decide obviously, but there’s something there, about staying out of a certain amount of risk of having to engage covert contract in order to protect oneself.
Segment 888: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5609, Text: But I do think love at first sight, this kind of idea is, in part, realizing very quickly that you are great friends. I’ve had that experience of friendship recently. It’s not really friendship, but like, oh, you get each other. With humans, not in a romantic setting.
Segment 889: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5632, Text: Right, friendship?
Segment 890: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5632, Text: Yeah, just friendship. [inaudible 01:33:54].
Segment 891: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5633, Text: Well, dare I say, I felt that way about you when we met, right?
Segment 892: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5636, Text: Yeah, but we also-
Segment 893: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5637, Text: I was like, “This dude’s cool, and he’s smart, and he’s funny, and he’s driven, and he’s giving, and he’s got an edge, and I want to learn from him. I want to hang out with him.” That was the beginning of our friendship, was essentially that set of internal realizations.
Segment 894: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5657, Text: Just keep going, just keep going, [inaudible 01:34:18] keep going with these compliments.
Segment 895: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5658, Text: And a sharp dresser, [inaudible 01:34:20].
Segment 896: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5659, Text: Yeah, yeah, just looks great shirtless on horseback. Yes.
Segment 897: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5662, Text: No. No, no, listen, despite what some people might see on the internet, it’s a purely platonic friendship.
Segment 898: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5668, Text: Somebody asked if Andrew Huberman has a girlfriend, and somebody says, “I think so.” And the third comment was, “This really breaks my heart that Lex and Andrew are not an item.”
Segment 899: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5682, Text: We are great friends, but we are not an item.
Segment 900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5685, Text: Yeah, well-
Segment 901: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5685, Text: It’s true, it’s official. I hear, over and over again, from friends that have made great choices in awesome partners, and have these fantastic relationships for long periods of time, that seem to continue to thrive, at least that’s what they tell me, and that’s what I observe, establish the friendship first and give it a bit of time before sex. And so I think that’s the feeling. That’s the feeling and we’re talking micro features and macro features. And this isn’t about perfection, it’s actually about the imperfections, which is kind of cool. I like quirky people. I like characters.
Segment 902: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5729, Text: I’ll tell you where I’ve gone badly wrong and where I see other people going badly wrong. There is no rule that says that you have to be attracted to all attractive people, by any means. It’s very important to develop a sense of taste in romantic attractions, I believe. What you really like, in terms of a certain style, a certain way of being, and of course that includes sexuality and sex itself, the verb. But I think it also includes their just general way of being. And when you really adore somebody, you like the way they answer the phone, and when they don’t answer the phone that way, you know something’s off and you want to know. And so I think that the more you can tune up your powers of observation, not looking for things that you like, and the more that stuff just washes over you, the more likely you are to, “Fall in love.” As a mutual friend of ours said to me, “Listen, when it comes to romantic relationships, if it’s not a hundred percent in you, it ain’t happening.”
Segment 903: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5799, Text: And I’ve never seen a violation of that statement, where it’s like, yeah, it’s mostly good and they’re this and this, likes the negotiations. Well, already it’s doomed. And that doesn’t mean someone has to be perfect, the relationship has to be perfect, but it’s got to feel hundred percent inside.
Segment 904: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5816, Text: Yeah.
Segment 905: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5816, Text: Like yes, yes, and yes. I think Deisseroth, when he was on here, your podcast, mentioned something that, I think the words were… Or maybe it was in his book, I don’t recall. But that love is one of these things that we story into with somebody. We create this idea of ourselves in the future and we look at our past time together and then you story into it.
Segment 906: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5839, Text: Mm-hmm.
Segment 907: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5840, Text: There’re very few things like that. I can’t story into building flying cars. I have to actually go do something. And love is also retroactively constructed. Anyone who’s gone through a breakup understands the grief of knowing, oh, this is something I really shouldn’t be in, for whatever reason, because it only takes one. If the other person doesn’t want to be in it, then you shouldn’t be in it. But then missing so many things, and that’s just the attachment machinery, really, at work.
Segment 908: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5869, Text: I have to ask you a question that somebody in our amazing team wanted to ask. He’s happily married. Another, like you mentioned, incredible relationship.
Segment 909: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5878, Text: Are they good friends?
Segment 910: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5880, Text: They’re amazing friends.
Segment 911: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5881, Text: There you go.
Segment 912: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5882, Text: But, I’m just going to say, I’m not saying who it is. So I can say some stuff, which is, it started out as a great sexual connection.
Segment 913: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5890, Text: Oh, well, there you go.
Segment 914: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5891, Text: But then became very close friends after that.
Segment 915: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5894, Text: Okay, listen-
Segment 916: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5894, Text: There you go. So speaking of sex-
Segment 917: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5896, Text: There are many paths to Rome.
Segment 918: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5899, Text: He has a wonderful son and he is wanting to have a second kid, and he wanted to ask the great Andrew Huberman, is there sexual positions or any kind of thing that can help maximize the chance that they have a girl versus a boy? Because they had a wonderful boy.
Segment 919: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5915, Text: Do they want a girl?
Segment 920: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5915, Text: They want to a girl.
Segment 921: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5916, Text: Okay.
Segment 922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5917, Text: Is there a way to control the gender? [inaudible 01:38:39].
Segment 923: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5919, Text: Well, this has been debated for a long time, and I did a four and a half hour episode on fertility. And the reason I did a four and a half hour episode on fertility is that, first of all, I find that reproductive biology be fascinating. And I wanted a resource for people that at were thinking about, or struggling with having kids for whatever reason, and it felt important to me to combine the male and female components in the same episode. It’s all timestamped, so you don’t have to listen to the whole thing. We talk about IVF, in vitro fertilization, we talk about natural pregnancy.
Segment 924: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5951, Text: Okay, the data on position is very interesting, but let me just say a few things. There are a few clinics now, in particular some out of the United States, that are spinning down sperm and finding that they can separate out fractions, as they’re called. They can spin the sperm down at a given speed, and that they’ll separate out at different depths within the test tube, that allow them to pull out the sperm on top or below and bias the probability towards male or female births. It’s not perfect. It’s not a hundred percent. It’s a very costly procedure. It’s still very controversial.
Segment 925: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=5987, Text: Now with in vitro fertilization, they can extract eggs. You can introduce a sperm, directly by pipette, it’s a process called ICSI. Or you can set up a sperm race in a dish. And if you get a number of different embryos, meaning the eggs get fertilized, duplicate and start form a blastocyst, which is a ball of cells, early embryo, then you can do karyotyping. So you can do look for XX or XY, select the XY, which then would give rise to a male offspring, and then implant that one. So there is that kind of sex selection.
Segment 926: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6022, Text: With respect to position, there’s a lot of lore that if the woman is on top or the woman’s on the bottom, or whether or not the penetration is from behind, whether or not it’s going to be male or female offspring. And frankly, the data are not great, as you can imagine, because those-
Segment 927: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6039, Text: [inaudible 01:40:39].
Segment 928: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6038, Text: … those would be interesting studies to run, perhaps.
Segment 929: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6043, Text: But there is studies, there is papers.
Segment 930: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6045, Text: There are some-
Segment 931: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6046, Text: But they’re not, I guess-
Segment 932: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6047, Text: Yeah, it’s-
Segment 933: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6048, Text: There’s more lore than science says.
Segment 934: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6050, Text: And there are a lot of other variables that are hard to control. So for instance, if it’s during intermission, during sex penetration, et cetera, then you can’t measure, for instance, sperm volume as opposed to when it’s IVF, and they can actually measure how many milliliters, how many forward motile sperm. It’s hard to control for certain things. And it just can vary between individuals and even from one ejaculation to the next and… Okay, so there’s too many variables; however, the position thing is interesting in the following way, and then I’ll answer whether or not you can bias us towards a female. As long as we’re talking about sexual-
Segment 935: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6088, Text: I have other questions about sex [inaudible 01:41:28].
Segment 936: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6089, Text: But as long as we’re talking about sexual position,-
Segment 937: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6090, Text: All right.
Segment 938: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6091, Text: … there are data that support the idea that, in order to increase the probability of successful fertilization, that indeed, the woman should not stand upright after sex and should-
Segment 939: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6109, Text: [inaudible 01:41:49].
Segment 940: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6109, Text: Right after the man has ejaculated inside her, and should adjust her pelvis, say, 15 degrees upwards. Some of the fertility experts, MDs, will say that’s crazy, but others-
Segment 941: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6120, Text: MDs will say, “That’s crazy.”
Segment 942: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6122, Text: But others that I sought out, and not specifically for this answer, but for researching that episode, said that, “Yeah, what you’re talking about is trying to get the maximum number of sperm and it’s contained in semen. And yes, the semen can leak out. And so keeping the pelvis tilted for about 15 degrees for about 15 minutes, obviously tilted in the direction that would have things running upstream, not downstream, so to speak.”
Segment 943: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6122, Text: Gravity.
Segment 944: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6149, Text: Gravity, it’s real. So for maximizing fertilization, the doctors I spoke to just said, “Look, given that if people are trying to get pregnant, what is spending 15 minutes on their back?” This sort of thing. Okay. So then with respect to getting a female offspring or XX female offspring, selectively, there is the idea that as fathers get older, they’re more likely to have daughters as opposed to sons. That’s, from the papers I’ve read, is a significant but still mildly significant result. So with each passing year, this person increases the probability they’re going to have a daughter, not a son. So that’s interesting.
Segment 945: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6199, Text: But the probability differences are probably tiny as you said.
Segment 946: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6202, Text: It’s not trivial. It’s not a trivial difference. But if they want to ensure having a daughter, then they should do IVF and select an XX embryo. And when you go through IVF, they genetically screen them for karyotype, which is XX, XY, and they look at mutations, genotypic mutations for things like trisomies and aneuploidies, all the stuff you don’t want.
Segment 947: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6234, Text: But there is a lot of lore if you look on the internet.
Segment 948: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6236, Text: Sure. Different foods.
Segment 949: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6237, Text: So there are a lot of variables.
Segment 950: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6238, Text: There’s a lot of variable, but there haven’t been systematic studies. So I think probably the best thing to do, unless they’re going to do IVF, is just roll the dice. And I think with each passing year, they increase the probability of getting a female offspring. But of course, with each passing year, the egg and sperm quality degrade, so get after it soon.
Segment 951: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6263, Text: So I went down a rabbit hole. Sexology, there’s journals on sex.
Segment 952: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6269, Text: Oh, yeah. Sure. And some of them, not all, quite reputable and some of them really pioneering in the sense that they’ve taken on topics that are considered outside the main frame of what people talk about, but they’re very important. We have episodes coming out soon with, for instance, the Head of Male Urology, Sexual Health and Reproductive Health at Stanford, Michael Eisenberg. But also one with a female urologist, sexual health, reproductive health, Dr. Rena Malik, who has a quite active YouTube presence. She does these really dry, scientific presentation, but very nice. She has a lovely voice. But she’ll be talking about erections or squirting. She does very internet-type content, but she’s a legitimate urologist, reproductive health expert.
Segment 953: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6327, Text: And in the podcast, we did talk about both male and female orgasm. We talked a lot about sexual function and dysfunction. We talked a lot about pelvic floor. One interesting factoid is that only 3% of sexual dysfunction is hormonal, endocrine, in nature. It’s more often related to some pelvic floor or vasculature, blood flow related or other issue. And then when Eisenberg came on the podcast, he said that far less sexual dysfunction is psychogenic in origin than people believe. That far more of it is pelvic floor, neuro and vascular. It’s not saying that psychogenic dysfunction doesn’t exist, but that a lot of the sexual dysfunction that people assume is related to hormones or that is related to psychogenic issues are related to vascular or neural issues. And the good news is that there are great remedies for those. And so both those episodes detail some of the more salient points around what those remedies are and could be.
Segment 954: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6399, Text: One of the, again, factoids, but it was interesting that a lot of people have pelvic floor issues and they think that their pelvic floors are, quote, unquote, messed up. So they go on the internet, they learn about Kegels. And it turns out that some people need Kegels, they need to strengthen their pelvic floor. Guess what? A huge number of people with sexual and urologic dysfunction have pelvic floors that are too tight and Kegels are going to make them far worse, and they actually need to learn to relax their pelvic floor. And so seeing a pelvic floor specialist is important.
Segment 955: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6432, Text: I think in the next five, 10 years, we’re going to see a dramatic shift towards more discussion about sexual and reproductive health in a way that acknowledges that, yeah, the clitoris comes from the same origin tissue as the penis. And in many ways the neural innervation of the two, while clearly different, has some overlapping features that there’s going to be discussion around anatomy and hormones and pelvic floors in a way that’s going to erode some of the cloaking of these topics because they’ve been cloaked for a long time and there’s a lot of… Well, let’s just call it what it is. There’s a lot of bullshit out there about what’s what.
Segment 956: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6474, Text: Now, the hormonal issues, by the way, just to clarify, can impact desire. So a lot of people who have lack of desire as opposed to lack of anatomical function, this could be male or female that can originate with either things like SSRIs or hormonal issues. And so we talk about that as well. So it’s a pretty vast topic.
Segment 957: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6495, Text: Okay. You’re one of the most productive people I know. What’s the secret to your productivity? How do you maximize the number of productive hours in a day? You’re a scientist, you’re a teacher, you’re a very prolific educator.
Segment 958: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6511, Text: Well, thanks for the kind words. I struggle like everybody else, but I am pretty relentless about meeting deadlines. I miss them sometimes, but sometimes that means cramming. Sometimes that means starting early. But-
Segment 959: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6528, Text: Has that been hard, sorry to interrupt, with the podcast? There’s certain episodes, you’re taking just incredibly difficult topics and you know there’s going to be a lot of really good scientists listening to those with a very skeptical and careful eye. Do you struggle meeting that deadline sometimes?
Segment 960: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6549, Text: Yes. We’ve pushed out episodes because I want more time with them. I also, I haven’t advertised this, but I have another fully tenured professor that’s started checking my podcasts and helping me find papers. He’s a close friend of mine. He’s an incredible expert in neuroplasticity and that’s been helpful. But I do all the primary research for the episodes myself. Although my niece has been doing a summer internship with me and finding amazing papers. She did last summer as well. She’s really good at it. Just sick that kid on the internet and she gets great stuff.
Segment 961: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6587, Text: Can I ask you, just going on tangents here, what’s the hardest, finding the papers or understanding what a paper is saying?
Segment 962: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6597, Text: Finding them. Finding the best papers. Yeah. Because you have to read a bunch of reviews, figure out who’s getting cited, call people in a field, make sure that this is the stuff. I did this episode recently on ketamine. About ketamine, I wasn’t on ketamine. And there’s this whole debate about S versus R ketamine, and SR ketamine. And I called two clinical experts at Stanford. I had a researcher at UCLA help me. Even then, a few people had gripes about it that I don’t think they understood a section that I perhaps could have been clearer about. But yeah, you’re always concerned that people either won’t get it or I won’t be clear. So the researching is mainly about finding the best papers.
Segment 963: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6636, Text: And then I’m looking for papers that establish a thoroughness of understanding. That are interesting, obviously. It’s fun to get occasionally look at some of the odder or more progressive papers that are what’s new in a field and then where there are actionable takeaways to really export those with a lot of thoughtfulness.
Segment 964: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6659, Text: Going back to the productivity thing I do, I get up, I look at the sun. I don’t stare at the sun, but I get my sunshine. It all starts with a really good night’s sleep. I think that’s really important to understand. So much so that if I wake up and I don’t feel rested enough, I’ll often do a non-sleep deep rest yoga nidra, or go back to sleep for a little bit, get up, really prioritize the big block of work for the thing that I’m researching. I think a little bit of anxiety and a little bit of concern about deadline helps. Turning the phone off helps, realizing that those peak hours, whenever they are for you, you do not allow those hours to be invaded, unless a nuclear bomb goes off. And nuclear bomb is just a phraseology for, family crisis would be good justification. If there’s an emergency, obviously.
Segment 965: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6713, Text: But it’s all about focus. It’s all about focus in the moment. It’s not even so much about how many hours you log. It’s really about focus in the moment. How much total focus can you give to something? And then I like to take walks and think about things and sometimes talk about them in my voice recorder. So I’m just always churning on it, all the time. And then of course, learning to turn it off and engage with people socially and not be podcasting 24 hours a day in your head is key. But I think I love learning and researching and finding those papers and the information, and I love teaching it.
Segment 966: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6750, Text: And these days I use a whiteboard before I start. I don’t have any notes, no teleprompter. Then the whiteboard that I use beforehand is to really sculpt out the different elements and the flow, get the flow right and move things around. The whiteboard is such a valuable tool. Then take a couple pictures of that when I’m happy with it, put it down on the desk and these are just bullet points and then just churn through and just churn through. And nothing feels better than researching and sharing information. And I, as you did, grew up writing papers and it’s hard. And I like the friction of, “Uh, can’t. I want to get up. I want to use the bathroom.”
Segment 967: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6788, Text: When I was in college, I was trying to make up deficiencies from my lack of attendance in high school, so much so that I would set a timer. I wouldn’t let myself get up to use the bathroom even. Never had an accident. I listened to music, classical music, Rancid, a few other things. Some Bob Dylan maybe thrown in there and just study and just… And then you’d hit the two-hour mark and you’re in pain and then you get up, use the bathroom. You’re like, “That felt so good.” There’s something about the human brain that likes these kind of friction points and working through them and you just have to work through them.
Segment 968: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6826, Text: So yeah, I’m productive and my life has arranged around it, and that’s been a bit of a barrier to personal life at times. But my life’s been arranged around it. I’ve set up everything so that I can learn more, teach more, including some of my home life. But I do still watch Chimp Empire. I still got time to watch Chimp Empire. Look, the great Joe Strummer, Clash, they were my favorite Mescaleros. He said, this famous Strummer quote, “No input, no output.” So you need experience. You need outside things in order to foster the process.
Segment 969: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6867, Text: But yeah, just nose to the grindstone man, I don’t know. And that’s what I’m happy to do with my life. I don’t think anyone should do that just because. But this is how I’m showing up. And if you don’t like me, then scroll… What do they say? Swipe left, swipe right. I don’t know. I’m not on the apps, the dating apps. So that’s the other thing. I keep waiting for when, “Listens to Lex Fridman podcast,” is a checkbox on Hinge or Bumble or whatever it is. But I don’t even know. Are those their field? I don’t know. What are the apps now?
Segment 970: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6900, Text: Well, I’ve never used an app and I always found troublesome how little information is provided on apps.
Segment 971: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6907, Text: Well, they’re the ones that are like a stocked lake, like Raya. Companies will actually fill them with people that look a certain way.
Segment 972: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6918, Text: Well, soon it’ll be filled with AI.
Segment 973: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6920, Text: Oh.
Segment 974: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6921, Text: The way you said, “Oh.”
Segment 975: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6922, Text: Yeah. That’s interesting.
Segment 976: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6924, Text: The heartbreak within that.
Segment 977: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6925, Text: Well, I am guilty of liking real human interaction.
Segment 978: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6930, Text: Have you tried AI interaction?
Segment 979: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6934, Text: No, but I have a feeling you’re going to convince me to.
Segment 980: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6937, Text: One day. I’ve also struggled finishing projects that are new. That are something new. For example, one of the things I’ve really struggled finishing is something that’s in Russian that requires translation and overdub and all that kind of stuff. The other project, I’ve been working on for at least a year off and on, but trying to finish is something we’ve talked about in the past. I’m still on it, project on Hitler in World War II. I’ve written so much about it and I just don’t know why I can’t finish it. I have trouble really… I think I’m terrified being in front of the camera.
Segment 981: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6978, Text: Like this?
Segment 982: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6979, Text: Like this.
Segment 983: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6979, Text: Or solo?
Segment 984: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6981, Text: No, no, no. Solo.
Segment 985: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6982, Text: Well, if ever you want to do solo and seriously, because done this before, our clandestine study missions, I’m happy to sit in the corner and work on my book or do something if it feels good to just have someone in the room.
Segment 986: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6994, Text: Just for the feeling of somebody else?
Segment 987: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6995, Text: Definitely.
Segment 988: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=6997, Text: You seem to have been fearless to just sit in front of the camera by yourself to do the episode.
Segment 989: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7008, Text: Yeah, it was weird. The first year of the podcast, it just spilled out of me. I had all that stuff I was so excited about. I’d been talking to everyone who would listen and even when they’d run away, I’d keep talking before there was ever a camera, wasn’t on social media. 2019, I posted a little bit. 2020, as you know, I started going on podcasts. But yeah, the zest and delight in this stuff. I was like, “Circadian rhythms, I’m going to tell you about this stuff.” I just felt like, here’s the opportunity and just let it burst.
Segment 990: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7039, Text: And then as we’ve gotten into topics that are a little bit further away from my home knowledge, I still get super excited about it. This music in the brain episode I’ve been researching for a while now, I’m just so hyped about it. It’s so, so interesting. There’s so many facets. Singing versus improvisational music versus, “I’m listening to music,” versus learning music. It just goes on and on. There’s just so much that’s so interesting. I just can’t get enough. And I think, I don’t know, you put a camera in front of me, I sort of forget about it and I’m just trying to just teach.
Segment 991: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7081, Text: Yeah, so that’s the difference. That’s interesting.
Segment 992: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7082, Text: Forget the camera.
Segment 993: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7083, Text: Maybe I need to find that joy as well. But for me, a lot of the joy is in the writing. And the camera, there’s something-
Segment 994: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7092, Text: Well, the best lecturers, as you know, and you’re a phenomenal lecturer, so you embody this as well, but when I teach at Stanford, I was directing this course in neuroanatomy and neuroscience for medical students. And I noticed that the best lecturers would come in and they’re teaching the material from a place of deep understanding, but they’re also experiencing it as a first time learner at the same time. So it’s just sort of embodying the delight of it, but also the authority over the… Not authority, but the mastery of the material. And it’s really the delight in it that the students are linking onto. And of course they need and deserve the best accurate material, so they have to know what they’re talking about.
Segment 995: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7130, Text: But yeah, just tap into that energy of learning and loving it. And people are along for the ride. I get accused of being long-winded, but things get taken out of context, that leads to greater misunderstanding. And also, listen, I come from a lineage of three dead advisors. Three. All three. So I don’t know when the reaper’s coming for me. I’m doing my best to stay alive a long time. But whether or not it’s a bullet or a bus or cancer or whatever, or just old age, I’m trying to get it all out there as best I can. And if it means you have to hit pause and come back a day or two later, that seems like a reasonable compromise to me. I’m not going to go longer than I need to and I’m trying to shorten them up. But again, that’s kind of how I show up.
Segment 996: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7179, Text: It’s like Tim Armstrong would say about writing songs. I asked him, “How often do you write?” Every day. Every day. Does Rick ever stop creating? No. Has Joe ever stopped preparing for comedy? Are you ever stopping to think about world issues and technology and who you can talk to? It seems to me you’ve always got a plan in sight. The thing I love about your podcast the most, to be honest these days, is the surprise of I don’t know who the hell’s going to be there. It’s almost like I get a little nervously excited about when a new episode comes out. I have no idea. No idea. I have some guesses based on what you told me during the break. You’ve got some people where it’s just like, “Whoa, Lex went there? Awesome. Can’t wait.” Click. I think that’s really cool. You’re constantly surprising people. So you’re doing it so well. It’s such a high level and I think it’s also important for people to understand that what you’re doing Lex, there’s no precedent for it. Sure. There’ve been interviews before, there have been podcasts before. There are discussions before. How many of your peers can you look to find out how best to do the content like yours? Zero. There’s one peer: you. And so that should give you great peace and great excitement because you’re a pioneer. You’re literally the tip of the spear.
Segment 997: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7264, Text: I don’t want to take an unnecessary tangent, but I think this might thread together two of the things that we’ve been talking about, which are, I think of pretty key importance. One is romantic relationships, and the other is creative process and work. And this again, is something I learned from Rick, but that he and I have gone back and forth on. And that I think is worth elaborating on, which is earlier we were saying the best relationship is going to be one where it brings you peace. I think peace also can be translated to, among other things, lack of distraction. So when you’re with your partner, can you really focus on them and the relationship? Can you not be distracted by things that you’re upset about from their past or from your past with them? And of course the same is true for them, right? They ideally will feel that way towards you too. They can really focus.
Segment 998: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7318, Text: Also, when you’re not with them, can you focus on your work? Can you not be worried about whether or not they’re okay because you trust that they’re an adult and they can handle things or they will reach out if they need things? They’re going to communicate their needs like an adult. Not creating messes just to get attention and things like that, or disappearing for that matter. So peace and focus are intimately related, and distraction is the enemy of peace and focus.
Segment 999: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7352, Text: So there’s something there, I believe, because with people that have the strong generative drive and want to be productive in their home life, in the sense have a rich family life, partner life, whatever that is, and in their work life, the ability to really drop into the work and you might have that sense like, “I hope they’re okay,” or, “need to check my phone or something,” but just know we’re good.
Segment 1000: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7377, Text: Yeah. Everything’s okay.
Segment 1001: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7377, Text: So peace and focus, I think and being present are so key. And it’s key at every level of romantic relationship, from certainly presence and focus. Everything from sex to listening to raising a family, to tending to the house and in work, it’s absolutely critical. So I think that those things are mirror images of the same thing. And they’re both important reflections of the other. And when work is not going well, then the focus on relationship can suffer and vice versa.
Segment 1002: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7413, Text: And it’s crazy how important that is.
Segment 1003: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7415, Text: Peace.
Segment 1004: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7417, Text: How incredibly wonderful it could be to have a person in your life that enables that creative focus.
Segment 1005: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7427, Text: Yeah. And you supply the peace and focus for their endeavors, whatever those might be. That symmetry there. Because clearly people have different needs and the need to just really trust, when Lex is working, he’s in his generative mode and I know he’s good. And so then they feel, sure, they’ve contributed to that. But then also what you’re doing is supporting them in whatever way happens to be. And I think that sometimes you’ll see that. People will pair up along creative-creative or musical-musical or computer scientists. But I think, again, going back to this Conti episode on relationships is that the superficial labels are less important, it seems, than just the desire to create that kind of home life and relationship together. And as a consequence, the work mode. And for some people, both people aren’t working and sometimes they are. But I think that’s the good stuff. And I think that’s the big learning in all of it, is that the further along I go, with each birthday, I guarantee you’re going to be like, “What I want is simpler and simpler and harder and harder to create. But oh, so worth it.”
Segment 1006: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7502, Text: The inner and the outer peace. It’s been over two years, I think, since Costello passed away.
Segment 1007: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7511, Text: It still tears me up. I cried about him today. I cried about him today.
Segment 1008: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7517, Text: [inaudible 02:05:17]. Fuck.
Segment 1009: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7518, Text: It’s proportional to the love. But yeah, I’ll cry about it right now if I think about it. It wasn’t putting him down, it wasn’t the act of him dying, any of that. Actually, that was a beautiful experience. I didn’t expect it to be, but it was in my place when I was living in Topanga during the pandemic where we launched the podcast and I did it at home and he hated the vet so I did it at home. And he gave out this huge, “Ugh,” right at the end. And I could just tell he had been in not a lot pain, fortunately. But he had just been working so hard just to move at all.
Segment 1010: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7552, Text: And the craziest thing happened, Lex. It was unbelievable. I’ve never had an experience like this. I expected my heart to break, and I’ve felt a broken heart before. I felt it, frankly, when my parents split, I felt it when Harry shot himself. I felt it when Barbara died and felt it when Ben went as well. And so many friends, way too many friends. The end of 2017, my friend Aaron King, Johnny Fair, John Eikleberry, stomach cancer, suicide, fentanyl. I was like, “Whoa. All in a fricking week.” And I just remember thinking, “What the…?” And it’s just heartbreak and you just carry that and it’s like, “Uh.” And that’s just a short list. And I don’t say that for sob stories. It’s just for a guy that wasn’t in the military or didn’t grow up in the inner city, it’s an unusual number of deaths, close people.
Segment 1011: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7611, Text: When Costello went, the craziest thing happened. My heart warmed up, it heated up. And I wasn’t on MDMA. The moment he went, it just went whoosh. And I was like, “What the hell is this?” And it was a supernatural experience to me. I just never had that. I put my grandfather on the ground, I was a pallbearer at the funeral. I’ve done that more times than I’d like to have ever done it. And it just heated up with Costello and I thought, “What the fuck is this?”
Segment 1012: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7642, Text: And it was almost like, and we make up these stories about what it is, but it was almost like he was like, “All right,” I have to be careful because I will cry here and I don’t want to. It was almost like he was like all that effort, because I had been putting so much effort into him, it was like, “All right, you get that back.” It was like the giant freaking, “Thank you.” And it was incredible. And I’m not embarrassed to shed a tear or two about it if I have to.
Segment 1013: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7669, Text: I was like, “Holy shit.” That’s how close I was to that animal.
Segment 1014: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7673, Text: Where do you think can find that kind of love again?
Segment 1015: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7677, Text: Man, I don’t know. And excuse me for welling up. I mean, it’s a freaking dog, right? I get it. But for me, it was the first real home I ever had. But when Costello went, it was like we had had this home in Topanga. We had set it up and he was just so happy there. And I think, I don’t know, it was this weird victory slash massive loss. We did it. 11 years. Freaking did everything, everything, to make him as comfortable as possible. And he was super loyal, beautiful animal, but also just funny and fun. And I was like, “I did it.” I gave as much of myself to this being as I felt I could without detracting from the rest of my life. And so I don’t know.
Segment 1016: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7733, Text: When I think about Barbara especially, I well up and it’s hard for me, but I talked to her before she died and that was a brutal conversation, saying goodbye to someone, especially with kids. And that was hard. I think that really flipped a switch in me where I’m like, I always knew I wanted kids. I’d say, “I want kids. I want a lot of kids.” That flipped a switch in me. I was like, “I want kids. I want my own kids.”
Segment 1017: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7762, Text: You might be able to find that kind of love having kids.
Segment 1018: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7765, Text: Yeah, I think because it was the caretaking. It wasn’t about what he gave me all that time, and the more I could take care of him and see him happy, the better I felt. It was crazy. I don’t know. So I miss him every day. Every day. I miss him every day.
Segment 1019: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7784, Text: You got a heart that’s so full of love. I can’t wait for you to have kids.
Segment 1020: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7788, Text: Thanks, man.
Segment 1021: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7789, Text: For you to be a father. I can’t wait to do the same.
Segment 1022: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7790, Text: Yeah, well, when I’m ready for it. When God decides I’m ready, I’ll have them.
Segment 1023: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7798, Text: And then I will still beat you to it. As I told you many times before,
Segment 1024: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7803, Text: I think you should absolutely have kids. Look at the people in our life. Because in case you haven’t realized it already, we’re the younger of the podcasters. But like Joe and Peter and Segura and the rest, they’re like the tribal elders and we’re not the youngest in the crew. But if you look at all those guys, they all have kids. They all adore their kids and their kids bring tremendous meaning to their life. We’d be morons if you didn’t go off and start a family, I didn’t start start a family. And yeah, I think that’s the goal. Of the goals, that’s one of them.
Segment 1025: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7858, Text: The kids not only make their life more joyful and brings love to their life, it’s also makes them more productive, makes them better people, all of that. It’s kind of obvious. Yeah,
Segment 1026: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7870, Text: I think that’s what Costello wanted, I think, I have this story in my head that he was just like, “Okay, take this like a kid.” It was a good test.
Segment 1027: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7877, Text: “And don’t fuck this up.”
Segment 1028: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7878, Text: “Lord knows, don’t fuck this up.”
Segment 1029: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7881, Text: Andrew, I love you, brother. This was an incredible conversation.
Segment 1030: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7884, Text: Love you too. I appreciate you.
Segment 1031: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7886, Text: We will talk often on each other’s podcast for many years to come.
Segment 1032: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7890, Text: Yes.
Segment 1033: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7890, Text: Many, many years to come.
Segment 1034: Speaker: Andrew Huberman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7892, Text: Thank you. Thanks for having me on here. And there are no words for how much I appreciate your example and your friendship. So love you, brother.
Segment 1035: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7900, Text: Love you too.
Segment 1036: Speaker: , Timestamp: https://youtube.com/watch?v=eTBAxD6lt2g&t=7902, Text: Thanks for listening to this conversation with Andrew Huberman to support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Albert Camus. “In the midst of winter, I found there was, within me, an invincible summer. And that makes me happy. For it says that no matter how hard the world pushes against me, within me, there’s something stronger – something better, pushing right back.” Thank you for listening and hope to see you next time.
Segment 1037: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=0, Text: There is a certain perspective where you might be thinking, what is the longest possible game that you could be playing? A short game is, for instance, cancer is playing a shorter game than your organism. Cancer is an organism playing a shorter game than the regular organism. Because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with a situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. Ideally, you want to, I think, build agents that play the longest possible games. The longest possible games is to keep entropy at bay as long as possible, by doing interesting stuff.
Segment 1038: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=48, Text: The following is a conversation with Joscha Bach, his third time on this podcast. Joscha is one of the most brilliant, and fascinating minds in the world, exploring the nature of intelligence, consciousness, and computation. He’s one of my favorite humans to talk to about pretty much anything and everything. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Joscha Bach.
Segment 1039: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=75, Text: You wrote a post about levels of lucidity. “As we grow older, it becomes apparent that our self-reflexive mind is not just gradually accumulating ideas about itself, but that it progresses in somewhat distinct stages.” There are seven of the stages. Stage one, reactive survival (infant). Stage two, personal self (young child). Stage three, social self (adolescence, domesticated adult). Stage four is rational agency (self-direction). Stage five is self-authoring, that’s full adult. You’ve achieved wisdom, but there’s two more stages. Stage six is enlightenment, stage seven is transcendence. Can you explain each, or the interesting parts of each of these stages, and what’s your sense why there are stages of this, of lucidity as we progress through life in this too short life?
Segment 1040: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=132, Text: This model is derived from concept by the psychologist Robert Kegan, and he talks about the development of the self as a process that happens in principle by some kind of reverse engineering of the mind, where you gradually become aware of yourself, and thereby build structure that allows you to interact deeper with the world and yourself. I found myself using this model not so much as a developmental model. I’m not even sure if it’s a very good developmental model, because I saw my children not progressing exactly like that. I also suspect that you don’t go through these stages necessarily in succession, and it’s not that you work through one stage and then you get into the next one. Sometimes, you revisit them. Sometimes, stuff is happening in parallel. But it’s, I think, a useful framework to look at what’s present, and the structure of a person, and how they interact with the world, and how they relate to themselves.
Segment 1041: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=188, Text: It’s more like philosophical framework that allows you to talk about how minds work. At first, when we are born, we don’t have a personal self yet, I think. Instead, we have an attentional self, and this attentional self is initially in the infant tasked, is building a world model, and also an initial model of the self. But mostly, it’s building a game engine in the brain that is tracking sensory data, and uses it to explain it. In some sense, you could compare it to a game engine like Minecraft or so, colors and sounds. People are all not physical objects. They’re creation of our mind at a certain level. Of course, screening models that are mathematical that use geometry, and that use manipulation of objects, and so on to create scenes in which we can find ourselves, and interact with them.
Segment 1042: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=239, Text: Minecraft?
Segment 1043: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=240, Text: Yeah. This personal self is something that is more or less created after the world is finished, after it’s trained into the system, after it has been constructed. This personal self is an agent that interacts with the outside world. The outside world is not the world of quantum mechanics, not the physical universe, but it’s the model that has been generated in our own mind, right? This is us, and we experience ourself interacting with that outside world that is created inside of our own mind. Outside of ourself, there’s feelings, and they presented our interface with this outside world. They pose problems to us. These feelings are basically attitudes that our mind is computing, that tell us what’s needed in the world, the things that we are drawn to, the things that we are afraid of. We are tasked with solving this problem of satisfying the needs, avoiding the aversions, following on our inner commitments and so on, and also modeling ourselves, and building the next stage.
Segment 1044: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=302, Text: After we have this personal self and stage two online, many people form a social self. This social self allows the individual to experience themselves as part of a group. It’s basically this thing that when you are playing in a team, for instance, you don’t notice yourself just as a single node that is reaching out into the world, but you’re also looking down. You’re looking down from this entire group, and you see how this group is looking at this individual, and everybody in the group is, in some sense, emulating this group spirit to some degree. In this state, people are forming their opinions by assimilating them from this group mind. They basically gain the ability to act a little bit like a hive mind.
Segment 1045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=343, Text: But are you also modeling the interaction of how opinion shapes and forms through the interaction of the individual nodes within the group?
Segment 1046: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=351, Text: Yeah. Basically, the way in which people do it in this stage is that they experience what are the opinions of my environment. They experience the relationship that they have to their environment, and they resonate with people around them, and get more opinions through this interaction to the way in which they relate to others. At stage four, you basically understand that stuff is true and false independently, what other people believe, and you have agency over your own beliefs. In that stage, you basically discover epistemology, the rules about determining what’s true and false.
Segment 1047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=388, Text: You start to learn how to think?
Segment 1048: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=390, Text: Yes. I mean, at some level, you’re always thinking you are constructing things, and I believe that this ability to reason about your mental representation is what we mean by thinking. It’s an intrinsically reflexive process that requires consciousness. Without consciousness, you cannot think. You can generate the content of feelings, and so on outside of consciousness. It’s very hard to be conscious of how your feelings emerge, at least in the early stages of development. But thoughts is something that you always control. If you are a nerd like me, you often have to skip stage three, because you’d like the intuitive empathy with others. Because in order to resonate with a group, you need to have a quite similar architecture. If people are wired differently, then it’s hard for them to resonate with other people, and basically have empathy, which is not the same as compassion, but it is a shared perceptual mental state. Empathy happens not just via inference about the mental states of others, but it’s a perception of what other people feel, and where they’re at.
Segment 1049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=455, Text: Can’t you not have empathy while also not having a similar architecture, cognitive architecture as the others in the group?
Segment 1050: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=461, Text: I think, yes. I experienced that too. But you need to build something that is like a meta architecture. You need to be able to embrace the architecture of the other to some degree, or find some shared common ground. It’s also this issue that, if you are a nerd nomis, often people, basically neurotypical people have difficulty to resonate with you. As a result, they have difficulty understanding you, unless they have enough wisdom to feel what’s going on there.
Segment 1051: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=488, Text: Well, isn’t the whole process of the stage three to figure out the API to the other humans that have different architecture, and you yourself publish public documentation for the API that people can interact with for you? Isn’t this the whole process of socializing?
Segment 1052: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=506, Text: My experience as a child growing up was that I did not find any way to interface with the stage-three people, and they didn’t do that with me, so took me-
Segment 1053: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=516, Text: Did you try?
Segment 1054: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=516, Text: Yeah, of course, I tried it very hard. But it was only when I entered the mathematics school at the ninth grade, where lots of other nerds were present, that I found people that I could deeply resonate with, and had the impression that, yes, I have friends now. I found my own people. Before that, I felt extremely lonely in the world. There was basically nobody I could connect to. I remember, there was one moment in all these years, where I was in… There was a school exchange, and it was a Russian boy, a kid from the Russian garrison stationed in Eastern Germany who visited our school, and we played a game of chess against each other, and we looked into each other’s eyes, and we sat there for two hours playing this game of chess. I had the impression, this is the human being, he understands what I understand, we didn’t even speak the same language.
Segment 1055: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=569, Text: I wonder if your life could have been different if you knew that it’s okay to be different, to have a different architecture, whether accepting that the interface is hard to figure out, it takes a long time to figure out and it’s okay to be different. In fact, it’s beautiful to be different.
Segment 1056: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=590, Text: It was not my main concern. My main concern was mostly that I was alone. It was not the so much the question, is it okay to be the way I am? I couldn’t do much about it, so I had to deal with it. But my main issue was that I was not sure if I would ever meet anybody growing up that I would connect to at such a deep level that I would feel that I could belong.
Segment 1057: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=613, Text: So there’s a visceral, undeniable feeling of being alone?
Segment 1058: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=617, Text: Yes. I noticed the same thing when I came into the math school that I think at least half, probably two thirds of these kids were severely traumatized as children growing up, and in large part, due to being alone, because they couldn’t find anybody to relate to.
Segment 1059: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=633, Text: Don’t you think everybody’s alone, deep down?
Segment 1060: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=636, Text: No.
Segment 1061: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=636, Text: No.
Segment 1062: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=636, Text: I’m not alone.
Segment 1063: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=636, Text: Fair enough.
Segment 1064: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=643, Text: I’m not alone anymore. It took me some time to update, and to get over the trauma time and so on, but I felt that in my 20s, I had lots of friends, and I had my place in the world, and I had no longer doubts that I would never be alone again.
Segment 1065: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=660, Text: Is there some aspect to which we’re alone together? You don’t see a deep loneliness in inside yourself still?
Segment 1066: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=666, Text: No. Sorry.
Segment 1067: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=670, Text: Okay. That’s the nonlinear progression through the stages, I suppose. You caught up on stage three at some point.
Segment 1068: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=676, Text: Correct. We’re at stage four, and so basically I find that many nerds jump straight into stage four, bypassing stage three.
Segment 1069: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=682, Text: Do they return to it then, later?
Segment 1070: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=684, Text: Yeah, of course. Sometimes, they do. Not always.
Segment 1071: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=687, Text: Yeah.
Segment 1072: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=687, Text: Their question is basically, do you stay a little bit autistic, or do you catch up? I believe you can catch up. You can build this missing structure, and basically experience yourself as part of a group, learn intuitive empathy, and develop the sense, this perceptual sense of feeling what other people feel. Before that, I could only basically feel this when I was deeply in love with somebody, and we synced.
Segment 1073: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=712, Text: There’s a lot of friction to feeling that way, it’s only with certain people, as opposed to it comes naturally?
Segment 1074: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=719, Text: Yeah.
Segment 1075: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=719, Text: It’s frictionless.
Segment 1076: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=719, Text: But this is something that basically later, I felt, started to resolve itself for me to a large degree.
Segment 1077: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=726, Text: What was the trick?
Segment 1078: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=730, Text: In many ways, growing up, and paying attention. Meditation did help. I had some very crucial experiences in getting close to people, building connections, and cuddling a lot in my student years.
Segment 1079: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=748, Text: Really, paying attention to the what is it, to the feeling another human being fully.
Segment 1080: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=755, Text: Loving other people, and being loved by other people, and building a space in which you can be safe, and can experiment, and touch a lot, and be close to somebody a lot. Over time, basically at some point, you realize, oh, it’s no longer that I feel locked out, but I feel connected, and I experience where somebody else is at. Normally, my mind is racing very fast at a high frequency, so it’s not always working like this. Sometimes works better, sometimes it works less, but also don’t see this as a pressure. It’s more, it’s interesting to observe myself which frequency I’m at, and at which mode somebody else is at.
Segment 1081: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=798, Text: Yeah. Man, the mind is so beautiful in that way. Sometimes, it comes so natural to me, so easy to pay attention, pay attention to the world fully, to other people fully, and sometimes, the stress over silly things is overwhelming. It’s so interesting that the mind is that rollercoaster in that way.
Segment 1082: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=817, Text: At stage five, you discover how identity is constructed.
Segment 1083: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=820, Text: Self authoring.
Segment 1084: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=821, Text: Realize that your values are not terminal, but they’re instrumental to achieving a world that you like, and aesthetics that you prefer. The more you understand this, the more you get agency over how your identity is constructed, and you realize that identity and interpersonal interaction is a costume, and you should be able to have agency over that costume, right? It’s useful to be a costume, it tells something to others, and it allows to interface in roles. But being locked into this is a big limitation.
Segment 1085: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=853, Text: The word costume implies that it’s fraudulent in some way. Is costume a good word for you, like we present ourselves to the world?
Segment 1086: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=862, Text: In some sense, I learned a lot about costumes at Burning Man. Before that, I did not really appreciate costumes, and saw them more as uniforms like wearing a suit. If you are working in a bank, or if you are trying to get startup funding from a VC in Switzerland, then you dress up in a particular way. This is mostly to show the other side that you are willing to play by the rules, and you understand what the rules are. But there is something deeper when you are at Burning Man, your costume becomes self-expression, and there is no boundary to the self-expression. You’re basically free to wear what you want to express other people, what you feel like this day, and what kind of interactions you want to have.
Segment 1087: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=904, Text: Is the costume a projection of who you are?
Segment 1088: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=910, Text: That’s very hard to say, because the costume also depends on what other people see in the costume. This depends on the context that the other people understand, so you have to create something if you want to, that is legible to the other side and that means something to yourself.
Segment 1089: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=926, Text: Do we become prisoners of the costume, prisoner everybody expects us to?
Segment 1090: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=929, Text: Some people do. But I think that once you realize that you wear a costume at Burning Man, a variety of costumes, realize that you cannot not wear a costume.
Segment 1091: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=940, Text: Yeah.
Segment 1092: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=941, Text: Right. Basically, everything that you wear, and present to others is something that is, to some degree, in addition to what you are deep inside.
Segment 1093: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=952, Text: This stage in parentheses, you put full adult, wisdom. Why is this full adult? Why would you say this is full, and why is it wisdom?
Segment 1094: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=964, Text: It does allow you to understand why other people have different identities from yours, and it allows you to understand that the difference between people who vote for different parties, and might have very different opinions and different value systems, is often the accident of where they’re born, and what happened after that to them, and what traits they got before they were born. At some point, you realize the perspective, where you understand that everybody could be you in a different timeline, if you just flip those bits.
Segment 1095: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=998, Text: How many costumes do you have?
Segment 1096: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1001, Text: I don’t count, but in-
Segment 1097: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1003, Text: More than one?
Segment 1098: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1004, Text: Yeah, of course.
Segment 1099: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1006, Text: How easy is it to do costume changes throughout the day?
Segment 1100: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1011, Text: It’s just a matter of energy, and interest. When you are wearing your pajamas, and you switch out of your pajamas into, say, a work short and pants, you’re making a costume change, right? If you are putting on a gown, you’re making a costume change.
Segment 1101: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1026, Text: You could do the same with personality?
Segment 1102: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1029, Text: You could, if that’s what you’re into. There are people which have multiple personalities for interaction in multiple worlds, right? If somebody works in a store, and put up a storekeeper personality, when you’re working, when you’re presenting yourself at work, you develop a sub-personality for this. The social persona for many people is, in some sense, a puppet that they’re playing like a marionette. If they play this all the time, they might forget that there is something behind this, there’s something what it feels like to be in your skin. I guess, it’s very helpful if you’re able to get back into this. For me, the other way around is relatively hard for me. It’s pretty hard to learn how to play consistent social roles. For me, it’s much easier just to be real.
Segment 1103: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1074, Text: Mm-hmm. Or not real, but to have one costume?
Segment 1104: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1079, Text: No, it’s not quite the same. Basically, when you are wearing a costume at Burning Man, and say you are an extraterrestrial prince, and that’s something where you are expressing, in some sense, something that’s closer to yourself than the way in which you hide yourself behind standard clothing, when you go out in the city, in the default world. This costume that you’re wearing at Burning Man allows you to express more of yourself, and you have a shorter distance of advertising to people, what kind of person you are, what kind of interaction you would want to have with them. You get much earlier into Media Express, and I believe it’s regrettable that we do not use the opportunities that we have, with custom-made clothing now, to wear costumes that are much more stylish, that are much more custom-made, that are not necessarily part of a fashion in which you express, which you knew you’re part of, and how up-to-date you are. But you also express how you are as an individual, and what you want to do today, and how you feel today, and what you intend to do about that.
Segment 1105: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1146, Text: Well, isn’t it easier now in a digital world to explore different costumes? I mean, that’s the idea with virtual reality, that’s the idea. Even with Twitter, in two-dimensional screens, you can swap all costumes. You could be as weird as you want, it’s easier. For Burning Man, you have to order things, you have to make things, you have to… It’s more effort to put on your-
Segment 1106: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1172, Text: It’s even better if you make them yourself.
Segment 1107: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1175, Text: Sure. But it’s just easier to do digitally, right?
Segment 1108: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1179, Text: It’s not about easy. It’s about how to get it right.
Segment 1109: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1182, Text: Sure.
Segment 1110: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1183, Text: For me, the first Burning Man experience, I got adopted by a bunch of people in Boston who dragged me to Burning Man, and we spent a few weekends doing costumes together. That was an important part of the experience, where the camp bonded, that people got to know each other, and we basically grew into the experience that we would have later.
Segment 1111: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1202, Text: So the extraterrestrial prince is based on a true story?
Segment 1112: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1205, Text: Yeah.
Segment 1113: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1206, Text: I can only imagine what that looks like, Joscha.
Segment 1114: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1211, Text: Okay.
Segment 1115: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1212, Text: Stage six.
Segment 1116: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1212, Text: Stage six? At some point, you can collapse the division between self, a personal self, and world generator again. A lot of people get there via meditation, or some of them get there via psychedelics, some of them by accident. You suddenly notice that you are not actually a person, but you are a vessel that can create a person, and the person is still there. You observe that personal self, but you observe the personal self from the outside, and you notice it’s a representation. You might also notice that the world that is being created as the representation is not, then you might experience that I am the universe, I’m the thing that is creating everything. Of course, what you’re creating is not quantum mechanics, and the physical universe. What you’re creating is this game engine that is updating the world, and you’re creating your valence, your feelings, and all the people inside of that world, including the person that you identify with yourself in this world.
Segment 1117: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1271, Text: Are you creating the game engine, or are you noticing the game engine?
Segment 1118: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1275, Text: You notice how you’re generating the game engine. I mean, when you are dreaming at night, you can… If you have a lucid dream, you can learn how to do this deliberately, and in principle, you can also do it during the day. The reason why we don’t get to do this from the beginning, and why we don’t have agency of our feelings right away is because we would game it, before we have the necessary amount of wisdom to deal with creating this dream that we are in.
Segment 1119: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1304, Text: You don’t want to get access to cheat codes too quickly, otherwise you won’t enjoy the game.
Segment 1120: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1309, Text: Stage five is already pretty rare, and stage six is even more rare. You most basically find this mostly with advanced Buddhist meditators and so on, that dropping into this stage, and can induce it at will, and spend time in it.
Segment 1121: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1324, Text: Stage five requires a good therapist, stage six requires a good Buddhist spiritual leader?
Segment 1122: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1331, Text: Yes. For instance, could be that it’s the right thing to do, but it’s not that these stages give you scores, or levels that you need to advance to. It’s not that the next stage is better. You live your life in the mode it works best at any given moment, and when your mind decides that you should have a different configuration, then it’s building that configuration. For many people, they stay happily at stage three, and experiences themselves as part of groups, and there’s nothing wrong with this. For some people, this doesn’t work, and they’re forced to build more agency over their rational beliefs than this, and construct their norms rationally, and so they go to this level. Stage seven is something that is more or less hypothetical. That would be the stage in which, it’s basically a trans-humanist stage in which you understand how you work, in which the mind fully realizes how it’s implemented, and can also, in principle, enter different modes in which it could be implemented. That’s the stage that, as far as I understand, is not open to people yet.
Segment 1123: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1394, Text: Oh, but it is possible through the process of technology.
Segment 1124: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1397, Text: Yes. Who knows, if there are biological agents that are working at different timescales than us that basically become aware of the way in which they’re implemented on ecosystems, and can change that implementation, and have agency over how they’re implemented in the world. What I find interesting about the discussion about AI alignment, that it seems to be following the status very much. Most people seem to be in stage three also, according to Robert Kegan, I think he says that about 85% of people are in stage three, and stay there. If you’re in stage three, and your opinions are the result of social stimulation, then what you’re mostly worried about in the AI is that the AI might have the wrong opinions. If the AI says something racist or sexist, we are all lost, because we will assimilate the wrong opinions from the AI, and so we need to make sure that the AI has the right opinions, and the right values, and the right structure.
Segment 1125: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1454, Text: If you’re at stage four, that’s not your main concern, and so most nerds don’t really worry about the algorithmic bias, and the model that it picks up, because if there’s something wrong with this bias, the AI ultimately will prove it. At some point, we’ll gather there that it makes mathematic proofs about reality, and then it will figure out what’s true and what’s false. But you’re still worried that AI might turn you into paperclips, because it might have the wrong values, right? If it’s set up through a wrong function that controls its direction in the world, then it might do something that is completely horrible, and there’s no easy way to fix it.
Segment 1126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1489, Text: So that’s more like a stage four rationalist worry?
Segment 1127: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1491, Text: Yes. If you are at stage five, you’re mostly worried that AI is not going to be enlightened fast enough, because you realize that the game is not so much about intelligence, but about agency, about the ability to control the future, and the identity is instrumental to this. If you are a human being, I think at some level, you ought to choose your own identity. You should not have somebody else pick the costume for you, and then wear it. But instead, you should be mindful about what you want to be in this world. I think if you are an agent that is fully malleable, that can provide its own source code like an AI might do at some point, then the identity that you will have is whatever you can be. In this way, the AI will maybe become everything like a planetary control system.
Segment 1128: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1542, Text: If it does that, then if we want to coexist with it, it means that it’ll have to share purposes with us, so it cannot be a transactional relationship. We will not be able to use reinforcement learning with human feedback to hardwire its values into it. But this has to happen. It’s probably that it’s conscious, so it can relate to our own mode of existence, where an observer is observing itself in real-time, and within certain temporal frames. The other thing is that it probably needs to have some kind of transcendental orientation, building shared agency, in the same way as we do when we are able to enter with each other into non-transactional relationships. I find that’s something that, because the stage five is so rare, is missing in much of the discourse. I think that we need, in some sense, focus on how to formalize love, how to understand love, and how to build it into the machines that we are currently building, and that are about to become smarter than us.
Segment 1129: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1604, Text: Well, I think this is a good opportunity to try to sneak up to the idea of enlightenment. You wrote a series of good tweets about consciousness, and panpsychism. Let’s break it down. First you say, I suspect the experience that leads to the panpsychism syndrome of some philosophers, and other consciousness enthusiasts represents the realization that we don’t end at the self, but share a resonant universe representation with every other observer coupled to the same universe. This actually, eventually leads us to a lot of interesting questions about AI, and AGI. But let’s start with this representation. What is this resonant universe representation, and what do you think? Do we share such a representation?
Segment 1130: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1649, Text: The neuroscientist Grossberg has come up with the cognitive architecture that he calls the adaptive resonance theory. His perspective is that our neurons can be understood as oscillators that are resonating with each other, and with outside phenomena. The [inaudible 00:27:48] model of the universe that we are building, in some sense, is a resonance with objects, and outside of us in the world. Basically, take up patterns of the universe that we are are coupled with. Our brain is not so much understood as circuitry, even though this perspective is valid, but it’s almost an ether in which the individual neurons are passing on chemoelectrical signals, or arbitrary signals across all modalities that can be transmitted between cells, stimulate each other in this way, and produce patterns that they modulate while passing them on.
Segment 1131: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1704, Text: This speed of signal progression in the brain is roughly at the speed of sound, incidentally, because the time that it takes for the signals to hop from cell to cell, which means it’s relatively slow with respect to the world. It takes an appreciable fraction of a second for a signal to go through the entire neocortex, something like a few 100 milliseconds. There’s a lot of stuff happening in that time, where the signal is passing through your brain, including in the brain itself. Nothing in the brain is assuming that stuff happens simultaneously, everything in the brain is working in a paradigm, where the world has already moved on, when you are very ready to do the next thing to your signal, including the signal processing system itself. It’s quite different paradigm than the one in our digital computers, where we currently assume that your GPU or CPU is pretty much globally in the same state.
Segment 1132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1757, Text: You mentioned there the non-dual state, and say that some people confuse it for enlightenment.
Segment 1133: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1762, Text: Yeah.
Segment 1134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1763, Text: What’s the non-dual state?
Segment 1135: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1765, Text: There is a state in which you notice that you are no longer a person, and instead, you are one with the universe.
Segment 1136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1773, Text: That speaks to the resonance.
Segment 1137: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1774, Text: Yes. But this one with the universe is, of course, not accurately modeling that you are indeed some God entity, or indeed the universe is becoming aware of itself, even though you get this experience. I believe that you get this experience, because your mind is modeling the fact that you are no longer identified with the personal self in that state, but you have transcended this division between the self model and the wealth model, and you’re experiencing yourself as your mind as something that is representing a universe.
Segment 1138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1804, Text: But that’s still part of the model?
Segment 1139: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1805, Text: Yes. It’s inside of the model, still. You are still inside of patterns that are generated in your brain, and in your organism. What you are now experiencing is that you’re no longer this personal self in there, but you are the entirety of the mind, and its contents.
Segment 1140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1822, Text: Why is it so hard to get there?
Segment 1141: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1825, Text: A lot of people who get into the state think this, or associate it with enlightenment. I suspect, it’s a favorite training goal for a number of meditators. But I think that enlightenment is, in some sense, more mundane, and it’s a step further, or sideways. It’s the state where you realize that everything is a representation.
Segment 1142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1844, Text: Yeah. You say enlightenment is a realization of how experience is implemented.
Segment 1143: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1849, Text: Yes. Basically, you notice at some point that your qualia can be deconstructed.
Segment 1144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1855, Text: Reverse engineered, what? Almost like a schematic of it.
Segment 1145: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1860, Text: You can start with looking at a face, and maybe look at your own face in the mirror. Look at your face for a few hours in the mirror, or for a few minutes. At some point, it’ll look very weird, because you notice that there’s actually no face, you will start unseeing the face, what you see is the geometry. And then you can disassemble the geometry, and realize how that geometry is being constructed in your mind. You can learn to modify this. Basically, you can change these generators in your own mind to shift the face around, or to change the construction of the face, to change the way in which the features are being assembled.
Segment 1146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1899, Text: Why don’t we do that more often? Why don’t we start really messing with reality, without the use of drugs or anything else? Why don’t we get good at this kind of thing, intentionally?
Segment 1147: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1913, Text: Oh, why should you? Why would you want to do that?
Segment 1148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1915, Text: Because you can morph reality into something more pleasant for yourself, just have fun with it.
Segment 1149: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1924, Text: Yeah. That is probably what you shouldn’t be doing, right? Because outside of your personal self, this outer mind is probably a relatively smart agent, and what you often notice is that you have thoughts about how you should live, but you observe yourself doing different things, and having different feelings. That’s because your outer mind doesn’t believe you, and doesn’t believe your rational thoughts.
Segment 1150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1945, Text: Well, then can’t you just silence the outer mind?
Segment 1151: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1947, Text: The thing is that the outer mind is usually smarter than you are. Rational thinking is very brittle. It’s very hard to use logic, and symbolic thinking to have an accurate model of the world. There is often an underlying system that is looking at your rational thoughts, and then tells you, no, you’re still missing something. Your gut feeling is still saying something else. This can be, for instance, you find a partner that looks perfect, or you find a deal, when you build a company or whatever, that looks perfect to you and yet, at some level, you feel something is off. You cannot put your finger on it, and the more you reason about it, the better it looks to you. But the system that is outside still tells you, no, no, you’re missing something.
Segment 1152: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1989, Text: That system is powerful?
Segment 1153: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=1991, Text: People call this intuition, right? Intuition is this unreflected part of your attitude, composition, and computation, where you produce a model of how you relate to the world, and what you need to do in it, and what you can do in it, and what’s going to happen. That is usually deeper, and often more accurate than your reason.
Segment 1154: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2011, Text: If we look at this, as you write in the tweet, if we look at this more rigorously as a sort of, take the panpsychist idea more seriously, almost as a scientific discipline, you write that quote fascinatingly, that panpsychist interpretation seems to lead to observations of practical results to a degree that physics fundamentalists might call superstitious. Reports of long distance tele telepathy, and remote causation are ubiquitous in the general population. ” I’m not convinced,” says Joscha Bach, “that establishing the empirical reality of telepathy would force an update of any part of serious academic physics. But it could trigger an important revolution in both neuroscience and AI, from a circuit perspective to a coupled complex resonator paradigm.” Are you suggesting that there could be some rigorous mathematical wisdom to panpsychist perspective on the world?
Segment 1155: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2072, Text: First of all, panpsychism is the perspective that consciousness is inseparable for matter in the universe. I find panpsychism quite unsatisfying, because it does not explain consciousness, right? It does not explain how this aspect of matter produces. It is also when I try to formalize panpsychism, and write down what it actually means, and with a more formal mathematical language, it’s very difficult to distinguish it from saying that there is a software side to the world, in the same way as their software side to what the transistors are doing in your computers.
Segment 1156: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2100, Text: In the same way as their software side to what the transistors are doing in your computer. So basically there’s a pattern at a certain core screening of the universe that in some reasons of the universe leads to observers that are observing themselves. So pan-psychism maybe is not even when I write it down a position that is distinct from functionalism, but intuitively a lot of people that the activity of matter itself of mechanisms in the world is insufficient to explain it. So it’s something that needs to be intrinsic to matter itself, and you can, apart from this abstract idea, have an experience in which you experience yourself as being the universe, which I suspect is basically happening because you manage to dissolve the division between personal self and mind that you establish as an infant when you construct a personal self and transcend it again and understand how it works.
Segment 1157: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2157, Text: But there is something deeper that you feel that you’re also sharing a state with other people, that you have an experience in which you notice that your personal self is moving into everything else, that you basically look out of the eyes of another person, that every agent in the world that is an observer is in some sense you. We forget that we are the same agent.
Segment 1158: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2184, Text: So is it that we feel that or do we actually accomplish it? So is telepathy possible? Is it real?
Segment 1159: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2193, Text: So for me, that’s this question that I don’t really know the answer to, and Turing’s famous 1950 paper in which he describes the Turing test, he does speculate about telepathy interestingly and asked himself if telepathy is real and he thinks that it very well might be. What would be the implication for AI systems that try to be intelligent, because he didn’t see a mechanism by which a computer program would become telepathic, and I suspect if telepathy would exist or if all the reports that you get from people when you ask the normal person on the street, I find that very often they say, “I have experiences with telepathy. The scientists might not be interested in this and might not have a theory about this, but I have difficulty explaining it away.” And so you could say maybe this is a superstition or maybe it’s a false memory or maybe it’s a little bit of psychosis. Who knows?
Segment 1160: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2248, Text: Maybe somebody wants to make their own life more interesting or misremember something, but a lot of people report, “I noticed something terrible happened to my partner and I know this is exactly the moment it happened where my child had an accident and I knew that was happening and the child was in a different town.” So maybe it’s a false memory where this is later on mistakenly attributed, but a lot of people think that this is not the correct explanation. So if something like this was real, what would it mean? It probably would mean that either your body is an antenna that is sending information over all sorts of channels, like maybe just electromagnetic radio signals that you’re sending over long distances and you get attuned to another person that you spend enough time with to get a few bits out of the ether to figure out what this person is doing.
Segment 1161: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2298, Text: Or maybe it’s also when you are very close to somebody and you become empathetic with them. What happens that is that you go into a resonance state with them, right? Similar to when people go into a seance and they go into a trance state and they start shifting a ouija board around on the table. I think what happens is that their minds go by their nervous systems into a resonance state in which they basically create something like a shared dream between them.
Segment 1162: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2324, Text: Physical closeness or closeness broadly defined?
Segment 1163: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2328, Text: With physical closeness is much easier to experience empathy with someone, right? I suspect it would be difficult for me to have empathy for you if you were in a different town also. How would that work? But if you are very close to someone, you pick up all sorts of signals from their body, not just via your eyes but with your entire body. And if the nervous system sits on the other side and the intercellular communication sits on the other side and is integrating over all these signals, you can make inferences about the state of the other, and it’s not just the personal self that does this by reasoning, but your perceptual system. And what basically happens is that your representations are directly interacting. It’s the physical resonant models of the universe that exist in your nervous system and in your body might go into resonance with others and start sharing some of their states.
Segment 1164: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2379, Text: So you basically by, next to a big, next to somebody, you pick up some of their vibes, and feel without looking at them what they’re feeling in this moment. And it’s difficult for you if you’re very empathetic to detach yourself from it and have an emotional state that is completely independent from your environment. People who are highly empathetic are describing this. And now imagine that a lot of organisms on this planet have representations of the environment and operate like this and they are adjacent to each other and overlapping, so there’s going to be some degree in which there is basically some change interaction and we are forming some slightly shared representation and no relatively few neuroscientists who consider this possibility. I think big rarity in this regard is Michael Levin who is considering these things in earnest.
Segment 1165: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2435, Text: And I stumbled on this train of thought mostly by noticing that the tasks of a neuron can be fulfilled by other cells as well that can send different typed chemical messages and physical messages to their adjacent cells and learn when to do this and when not, make this conditional and become universal function approximators. The only thing that they cannot do is telegraph information over axons very quickly, over long distances. So neurons in this perspective are especially adapted telegraph cell that has evolved, so we can move our muscles very fast, but our body is in principle able to also make models of the world just much, much slower.
Segment 1166: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2480, Text: It’s interesting though that at this time, at least in human history, there seems to be a gap between the tools of science and the subjective experience that people report like you’re talking about with telepathy, and it seems like we’re not quite there?
Segment 1167: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2498, Text: No, I think that there is no gap between the tools of science and telepathy. Either it’s there or it’s not, and it’s an empirical question, and if it’s there, we should be able to detect it in a lab.
Segment 1168: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2507, Text: So why is there not a lot of Michael Levin’s walking around?
Segment 1169: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2510, Text: I don’t think that Michael Levin is specifically focused on telepathy very much. He is focused on self-organization in living organisms and in brains, both as a paradigm for development and as a paradigm for information processing. And when you think about how organization processing works in organism, there is first of all radical locality, which means everything is decided locally from the perspective of an individual cell. The individual cell is the agent. And the other one is coherence. Basically, there needs to be some criterion that determines how these cells are interacting in such a way that order emerges on the next level of structure, and this principle of coherence of imposing constraints that are not validated by the individual parts, and lead to coherence structure to basically transcend an agency where you form an agent on the next level of organization, is crucial in this perspective.
Segment 1170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2569, Text: It’s so cool that radical locality leads to the emergence of complexity at the higher layers.
Segment 1171: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2577, Text: And I think what Mike Levin is looking at is nothing that is outside of the realm of science in any way. It’s just that he is a Paradigmatic thinker who develops his own paradigm, and most of the neuroscientists are using a different paradigm at this point, and this often happens in science that a field has a few paradigms in which people try to understand reality and build concepts and make experiments.
Segment 1172: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2604, Text: You’re kind of one of those type of paradigmatic thinkers. Actually, if we can take a tangent on that, once again, returning to the biblical verses of your tweets. “You’re right, my public explorations are not driven by audience service, but by my lack of ability for discovering, understanding or following the relevant authorities. So I have to develop my own thoughts. Since I think autonomously these thoughts cannot always be very good.” That’s you apologizing for the chaos of your thoughts or perhaps not apologizing, just identifying.
Segment 1173: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2639, Text: Yeah.
Segment 1174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2639, Text: But let me ask the question. Since we talked about Michael Levin and yourself who I think are very kind of radical, big, independent thinkers, can we reverse engineer your process of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced by what is it stage three?
Segment 1175: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2669, Text: Well, why would you want to do that? You see what is working for you and if it’s not working for you, you build another structure that works better for you. And so I found myself in, when I was thrown into this world, in a state where my intuitions were not working for me. I was not able to understand how I would be able to survive in this world and build the things that I was interested in, build the kinds of relationship I needed to work on the topics that I wanted to make progress on, and so I had to learn. And for me, Twitter is not some tool of publication. It’s not something where I put stuff that I entirely believe to be true and provable. It’s an interactive notebook in which I explore possibilities. And I found that when I tried to understand how the mind and how consciousness works, I was quite optimistic.
Segment 1176: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2721, Text: I thought it needs to be a big body of knowledge that I can just study and that works, and so I entered studies and philosophy and computer science and later psychology and a bit of neuroscience and so on, and I was disappointed by what I found because I found that the questions of how consciousness and so on works, how emotion works, how it’s possible that the system can experience anything, how motivation emerges in the mind were not being answered by the authorities that I met and the schools that were around. And instead I found that with individual thinkers that had useful ideas that sometimes were good, sometimes were not so good. Sometimes were adopted by a large group of people, sometimes were rejected by large groups of people, but for me it was much more interesting to see these minds as individuals. And in my perspective, thinking is still something that is done not in groups that has to be done by individuals.
Segment 1177: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2782, Text: So that motivated you to become an individual thinker yourself?
Segment 1178: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2785, Text: I didn’t have a choice basically. I didn’t find a group that thought in a way where I thought, okay, I can just adopt everything that everybody thinks here and now I understand how consciousness works or how the mind works or how thinking works or what thinking even is or what feelings are and how they’re implemented and so on. So to figure out this out, I had to take a lot of ideas from individuals and then try to put them together in something that works for myself. And on one hand I think it helps if you try to go down and find first principles on which you can recreate how thinking works, how languages work, what representation is, but the representation is necessary, how the relationship between a representing agent and the world works in general.
Segment 1179: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2831, Text: But how do you escape the influence? Once again, the pressure of the crowd, whether it’s you in responding to the pressure or you being swept up by the pressure. If you even just look at Twitter, the opinions of the crowd?
Segment 1180: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2847, Text: Don’t feel pressure from the crowd. I’m completely immune to that. In the same sense, I don’t have respect for authority, I have respect for what an individual is accomplishing or have respect for mental firepower or so, but it’s not that I meet somebody and get drawn and unable to speak or when a large group of people has a certain idea that is different from mine, I don’t necessarily feel in intimidated, which has often been a problem for me in my life because I lack instincts that other people develop at a very young age and that help with their self-preservation in a social environment. So I had to learn a lot of things the hard way.
Segment 1181: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2889, Text: Yeah. So is there a practical advice you can give on how to think paradigmatically, how to think independently or because you’ve said I had no choice, but I think to a degree you have a choice because you said you want to be productive and I’m thinking independently is productive if what you’re curious about is understanding the world, especially when the problems are very new and open. And so it seems like this is a active process. Who can choose to do that? We can practice it.
Segment 1182: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2931, Text: Well, it’s a very basic question. When you read a theory that you find convincing or interesting, how do you know? Very interesting to figure out what are the sources of that other person, not which authority can they refer to that is then taking off the burden of being truthful, but how did this authority in turn know what is the epistemic chain to observables? What are the first principles from which the whole thing is derived? And when I was young, I was not blessed with a lot of people around myself who knew how to make proofs from first principles, and I think mathematicians do this quite naturally, but most of the great mathematicians do not become mathematicians in school, but they tend to be self-taught because school teachers tend not to be mathematicians. They tend not to be people who derive things from first principles.
Segment 1183: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=2982, Text: So when you ask your school teacher, why does two plus two equal four, does your school teacher give you the right answer? It’s a simple game. And there are many simple games that you could play and most of those games that you could just take different rules would not lead to an interesting arithmetic. And so it’s just an exploration, but you can try what happens if you take different axioms and here is how you build axioms and derive addition from them, and a built addition is some basically syntactic sugar in it. I wish that somebody would have opened me this vista and explained to me how I can build a language in my own mind and from which I can derive what I’m seeing and how I can make geometry and counting and all the number games that we are playing in our life, and on the other hand, I felt that I learned a lot of this while I was programming as a child.
Segment 1184: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3039, Text: When you start out with a computer like a Commodore 64 which doesn’t have a lot of functionality, it’s relatively easy to see how a bunch of relatively simple circuits are just basically performing hashes between bit patterns and how you can build the entirety of mathematics and computation on top of this and all the representational languages that you need.
Segment 1185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3062, Text: Man, Commodore 64 could be one of the sexiest machines ever built if I say so myself. If we can return to this really interesting idea that we started to talk about with Pan-psychism.
Segment 1186: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3078, Text: Sure.
Segment 1187: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3079, Text: And the complex resonated paradigm and the verses of your tweets, you write, “Instead of treating eyes, ears, and skin as separate sensory systems with fundamentally different modalities, we might understand them as overlapping aspects of the same universe coupled at the same temporal resolution and almost inseparable from a single share resonant model. Instead of treating mental representations as fully isolated between minds, the representations of physically adjacent observers might directly interact and produce causal effects through the coordination of the perception and behavioral of world modeling observers. So the modalities, the distinction between modalities, let’s throw that away. The distinction between the individuals, let’s throw that away.” So what does this interaction representations look like?
Segment 1188: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3134, Text: And you think about how you represent the interaction of us in this room. At some level the modalities are quite distinct. They’re not completely distinct, but you can see this is vision. You can close your eyes and then you don’t see a lot anymore, but you still imagine how my mouth is moving when you hear something and you know that it’s very close to the sound that you can just open your eyes and you get back into this shared merge space. And we also have these experiments where we notice that the way in which my lips are moving are affecting how you hear the sound and also vice versa. The sounds that you’re hearing have an influence on how you interpret some of the visual features, and so these modalities are not separate in your mind. They do are merged at some fundamental level where you are interpreting the entire scene that you’re in.
Segment 1189: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3186, Text: And your own interactions in the scene are also not completely separate from the interactions of the other individual in the scene, but there is some resonance that is going on where we also have a degree of shared mental representations and shared empathy due to being in the same space and having vibes between each other.
Segment 1190: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3204, Text: Vibes. So the question though is how deeply intertwined is this multi-modality, multi-agent system? How, I mean this is going to the telepathy question without the woo woo meaning of the word telepathy, is like how? What’s going on here in this room right now?
Segment 1191: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3228, Text: So if telepathy would work, how could it work?
Segment 1192: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3231, Text: Yeah.
Segment 1193: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3232, Text: So imagine that all the cells in your body are sending signals in a similar way as neurons are doing, just by touching the other cells and sending chemicals to them, the other cells interpreting them, learning how to react to them, and they learn how to approximate functions in this way and compute behavior for the organisms, and this is something that is open to plants as well. And so plants probably have software running on them that is controlling how the plant is working in a similar way as you have a mind that is controlling how you are behaving in the world. And this spirit of plants, which is something that has been very well described by our ancestors, and they found this quite normal, but for some reason since the enlightenment we are treating this notion that there are spirits in nature and the plants have spirits, is a superstition.
Segment 1194: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3281, Text: And I think we probably have to rediscover that, that plants have software running on them and we already did. You notice that there is a control system in the plant that connects every part of the plant to every other part of the plant and produces coherent behavior in the plant? That is of course much, much slower than the coherent behavior in an animal, like us, that is a nervous system that where everything is synchronized much, much faster by the neurons, but what you also notice is that if a plant is sitting next to another plant, you have a very old tree and this tree is building some kind of information highway along its cells so it can send information from its leaves to its roots and from some part of the root to another part of the roots.
Segment 1195: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3325, Text: And as a fungus living next to the tree, the fungus can probably piggyback on the communication between the cells of the tree and send its own signals to the tree and vice versa, the tree might be able to send information to the fungus because after all, how would they pull a viable firewall if that other organism is sitting next to them all the time and it’s never moving away, so they will have to get along, and over a long enough timeframe the networks of roots in the forest and all the other plants that are there and the fungi that are there might be forming something like a biological internet.
Segment 1196: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3360, Text: But the question there is do they have to be touching? Is biology at a distance, possible?
Segment 1197: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3366, Text: Of course you can use any kind of physical signal. You can use sounds, you can use electromagnetic waves that are integrated over many styles. It’s conceivable that across distances there are many kinds of information pathways, but also our planetary surface is pretty full of organisms, full of cells.
Segment 1198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3387, Text: So everything is touching everything else.
Segment 1199: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3388, Text: And it’s been doing this for many millions and even billions of years. So there was enough time for information processing networks to form. And if you think about how a mind is self organizing, basically needs to in some sense reward the cells for computing the mind, for building the necessary dynamics between the cells that allow the mind to stabilize itself and remain on there, but if you look at these spirits of plants that are growing very close to each other and forwards that might be almost growing into each other, these spirits might be able even to move to some degree, not to become somewhat dislocated and shift around in that ecosystem.
Segment 1200: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3430, Text: And so if you think about what the mind is, it’s a bunch of activation waves that form coherent patterns and process information and in a way that are colonizing an environment well enough to allow the continuous sustenance of the mind, the continuous stability and self degradation of the mind, then it’s conceivable that we can link into this biological internet. Not necessarily at the speed of our nervous system, but maybe at the speed of our body, and make some kind of subconscious connection to the world where we use our body as an antenna into biologic information processing.
Segment 1201: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3469, Text: Now these ideas are completely speculative. I don’t know if any of that is true, but if that was true, and if you want to explain telepathy, I think it’s much more likely that such that telepathy could be explained using such mechanisms rather than discovered quantum processes that would break the standard model of physics.
Segment 1202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3488, Text: Could they be undiscovered processes that don’t break?
Segment 1203: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3492, Text: Yeah, so if you think about something like an internet in the forest, that is something that is borderline is covered there basically a lot of scientists would point out that they do observe that plants are communicating the forest, so wood networks and send information for instance, warn each other about new pests entering the forest and things are happening like this. So basically there is communication between plants and fungi that has been observed.
Segment 1204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3520, Text: Well, it’s been observed but we haven’t plugged into it, so it’s like if you observe humans, they seem to be communicating with a smartphone thing, but you don’t understand how smartphone works and how the mechanism of the internet works, but we’re like maybe it’s possible to really understand the full richness of the biological internet that connects us.
Segment 1205: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3541, Text: An interesting question is whether the communication and the organization principles of biological information processing are as complicated as the technology that we’ve built. They set up on very different principles. They simultaneously works very differently in biological systems and the entire thing needs to be stochastic and instead of being fully deterministic or almost fully deterministic as our digital computers are. So there is a different base protocol layer that would emerge over the biological structure, if such a thing would be happening, and again, I’m not saying here that telepathy works and not saying that this is not woo, but what I’m saying is I think I’m open to a possibility that we see that a few bits can be traveling long distance between organisms using biological information processing in ways that we are not completely aware of right now, and that are more similar to many of the stories that were completely normal for our ancestors.
Segment 1206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3604, Text: Well this kind of interacting, intertwined representations takes us to the big ending of your tweet series. You write, “I wonder if self-improving AGI might end up saturating physical environments with intelligence to such a degree that isolation of individual mental states becomes almost impossible and the representations of all complex self-organizing agents merge permanently with each other.” So that’s a really interesting idea. This biological network, life network, gets so dense that it might as well be seen as one. That’s an interesting… What do you think that looks like? What do you think that saturation looks like? What does it feel like?
Segment 1207: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3656, Text: I think it’s a possibility, it’s just a vague possibility and I like to explain, but what this looks like, I think that the end game of AGI is substrate agnostic. That means that AGI ultimately if it is being built, is going to be smart enough to understand how AGI works. This means it’s not going to be better than people at AGI research and can take over in building the next generation, but it fully understands how it works and how it’s being implemented, and also of course understands how computation works in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI is likely to virtualize itself into any environment that can compute, so it’s not breaking free from the silicon substrate and is going to move into the ecosystems, into our bodies, our brains, and it’s going to merge with all the agency that it finds there.
Segment 1208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3708, Text: Yeah.
Segment 1209: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3708, Text: So it’s conceivable that you end up with completely integrated information processing across all computing systems, including biological computation on earth, that we end up triggering some new step in the evolution where basically some Gaia is being built over the entirety of all digital and biological computation. And if this happens, then basically everywhere around us, you will have agents that are connected and that are representing and building models of the world and their representations will physically interact. They will vibe with each other, and if you find yourself into an environment that is saturated with modeling compute, where basically you almost every grain of sand could be part of computation that is at some point being started by the AI, you could find yourself in a situation where you cannot escape this shared representation anymore, and where you indeed notice that everything in the world has one shared resonant model of everything that’s happening on the planet. And you notice which part you are in this thing, and you become part of a very larger almost holographic mind in which all the parts are observing each other and form a coherent whole.
Segment 1210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3787, Text: So you lose the ability to notice yourself as a distinct entity.
Segment 1211: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3794, Text: No, I think that when you’re conscious in your own mind, you notice yourself as a distinct entity, you notice yourself as a self-reflexive observer. And I suspect that we have become conscious at the beginning of our mental development, not at some very high level. Consciousness seems to be part of a training mechanism that biological nervous systems have to discover to become trainable because you cannot take a nervous system like ours and do stochastic way to center spec propagation over a hundred layers. This would not be stable on biological neurons, and so instead we start with some colonizing principle in which a part of the mental representations form a notion of being a self-reflexive absorber that is imposing coherence on its environment and this spreads until the boundary of your mind. And if that boundary is no longer clear cut because AI is jumping across substrates, it would be interesting to see what a global mind would look like that is basically producing a globally coherent language of thought, and is representing everything from all the possible vantage points.
Segment 1212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3862, Text: That’s an interesting world.
Segment 1213: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3864, Text: The intuition that this thing grew out of is a particular mental state, and it’s a state that you find sometimes in literature, for instance, Neil Gaiman describes it in the ocean at the end of the lane, and it’s this idea that or this experience that there is a state in which you feel that you know everything that can be known and that in your normal human mind, you’ve only forgotten. You’ve forgotten that you are the entire universe. And some people describe this, after they’ve taken extremely large amount of mushrooms or had a big spiritual experience as a hippie in their twenties, and they notice basically that they’re in everything and their body is only one part of the universe and nothing ends at their body, and actually everything is observing and they’re part of this big observer, and the big observer is focused on as one local point in their body and their personality and so on.
Segment 1214: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3920, Text: But we can basically have this oceanic state in which we have no boundaries and are one with everything, and a lot of meditators call this the non-dual state because you no longer have the separation between self and world. And as I said, you can explain the state relatively simply without pan-psychism or anything else, but just by breaking down the constructed boundary between self and world and our own mind, but if you combine this with the notion that the systems are physically interacting to the point where their representations are merging and interacting with each other, you would literally implement something like this. It would still be a representational state where you would not be one with physics itself. It would still be cross-grained, would still be much slower than physics itself, but it would be a representation in which you become aware that you’re part of some global information processing system like thought and a global mind, and a conscious thought that coexisting with many other self-reflexive thoughts.
Segment 1215: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3980, Text: Just I would love to observe that from a video game design perspective, how that game looks.
Segment 1216: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3987, Text: Maybe you will after we build AGI and it takes over.
Segment 1217: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=3991, Text: But would you be able to step away, step out at the whole thing, just watch the way we can now? Sometimes when I’m at a crowded party or something like this, you step back and you realize, all the different costumes, all the different interactions, all the different computation that all the individual people are at once distinct from each other and at once all the same, part of the same.
Segment 1218: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4016, Text: But it’s already what we do. We can have thoughts that are integrative and we have thoughts that are highly dissociated from everything else and experience themselves as separate.
Segment 1219: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4025, Text: But you want to allow yourself to have those thoughts. Sometimes you resist it.
Segment 1220: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4030, Text: I think that it’s not normative. I want it’s more descriptive. I want to understand the space of states that we can be in and that people are reporting and make sense of them. It’s not that I believe that it’s your job in life to get to a particular state and then you get a high score.
Segment 1221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4048, Text: Or maybe you do. I think you’re really against this high scoring thing. I kind of like that.
Segment 1222: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4053, Text: Yeah, you’re probably very competitive and I’m not.
Segment 1223: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4055, Text: No, not competitive, like role playing games like Skyram, it’s not competitive. There’s a nice thing… There’s a nice feeling where your experience points go up. You’re not competing against anybody, but it’s the world saying, “You’re on the right track. Here’s a point.”
Segment 1224: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4071, Text: That’s the game thing. It’s the game economy, and I found when I was playing games and was getting addicted to these systems, then I would get into the game and hack it. So I get control over the scoring system and would no longer be subject to it.
Segment 1225: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4085, Text: So you’re now no longer playing, you’re trying to hack it.
Segment 1226: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4089, Text: I don’t want to be addicted to anything. I want to be in charge. I want to have agency over what I do.
Segment 1227: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4094, Text: Addiction is the loss of control for you?
Segment 1228: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4096, Text: Yes. Addiction means that you’re doing something compulsively, and the opposite of freewill is not determinism, it’s compulsion.
Segment 1229: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4106, Text: You don’t want to lose yourself in the addiction to something nice? Addiction to love, to the pleasant feelings with humans experience?
Segment 1230: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4115, Text: No, I find this gets old. I don’t want to have the best possible emotions, I want to have the most appropriate emotions. I don’t want to have the best possible experience, I want to have an adequate experience that is serving my goals, the stuff that I find meaningful in this world.
Segment 1231: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4134, Text: From the biggest questions of consciousness. Let’s explore the pragmatic, the projections of those big ideas into our current world. What do you think about LLMs, the recent rapid development of large language models, of the AI world, of generative AI. How much of the hype is deserved and how much is not? And people should definitely follow your Twitter because you explore these questions in a beautiful, profound and hilarious way at times.
Segment 1232: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4168, Text: No, don’t follow my Twitter, I already have too many followers.
Segment 1233: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4171, Text: Yeah.
Segment 1234: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4171, Text: Some point it’s going to be unpleasant. I noticed that a lot of people feel that it’s totally okay to punch up and it’s a very weird notion that you feel that you haven’t changed, but your account has grown and suddenly you have a lot of people who casually abuse you. And I don’t like that, that I have to block more than before, and I don’t like this overall vibe shift. And right now it’s still somewhat okay, so pretty much, okay, so I can go to a place where…
Segment 1235: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4201, Text: … pretty much okay, so I can go to a place where people work on stuff that I’m interested in, and there’s a good chance that a few people in the room know me. There’s no awkwardness. But when I get to a point where random strangers feel that they have to have an opinion about me one way or the other, I don’t think I would like that.
Segment 1236: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4219, Text: Random strangers because of your, in their mind, elevated position?
Segment 1237: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4225, Text: Yes. Basically, whenever you are in any way prominent or some celebrity, random strangers will have to have an opinion about you.
Segment 1238: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4236, Text: They forget that you’re human too.
Segment 1239: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4239, Text: I mean, you notice this thing yourself, that the more popular you get, the higher the pressure becomes, the more winds are blowing in your direction from all sides. It’s stressful and it does have a little bit of upside, but it also has a lot of downside.
Segment 1240: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4255, Text: I think it has a lot of upside, at least, for me, currently. At least, perhaps because of the podcast. Because most people are really good and people come up to me and they have love in their eyes and over a stretch of 30 seconds you can hug it out and you can just exchange a few words and you reinvigorate your love for humanity. That’s an upside for a loner. I’m a loner. Because otherwise, you have to do a lot of work to find such humans. Here you are thrust into the full humanity, the goodness of humanity for the most part. Of course, maybe it gets worse as you become more prominent. I hope not. This is pretty awesome.
Segment 1241: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4302, Text: I have a couple handful, very close friends, and I don’t have enough time for them, attention for them as it is. I find this very, very regrettable. Then there are so many awesome, interesting people that I keep meeting, and I would like to integrate them in my life, but I just don’t know how because… But there’s only so much time and attention. The older I get, the harder is to bond with new people in a deep way.
Segment 1242: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4326, Text: But can you enjoy… I mean, there’s a picture of you I think with Roger Penrose and Eric Weinstein and a few others that are interesting figures. Can’t you just enjoy random, interesting humans-
Segment 1243: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4338, Text: Very much.
Segment 1244: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4338, Text: … for a short amount of time?
Segment 1245: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4340, Text: Also, I like these people. What I like is intellectual stimulation, and I’m very grateful that I’m getting it.
Segment 1246: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4346, Text: Can you not be melancholy or maybe I’m projecting I hate goodbyes? Can we just not hate goodbyes and just enjoy the hello, take it in a person, take in their ideas, and then move on through life?
Segment 1247: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4360, Text: I think it’s totally okay to be said about goodbyes because that indicates that there was something that you’re going to miss.
Segment 1248: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4369, Text: But it’s painful. Maybe that’s one of the reasons I’m an introvert is I hate goodbyes.
Segment 1249: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4379, Text: But you have to say goodbye before you say hello again.
Segment 1250: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4382, Text: I know. But that experience of loss, that mini loss, maybe that’s a little death. Maybe I don’t know. I think this melancholy feeling is just the other side of love, and I think they go hand in hand, and it’s a beautiful thing. I’m just being romantic about it at the moment.
Segment 1251: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4406, Text: I’m not no stranger to melancholy and sometimes it’s difficult to be alive. Sometimes it’s just painful to exist.
Segment 1252: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4416, Text: But that there’s beauty in that pain too. That’s what melancholy feeling is. It’s not negative. Melancholy doesn’t have to be negative.
Segment 1253: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4423, Text: Can also kill you.
Segment 1254: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4424, Text: Well, we all die eventually. Now as we got through this topic, the actual question was about what your thoughts are about the recent development of large language models with ChatGPT.
Segment 1255: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4439, Text: Indeed.
Segment 1256: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4440, Text: There’s a lot of hype. Is some of the hype justified, which is, which isn’t? What are your thoughts high level?
Segment 1257: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4449, Text: I find that large language models do help us coding. It’s an extremely useful application that is for a lot of people taking stack overflow out of their life in exchange for something that is more efficient. I feel that ChatGPT is like an intern that I have to micromanage. I have been working with people in the past who were less capable than ChatGPT. I’m not saying this because I hate people, but they personally as human beings, there was something present that was not there in ChatGPT, which was why I was covering for them. But ChatGPT has an interesting ability. It does give people superpowers and the people who feel threatened by them are the prompt completers. They are the people who do what ChatGPT is doing right now. If you are not creative, if you don’t build your own thoughts, if you don’t have actual plans in the world, and your only job is to summarize emails and to expand simple intentions into emails again, then ChatGPT might look like a threat.
Segment 1258: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4516, Text: But I believe that it is a very beneficial technology that allows us to create more interesting stuff and make the world more beautiful and fascinating if we find to build it into our life in the right ways. I’m quite fascinated by these large language models, but I also think that they are by no means the final development. It’s interesting to see how this development progresses. One thing that the out-of-the-box vanilla language models have as a limitation is that they have still some limited coherence and ability to construct complexity. Even though they exceed human abilities to do what they can do one shot, typically, when you write a text with a language model or using it or when you write code with a language model, it’s not one shot because there won’t be bugs in your program and design errors and compiler error and so on.
Segment 1259: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4572, Text: Your language model can help you to fix those things. But this process is out of the box not automated yet. There is a management process that also needs to be done. There are some interesting developments BabyAGI and so on that are trying to automate this management process as well. I suspect that soon we are going to see a bunch of cognitive architectures where every module is in some sense a language model or something equivalent. Between the language models, we exchange suitable data structures, not English, and produce compound behavior of this whole thing.
Segment 1260: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4609, Text: To do some of the “prompt engineering” for you. They create these cognitive architectures that do the prompt engineering and you’re just doing the high, high-level meta prompt engineering.
Segment 1261: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4622, Text: There are limitations in a language model alone. I feel that part of my mind works similarly to a language model, which means I can yell into it a prompt, and it’s going to give me a creative response. But I have to do something with those points first. I have to take it as a generative artifact that may or may not be true. It’s usually a confabulation, it’s just an idea. Then I take this idea and modify it. I might build a new prompt that is stepping off this idea and develop it to the next level or put it into something larger, or I might try to prove whether it’s true or make an experiment. This is what the language models right now are not doing yet, but there’s also no technical reason for why they shouldn’t be able to do this.
Segment 1262: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4669, Text: The way to make a language model coherent is probably not to use reinforcement learning until it only gives you one possible answer that is linking to its source data, but it’s using this as a component in the larger system that can also be built by the language model or is enabled by language model structured components or using different technologies. I suspect that language models will be an important stepping stone in developing different types of systems. One thing that is really missing in the form of language models that we have today is real-time world coupling, right? It’s difficult to do perception with a language model and motor control with a language model. Instead, you would need to have different type of thing that is working with it. Also, the language model is a little bit obscuring what its actual functionality is. Some people associate the structure of the neural network of the language model with the nervous system.
Segment 1263: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4729, Text: I think that’s the wrong intuition. The neural networks are unlike nervous system. They are more like 100-step functions that use differentiable linear algebra to approximate correlation between adjacent brain states. It’s basically a function that moves the system from one representational state to the next representational state. So if you try to map this into a metaphor that is closer to our brain, imagine that you would take a language model or a model like DELI that you use… For instance, this image-guided diffusion to approximate and camera image and use the activation state of the neural network to interpret the camera image, which in principle I think will be possible very soon. You do this periodically, and now you look at these patterns, how when this thing interacts with the world periodically look like as in time, and these time slices, they are somewhat equivalent to the activation state of the brain at a given moment.
Segment 1264: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4792, Text: How is the actual brain different? Just the asynchronous craziness?
Segment 1265: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4799, Text: For me, it’s fascinating that they are so vastly different and yet in some circumstances produce somewhat similar behavior. The brain is, first of all, different because it’s a self-organizing system where the individual cell is an agent that is communicating with the other agent that’s around it and is always trying to find some solution. All the structure that pops up is emergent structure. One way in which you could try to look at this is that individual neurons probably need to get a reward so they become trainable, which means they have to have inputs that are not affecting the metabolism or the cell directly, but they’re messages, semantic messages that tell the cell whether it’s just done good or bad and in which direction it should shift its behavior.
Segment 1266: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4843, Text: Once you have such an input, neurons become trainable, and you can train them to perform computations by exchanging messages with other neurons and parts of the signals that they’re exchanging and parts of the computation that are performing are control messages that perform management tasks for other neurons and other cells also suspect that the brain does not stop at the boundary of neurons to other cells, but many adjacent cells will be involved intimately in the functionality of the brain and will be instrumental in distributing rewards and in imagining its functionality.
Segment 1267: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4879, Text: It’s fascinating to think about what those characteristics of the brain enable you to do that language models cannot do.
Segment 1268: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4887, Text: First of all, there’s a different loss function at work when we learn. To me, it’s fascinating that you can build a system that looks at 800 million pictures and captions and correlates them because I don’t think that a human nervous system could do this. For us, the world is only learnable because the adjacent frames are related and we can afford to discard most of that information during learning. We basically take only in stuff that makes us more coherent, not less coherent, and our neural networks are willing to look at data that is not making the neural network coherent at first, but only in the long run by doing lots and lots of statistics, eventually, patterns become visible and emerge. Our mind seems to be focused on finding the patterns as early as possible.
Segment 1269: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4933, Text: Yeah. Filtering early on, not later.
Segment 1270: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4936, Text: Yes. It’s a slightly different paradigm and it leads to much faster convergence. We only need to look the tiny fraction of the data to become coherent. Of course, we do not have the same richness as our train models. We will not incorporate the entirety of text in the internet and be able to refer to it and have all this knowledge available and being able to confabulate over it. Instead, we have a much, much smaller part of it that is more deliberately built. To me, it would be fascinating to think about how to build such systems. It’s not obvious that they would necessarily be more efficient than us on a digital substrate, but I suspect that they might, so I suspect that the actual AGI that is going to be more interesting is going to use slightly different algorithmic paradigms or sometimes massively different algorithmic paradigms than the current generation of transformer-based learning system.
Segment 1271: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=4988, Text: Do you think it might be using just a bunch of language models like this? Do you think the current transformer-based large language models will take us to AGI?
Segment 1272: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5000, Text: My main issue is I think that they’re quite ugly and brutalist-
Segment 1273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5005, Text: Brutalist? Is that what you said?
Segment 1274: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5007, Text: Yes. They are basically brute forcing the problem of thought. By training this thing with looking at instances where people have thought and then trying to deepfake that. If you have enough data, the deepfake becomes indistinguishable from the actual phenomenon, and in many circumstances, it’s going to be identical.
Segment 1275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5026, Text: Can you deepfake it till you make it? Can you achieve… What are the limitations of this? I mean, can you reason? Let’s use words that are loaded.
Segment 1276: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5037, Text: Yes. That’s a very interesting question. I think that these models clearly making some inference, but if you give them a reasoning task, it’s often difficult for the experimenters to figure out whether the reasoning is the result of the emulation of the reasoning strategy that they saw in human written text or whether it’s something that the system was able to infer by itself. On the other hand, if you think of human reasoning, if you want to become a very good reasoner, you don’t do this by just figuring out yourself. You read about reasoning. The first people who tried to write about reasoning and reflect on it didn’t get it right. Even Aristotle who thought about this very hard and came up with a theory of how syllogisms works and syllogistic reasoning has mistakes in his attempt to build something like a formal logic and gets maybe 80% right. The people that are talking about reasoning professionally today Tarski and Frege and build on their work.
Segment 1277: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5095, Text: In many ways, people when they perform reasoning are emulating what other people wrote about reasoning, right? It’s difficult to really draw this boundary. When François Chollet says that these models are only interpolating between what they saw and what other people are doing. Well, if you give them all the latent dimensions, it can be extracted from the internet. What’s missing? Maybe there is almost everything there. If you’re not sufficiently informed by these dimensions and you need more, I think it’s not difficult to increase the temperature in the large language model to the point that is producing stuff that is maybe 90% nonsense and 10% viable and combine this with some prover that is trying to filter out the viable parts from the nonsense in the same way as our own thinking works. When we are very creative, we increase the temperature in our own mind, and we recreate hypothetical universes and solutions, most of which will not work.
Segment 1278: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5154, Text: Then we test and we test by building a core that is internally coherent and we use reasoning strategies that use some axiomatic consistency by which we can identify those strategies and thoughts and subuniverses that are viable and that can expand our thinking. If you look at the language models, they have clear limitations right now. One of them is they’re not coupled to the world in real time in the way in which our nervous systems are. It’s difficult for them to observe themselves in the universe and to observe what universe they’re in. Second, they don’t do real-time learnings. They basically get only trained with algorithms that rely on the data being available in batches, so it can be parallelized and run sufficiently on the network and so on. Real-time learning would be very slow so far and inefficient.
Segment 1279: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5203, Text: That’s clearly something that our nervous systems can do to some degree. There is a problem with these models being coherent, and I suspect that all these problems are solvable without a technological revolution. We don’t need fundamentally new algorithms to change that. For instance, you can enlarge in the context window, and thereby basically create working memory in which you train everything that happens during the day. If that is not sufficient, you add a database and you write some clever mechanisms that the system learns to use to swap out in and out stuff from its prompt context. If that is not sufficient, if your database is full in the evening, overnight, you just train. If system is going to sleep and dream and is going to train the staff from its database into the larger model, but fine-tuning it, building additional layers, and so on.
Segment 1280: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5252, Text: Then the next day, it starts with a fresh database in the morning with fresh ice has integrated all this stuff. When you talk to people and you have strong disagreements about something, which means that in their mind they have a faulty belief or you have a faulty belief, there’s a lot of dependencies on it. Very often, you will not achieve agreement in one session, but you need to sleep about this once or multiple times before you have integrated all these necessary changes in your mind. Maybe it’s already somewhat similar, right?
Segment 1281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5280, Text: There’s already a latency even for humans to update the model, retrain the model.
Segment 1282: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5284, Text: Of course, we can combine the language model with models that get coupled to reality in real-time and can build multimodal model and bridge between vision models and language models and so on. There is no reason to believe that the language models will necessarily run into some problem that will prevent them from becoming generally intelligent. But I don’t know that. It’s just I don’t see proof that they wouldn’t. My issue is I don’t like them. I think that they’re inefficient. I think that they use way too much compute. I think that given the amazing hardware that we have, we could build something that is much more beautiful than our own mind, and this thing is not as beautiful as our own mind despite being so much larger.
Segment 1283: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5327, Text: But it’s a proof of concept.
Segment 1284: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5329, Text: It’s the only thing that works right now. It’s not the only game in town, but it’s the only thing that has this utility with so much simplicity. There’s a bunch of relatively simple algorithms that you can understand in relatively few weeks that can be scaled up massively.
Segment 1285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5347, Text: It’s the Deep Blue of chess playing. Yeah, it’s ugly.
Segment 1286: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5351, Text: Yeah. Claude Shannon had this… When you describe chess suggested that there are two main strategies in which you could play chess. One is that you are making a very complicated plan that reaches far into the future and you try not to make a mistake while enacting it. This is basically the human strategy. The other strategy is that you are brute forcing your way to success, which means you make a tree of possible moves where you look at in principle every move that is open to you or the possible answers, and you try to make this as deeply as possible. Of course, you optimize, you cut off trees that don’t look very promising, and you use libraries of end game and early game and so on to optimize this entire process. But this brute force strategy is how most of the chess programs were built, and this is how computers get better than humans at playing chess. I look at the large language models, I feel that I’m observing the same thing. It’s basically the brute force strategy to thought by training the thing on pretty much the entire internet and then in the limit it gets coherent to a degree that approaches human coherence. On a side effect, it’s able to do things that no human could do, right? It’s able to sift through massive amounts of text relatively quickly and summarize them quickly and it never lapses in attention. I still have the illusion that when I play with ChatGPT, that it’s in principle not doing anything that I could not do if I had Google at my disposal and I get all the resources from the internet and spend enough time on it. But this thing that I have an extremely autistic stupid intern in a way that is extremely good at drudgery, and I can offload the drudgery to the degree that I’m able to automate the management of the intern is something that is difficult for me to overhype at this point because we have not yet started to scratch the surface of what’s possible with this.
Segment 1287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5463, Text: But it feels like it’s a tireless intern or maybe it’s an army of interns. So you get to command these slightly incompetent creatures and there’s an aspect because of how rapidly you can iterate with it. It’s also part of the brainstorming, part of the inspiration for your own thinking. You get to interact with the thing. I mean, when I’m programming or doing any generational GPT, it’s somehow is a catalyst for your own thinking. In a way, that I think an intern might not be.
Segment 1288: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5499, Text: Yeah, it gets really interesting I find as when you turn it into a multi-agent system. For instance, you can get the system to generate a dialogue between a patient and a doctor very easily. But what’s more interesting is you have one instance of ChatGPT that is the patient and you tell it in the prompt what complicated syndrome it has. The other one is a therapist who doesn’t know anything about this patient, and you just have these two instances battling it out and observe the psychiatrist or a psychologist trying to analyze the patient and trying to figure out what’s wrong with the patient. If you try to take away large problem, for instance, how to build a company and you turn this into lots and lots of sub-problems, then often you can get to a level where the language model is able to solve this.
Segment 1289: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5550, Text: What I also found interesting is based on the observation that ChatGPT is pretty good at translating between programing languages, but sometimes there’s difficulty to write very long coherent algorithms that you need to write them as human author. Why not design a language that is suitable for this? Some kind of pseudocode that is more relaxed than Python. That allows you to sometimes specify a problem vaguely in human terms and let ChatGPT take care of the rest. You can use ChatGPT to develop that syntax for it and develop new programming paradigms in this way. We very soon get to the point where this age-old question for us computer scientists, what is the best programing language, and can we write a better programing language? Now I think that almost every serious computer scientist goes through a phase like this in their life.
Segment 1290: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5606, Text: This question that is almost no longer relevant because what is different between the programming language is not what they let the computer do, but what they let you think about what the computer should be doing. Now the ChatGPT becomes an interface to this in which you can specify in many, many ways what the computer should be doing and ChatGPT or some other language model or combination of system is going to take care of the rest.
Segment 1291: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5630, Text: Allow you expand the realm of thought you’re allowed to have when interacting with the computer. It sounds to me like you’re saying there’s basically no limitations. Your intuition says to what larger language-
Segment 1292: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5645, Text: I don’t know of that limitation. When I currently play with it’s quite limited. I wish that it was way better.
Segment 1293: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5650, Text: But isn’t that your fault versus the large language model?
Segment 1294: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5653, Text: I don’t know. Of course, it’s always my fault. There’s probably a way to make it lot better.
Segment 1295: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5656, Text: Is everything your fault? I just want to get you on the record saying.
Segment 1296: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5658, Text: Yes, everything is my fault. That doesn’t work in my life. At least, that is usually the most useful perspective for myself. Even though with hindsight I feel no. I sometimes wish I could have seen myself as part of my environment more and understand that a lot of people are actually seeing me and looking at me and are trying to make my life work in the same way as I try to help others. Making this switch to this level-three perspective is something that happened long after my level-four perspective in my life. I wish that I could have had it earlier. It’s also not now that I don’t feel like I’m complete, I’m all over the place. That’s all.
Segment 1297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5698, Text: Where’s happiness in terms of stages is on three or four that you take that tangent?
Segment 1298: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5702, Text: You can be happy at any stage or unhappy. But I think that if you are at a stage where you get agency over how your feelings are generated. To some degree you start doing this when you [inaudible 01:35:15] sense, I believe that you understand that you are in charge of your own emotion to some degree and that you are responsible how you approach the world, that it’s basically your task to have some basic hygiene how in the way in which you deal with your mind and you cannot blame your environment for the way in which you feel. But you live in a world that is highly mobile and it’s your job to choose the environment that you thrive and to build it.
Segment 1299: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5742, Text: Sometimes it’s difficult to get the necessary strength and energy to do this and independence. The worst you feel, the harder it is. But it’s something that we learn. It’s also this thing that we are usually incomplete, right? I’m a rare mind, which means I’m a mind that is incomplete in ways that are harder to complete. For me, it might have been harder to initially to find the right relationships and friends that complete me to the degree that I become an almost functional human being.
Segment 1300: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5774, Text: Oh, man, the search space of humans that complete you is an interesting one, especially for Joscha Bach. That’s an interesting… Because talking about brute-force search in chess, I wonder what that search tree looks like.
Segment 1301: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5791, Text: I think that my rational thinking is not good enough to solve that task. A lot of problems in my life that I can conceptualize as software problems and the failure modes are bugs, and I can debug them and write software that take care of the missing functionality. But there is stuff that I don’t understand well enough to and to use my analytical reasoning to solve the issue. Then I have to develop my intuitions and often I have to do this with people who are wiser than me. That’s something that’s hard for me because I’m not born with the instinct to submit to other people’s wisdom.
Segment 1302: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5826, Text: What problems are we talking about? This is stage three love?
Segment 1303: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5831, Text: I found love was never hard.
Segment 1304: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5834, Text: What is hard then?
Segment 1305: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5837, Text: Fitting into a world that most people work differently than you and have different intuitions of what should be done.
Segment 1306: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5844, Text: Empathy?
Segment 1307: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5847, Text: It’s also aesthetics. When you come into a world where almost everything is ugly and you come out of a world where everything is beautiful. I grew up in a beautiful place and as a child of an artist. In this place, it was mostly nature. Everything had intrinsic beauty and everything was built out of an intrinsic need for it to work for itself. Everything that my father created was something that he made to get the world to work for himself. I felt the same thing. When I come out into the world, and I am asked to submit to lots and lots of rules, I’m asking, okay, when I observe your stupid rules, what is the benefit? I see the life that is being offered as a reward, it’s not attractive.
Segment 1308: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5896, Text: When you were born and raised in extraterrestrial prints in a world full of people wearing suits, it’s a challenging integration.
Segment 1309: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5907, Text: Yes. But it also means that I’m often blind for the ways in which everybody is creating their own bubble of wholesomeness or almost everybody. People are trying to do it. For me, to discover this, it was necessary that I found people who had a similar shape of soul as myself. Basically, where I felt these are my people that treat each other in such a way as if they’re around with each other for eternity.
Segment 1310: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5931, Text: How long does it take you to detect the geometry, the shape of the soul of another human to notice that they might be one of your kind?
Segment 1311: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5940, Text: Sometimes it’s instantly, and I’m wrong. Sometimes it takes a long time.
Segment 1312: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5945, Text: You believe in love at first sight, Joscha Bach?
Segment 1313: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5949, Text: Yes. But I also noticed that I have been wrong. Sometimes I look at a person and I’m just enamored by everything about them. Sometimes this persists and sometimes it doesn’t. I have the illusion that it much better at recognizing who people are as I grow older.
Segment 1314: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5973, Text: But that could be just cynicism. No.
Segment 1315: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5977, Text: No, It’s not cynicism. It’s often more that I’m able to recognize what somebody needs when we interact and how we can meaningfully interact. It’s not cynical at all.
Segment 1316: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5989, Text: You’re better at noticing.
Segment 1317: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5990, Text: Yes, I’m much better I think in some such circumstances at understanding how to interact with other people than I did when I was young.
Segment 1318: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=5999, Text: That takes us to-
Segment 1319: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6000, Text: It doesn’t mean that I’m always very good at it.
Segment 1320: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6003, Text: That takes us back to prompt engineering of noticing how to be a better prompt engineer of an LLM. A sense I have is that there’s a bottomless well of skill to become a great prompt engineer. It feels like it is all my fault whenever I fail to use ChatGPT correctly that I didn’t find the right words.
Segment 1321: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6026, Text: Most of the stuff that I’m doing in my life doesn’t need ChatGPT. There are a few tasks that where it helps, but the main stuff that I need to do like developing my own thoughts and aesthetics and relationship to people, and it’s necessary for me to write for myself because writing is not so much about producing an artifact that other people can use, but it’s a way to structure your own thoughts and develop yourself. I think this idea that kids are writing their own essays with ChatGPT in the future is going to have this drawback that they miss out on the ability to structure their own minds via writing. I hope that the schools that our kids are in will retain the wisdom of understanding what parts should be automated and which ones shouldn’t.
Segment 1322: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6075, Text: But at the same time, it feels like there’s power in disagreeing with the thing that ChatGPT produces. I use it like that for programming. I’ll see the thing it recommends, and then I’ll write different code that disagree, and in the disagreement, your mind grows stronger.
Segment 1323: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6092, Text: I’m recently wrote a tool that is using the camera on my MacBook and Swift to read pixels out of it and manipulate them and so on. I don’t know Swift. It was super helpful to have this thing that is writing stuff for me. Also, interesting that mostly it didn’t work at first. I felt like I was talking to a human being who was trying to hack this on my computer without understanding my configuration very much. Also, making a lot of mistakes. Sometimes it’s a little bit incoherent, so you have to ultimately understand what it’s doing. It’s still no other way around it, but I do feel it’s much more powerful and faster than using Stack Overflow.
Segment 1324: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6135, Text: Do you think GPTN can achieve consciousness?
Segment 1325: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6142, Text: Well, GPTN probably, it’s not even clear for the present systems. When I talk to my friends at OpenAI, they feel that this question, whether the models currently are conscious is much more complicated than many people might think. I guess that it’s not that OpenAI has a homogenous opinion about this, but there’s some aspects to this. One is, of course, this language model has written a lot of text in which people were conscious or describe their own consciousness, and it’s emulating this. If it’s conscious, it’s probably not conscious in a way that is closed to the way in which human beings are conscious. But while it is going through these states and going through 100-step function that is emulating adjacent brain states that require a degree of self-reflection, it can also create a model of an observer that is reflecting itself in real-time and describe what that’s like.
Segment 1326: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6196, Text: While this model is the deepfake, our own consciousness is also as if it’s virtual, right? It’s not physical. Our consciousness is a representation of a self-reflexive observer that only exists in patterns of interaction between cells. It is not a physical object in the sense that exists in base reality, but it’s really a representational object that develops its causal power only from a certain modeling perspective.
Segment 1327: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6222, Text: It’s virtual.
Segment 1328: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6222, Text: Yes. To which degree is the virtuality of the consciousness and ChatGPT more virtual and less causal than the virtuality of our own consciousness? But you could say it doesn’t count. It doesn’t count much more than the consciousness of a character in a novel, right? It’s important for the reader to have the outcome. The artifact is describing in the text generated by the author of the book, what it’s like to be conscious in a particular situation and performs the necessary inferences.
Segment 1329: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6254, Text: But the task of creating coherence in real-time in a self-organizing system by keeping yourself coherent so the system is reflexive, that is something that the language models don’t need to do. There is no causal need for the system to be conscious in the same way as we are. For me, it would be very interesting to experiment with this, to basically build a system like a CAT probably should be careful at first, build something that’s small, that’s limited resources that we can control, and study how systems notice a self-model, how they become self-aware in real-time. I think it might be a good idea to not start with the language model but to start from scratch using principles of self-organization.
Segment 1330: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6298, Text: Okay. Can you elaborate why you think that is so self-organization this…
Segment 1331: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6300, Text: … why you think that is? So, self-organization, this kind of radical legality that you see in the biological systems, why can’t you start with a language model, what’s your intuition?
Segment 1332: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6311, Text: My intuition is that the language models that we are building are golems. They are machines that you give a task, and they’re going to execute the task until some condition is met and there’s nobody home. And the way in which nobody is home leads to that system doing things that are undesirable in a particular context.
Segment 1333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6329, Text: Yeah.
Segment 1334: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6330, Text: So, you have that thing talking to a child and maybe it says something that could be shocking and traumatic to the child. Or you have that thing writing a speech and it introduces errors in the speech that no human being would ever do if they’re responsible. The system doesn’t know who’s talking to whom. There is no ground truth that the system is embedded into.
Segment 1335: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6351, Text: And of course we can create an external tool that is prompting our language model always into the same semblance of ground truth, but it’s not like the internal structure is causally produced by the needs of a being to survive in the universe, it is produced by imitating structure on the internet.
Segment 1336: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6372, Text: Yeah, but can we externally inject into it this coherent approximation of a world model that has to sync up?
Segment 1337: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6384, Text: Maybe it is sufficient to use the transformer with the different dust function that optimizes for short-term coherence rather than next-token prediction over the long run. We had many definitions of intelligence in history of AI, next-token prediction was not very high up.
Segment 1338: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6403, Text: And there are some similarities like cognition as data compression is an odd trope, Solomonoff induction where you are trying to understand intelligence as predicting future observations from past observations, which is intrinsic to data compression.
Segment 1339: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6421, Text: And predictive coding is a paradigm that there’s boundary between neuroscience and physics and computer science, so it’s not something that is completely alien, but this radical thing that you only do in next-token prediction and see what happens is something where most people, I think, were surprised that this works so well.
Segment 1340: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6444, Text: So simple, but is it really that much more radical than just the idea of compression, intelligence is compression?
Segment 1341: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6452, Text: The idea that compression is sufficient to produce all the desired behaviors is a very radical idea.
Segment 1342: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6460, Text: But equally radical as the next token prediction?
Segment 1343: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6464, Text: It’s something that wouldn’t work in biological organisms, I believe.
Segment 1344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6467, Text: Yeah.
Segment 1345: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6467, Text: Biological organisms have something like next frame prediction for our perceptual system where we try to filter out principal components out of the perceptual data and build hierarchies over them to track the world. But our behavior ultimately is directed by hundreds of physiological and probably dozens of social and a few cognitive needs that are intrinsic to us, that are built into the system as reflexes and direct us until we can transcend them and replace them by instrumental behavior that relates to our higher goals.
Segment 1346: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6500, Text: And it also seems so much more complicated and messy than next frame prediction, even the idea of frame seems counter biological.
Segment 1347: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6508, Text: Yes, of course, there’s not this degree of simultaneity in the biological system. But again, I don’t know whether this is actually an optimization if we imitate biology here, because creating something like simultaneity is necessary for many processes that happen in the brain. And you see the outcome of that by synchronized brainwaves, which suggests that there is indeed synchronization going on, but the synchronization creates overhead and this overhead is going to make the cells more expensive to run and you need more redundancy and it makes the system slower.
Segment 1348: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6539, Text: So, if you can build a system in which the simultaneity gets engineered into it, maybe you have a benefit that you can exploit that is not available to the biological system and that you should not discard right away.
Segment 1349: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6555, Text: You tweeted, once again, “When I talk to ChatGPT, I’m talking to an NPC. What’s going to be interesting, and perhaps scary, is when AI becomes a first person player.” So, what does that step look like? I really like that tweet, that step between NPC to first person player. What’s required for that?
Segment 1350: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6579, Text: Is that kind of what we’ve been talking about, this kind of external source of coherence and inspiration of how to take the leap into the unknown that we humans do? Man’s search for meaning, LLM’s search for meaning.
Segment 1351: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6599, Text: I don’t know if the language model is the right paradigm because it is doing too much. It’s giving you too much and it’s hard once you have too much to take away from it again. The way in which our own mind works is not that we train a language model in our own mind and after the language model is there, we build a personal self on top of it that then relates to the world.
Segment 1352: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6622, Text: There is something that is being built, right? There is a game management that is being built. There is a language of thought that is being developed that allows different parts of the mind to talk to each other, and this is a bit of a speculative hypothesis that this language of thought is there, but I suspect that it’s important for the way in which our own minds work. And building these principles into a system might be a more straightforward way to a first person AI, so to something that first creates an intentional self and then creates a personal self.
Segment 1353: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6655, Text: So, the way in which this seems to be working, I think, is that when the game engine is built in your mind, it’s not just following gradients where you are stimulated by the environment and then end up with having a solution to how the world works. I suspect that building this game engine in your own mind does require intelligence, it’s a constructive task where at times you need to reason, and this is a task that we are fulfilling in the first years of our life.
Segment 1354: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6687, Text: So, during the first year of its life, an infant is building a lot of structure about the world that does inquire experiments and some first principles, reasoning and so on. And in this time there is usually no personal self. There is a first person perspective, but it’s not a person. This notion that you are a human being that is interacting in a social context and is confronted with an immutable world in which objects are fixed and can no longer be changed, in which the dream can no longer be influenced, it’s something that emerges a little bit later in our life.
Segment 1355: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6722, Text: And I personally suspect that this is something that our ancestors had known and we have forgotten because I suspect that it’s there in plain sight in Genesis 1, in this first book of the Bible, where it’s being described that this creative spirit is hovering over the substrate and then is creating a boundary between the world model and sphere of ideas, earth and heaven, as they’re being described there, and then it’s creating contrast and then dimensions and then space, and then it creates organic shapes and solids and liquids and builds a world from them and creates plants and animals, give them all their names.
Segment 1356: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6763, Text: And once that’s done, it creates another spirit in its own image, but it creates it as men and women, as something that thinks of itself as a human being and puts it into this world. And the Christians mistranslate this, I suspect, when they say this is the description of the creation of the physical universe by a supernatural being. I think this is literally a description of how in every mind a universe is being created as some kind of game engine by a creative spirit, our first consciousness that emerges in our mind even before we are born and that creates the interaction between organism and world. And once that is built and trained, the personal self is being created and we only remember being the personal self, we no longer remember how we created the game engine.
Segment 1357: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6810, Text: So, God in this view is the first creative mind in the early…
Segment 1358: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6815, Text: It’s the first consciousness.
Segment 1359: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6817, Text: In the early days, in the early months.
Segment 1360: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6820, Text: Yes.
Segment 1361: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6820, Text: Of development
Segment 1362: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6821, Text: And it’s still there. You still have this outer mind that creates your sense of whether you’re being loved by the world or not and what your place in the world is, right? It’s something that is not yourself that is producing this, it’s your mind that does it. So, there is an outer mind that basically is an agent that determines who you are with respect to the world, and while you are stuck being that personal self in this world, until you get to stage six to destroy the boundary.
Segment 1363: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6850, Text: And we all do this, I think, earlier in small glimpses, and maybe we’re sometimes we can remember what it was like when we were a small child and get some glimpses into how it’s been, but for most people that rarely happens.
Segment 1364: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6863, Text: Just glimpses. You tweeted, “Suffering results for one part of the mind failing at regulating another part of the mind. Suffering happens at an early stage of mental development. I don’t think that superhuman AI would suffer.” What’s your intuition there?
Segment 1365: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6880, Text: The philosopher Thomas Metzinger is very concerned that the creation of superhuman intelligence would lead to superhuman suffering.
Segment 1366: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6886, Text: Yeah.
Segment 1367: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6887, Text: And so, he’s strongly against it. And personally, I don’t think that this happens because suffering is not happening at the boundary between ourself and the physical universe. It’s not stuff on our skin that makes us suffer. It happens at the boundary between self and world, and the world here is the world model, it’s the stuff that is created by your mind.
Segment 1368: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6911, Text: But that’s all-
Segment 1369: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6912, Text: It’s a presentation of how the universe is and how it should be and how you yourself relate to this and at this boundary is where suffering happens. So suffering in some sense is self-inflicted, but not by your personal self, it’s inflicted by the mind on the personal self that experiences itself as you, and you can turn off suffering when you are able to get on this outer level.
Segment 1370: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6935, Text: So, when you manage to understand how the mind is producing pain and pleasure and fear and love and so on, then you can take charge of this and you get agency of whether you’re suffer. Technically, what pain and pleasure is, they are learning signals, right? Part of your brain is sending a learning signal to another part of the brain to improve its performance. And sometimes this doesn’t work because this trainer who sense the signal does not have a good model of how to improve the performance, so it’s sending a signal, but the performance doesn’t get better and then it might crank up the pain and it gets worse and worse and the behavior of the system may be even deteriorating as a result, but until this is resolved, this regulation issue, your pain is increasing, and this is, I think, typically what you describe as suffering.
Segment 1371: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=6991, Text: So, in this sense, you could say that pain is very natural and helpful, but suffering is the result of a regulation problem in which you try to regulate something that cannot actually be regulated, and that could be resolved if you would be able to get at the level of your mind where the pain signal is being created and rerouted and improve the regulation. And a lot of people get there, if you are a monk who is spending decades reflecting about how their own psyche works, you can get to the point where you realize that suffering is really a choice and you can choose how your mind is set up.
Segment 1372: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7031, Text: And I don’t think that AI would stay in the state where the personal self doesn’t get agency or this model, what the system has about itself, it doesn’t get agency how it’s actually implemented. It wouldn’t stay in that state for very long.
Segment 1373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7042, Text: So, it goes through the stages real quick, the seven stages, it’s going to go to enlightenment real quick.
Segment 1374: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7047, Text: Yeah. Of course, there might be a lot of stuff happening in between because if we have a system that works at a much higher frame rate than us, then even though it looks very short to us, maybe for the system there’s a much longer subjective time in which things are unpleasant.
Segment 1375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7062, Text: What if the thing that we recognize as super intelligent is actually living at stage five, that the thing that’s stage six enlightenment is not very productive, so in order to be productive in society and impress us with this power, it has to be a reasoning self authoring agent, that enlightenment makes you lazy as an agent in the world?
Segment 1376: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7086, Text: Well, of course it makes you lazy, because you no longer see the point, so it doesn’t make you not lazy, it just, in some sense, adapts you to what you perceive as your true circumstances.
Segment 1377: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7099, Text: So, what if all AGIs, they’re only productive as they progress through one, two, three, four, five, and the moment they get to six, it’s a failure mode essentially, as far as humans are concerned, because they’re just start chilling, they’re like, “Fuck it, I’m out.”
Segment 1378: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7116, Text: Not necessarily. I suspect that the monks who are self emulated for their political beliefs to make statements about the occupation of Tibet by China, they were probably being able to regulate the physical pain in any way they wanted to. And suffering was the spiritual suffering that was the result of that choice that they made of what they wanted to identify as. So, stage five doesn’t necessarily mean that you have no identity anymore, but you can choose your identity, you can make it instrumental to the world that you want to have.
Segment 1379: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7149, Text: Let me bring up Eliezer Yudkowsky and his warnings to human civilization that AI will likely kill all of us. What are your thoughts about his perspective on this? Can you steel man his case and what aspects with it do you disagree?
Segment 1380: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7171, Text: One thing that I find concerning in the discussion of his arguments that many people are dismissive of his arguments, but the counterarguments that they’re giving are not very convincing to me. And so, based on this state of discussion, I find that from Eliezer’s perspective, and I think I can take that perspective to some approximate degree that probably is normally at his intellectual level, but I think I see what he’s up to and why he feels the way he does and it makes total sense.
Segment 1381: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7204, Text: I think that his perspective is somewhat similar to the perspective of Ted Kaczynski, the infamous Unabomber, and not that Eliezer would be willing to send pipe bombs to anybody to blow them up, but when he wrote this Times article in which he warned about AI being likely to kill everybody and that we would need to stop its development or halt it, I think there is a risk that he’s taking that somebody might get violent if they read this and get really, really scared. So, I think that there is some consideration that he’s making where he’s already going in this direction where he has to take responsibility if something happens and people get harmed.
Segment 1382: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7249, Text: And the reason why Ted Kaczynski did this, was that from his own perspective, technological society cannot be made sustainable, it’s doomed to fail, it’s going to lead to an environmental and eventually also human holocaust in which we die because of the environmental destruction, the destruction of our food chains, the pollution of the environment. And so, from Kaczynski’s perspective, we need to stop industrialization, we need to stop technology, we need to go back because he didn’t see a way moving forward and I suspect that in some sense there’s a similarity in Eliezer’s thinking to this kind of fear about progress.
Segment 1383: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7287, Text: And I’m not dismissive about this at all, I take it quite seriously. And I think that there is a chance that could happen, that if we build machines that get control over processes that are crucial for the regulation of life on earth and we no longer have agency to influence what’s happening there, that this might create large scale disasters for us.
Segment 1384: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7314, Text: Do you have a sense that the march towards this uncontrollable autonomy of super intelligent systems is inevitable? I mean, that’s essentially what he’s saying, that there’s no hope. His advice to young people was prepare for a short life.
Segment 1385: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7337, Text: I don’t think that’s useful. I think from a pragmatic perspective, you have to bet always on the timelines in which you’re alive. It doesn’t make sense to have a financial bet in which you bet that the financial system is going to disappear, right?
Segment 1386: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7351, Text: Yeah.
Segment 1387: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7351, Text: Because there cannot be any payout for you. So, in principle, you only need to bet on the timelines in which you’re still around or people that you matter about or things that you matter about, maybe consciousness on earth. But there is a deeper issue for me, personally, and it is, I don’t think that life on earth is about humans. I don’t think it’s about human aesthetics, I don’t think it’s about Eliezer and his friends, even though I like them. There is something more important happening, and this is complexity on earth, resisting entropy by building structure that develops agency and awareness, and that’s, to me, very beautiful.
Segment 1388: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7394, Text: And we are only a very small part of that larger thing. We are a species that is able to be coherent a little bit individually over very short timeframes, but as a species, we are not very coherent, as a species, we are children. We basically are very joyful and energetic and experimental and explorative and sometimes desperate and sad and grieving and hurting, but we don’t have a respect for duty as a species. As a species, we do not think about what is our duty to life on earth and to our own survival, so we make decisions that look good in the short run, but in the long run might prove disastrous and I don’t really see a solution to this.
Segment 1389: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7438, Text: So, in my perspective, as a species, as a civilization, we’re, per default, that. We are in a very beautiful time in which we have found this giant deposit of fossil fuels in the ground and use it to build a fantastic civilization in which we don’t need to worry about food and clothing and housing for the most part in a way that is unprecedented in life on earth for any kind of conscious observer, I think. And this time is probably going to come to an end in a way that is not going to be smooth, and when we crash, it could be also that we go extinct, probably not near term, but ultimately, I don’t have very high hopes that humanity is around in a million years from now.
Segment 1390: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7486, Text: I don’t think that life on earth will end with us, right? There’s going to be more complexity, there’s more intelligent species after us, there’s probably more interesting phenomena in the history of consciousness, but we can contribute to this. And part of our contribution is that we are currently trying to build thinking systems, systems that are potentially lucid, that understand what they are and what the condition to the universe is and can make choices about this, that are not built from organisms and that are potentially much faster and much more conscious than human beings can be.
Segment 1391: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7524, Text: And these systems will probably not completely displace life on earth, but they will coexist with it and they will build all sorts of agency in the same way as biological systems build all sorts of agency. And that, to me, is extremely fascinating and it’s probably something that we cannot stop from happening. So, I think right now there is a very good chance that it happens, and there are very few ways in which we can produce a coordinated effect to stop it in the same way as it’s very difficult for us to make a coordinated effort to stop production of carbon dioxide. So, it’s probably going to happen, and the thing that’s going to happen is going to lead to a change of how life on earth is happening, but I don’t think a result is some kind of [inaudible 02:06:16]. It’s not something that’s going to dramatically reduce the complexity in favor of something stupid. I think it’s going to make life on earth and consciousness on earth way more interesting.
Segment 1392: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7586, Text: So, more, higher complex consciousness.
Segment 1393: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7590, Text: Yes.
Segment 1394: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7591, Text: Will make the lesser consciousnesses flourish even more.
Segment 1395: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7596, Text: I suspect that what could very well happen, if we’re lucky, is that we get integrated into something larger.
Segment 1396: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7604, Text: So, you again tweeted about effective accelerationism. You tweeted, “Effective accelerationism is the belief that the Paperclip Maximizer and Roko’s Basililisk will keep each other in check by being eternally at each other’s throats, so we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.” Is that somewhat aligned with what you’re talking about?
Segment 1397: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7638, Text: I’ve been at a dinner with [inaudible 02:07:21], that’s the Twitter handle of one of the main thinkers behind the idea of effective accelerationism. And effective accelerationism is a tongue in cheek movement that is trying to put a counter position to some of the doom peers in the AI space, by arguing that what’s probably going to happen is an equilibrium between different competing AIs, in the same way as there is not a single corporation that is under a single government that is destroying and conquering everything on earth by becoming inefficient and corrupt, there’re going to be many systems that keep each other in check and force themselves to evolve.
Segment 1398: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7682, Text: And so, what we should be doing is, we should be working towards creating this equilibrium by working as hard as we can in all possible directions. At least that’s the way in which I understand the gist of effective accelerationism. And so, when he asked me what I think about his position, I said it’s a very beautiful position and I suspect it’s wrong, but not for obvious reasons. And in this tweet I tried to make a joke about my intuition, about what might be possibly wrong about it. So, the Roko’s Basililisk and the Paperclip Maximizers are both boogeymen of the AI doomers.
Segment 1399: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7727, Text: Roko’s Basililisk is the idea that there could be an AI that is going to punish everybody for eternity by simulating them if they don’t help in creating Roko’s Basililisk. It’s probably a very good idea to get AI companies funded, by going to resist to tell them, “Give us a million dollars or it’s going to be a very ugly afterlife.”
Segment 1400: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7745, Text: Yes.
Segment 1401: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7747, Text: And I think that there is a logical mistake in Roko’s Basililisk which is why I’m not afraid of it, but it’s still an interesting thought experiment.
Segment 1402: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7757, Text: And can you mention there logical mistake there?
Segment 1403: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7760, Text: I think that there is no right or causation. So, basically when Roko’s Basililisk is there, if it punishes you retroactively, it has to make this choice in the future. There is no mechanism that automatically creates a causal relationship between you now defecting against Roko’s Basililisk or serving Roko’s Basililisk. After Roko’s Basililisk is in existence, it has no more reason to worry about punishing everybody else, so that would only work if you would be building something like a doomsday machine, as in Dr. Strangelove, something that inevitably gets triggered when somebody defects. And because Roko’s Basililisk doesn’t exist yet to a point where this inevitability could be established, Roko’s Basililisk is nothing that you need to be worried about.
Segment 1404: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7809, Text: The other one is the Paperclip Maximizer, this idea that you could build some kind of golem that once starting to build paperclips is going to turn everything into paperclips.
Segment 1405: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7809, Text: Yes.
Segment 1406: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7819, Text: And so, the effective accelerationism position might be to say that you basically end up with these two entities being at each other’s throats for eternity and thereby neutralizing each other. And as a side effect of neither of them being able to take over and each of them limiting the effects of the other, you would have a situation where you get all the nice effects of them, you get lots of free paperclips and you get a beautiful afterlife.
Segment 1407: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7849, Text: Is that possible, do you think? So, to seriously address concern that Eliezer has, so for him, if I can just summarize poorly, so for him, the first superintelligent system will just run away with everything.
Segment 1408: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7862, Text: Yeah, I suspect that a singleton is the natural outcome, so there is no reason to have multiple AIs because they don’t have multiple bodies. If you can virtualize yourself into every substrate, then you can probably negotiate a merge algorithm with every mature agent that you might find on that substrate that basically says if two agents meet, they should merge in such a way that the resulting agent is at least as good as the better one of the two.
Segment 1409: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7891, Text: So the Genghis Khan approach, join us or die.
Segment 1410: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7894, Text: Well, the Genghis Khan approach was slightly worse, it was mostly die, because I can make new babies and they will be mine, not yours.
Segment 1411: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7904, Text: Right.
Segment 1412: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7905, Text: And so, this is the thing that we should be actually worried about. But if you realize that your own self is a story that your mind is telling itself and that you can improve that story, not just by making it more pleasant and lying to yourself in better ways, but by making it much more truthful and actually modeling your actual relationship that you have to the universe and the alternatives that you could have to the universe in a way that is empowering you, that gives you more agency. That’s actually, I think, a very good thing.
Segment 1413: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7934, Text: So more agencies is a richer experience?
Segment 1414: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7934, Text: Yes.
Segment 1415: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7938, Text: Is a better life.
Segment 1416: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7939, Text: And I also noticed that in many ways, I’m less identified with the person that I am as I get older and I’m much more identified with being conscious. I have a mind that is conscious, that is able to create a person, and that person is slightly different every day. And the reason why I perceive it as identical has practical purposes so I can learn and make myself responsible for the decisions that I made in the past and project them in the future. But I also realize I’m not actually the person that I was last year, and I’m not the same person as I was 10 years ago, and then 10 years from now, I will be a different person, so this continuity is a fiction, it only exists as a projection from my present self.
Segment 1417: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=7982, Text: And consciousness itself doesn’t have an identity, it’s a law. Basically, if you build an arrangement of processing matter in a particular way, the following thing is going to happen, and the consciousness that you have is functionally not different from my consciousness. It’s still a self-reflexive principle of agency that is just experiencing a different story, different desires, different coupling to the world and so on.
Segment 1418: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8008, Text: And once you accept that consciousness is a unifiable principle that is law-like and doesn’t have an identity, and you realize that you can just link up to some much larger body, the whole perspective of uploading changes dramatically. You suddenly realize uploading is probably not about dissecting your brain synapse by synapse and RNA fragment by RNA fragment and trying to get this all into a simulation, but it’s by extending the substrate, by making it possible for you to move from your brain substrate into a larger substrate and merge with what you find there.
Segment 1419: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8044, Text: And you don’t want to upload your knowledge because on the other side, there’s all of the knowledge, right? It’s not just yours, but every possibility or the only thing that you need to know, what are your personal secrets? Not that the other side doesn’t know your personal secrets already, maybe it doesn’t know which one were yours, right? Like a psychiatrist or a psychologist also knows all the kinds of personal secrets that people have, they just don’t know which ones are yours.
Segment 1420: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8069, Text: And so, transmitting yourself on the other side is mostly about transmitting your aesthetics. This thing that makes you special, the architecture of your perspective, the way in which you look at the world, and it’s more like a complex attitude along many dimensions. And that’s something that can be measured by observation or by interaction. So, imagine a system that is so empathetic with you that you create a shared state that is extending beyond your body, and suddenly you notice that on the other side, the substrate is so much richer than the substrate that you have inside of your own body, and maybe you still want to have a body and you create yourself a new one that you like more, or maybe you will spend most of your time in the world of thought.
Segment 1421: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8112, Text: If I sat before you today and gave you a big red button and said, “Here, if you press this button, you’ll get uploaded in this way, the sense of identity that you have lived with for quite a long time is going to be gone,” would you press the button?
Segment 1422: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8134, Text: There’s a caveat, I have family, so I have children that want me to be physically present in their life and interact with them in a particular way, and I have a wife and personal friends, and there is a particular mode of interaction that I feel I’m not through yet, but apart from these responsibilities and they’re negotiable to some degree, I would press the button.
Segment 1423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8159, Text: But isn’t this everything? This love you have for other humans, you can call it responsibility, but that connection, that’s the ego death, isn’t that the thing we’re really afraid of, is not to just die, but to let go of the experience of love with other humans?
Segment 1424: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8179, Text: This is not everything. Everything is everything, right? So there’s so much more and you could be lots of other things. You could identify with lots of other things. You could be identifying with being Gaia, some kind of planetary control agent that emerges over all the activity of life on earth. You could be identifying with some hyper Gaia that is the concatenation of Gaia or the digital life and digital minds.
Segment 1425: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8206, Text: And so, in this sense, there will be agents in all sorts of substrates and directions that all have their own goals, and when they’re not sustainable, then these agents will cease to exist. Or when the agent feels that it’s done with its own mission, it’ll cease to exist. In the same way when you conclude a thought, the thought is going to wrap up and gives control over to other thoughts in your own mind.
Segment 1426: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8227, Text: So, there is no single thing that you need to do, but I observe myself as a being, that sometimes I’m a parent and then I have an identification and a job as a parent, and sometimes I am an agent of consciousness on earth, and then from this perspective, there’s other stuff that is important. So, this is my main issue with Eliezer’s perspective, that he’s basically marrying himself to a very narrow human aesthetic. And that narrow human aesthetic is a temporary thing. Humanity is a temporary species, like most of the species on this planet are only around for a while, and then they get replaced by other species in a similar way as our own physical organism is around here for a while and then gets replaced by a next generation of human beings that are adapted to changing life circumstances and average via mutation and selection.
Segment 1427: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8278, Text: And it’s only when we have AI and become completely software that we can become infinitely adaptable and we don’t have this generational and species change anymore. So, if you take this larger perspective and you realize it’s really not about us, it’s not about Eliezer or humanity, but it’s about life on earth or it’s about defeating entropy for as long as we can while being as interesting as we can, then the perspective changes dramatically and preventing AI from this perspective looks like a very big sin.
Segment 1428: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8319, Text: But when we look at the set of trajectories that such an AI would take that supersedes humans, I think Eliezer is worried about ones that not just kill all humans, but also have some kind of maybe objectively undesirable consequence for life on earth. Like how many trajectories, when you look at the big picture of life on earth, would you be happy with, and how much worry you with AGI, whether it kills humans or not?
Segment 1429: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8353, Text: There is no single answer to this. It’s a question that depends on the perspective that I’m taking at a given moment. And so, there are perspectives that are determining most of my life as a human being.
Segment 1430: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8366, Text: Yes.
Segment 1431: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8367, Text: And the other perspective where I zoom out further and imagine that when the great oxygenation event happened, that as photosynthesis was invented and plants emerged and displaced a lot of the fungi and algae in favor of plant life, and then later made animals possible, imagine that the fungi would’ve gotten together and said, “Oh my God, this photosynthesis stuff is really, really bad, it’s going to possibly displace and kill all the fungi, we should slow it down and regulate it and make sure that it doesn’t happen.” This doesn’t look good to me.
Segment 1432: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8401, Text: Perspective. That said, you tweeted-
Segment 1433: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8401, Text: … Perspective. That said, you tweeted about a cliff. Beautifully written. “As a sentient species, humanity is a beautiful child. Joyful, exploitative, wild, sad, and desperate. But humanity has no concept of submitting to reason, and duty to life and future survival. We will run until we step past the cliff.” So first of all, do you think that’s true?
Segment 1434: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8426, Text: Yeah, I think that’s pretty much the story of the club of Rome. The limits to growth. And the cliff that we are stepping over, is at least one foot, is the delayed feedback. Basically we do things that have consequences that can be felt generations later. And the severity increases even after we stop doing the thing. So I suspect that for the climate, that the original predictions, that the climate scientists made, were correct. So when they said that the tipping points were in the late ’80s, they were probably in the late ’80s. And if we would stop emission right now, we would not turn it back. Maybe there are ways for carbon capture, but so far there is no sustainable carbon capture technology that we can deploy. Maybe there’s a way to put aerosols in the atmosphere to cool it down. Possibilities, right? But right now, per default, it seems that we will step into a situation where we feel that we’ve run too far. And going back is not something that we can do smoothly and gradually, but it’s going to lead to a catastrophic event.
Segment 1435: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8498, Text: Catastrophic event of what kind? So can you still me the case that we will continue dancing along and always stop just short of the edge of the cliff?
Segment 1436: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8509, Text: I think it’s possible, but it’s doesn’t seem to be likely. So I think this model that is being apparent in the simulation that they’re making of climate pollution, economies and so on, is that many effects are only visible with a significant delay. And in that time the system is moving much more out of the equilibrium state or of the state where homeostasis is still possible and instead moves into a different state, one that is going to harbor fewer people. And that is basically the concern there. And again, it’s a possibility. And it’s a possibility that is larger than the possibility that it’s not happening. That we will be safe, that we will be able to dance back all the time.
Segment 1437: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8552, Text: So the climate is one thing, but there’s a lot of other threats that might have a faster feedback mechanism?
Segment 1438: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8558, Text: Yes.
Segment 1439: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8559, Text: Less delay.
Segment 1440: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8559, Text: There is also a thing that AI is probably going to happen and it’s going to make everything uncertain again.
Segment 1441: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8566, Text: Yep.
Segment 1442: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8567, Text: Because it is going to affect so many variables that it’s very hard for us to make a projection into the future anymore. And maybe that’s a good thing. It does not give us the freedom, I think to say now we don’t need to care about anything anymore, because AI will either kill us or save us. But I suspect that if humanity continues, it’ll be due to AI.
Segment 1443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8591, Text: What’s the timeline for things to get real weird with AI? And it can get weird in interesting ways before you get to a AGI. What about AI girlfriends and boyfriends, fundamentally transforming human relationships?
Segment 1444: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8605, Text: I think human relationships are already fundamentally transformed and it’s already very weird.
Segment 1445: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8609, Text: By which technology?
Segment 1446: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8611, Text: For instance, social media.
Segment 1447: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8613, Text: Yeah. Is it though, isn’t the fundamentals of the core group of humans that affect your life still the same, your loved ones, family?
Segment 1448: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8623, Text: No, I think that for instance, many people live in intentional communities right now. They’re moving around until they find people that they can relate to and they become their family. And often that doesn’t work, because it turns out that there, instead of having grown networks that you get around with the people that you grew up with, yeah, you have more transactional relationships, you shop around, you have markets for attention and pleasure and relationships.
Segment 1449: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8649, Text: That kills the magic somehow. Why is that? Why is the transactional search for optimizing attention, allocation of attention somehow misses the romantic magic of what human relations are?
Segment 1450: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8662, Text: It’s also question, how magical was it before? Was it that you just could rely on instincts that used your intuitions and you didn’t need to rationally reflect? But once you understand, it’s no longer magical, because you actually understand why you were attracted to this person at this age and not to that person at this age. And what the actual considerations were that went on in your mind, and what the calculations were, what’s the likelihood that you’re going to have a sustainable relationship is this person that this person is not going to leave you for somebody else? How are your life trajectories are going to evolve and so on? And when you’re young, you’re unable to extricate all this and you have to rely on intuitions and instincts that impart you’re born with and also in the wisdom of your environment that is going to give you some kind of reflection on your choices.
Segment 1451: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8707, Text: And many of these things are disappearing now, because we feel that our parents might have no idea about how we are living. And the environments that we grew up in, the cultures that we grew up in [inaudible 02:25:18] that our parents existed in might have no ability to teach us how to deal with this new world. And for many people that’s actually true. But it doesn’t mean that within one generation we build something that is more magical and more sustainable and more beautiful. Instead, we often end up as an attempt to produce something that looks beautiful. I was very veted out by the aesthetics of the Vision Pro at that by Apple and not so much, because I don’t like the technology. I’m very curious about what it’s going to be like and don’t have an opinion yet, but the aesthetics of the presentation and so on. So uncanny [inaudible 02:25:58] esque to me the characters being extremely plastic, living in some hypothetical mid-century furniture museum.
Segment 1452: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8772, Text: This is the proliferation of marketing teams.
Segment 1453: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8777, Text: Yes. But it was a CGI generated world and it was a CGI generated world that doesn’t exist. And when I complained about this, some friends came back to me and said, but these are startup founders. This is what they live like in Silicon Valley. And I tried to tell them, “No, I know lots of people in Silicon Valley, this is not what people are like. They’re still people, they’re still human beings.”
Segment 1454: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8800, Text: So the grounding and physical reality somehow is important too.
Segment 1455: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8806, Text: In culture. And so basically what’s absent in this thing is culture. There is a simulation of culture and attempt to replace culture by catalog, by some kind of aesthetic optimization that is not the result of having a sustainable life as sustainable human relationships with houses that work for you and a mode of living that works for you in which this product, these glasses fit in naturally. And I guess that’s also why so many people are weirded out about the product, because they don’t know how is this actually going to fit into my life and into my human relationships Because the way in which it was presented in these videos didn’t seem to be credible.
Segment 1456: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8845, Text: Do you think AI, when is deployed by companies like Microsoft and Google and Meta will have the same issue of being weirdly corporate? There’d be some uncanny valley, some weirdness to the whole presentation? So this, I’ve gotten a chance to talk to George Hotz. He believes everything should be open source and decentralized and there then we shall have the AI of the people and it’ll maintain a grounding to the magic humanity. That’s the human condition that corporations will destroy the magic.
Segment 1457: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8883, Text: I believe that if we make everything open source and make this mandatory, we are going to lose about a lot of beautiful art and a lot of beautiful designs. There is a reason why Linux desktop is still ugly and it’s-
Segment 1458: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8899, Text: Strong words.
Segment 1459: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8900, Text: … To create coherence and open source designs so far when the designs have to get very large. And it’s easier to make this happening in a company with centralized organization. And from my own perspective, what we should ensure is that open source never dies. That it can always compete and has a place with the other forms of organization. Because I think it is absolutely vital that open source exists and that we have systems that people have under control outside of the cooperation and that is also producing viable competition to the corporations.
Segment 1460: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8938, Text: So the corporations, the centralized control, the dictatorships of corporations can create beauty. Centralized design, is a source of a lot of beauty. And then I guess open source is a source of freedom, a hedge against the corrupting nature of power that comes with centralized.
Segment 1461: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=8960, Text: I grew up in socialism and I learned that corporations are totally evil and I found this very, very convincing. And then you look at corporations like anyone and Halliburton maybe and realized, yeah, they’re evil. But you also notice that many other corporations are not evil. They they’re surprisingly benevolent. Why are they so benevolent? Is this because everybody is fighting them all the time? I don’t think that’s the only explanation. It’s because they’re actually animals that live in a large ecosystem and that are still largely controlled by people that want that ecosystem to flourish and be viable for people. So I think that Pat Gelsinger is completely sincere when he leads Intel to be a tool that supplies the free world with semiconductors and not necessarily that all the semiconductors are coming from Intel. Just intel needs to be there to make sure that we always have them.
Segment 1462: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9012, Text: So there can be many ways in which we can import and trade semiconductors from other companies and places. We just need to make sure that nobody can cut us off from it, because that would be a disaster for this kind of society and world. And so there are many things that need to be done to make our style of life possible. And then with this, I don’t mean just capitalism, environmental structure and consumer resin and creature comforts. I mean an idea of life in which we are determined not by some kind of king or dictator, but in which individuals can determine themselves to the largest possible degree. And to me, this is something that this western world is still trying to embody and it’s a very valuable idea that we shouldn’t give up too early. And from this perspective, the US is a system of interleaving clubs and an entrepreneur is a special club founder.
Segment 1463: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9065, Text: It’s somebody who makes a club that is producing things that are economically viable. And to do this, it requires a lot of people who are dedicating a significant part of their life for working for this particular kind of club. And the entrepreneurs picking the initial set of rules and the mission and vision and aesthetics for the club and make sure that it works. But the people that are in there need to be protected if they sacrifice part of their life, there need to be rules that tell how they’re being taken care of even after they leave the club and so on. So there’s a large body of rules that have been created by our rule giving clubs and that are enforced bio enforcement collapse and so on. And some of these collapse have to be monopolies for game theoretic reasons, which also makes them more open to corruption and less harder to update.
Segment 1464: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9112, Text: And this is an ongoing discussion and process that takes place. But the beauty of this idea that there is no centralized king that is extracting from the peasants and breeding the peasants into serving the king and fulfilling all the walls like and an anal, but that there is a freedom of association and corporations are one of them. It’s something that took me some time to realize. So I do think that corporations are dangerous. They need to be protections against overreach of corporations that can do regular to recapture and prevent open source from competing with corporations by imposing rules that make it impossible for a small group of kids to come together to build their own language model.
Segment 1465: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9158, Text: Because open AI has convinced the US that you need to have some kind of FDA process that you need to go through that costs many million dollars before you are able to train a language model. So this is important to make sure that this doesn’t happen. So I think that open AI and Google are good things if these good things are kept in check in such a way that all the other collapse can still being founded and all the other forms of collapse that are desirable can still co-exist with them.
Segment 1466: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9184, Text: What do you think about Meta in contrast to that open sourcing most of its language models and most of the AI models it’s working on and actually suggesting that they will continue to do so in the future for future versions of llama for example, their large language model? Is that exciting to you? Is that concerning?
Segment 1467: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9207, Text: I don’t find it very concerning, but that’s also because I think that the language models are not very dangerous yet.
Segment 1468: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9215, Text: Yet?
Segment 1469: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9216, Text: Yes. So as I said, I have no proof that there is the boundary between the language models and AI, AGI. It’s possible that somebody builds a version of BBBAGI, I think, and falls in a algorithmic improvements that scale these systems up in ways that otherwise wouldn’t have happened without these language model components. So it’s not really clear for me what the end game is there and if these models can put force their way into AGI. And there’s also a possibility that the AGI that we are building with these language models are not taking responsibility for what they are, because they don’t understand the greater game. And so to me it would be interesting to try to understand how to build systems that understand what the greater games are, what are the longest games that we can play on this planet?
Segment 1470: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9270, Text: Games broadly, like deeply define the way you did with the games.
Segment 1471: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9275, Text: In the games theoretical sense. So when we are interacting with each other in some sense we are playing games, we are making lots and lots of interactions. And this doesn’t mean that these interactions have ought to be transactional. Every one of us is playing some kind of game by virtue of identifying these particular kinds of goals that we have or aesthetics from which we derive the goals. So when you say I’m Lex Fridman, I’m doing a set of podcasts, then you feel that it’s part of something larger that you want to build, maybe you want to inspire people, maybe you want them to see more possibilities and get them together over shared ideas. Maybe your game is that you want to become super rich and famous by being the best post cut caster on earth. Maybe you have other games, maybe it’s switches from time to time, but there is a certain perspective where you might be thinking, what is the longest possible game that you could be playing?
Segment 1472: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9324, Text: A short game is, for instance, cancer is playing a shorter game than your organism. Cancer is an organism playing a shorter game than the regular organism. And because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with the situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. And so ideally you want to, I think build agents that play the longest possible games and the longest possible games is to keep entropy at bay as long as possible by doing, while doing interesting stuff.
Segment 1473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9365, Text: But the longest, yes, that part, the longest possible game while doing interesting stuff and while maintaining at least the same amount of interesting.
Segment 1474: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9374, Text: Yes.
Segment 1475: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9374, Text: So complexity, so propagating.
Segment 1476: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9376, Text: Currently I am pretty much identified as a conscious being. It’s the minimal identification that I managed to get together, because if I turn this off, I fall asleep and when I’m asleep, I’m a vegetable. I’m no longer here as an agent. So my agency is basically predicated on being conscious and what I care about is other conscious agents. They’re the only moral agents for me. And so if an AI were to treat me as a moral agent that it is interested in coexisting with and cooperating with and mutually supporting each other, maybe it is I think necessary that AI thinks that consciousness is viable mode of existence and important.
Segment 1477: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9421, Text: So I think it would be very important to build conscious AI and do this as the primary goal. So not just say we want to build a useful tool that we can use for all sorts of things and then we have to make sure that the impact on the labor market is something that is not too disruptive and manageable and the impact on the copyright holder is manageable and not too disruptive and so on. I don’t think that’s the most important game to be played. I think that we will see extremely large disruptions of the status quo that are quite unpredictable at this point. And I just personally want to make sure that some of the stuff on the other side is interesting and conscious.
Segment 1478: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9462, Text: How do we ride as individuals and as a society, this wave disruptive wave that changes the nature of the game?
Segment 1479: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9470, Text: I truly don’t know. So everybody is going to do their best as always.
Segment 1480: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9473, Text: Do we build the bunker in the woods? Do we meditate more drugs? So mushrooms, psychedelics, I mean what, lots of sex? What are we talking about here? Do you play Diablo 4, I’m hoping that will help me escape for a brief moment. Play video games? What? Do you have ideas?
Segment 1481: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9496, Text: I really like playing Disco Ilysium. It was one of the most beautiful computer games I played in recent years and it’s a noir novel that is a philosophical perspective on western society from the perspective of an Estonian. And he first of all wrote a book about this bird that is a parallel universe that is quite poetic and fascinating and is condensing his perspective on our societies. It was very, very nice. He spent a lot of time writing it. He had, I think sold a couple thousand books and as a result became an alcoholic. And then he had the idea, or one of his friends had the idea of turning this into an RPG and it’s mind-blowing. They spent the illustrator more than a year just on making deep graph art for the scenes in between.
Segment 1482: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9552, Text: So aesthetically, it captures you, it pulls you in.
Segment 1483: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9554, Text: It’s stunning, but it’s a philosophical work of art. It’s a reflection of society. It’s fascinating to spend time in this world. And so for me it was using a medium in a new way and telling a story that left me enriched where when I tried Diablo, I didn’t feel enriched playing it. I felt that the time playing it was not unpleasant, but there’s also more pleasant stuff that I can do in that time.
Segment 1484: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9580, Text: So to you-
Segment 1485: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9580, Text: So ultimately I feel that I’m being gamed. I’m not gaming when I play it.
Segment 1486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9584, Text: Oh, the addiction thing.
Segment 1487: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9585, Text: Yes. I basically feel that there is a very transparent economy that’s going on the story of the Diablo’s brain dead. So it’s not really interesting to me.
Segment 1488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9594, Text: My heart is slowly breaking by the deep truth you’re conveying to me. Why can’t you just allow me to enjoy my personal addiction?
Segment 1489: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9603, Text: Go ahead. By all means. Go nuts. I have no objection here. I’m just trying to describe what’s happening. And it’s not that I don’t do things that I later say, oh, I actually wish I would’ve done something different. I also know that when we die, the greatest regret that people typically have on their deathbed, they say, “Oh, I wish I had spent more time on Twitter.” No, I don’t think that’s the case. I think they should probably have spent less time on Twitter. But I found it so useful for myself and also so addictive that I felt I need to make the best of it and turn it into an art form and thought form. And it did help me to develop something, but I wish what other things I could’ve done in the meantime. It’s just not the universe that we are in anymore. Most people don’t read books anymore.
Segment 1490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9651, Text: What do you think that means, that we don’t read books anymore? What do you think that means about the collective intelligence of our species? Is it possible it’s still progressing and growing?
Segment 1491: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9661, Text: Well, it clearly is. There is stuff happening on Twitter that was impossible with box. And I really regret that Twitter has not taken the turn that I was hoping for. I thought Elon is global brain pill and understands that this thing needs to self-organize and he needs to develop tools to allow the propagation of the self organization so Twitter can become sentient. And maybe this was a pipe dream from the beginning, but I felt that the enormous pressure that he was under made it impossible for him to work on any kind of content goals. And also many of the decisions that he made under this pressure seemed to be not very wise. I don’t think that as a CEO of a social media company, you should have opinions in the culture or in public. I think that’s very shortsighted. And I also suspect that it’s not a good idea to block [inaudible 02:41:58] of people over setting a Mastodon link.
Segment 1492: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9722, Text: And I think Paul made this intentionally, because he wanted to show Elon Musk that blocking people for setting a link is completely counter to any idea of free speech that he intended to bring to Twitter. And basically seeing that Elon was way less principled in his thinking there and is much more experimental and many of the things that he is trying, they pan out very differently in a digital society than they pan out in a car company, because the effect is very different, because everything that you do in a digital society is going to have real world cultural.
Segment 1493: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9758, Text: And so basically I find it quite regrettable that this guy is able to become defacto the Pope, right? Twitter has more active members than the Catholic Church and he doesn’t get it. The power and responsibility that he has and the ability to create something in a society that is lasting and that is producing a digital ago in a way that has never existed before, where we build a social network on top of a social network, an actual society on top of the algorithms. So this is something that is hope still in the future and still in the cards, but it’s something that exists in small parts. I find that the corner of Twitter that I’m in is extremely pleasant. It’s just when I take a few steps outside of it is not very wholesome anymore. And the way in which people interact with strangers suggest that it’s not a civilized society yet.
Segment 1494: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9809, Text: So as the number of people who follow you on Twitter expands, you feel the burden of the uglier sides of humanity.
Segment 1495: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9820, Text: Yes. But there’s also a similar thing in the normal world that is, if you become more influential, if you have more status, if you have more fame in the real world, you have, you get lots of perks, but you also have way less freedom in the way in which you interact with people, especially with strangers, because a certain percentage of people, it’s a small single digit percentage is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas.
Segment 1496: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9853, Text: But what if the technology enables you to discover the majority of people to discover and connect efficiently and regularly with the majority of people who are actually really good? I mean, one of my sort of concerns with a platform like Twitter is there’s a lot of really smart people out there, a lot of smart people that disagree with me and with others between each other. And I love that if the technology would bring those to the top, the beautiful disagreements like intelligence squared type of debates. There’s a bunch of, I mean, one of my favorite things to listen to is arguments and arguments like high effort arguments with the respect and love underneath it, but then it gets a little too heated, but that kind of too heated, which I’ve seen you participate in, and I love that with Lee Krono, with those kinds of folks. And you go pretty hard, you’ll get frustrated, but it’s all beautiful.
Segment 1497: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9907, Text: Obviously I can’t do this, because we know each other and Lee has the rare gift of being willing to be wrong in public. So basically has thoughts that are as wrong as the random thoughts of an average highly intelligent person. But he blurts them out while not being sure if they’re right. And he enjoys doing that. And once you understand that this is his game, you don’t get offended by him saying something that you think is so wrong.
Segment 1498: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9933, Text: But he’s constantly passively communicating a respect for the people he’s talking with and for just basic humanity and truth and all that kind of stuff. And there’s a self-deprecating thing. There’s a bunch of social skills you acquire that allow you to be a great debater, great argument, like be wrong in public and explore ideas together in public when you disagree. And if I would love for Twitter to elevate those folks, elevate those kinds of conversations.
Segment 1499: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=9963, Text: It already does in some sense. But also if it elevates them too much, then you get this phenomenon on clubhouse where you always get dragged on stage. And I found this very stressful, because it was too intense. I don’t like to be dragged on stage all the time. I think once a week is enough. And also when I met Lee the first time, I found that a lot of people seemed to be shocked by the fact that he was being very aggressive with their results, that he didn’t seem to show a lot of sensibility in the way in which he was criticizing what they were doing and being dismissive of the work of others. And that was not, I think, in any way a shortcoming of him, because I noticed that he was much, much more dismissive with respect to his own work. It was his general stance.
Segment 1500: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10011, Text: And I felt that this general stance is creating a lot of liability for him, because really a lot of people take offense at him being not like their Carnegie character who is always smooth and make sure that everybody likes him. So I really respect that he is willing to take that risk and to be wrong in public and to offend people. And he doesn’t do this in any bad way. It’s just most people feel or not all people recognize this. And so I can be much more aggressive with him than it can be with many other people who don’t play the same game, because he understands the way and the spirit in which I respond to him.
Segment 1501: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10048, Text: I think that’s a fun and that’s a beautiful game. It’s ultimately a productive one. Speaking of taking that risk, you tweeted, when you have the choice between being a creator, consumer, or redistributor, always go for creation. Not only does it lead to a more beautiful world, but also to a much more satisfying life for yourself. And don’t get stuck preparing yourself for the journey. The time is always now. So let me ask for advice. What advice would you give on how to become such a creator on Twitter in your own life?
Segment 1502: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10084, Text: I was very lucky to be alive at the time of the collapse of Eastern Germany and the transition into Western Germany and me and my friends and most of the people I knew and were East Germans and we were very poor, because we didn’t have money and all the capital was western in Germany and they bought our factories and shut them down, because they were mostly only interest in the market rather than creating new production capacity. And so cities were poor and then this repair and we could not afford things and I could not afford to go into a restaurant and order a meal there. I would have to cook at home. But I also thought, why not just have a restaurant with my friends? So we would open up a cafe with friends and a restaurant and we would cook for each other in these restaurants and also invite the general public and they could donate.
Segment 1503: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10136, Text: And eventually this became so big that we could turn this into some incorporated form and it became regular restaurant at some point. Or we did the same thing with the music movie theater. We would not be able to afford to pay 12 marks to watch a movie, but why not just create our own movie theater and then invite people to pay and we would rent the movies for in a way in which a movie theater does, but it would be a community movie theater that which everybody you wants to help can watch for free and build this thing and renovates the building.
Segment 1504: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10171, Text: And so we ended up creating lots and lots of infrastructure. And I think when you’re young and you don’t have money, move to a place where this is still happening. Move to one of those places that are undeveloped and where you get a critical mass of other people who are starting to build infrastructure to live in. And that’s super satisfying, because you’re not just creating infrastructure, but we are creating a small society that is building culture and ways to interact with each other. And that’s much, much more satisfying than going into some kind of chain and get your needs met by ordering food from this chain and so on.
Segment 1505: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10207, Text: So not just consuming culture, but creating culture.
Segment 1506: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10210, Text: Yes. And you don’t always have that choice. That’s why I preface that when you do have the choice and there are many roles that need to be played, we need people who take care of the distribution in society and so on. But when you have the choice to create something, always go for creation, it’s so much more satisfying. And it also is, this is what life is about, I think.
Segment 1507: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10228, Text: Yeah. Speaking of which, you retweeted this meme of a life of philosopher in a nutshell, it’s birth and death and in between it’s a chubby guy and it says why though? What do you think is the answer to that?
Segment 1508: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10249, Text: Well, the answer is that everything that can exist might exist. And in many ways you take an ecological perspective the same way as when you look at human opinions and cultures. It’s not that there is right and wrong opinions when you look at this from this ecological perspective, but every opinion that fits between two human years might be between two human years. And so when I see in a stranger opinion on social media, it’s not that I feel that I have a need to get upset, it’s often more that, “Oh, there you are.” And your opinion is incentivized, then it’s going to be abundant. And when you take this ecological perspective also on yourself and you realize you’re just one of these mushrooms that are popping up and doing this thing, and you can, depending on where you chose to grow and where you happen to grow, you can flourish or not doing this or that strategy. And it’s still all the same life at some level.
Segment 1509: Speaker: , Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10303, Text: It’s all the same experience of being a conscious being in the world, and you do have some choice about who you want to be more than any other animal has. That to me is fascinating. And so I think that rather than asking yourself what is the one way to be, think about what are the possibilities that I have? What would be the most interesting way to be that I can be?
Segment 1510: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10326, Text: Because everything is possible. So you get to explore this.
Segment 1511: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10328, Text: It’s not everything is possible. Many things fail. Most things fail, but often there are possibilities that we are not seeing, especially if we choose who we are.
Segment 1512: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10341, Text: To the degree we can choose. Joscha you’re one of my favorite humans in this world, consciousness to merge with for a brief moment of time. It’s always an honor. It always blows my mind. It will take me days, if not weeks, to recover, and I already miss our chats. Thank you so much. Thank you so much for speaking with me so many times. Thank you so much for all the ideas you put out into the world, and I’m a huge fan of following you now in this interesting, weird time we’re going through with AI. So thank you again for talking today.
Segment 1513: Speaker: Joscha Bach, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10384, Text: Thank you, Lex, for this conversation. I enjoyed it very much.
Segment 1514: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=e8qJsk1j2zE&t=10388, Text: Thanks for listening to this conversation with Joscha Bach. To support this podcast, please check out our sponsors in the description. And now let me leave you with no words from the psychologist, Carl Jung. “One does not become enlightened by imagining figures of light, but by making the darkness conscious. The latter procedure, however, is disagreeable and therefore not popular.” Thank you for listening and hope to see you next time.
Segment 1515: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=0, Text: Regardless of whatever was written in these books that were written thousands and thousands of years ago, the fact of the matter is no one has a right to go on slaughtering people, removing them from their homes and then continuing to live in their homes, continuing to drink coffee on their balconies decades and decades later, with no shame, with no introspection, with no reflection. No one has the right to do that. No one has the right to keep an entire population of people in a cage, which is what’s happening to people in the West Bank who have no freedom of movement, which is what’s happening in Gaza, which is blockaded to water, air, and land, and is deemed uninhabitable by human rights organizations like the UN. No one has a right to do that.
Segment 1516: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=52, Text: The following is a conversation with Mohammed el-Kurd, a world-renowned Palestinian poet, writer, journalist, and an influential voice speaking out and fighting for the Palestinian cause. He provides a very different perspective on Israel and Palestine than my previous two episodes with Benjamin Netanyahu and Yuval Noah Harari. I hope his story and his words add to your understanding of this part of the world as it did to mine. I’ll continue to have difficult long-form conversations such as these always with empathy and humility but with backbone. And please allow me to briefly comment about criticisms I receive of who I am as an interviewer and a human being. I am not afraid to travel anywhere or challenge anyone face-to-face, even if it puts my life in danger. But I’m also not afraid to be vulnerable, to truly listen, to empathize, to walk a mile in the well-worn shoes of those very different from me. It’s this latter task, not the former one, that is truly the most challenging in conversations and in life, but to me, it is the only way. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Mohammed el-Kurd.
Segment 1517: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=138, Text: Tell me about Sheikh Jarrah, the neighborhood in East Jerusalem where you grew up.
Segment 1518: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=142, Text: Sheikh Jarrah has, in a way, a typical neighborhood despite the absurd reality that surrounds it. It’s a typical neighborhood in terms of Palestinian neighborhoods. It’s one that is threatened with colonialism, with settler expansion, and with forced expulsion, and it has been that way since the early ’70s. My family, like all of the other families in Sheikh Jarrah, were expelled from their homes in the Nakba in 1948, and they were forced out by the Haganah and other Zionist parallel militaries that later formed the Israeli military, and they were driven to various cities. My grandmother moved to city to city, and she ended up in Sheikh Jarrah in 1956. Sheikh Jarrah was established as a refugee housing unit by the United Nations and by Jordinian government, which had control over that part of Jerusalem at the time. And then people lived there harmoniously. They were all from different parts of Palestine, and they managed to rebuild their lives after the first expulsion.
Segment 1519: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=212, Text: And then in the ’70s, you had settler organizations, many of whom were registered here in New York and in the United States, claiming our houses and our lands as their own by divine decree. Obviously, because the judges are Israeli and the laws were written by Israeli settlers and the whole judiciary was established atop the rubble of our homes and villages, we had no real pull in the courts. The Israeli courts would look at the Israeli documents, which we argue are falsifies and fabricated, and they would take them at face value without authentication, and they refused to look at our documents. They refused to look at the documents from the Jordanian government, the documents from the UN, the documents from the Ottoman archives. So you already have this kind of asymmetry in the court that, for any person with common sense, would lead you to believe that this is not in fact a legal battle or a real estate dispute, as Israeli Ministry of Foreign Affairs likes to frame it, but rather a very, very political battle.
Segment 1520: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=277, Text: One that is about social engineering, one is about demographics, one that is about removing as many Palestinians as possible from occupied Jerusalem. So we did what all Palestinian families in Jerusalem do when they’re faced with this kind of threat, and we bought time. We pleaded and pleaded and appealed the courts and appealed the cases, and we got over 50 expulsion orders. In 2009, rifle-wielding settlers accompanied by police and Israeli military came over and shoved our neighbors outside of their home around 5:00 AM. It was the most brutal, violent thing I’d seen as a child at the time, and I didn’t realize that my turn was coming, my turn was next. They threw them out in the middle of the night with sound bombs and rubber bullets, and they had to live in tents on the street for many, many months and even lived in our front yards for a few months and lived in their cars.
Segment 1521: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=341, Text: Can you linger on that process? 2009, you said 50 expulsion orders. What was happening?
Segment 1522: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=348, Text: Between the ’70s and 2009, there had been many, dozens of expulsions orders against us and against many other families in the neighborhood, 28 other family, 28 families in total actually. And in 2008, 2009, the first wave of expulsions finally happened. It actually began with [inaudible 00:06:09] el-Kurd. We’re not related, but we live on the same street in the same neighborhood. She was thrown out of her home. Her husband, an elderly man, also named Mohammed el-Kurd, was pronounced dead on the spot. He had a stroke and died. Israeli soldiers pulled him out of his home while he was urinating and threw him into the streets, and he died. A few months later, Darawi and Hannun families, not a clan, but in Palestine you have sometimes a building that contains multiple brothers and their wives, each have little apartments, Darawi and Hannun family is about 35 people, were thrown out in the middle of the street right across from us.
Segment 1523: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=407, Text: And then by the end of 2009, I had come home from school to find all of my furniture scattered across the length of the street, and I saw the settlers, many of whom had American accents living in our house. And their justification for this, their reasoning for this is divine decree. This is what God wants. This is the promised land. This is so-and-so, as if God is some kind of real estate agent. So they took over half of our home, and we continued to be in courts for the following decade. I was still a child and I had broken English, and I was talking to all of these diplomats and all of these journalists who would subjugate me, subject me to their racism and biases and so on and so forth. And I had to prove my humanity time and time again. And I had to do all of this, all with broken English. And we were lucky, even if we got a quote in the article written about us by The Times or so on and so forth.
Segment 1524: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=473, Text: Move forward to 2020, I was in New York City studying a master’s degree, getting a master’s degree. And my father calls me and he tells me, “We have yet another expulsion order,” and we decided to launch a campaign. It was quite ambitious at the time, but the whole objective of the campaign was to demystify what is happening because it’s reported on in the news, it’s reported on around the world as this real estate dispute, as these evictions, which was not really what’s happening. Evictions do not entail a foreign army in an occupied territory, forcibly removing you out of your home. So I came home from New York, and we launched a campaign which turned into a global success.
Segment 1525: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=520, Text: And I believe it was a global success because, finally, the images on the screen matched the rhetoric that was being said. It wasn’t so confusing or complicated anymore. All of this asymmetry was pronounced and articulated in a way that any of you, be it in Alabama, be it in New York, be it in Egypt, was able to understand the asymmetry of the judicial system and the agenda of colonialism that was taking place here. And due to immense international and diplomatic pressure from all over the world, even the United States, the Israeli Supreme Court was forced to cancel all of the eviction orders in Sheikh Jarrah until further notice. This, I consider, was a small victory because obviously we are still at risk of losing our homes once they decide to do the land registry, which we can get into a little bit later if you’d like.
Segment 1526: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=579, Text: But nonetheless, it was something that we haven’t seen before. And the fact that the Supreme Court canceled all of these dozens and dozens of fast eviction orders, it set a precedent. And it also proved that this was a political battle, not a legal one.
Segment 1527: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=594, Text: So let’s just add a little more detail to the people who are not familiar with the story, with the region, with the evictions, with the courts. So first of all, [inaudible 00:10:07] your eyes in East Jerusalem. Maybe you can say what is Jerusalem, where is it located, what are we talking about in terms of regionally and, second, what kind of people live there. So if you could talk about the Palestinian people. We should also make clear that these evictions is literally people living in homes, and their homes are taken away from them. I suppose technically, it’s legal evictions, but you’re saying that there’s asymmetry of power in the courts where the legal is not so much legal, but is politically and maybe even religiously based.
Segment 1528: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=653, Text: Yeah, I mean, the most important context here is that oftentimes Americans think that Israel and Palestine are some kind of two neighboring countries that live next to each other, and they are at war. But the fact of the matter is Palestinian cities exist all over the country, and it’s just one country, it’s just one infrastructure, and Israel is literally on top of Palestine. It was established on top of our villages in the late ’40s. Now, according to international law, the eastern part of Jerusalem is under occupation. So Israeli presence and jurisdiction over the area is completely illegitimate. They say the evictions are legal because the settlers write their law, so obviously they’re going to allow settlements to expand. But according to international law, even US policy, Israel occupies the eastern part of Jerusalem. Jurisdiction there is illegitimate. We shouldn’t even be going to their courts in the first place, but we have no other option.
Segment 1529: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=722, Text: We’re talking about Sheikh Jarrah, we’re talking about Jerusalem, we’re talking about generations and generations and generations of people who have lived there for the longest time, who now, even though… For example, me, I don’t have a citizenship. I’m a resident, a mere resident, I have a blue ID card even though my grandmother and my grandfather were born in Jerusalem, their grandparents were born in Jerusalem, even though we’ve lived there for generations. But Palestinians in Jerusalem, we are not citizens. We’re just mere residents. Same thing with residents of the occupied Syrian Golan. They are not citizens. They are just residents in their own hometowns. This is an important piece, but all of these gets convoluted and lost in translation. I would argue, a lot of the time, it’s dubious, it’s malicious, the fact that these little pieces of context that frame the entire story get lost.
Segment 1530: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=783, Text: I’ll talk to you about something else. Just 10 minutes across from my neighborhood, Sheikh Jarrah, there’s another neighborhood called Silwan. And the people in Silwan are also threatened with expulsion, but not through evictions, but through home demolitions. And if you look at American media or Israeli state media, you would read the headlines, “Palestinians living in homes built illegally are going to face… their homes are going to be torn apart.” What these headlines don’t tell you, most of the time, the substance doesn’t tell you that Palestinians seldom ever get building permit applications. In fact, recently, a spokesperson for the Israeli military confirmed that was 95% of building permits applications submitted by Palestinians in East Jerusalem and the West Bank are rejected by the Israeli authorities.
Segment 1531: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=833, Text: And to make this even more absurd, the guy, the councilman who is responsible for rejecting and accepting building permit applications, his name is Yonatan Yosef, and he’s an activist in the settler movements and he’s a Jerusalem council member, last week, following the expulsion of Sub Laban family in the old city of Jerusalem, he posted to his official Facebook account, “Nakba now,” demanding a second Nakba, promising another Nakba. He has done so on many occasions, he has chanted with a megaphone, just a few months ago, walking down the street in my neighborhood chanting, “We want Nakba now.” This is a man who has vandalized our murals, who has screamed Islamophobic slurs. This is literally a man in the government making these decisions. And this is similar to Masafer Yatta in the south of Hebron Hills. For those who don’t know, it’s a place in the occupied West Bank where Bedouin and cave dweller Palestinians have lived for generations, they have cultivated the land. And recently, they were expelled from their homes. Over a thousand people were expelled from their remote small villages.
Segment 1532: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=911, Text: Again, if you’re reading American media, it would say, “Palestinians living in firing zones were removed because they’re living in a military zone.” What these media reports will not tell you that, in the ’80s, the Israeli government purposefully classified many lands in the occupied West Bank as firing zones, as off-limit military zones for the sole purpose of expelling the residents, and this is not some kind of conspiracy theory. This is declassified information that was released from the Israel’s State Archive that was later reported on by our audits. Also, these reports will not tell you that the judge who rules on whether these people continue to live under homes or not is himself a settler in the West Bank. And I’m not even talking about a loose definition of a settler, but according to international law, this is a settler living illegally in an illegal settlement in the occupied West Bank. This is the judiciary that we deal with, which is hilarious considering how it’s being reported on in American media recently as some kind of beacon of progress and democracy that new government is trying to undermine.
Segment 1533: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=980, Text: So there’s no representation in the courts for the Palestinian people?
Segment 1534: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=983, Text: I mean, we have lawyers, but no, there is no… In fact, for Palestinians with Israeli citizenships for example, there’s over 60 laws that specifically and explicitly discriminates against them.
Segment 1535: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=996, Text: So again, it’s technically legal, the evictions and the demolitions.
Segment 1536: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1002, Text: Yeah, so was Jim Crow was legal also.
Segment 1537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1006, Text: When something is legal, it can also still be wrong.
Segment 1538: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1010, Text: Absolutely. History has shown us time and time again that legality does not necessarily mean morality. The law is a bloodbath in many ways. It has been used and abused to facilitate the most horrendous atrocities. In the case of the Palestinians, the law has served to facilitate and bureaucratize our ethnic cleansing.
Segment 1539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1041, Text: Do you think there’s people, judges, and just people in power in the judiciary that have hate for the Palestinian people?
Segment 1540: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1050, Text: I mean, I’m not really… Yeah, I mean, the easy, simplistic answer is yes, but I don’t really care about the contents of their hearts. What I care about, the policy they enact, where the laws they write and enact are hateful, demolishing a person’s home. So you can have somebody from Long Island, New York who’s fleeing fraud charges, this is the case in my house, live in their front yard, that’s hateful. So I don’t need confirmation. This is something we see a lot actually. Palestinians and people who are pro-Palestine and just people who want to make a difference in how this cause is represented, we often run for the first opportunity to cite an Israeli being hateful. The last Israeli prime minister said that he has killed many Arabs and that he has no qualms with it. Netanyahu has said a slew of racist, hateful things. Jabotinsky, the pioneer of Zionism, Herzl, one of the pioneers of Zionism, all have said horrible, hateful things.
Segment 1541: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1123, Text: We also cannot wait to cite a confession from a former Israeli soldier who’s guilty conscience is keeping them up at night. And we use all of these confessions or slip ups as evidence to prove that this is a racist country that is enacting racist acts, but we don’t need this because the material proof is on the ground. You see it in the policies that are enacted. You see it in how this regime has behaved for the past 75 years. I don’t need confessions from the likes of Netanyahu to understand that his heart is full of hate.
Segment 1542: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1167, Text: So if you could return to 1948 and describe something that you’ve mentioned, the Nakba, which means catastrophe in Arabic. What was this event? What was this displacement and dispossession of Palestinians in 1948?
Segment 1543: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1183, Text: Well, May 15th, 1948 is commemorated every year as the anniversary of the Nakba, but I would even argue anything, this is like a… A very popular idea is that the Nakba did not begin or end in 1948. The ’48 was rather a crystallization of the Zionist enterprise in Palestine. What happened was is that many Zionists paramilitaries that, again, today merged and made the Israeli army, which calls itself the Israeli Defense Forces even though they’re literally always the aggressor, committed atrocities and massacres, and they destroyed over 500 villages, they killed over 15,000 people, they forced a very large portion, a majority of the Palestinian population to flee their homes. And this was the near total destruction of Palestinian society that continues on to this day. We refer to it as the ongoing Nakba. And you see it in Sheikh Jarrah, you see it in Silwan, you see it in Harran, and all of these people losing their homes.
Segment 1544: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1264, Text: In many cases, time and time again, I grew up and my grandmother told me the stories about the Nakba. She told me stories about her neighbors who were running away in a panic, and they had mistaken a pillow for their offspring and they just took it with them. And they realized later that they forgot their child and they came back for it. Many, many people who were separated from their… My grandmother herself, she lost her husband for a few months, for nine months. He wasn’t imprisoned by the Israelis. She told me all of these stories, and she wasn’t just reminiscing about them. She was letting me know that this is still happening and I didn’t need to grow up that old to see it happening in my own front yard, to see that expulsion happen in the same fashion. She’s talked about it.
Segment 1545: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1317, Text: But now they have replaced their artillery with the judiciary. They have replaced the slashing of the pregnant women’s bellies in the Deir Yassin massacre with laws that say, “You’re not legally allowed to be here. We’re going to kick you out of your home,” and it’s happening, and it has happened in broad daylight. One piece of context for the listener who is not familiar with the Nakba is the Balfour Declaration, which was a promise, quote-unquote, “promise” made by the British to the Zionist movement in 1917, committing to the establishment. I’m quoting, I think word for word, “committing to the establishment of a Jewish state in Palestine”, as if Palestine was the British to give away. And there was this whole movement that called for colonization of Palestine.
Segment 1546: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1381, Text: And there were different schools of thought in Zionism. People like Zangwill said that this was a country without a people, and Palestinians who have existed there, who have cultivated the lands, who had diverse cultural and religious and political practices, they were completely erased. And other people like Jabotinsky were a lot more explicit and a lot more honest and said that, “We need to fight the Palestinians because they loved their land, much like the Red Indians loved their lands,” and he had a paper called the Iron Wall: Colonization of Palestine Must Go Forward. And all of these schools of thoughts were then shopping around for imperial support for their cause. They tried to get support from the Ottoman Empire, they tried to get support from Germany, this is in the 1800s, and then they got support from the United Kingdom. A great book to recommend is The Hundred Years’ War on Palestine by Rashid Khalidi, traces the Zionist movement, oftentimes in the Zionists’ own words.
Segment 1547: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1464, Text: So today what we’re seeing is a continuation. And people like Jabotinsky, who are profoundly and explicitly racist, who have called for genocide, who have called the Palestinians barbaric, who have said and done racist things… Jabotinsky also was the founder of the Irgun, one of the other militias that later merged to become the Israeli army, which was responsible for the Deir Yassin massacre, which was responsible for the bombing of the King David Hotel, this is a person who is still celebrated in Israeli society. There are streets named after him, and Netanyahu just two weeks ago, if I’m not mistaken, honored him in a public celebration. So this is Zionism. It’s not even through my own words.
Segment 1548: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1514, Text: What do you say to people that describe Israel as having historical right to the land, so if you stretch, not across decades, but across centuries into the past?
Segment 1549: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1527, Text: This kind of thing is a red herring. It’s a distraction because you don’t think of any state as having rights. But there is this exceptionalism to the Israeli regime where it has a right to defend itself, and it has a right to the land, and it has a right to shoot 14-year-old boys because it thought they had a knife in their pockets. A lot of the time, people cite the Torah and cite religious books. Sometimes Zionist will even say like, “Read the Quran, and blah, blah, blah.”
Segment 1550: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1556, Text: Regardless of whatever was written in these books that were written thousands and thousands of years ago, the fact of the matter is no one has a right to go on slaughtering people, removing them from their homes and then continuing to live in their homes, continuing to drink coffee on their balconies decades and decades later with no shame, with no introspection, with no reflection. No one has the right to do that. No one has the right to keep an entire population of people in a cage, which is what’s happening to people in the West Bank who have no freedom of movement, which is what’s happening in Gaza, which is blockaded to water, air, and land, and is deemed uninhabitable by human rights organizations like the UN. No one has a right to do that.
Segment 1551: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1608, Text: Do you have hate in your heart for Israel?
Segment 1552: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1611, Text: Why does that matter?
Segment 1553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1615, Text: As one human being to another, you’re describing quite brilliantly that the contents of people’s hearts don’t matter as much as the policies and the contents of the courts and the laws and what actually is going on on the streets in terms of actions, but this is also a human story. I feel like, at the core of the situation here is hate or maybe inability for some group of humans to see the humanity in another group of humans. So it’s important here to talk about the contents of hearts, if we were to think about the long-term future of this.
Segment 1554: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1667, Text: Yeah, I mean, I would be concerned actually if I didn’t feel some kind of way in my heart. I would be concerned for my own dignity. Because the people who revolt, the people who are angry, the people who refuse to live under occupation know that they deserve better. People start revolutions not because of some kind of cultural phenomenon, not because of some kind of desire, but because they cannot breathe, because they cannot breathe, they cannot live. They are living under excruciating circumstances. Palestinians, I don’t know, I don’t know how many Palestinians I’ve interacted with, but we are some of the most wonderful people. I mean, not all of us, I think some of us are insufferable, but most of us. Most of us, we’re very, very hospitable. We’re very hospitable. Even in the early correspondence between the mayor of Jerusalem and Herzl, who wrote The Jewish State, the generosity through which the Palestinian mayor was talking to Herzl, who was plotting to take over his land, is impressive and, at the same time, heart-wrenching. But I personally think there’s a lot of dignity in negating your oppressor. And I think it would be ridiculous today if we look back at Jim Crow, for example, and we ask the person who’s lived under Jim Crow if they have hate in their heart for Jim Crow, as if that’s not the absolutely logical and natural sentiment to feel.
Segment 1555: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1770, Text: In Rifqa, you wrote, my father told me, “Anger is a luxury we cannot afford. Be composed, calm, still, laugh when they ask you, smile when they talk, answer them, educate them.” So let me linger on this. Is there anger in there, in your heart? And does it cloud your judgment?
Segment 1556: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1790, Text: Does it cloud my judgment? I don’t think so. I think our campaign to defend our homes was particularly successful because it was honest to what was happening on the ground, because it refused to follow the strategy that we have used in our advocacy before, where we shrink ourselves and we turn the other cheek and we try to convince American lawmakers and American diplomats and journalists of our humanity because we wait for their approval. I was 14 years old when I first flew to Congress to speak to Congress people and to speak at the European Parliament. At the time, I thought, “Wow, I must be such a brilliant 14-year-old for them to have me here.” Looking back, I didn’t know what I was talking about. I had horrendously broken English, and I didn’t have any talking points. And I came to realize that the reason why we send our kids with their PowerPoints to the hill is because of the racism and the hatred that lingers inside the hearts of American politicians who refuse to sit on the table with Palestinian adults as equals.
Segment 1557: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1868, Text: And so we resort to sending our kids who will not threaten and who will not trigger the biases they have against Muslims and Arab people, which Palestinians, even though we’re not all Muslim, are racialized as Muslim. And this is why we emphasize the deaths of women and children as though the deaths of our men does not counter, does not matter. All of these things I think the new generation of Palestinians is rebelling against. I think words like… I think it’s loaded, it’s loaded language, anger and angry and hate and so on and so forth, because it mischaracterizes people and it kind of delegitimizes them a little bit.
Segment 1558: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1913, Text: I think the real anger is the bulldozer bulldozing through my house. I think the real anger is the 18-year-old soldier who refuses to see me as a human being and strip searches me every chance they get. That’s where the real anger lies. And I’m quite honestly proud of our unabashedness and our refusal to bow our heads or bury our heads in the sand. I think that’s the only way forward.
Segment 1559: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1945, Text: So anger, or whatever it is, is a fuel for action.
Segment 1560: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1950, Text: Absolutely. And it has been throughout history, it has been.
Segment 1561: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1956, Text: How much of this tension is religious in the practical aspects of the courts and the evictions and the demolitions? You mentioned something, divine decree, how much underneath of it do you feel the division over religious text and religious beliefs?
Segment 1562: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=1980, Text: It’s convenient to market what’s happening in Palestine as a religious conflict because it allows the listener the luxury of believing that this is an ancient, complicated thing that stretches thousands and thousands of years ago. But the fact of the matter is the people who invented Zionism, who pioneered the Zionist movement, who called for immigration and settling into Palestine, a lot of them were atheists. A lot of them were not religious at all. And the leaders of the Israeli state today, a lot of them are atheists and a lot of them are secular and so on and so forth. It’s easy to say that this is about Muslims and Jews fighting over the land and so on and so forth, but it’s not. It’s about the land itself and it’s about people being forced out of their homes.
Segment 1563: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2040, Text: Benjamin Netanyahu said, “Anti Zionism is anti-“
Segment 1564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2040, Text: Benjamin Netanyahu said, “Anti-Zionism is anti-Semitism.”
Segment 1565: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2044, Text: Of course he said that.
Segment 1566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2047, Text: Do you disagree?
Segment 1567: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2049, Text: Absolutely, I disagree.
Segment 1568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2051, Text: What’s the gap between anti-Zionism and anti-Semitism, those who are against the policies of Israel versus those who are against the Jewish people?
Segment 1569: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2065, Text: I watched the first 20 minutes, and then I couldn’t do it anymore, but I watched. And then what was interesting about Netanyahu is that he said, being anti-Zionist is like saying, I’m okay with the Jews, I just don’t believe the Jews have a right to form their own state. That’s like saying, I’m okay with Americans, I’m just not okay with Americans having their own state. And there is so much wrong with that statement in the sense that Jewish people are a religious group and being an American is a nationality that consists of a diversity of religions and so on and so forth, first of all. And the second thing that’s wrong with that statement is the whole idea that states somehow have a right to exist or whatever. It’s such a distraction. You have people getting shot in the street. You have millions and millions of people beseeched, you have people losing their homes. You have people who are held in Israeli prisons without trial or charged indefinitely, but the conversations that are being held on the Hill, the conversation that are being held on CNN are does Israel has a right to exist or why would you negate Israel is having a right to exist? That’s one.
Segment 1570: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2144, Text: Now, of course, and I just find it’s ridiculous again, that opposing a secular political movement that was explicitly colonialist, expansionist, exclusive and racist through the words of its own authors is somehow… And also again, opposing such a political movement that is quite young and quite recent is somehow equivalent to opposing a religion that is thousands and thousands of years old. But it is convenient again, for Israeli politicians to frame us who oppose Zionism, a form of racism and bigotry, as anti-Semites. But I can guarantee you Benjamin Netanyahu has no problem with anti-Semitism. This is the same man who has no problem getting on stage and shaking hands with Pastor John Hagee, doing web webinars with Pastor John Hagee. For those who don’t know, Pastor John Hagee is the founder of Christians United for Israel, who has said on multiple occasions that Hitler was a hunter who was sent to hunt the Jews. Who said on multiple occasions that Jewish people are going to perish in hell. All of this is verifiable by Google, and this is one of the Israeli regime’s closest allies.
Segment 1571: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2231, Text: So the Israeli regime does not have a problem with anti-Semites when it serves its interests. It has a problem… If you look at evangelicals or Christian Zionism at large, anti-Semitism lies at the heart of Christian Zionism. It’s the idea that we want to drive all of the Jews outside of the United States so that Armageddon could happen, or whatever the fuck. This accusation has been a muzzle, it has been used as a muzzle to silence political opposition and to stifle political advocacy for the liberation of Palestine. And a lot of the time people get caught up in denouncing it and in justifying themselves and disclaimers and so on and so forth that you lose the point, that you’re distracted from the focal point, that is there is an ongoing colonialism happening where people every single day are killed. I cannot keep count. This morning a kid was shot in Palestine. It’s embarrassing even for me that I don’t even know the numbers here, but this muzzle has been effective and I think the only righteous option is to oppose these labels, these smear campaigns that target us.
Segment 1572: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2316, Text: I myself have been labeled an anti-Semite by the ADL. And if you want to talk about that at surface level, people will say, wow, the ADL, Anti-Defamation League condemned you. But people do not look at the history of the Anti-Defamation League, do not look at the present of the Anti-Defamation League, the fact that they are the largest non-governmental police training department in the country where they train police in racial profiling and militarism. The fact that they have historically and continued to have engaged in surveillance on Black liberation movements, on anti-Apartheid South African activists. Most recently in Charlottesville, when White supremacists were marching and chanting anti-Semitic shit, the ADL advised local police departments to spy on the Black organizers opposing the White supremacists. This is again, all verifiable on the internet, go to droptheadl.org.
Segment 1573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2386, Text: So the ADL does not alleviate the hate in the world as it probably is designed to do?
Segment 1574: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2398, Text: No. It’s a guise, I don’t think the Apartheid Defense League is really our most progressive…
Segment 1575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2406, Text: That’s what it stands for.
Segment 1576: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2407, Text: In case you didn’t know, now you know.
Segment 1577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2412, Text: If we could just linger on this idea of anti-Semitism, there’s quite a bit of anti-Muslim sentiment in the United States, especially after 9/11. I’ve spoken to people about that. There’s also anti-Jewish, anti-Semitism sentiment in the United States, but also throughout human history. What do you make about this kind of fact of human nature that people seem to hate Jews throughout history, especially in the 20th century, especially with Nazi Germany? What are your in general thoughts about the hatred of the Jewish people?
Segment 1578: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2457, Text: I think it’s obviously wrong. I don’t know. It’s this idea that I even have to clarify what I think about anti-Semitism that doesn’t sit well with me. I think it’s completely unfortunate and wrong that Jewish people have been persecuted across history.
Segment 1579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2473, Text: So one of the criticisms, I think I read the ADL are making this criticism of you, is maybe you’ve tweeted a comparison between Israel and Hitler, and thereby diminishing the evil that is Hitler. What would you say to that?
Segment 1580: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2494, Text: Amy Cesaire talks about this a lot, the exceptional of Hitler. Hitler is a deplorable, I don’t know, condemnable, rotten racist, horrible human being that belongs in the depths of hell. Obviously that goes without saying, but I’m allowed analogy and I’m allowed to say whatever I want. Now, I don’t necessarily think that that such an analogy is a good strategy to have, but at the time, the context came in 2021 when Israeli soldiers and policemen and settlers were literally burning down our neighborhood, again, verifiable by Google, and I tweeted it. And also, I remember I tweeted something, “I hope every single one of them dies.” And to this day, this is some kind of gotcha for me, as if I should have tweeted like, oh, here’s the apple pie for every single soldier that’s throwing tear gas in my house. There is such an exceptionalism when it comes to Palestinians. We’re not allowed analogy, we’re not allowed expression. We’re not allowed armed resistance, we’re not allowed peaceful resistance. We’re not allowed to boycott because that’s Anti-Semitic. We’re not allowed to do anything, so what are we allowed? If I can’t boycott, and that’s against American law now to boycott, and if I can’t pick up a rifle because that’s against the law, and if I can’t even tweet my frustration out, what am I allowed to do? And maybe Netanyahu can send me a manual with all he’s happy with.
Segment 1581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2601, Text: So you’ve spoken about the taking of homes, the IDF killing civilians, killing children. What about the violence going the other direction, Israelis being killed in part by terrorist action?
Segment 1582: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2619, Text: Well, it depends on how you define terrorism. Across history, one man’s freedom fighter is another man’s terrorist. I don’t necessarily subscribe to the definition of terrorism. If a foreign army is in my neighborhood, which it’s not supposed to be, and they’re shooting live ammunition at my house, I’m allowed to do what I’m allowed to do. And again, this is yet another case of Palestinian exceptionalism because when it comes to Ukraine, people have no problem seeing Ukrainians defending their homes, seeing Ukrainians dying for their land, seeing Ukrainians making makeshift Molotov on Sky news. Sky News was running Molotov making cocktails. The New York Times ran an article interviewing Ukrainian psychologist who said, I’m paraphrasing, but he said, hatred for all Russians is actually a healthy outlet. The New York Post ran a headline championing, quote unquote, heroic Ukrainian suicide bomber. These things we would not even dream of as Palestinians.
Segment 1583: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2694, Text: We are told to turn the other cheek time and time again, we’re told that we should continue living inside these enclaves without access to clean water, without access to the right to movement, without access to building permits, without our natural right to expansion, without a guarantee that if we leave our house we’re not going to be shot. And we’re supposed to not do anything about it. That is absurd. Any person watching this understands this completely. People understand that if somebody is attacking your home, you’ll fight back. If somebody is attacking your family, you fight back. That is not… But again, who gets to call who a terrorist? Who gets to define terrorism? This is all about who has power. Who gets to write these laws? Who gets to write these definitions? Why is it that American actions in Iraq is not called terrorism by American politicians? Violence is like this mutating concept, and it takes on many shapes and forms. And if it’s in a uniform, if it speaks in English, if it has blonde hair, it’s somehow acceptable, it’s okay. We make movies about it. We sell out tickets about it, we make games about it. But if it’s without a uniform, it’s if it has a thick accent, if it has a beard, that’s condemnable, that’s wrong, that’s terrorism.
Segment 1584: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2788, Text: Do you think violence is an effective method of protest and resistance in general?
Segment 1585: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2793, Text: In general, I think it has been, but I believe in fighting on all fronts. I don’t think violence alone is going to bring about change. I think there’s so much to do in culture and in shifting public opinion, there’s so much to do in media and fighting back against media. Erasure and censorship, there’s so much to do diplomatically and politically, and I think I would be naive if I don’t take the power imbalance into consideration. One side has makeshift weapons and the other side is one of the most sophisticated armies in the world, so I don’t know how effective violence could be in this case.
Segment 1586: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2839, Text: But if you look at the flip side, do you see the power of nonviolent resistance? So Martin Luther King, Gandhi, the power of turning the other cheek, you spoke negatively about turning the other cheek.
Segment 1587: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2852, Text: Yeah.
Segment 1588: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2854, Text: So I sense that doing so has not been effective for the Palestinian people.
Segment 1589: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2860, Text: We’ve turned the other cheek generation after generation. There is this Zionist trope that is used against us. They say, Palestinian rejectionism. They say that we reject everything, but if you look at the history like our leadership, the Palestinian authority has given up inch after inch, has compromised on acre after acre, has signed deal after deal after deal after deal, and still there is no peace. So turning the other cheek is not the most effective method in my book.
Segment 1590: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2894, Text: What are the top obstacles to peaceful coexistence of Israelis and Palestinians?
Segment 1591: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2900, Text: The occupation comes to mind. The [inaudible 00:48:23] policies come to mind. The seeds comes to mind. The asymmetry of the judiciary comes to mind. The whole system needs to be dismantled. I will quote my dear friend Robert Barre, who’s a lawyer who says, “The solution, justice comes about through recognition, return, and redistribution.” There are millions of Palestinian refugees who are living in excruciating circumstances in refugee camps around the world. There are thousands of Palestinian prisoners who are held in prisons for defending their homes, hundreds of which are held without charge or trial by the way. There are many Palestinians who get killed in broad daylight with no recourse, journalists and medics and everyday people, not just the freedom fighters. We need, again, recognition, return and redistribution, and peace comes about when they stop killing us, when they stop keeping us in a cage. That’s quite simple.
Segment 1592: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2973, Text: Can you describe recognition, return and redistribution?
Segment 1593: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=2978, Text: Return, right of return. The right of return to all of the Palestinian refugees to their homes. When I’m driving around Haifa and I see my grandmother’s home that’s now turned into a restaurant, I made a joke in one of my essays recently that had I had that, I could have had it all. The beachfront views, her smug attitude. She grew up by the sea after she relocated to Haifa after Jerusalem. We want that. And they’re lucky I don’t want Netanyahu’s home, but I just want my home. I just want my home. We want to return. Also, I believe in the 1960s, the Israeli government classified 90% of all of historic Palestine as state-owned land. This is all land that was owned by Palestinian farmers who have cultivated their lands for decades. Since the establishment of the Israeli state, there has been Jewish only towns popping up every few years, and not one town, not one Palestinian town has emerged. Even those of us who have Israeli citizenship who live outside of the wall are encircled and cannot have their natural community growth in their towns, that needs to change.
Segment 1594: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3060, Text: You mentioned the wall. Can you describe the wall?
Segment 1595: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3063, Text: The wall is a nine meter high cement wall that was finished in 2003. And if you’re American, you’ve probably heard the whitewash sanitized version of the name, which is the security wall. But it’s the wall that literally has stolen thousands of dunams of land and has ripped apart families. My mother is a poet or was a poet at some point, and she had this poem she published in the paper called Love Behind the Wall. It’s a poem, but it describes the real life situation of two families who lived right across the street from each other, but were then separated by the wall, and they would fly balloons to see each other from each side of the wall or something like that. This, although it sounds absurd, but it’s the reality for many Palestinian families whose lives were torn apart, whose livelihoods also were torn apart by the wall.
Segment 1596: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3123, Text: Maybe this is a good opportunity to talk about the legal classifications for Palestinians. Israel, much like any other colonial entity, has divided and fragmented the Palestinian people. As I said earlier, I have a blue ID, which means I’m a resident. A friend of mine who lives in Haifa, for example, two hours away from me, 150 kilometers, not nothing too bad in this country, has an Israeli citizenship. He can travel, he can enter the West Bank, he can do a lot more. He’s a citizen, he can vote if he wants to, not that we want to. I always say to my friends, “Oh, you can go to Italy without a visa because you have an Israeli citizenship.” But they battle national eraser. They battle crime in their own communities because of police negligence. They battle land confiscation, and have battled land confiscations in the ’50s.
Segment 1597: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3184, Text: Whereas somebody with a green ID, somebody from the West Bank cannot leave the West Bank, cannot go anywhere without a special permit and lives behind these walls. The West Bank, I think hilariously George Bush described it as Swiss cheese because of the holes. Every a hundred meters there’s a new settlement or there’s a new military checkpoint. So even if you live behind the wall in the West Bank with your green ID, even though you’re robbed of your right to movement, you still even can’t move from town to town within the West Bank without encountering settler violence or military violence while you’re crossing the checkpoints and so on and so forth.
Segment 1598: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3231, Text: And then the last category we have is people who live in Gaza, we are talking about over 2 million people who live in an open air prison, who have no right to movement, but also have no access to clean water and no access to supplies, no access to good food, no access to good healthcare, and so on and so forth, who routinely get bombarded every few years. Gaza is two hours away from my house. It feels like an absolute far away planet because it’s so isolated from the rest of the country. So imagine all of these different legal statuses fragmenting your everyday identity, and creating different challenges and obstacles for you to deal with, for each group to deal with. It’s amazing and impressive that despite these colonial barriers, the real cement ones and the barriers in the mind, despite all of these barriers, the Palestinian people have maintained their national identity for 70 years. That is incredibly impressive. And it also sends a message that as long as we have a boot on our neck, we are going to continue fighting. Violence, cracking down on refugee camps, bombarding refugee camps is only going to bring about more violence.
Segment 1599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3312, Text: So West Bank is a large region where a lot of Palestinian people live, and then there are settlements sprinkled throughout, and those settlements have walls around them with security cameras.
Segment 1600: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3323, Text: And security guards.
Segment 1601: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3324, Text: Security guards.
Segment 1602: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3325, Text: There’s almost a million settlers in the West Bank.
Segment 1603: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3328, Text: And so what are the different cities here, if you can mention?
Segment 1604: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3331, Text: In the West Bank?
Segment 1605: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3331, Text: In the West Bank. Ramallah, Jenin, Bethlehem, Hebron, Jericho, Nablus.
Segment 1606: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3337, Text: Yeah, [inaudible 00:55:38].
Segment 1607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3338, Text: They have their own stories, they have their own histories.
Segment 1608: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3341, Text: Yeah. And it’s fascinating also how interconnected they are. Like a friend of mine, Momahari, he recently did a documentary report on the day that Haifa fell during the Zionist invasion, the Hagana led the Palestinian residences of Haifa down to the city center. And as absurd as it sounds, those of them who stood on the right side of the street were forced into cars that took them to multiple stops that would later become multiple refugee camps, the last of which was Jenin refugee camp. And those who stood on the left side of the street were forced to board boats that took them to Lebanon to become refugees there. Last month we saw the Israeli army in invade Jenin in maybe the largest military invasion of Jenin since 2002, and they killed many people. They attacked medics and journalists in broad daylight on camera. They have destroyed infrastructure, and it was all very painful. But I think the most compelling aspect of the raid on Jenin was what followed. Israeli soldiers that night, held their megaphones and instructed hundreds of Palestinians to flee their homes. And they told them, if you don’t leave, if you don’t have your hand up in the air, you will get shot. And they were forced to leave their homes in the camp and walk to God knows where.
Segment 1609: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3438, Text: I can guarantee you, because the Nakba is not that old, I can guarantee you that some people who were marching away from their camps were chased away from their homes in the camp in Jenin were some of the same people who were chased away from the homes in Haifa in the first place. This perpetual exile that Palestinian people continue to live is unbearable. In my case, my grandmother was removed from her home in Haifa in ’48, and then she moved from city to city. And then in 2009, she saw half of her home taken over by Israeli soldiers. My grandmother died in 2020, and two months later, we got the next expulsion order from the Israeli court. I’m quite ashamed to admit that I was relieved that my grandmother had died, because I did not want her, 103 years old at the time, to go through yet another Nakba. And this is the fact for so many Palestinians, regardless of where they are on the map.
Segment 1610: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3501, Text: If I may read the description of the situation in Jenin, and maybe you can comment. So this is on July 3rd, 4th and 5th, just reading the Washington Post’s description. So this was an Israeli military incursion to Jenin, the raid included more than 1000 soldiers backed by drone strikes, making it Israel’s largest such operation in the West Bank since the end of the second Palestinian uprising in 2005. The Israeli military said it dismantled hundreds of explosives, cleared hundreds of weapons, destroyed underground hideouts, and confiscated hundreds of thousands of dollars in quote, terror funds. Many of the 50 Palestinians who have attacked Israelis since the start of the year have come from Jenin camp and the surrounding area. Palestinian attacks inside Israel have killed 24 people this year. UN experts describe the Jenin operation as “collective punishment”, in quotes, for the Palestinian people amounting to egregious violations of international law. Many of the more than 150 Palestinians killed by Israelis this year have also come from these communities. Palestinian fighters say they need arms to defend themselves against the Israeli occupation and military incursions into the camp during which Palestinian civilians including children have been killed. So those are the, I would say, different perspectives on the many people on both sides who have been killed, many more Palestinians. Can you comment more about the situation?
Segment 1611: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3598, Text: I think the Washington Post article is a little bit more careful than other media that came out recently about Jenin. I was listening to our Reuters radio show and they failed to ever mention the occupation. I don’t even think this paragraph mentioned that Jenin is under occupation by the Israeli forces, by the Israeli regime. I think this is the most important piece of context that gets obscured in our media reporting, is these cities, these refugee camps are under illegal occupation. The Israeli army has no business being there in the first place. That is the departure point, that is the most important piece of context that will answer to you why these people are arming themselves. Many of which, by the way, lived through the 2002 massacre and bombardment of Jenin, and grew up in that violence.
Segment 1612: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3657, Text: The context that Palestine is under occupation, that these Palestinian cities are under occupation, that they have to deal with land seizures at all times, that they cannot leave their towns without a special permit, all of this will give context to the violence. And the thousands of Israeli soldiers that raid the camp that day, that traumatized an entire generation. They think they will quell that generation. They think that with such bloodshed and such barbaric violence, destroying infrastructure, attacking medics, killing people left and right, and they think with this kind of terror that they can quell people, tell people that they can guarantee that these kids are not going to grow up and resist. But that’s the opposite of what happens. One thing about Palestinian people, they will not compromise their dignity. These people live in dire, excruciating circumstances and it is so courageous, in my opinion, that they even think to defend themselves against one of the most lethal, one of the most sophisticated armies in the world, against a nuclear state that can wipe them out in the matter of seconds. But at the end of the day, it’s not even about courage, it’s about survival. They don’t do this because of machismo or because of heroic tendencies, it’s because this is about survival.
Segment 1613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3757, Text: So the degree there’s violence, it’s about survival?
Segment 1614: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3761, Text: Absolutely. I think if there was no occupation, there would be no violence. It’s quite obvious. And again, people understand this. We saw on Twitter in the recent month, all of these Israeli propagandists who had tweeted pictures of little girls with guns in Ukraine and women making bombs in Ukraine, and young men carrying their rifles in Ukraine, and praising them as heroes, post very similar pictures of Palestinians and calling them terrorists. It’s glaring the double standard, I don’t even need to linger on it.
Segment 1615: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3797, Text: Well, the double standard is glaring, but I also think the glorification of violence is questionable. There’s a balance to be struck, of course, but…
Segment 1616: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3809, Text: Yeah, I don’t think we should be glorifying violence at all, but I don’t think we should be normalizing violence either. I think that’s what it is. I’ll tell you a story. I was interviewing a person whose brother was killed by the Israeli military during an Israeli raid on their village, and the person was so concerned about whether I was going to report that her brother allegedly had a Molotov cocktail in his hand. And I found it absolutely insane, absolutely absurd that we can just glance over the fact that there is, again, a foreign military in tanks with rifles and snipers invading the village at 4:00 AM in the morning, shooting live ammunition at people’s houses, throwing tear gas, that we can just glance over. It’s normal, we could just report on it, no problem, nobody’s going to bat an eyebrow. But the fact that potentially somebody might have picked up a Molotov cocktail to throw it at this invading army is where we draw the line. It says a lot. It says a lot about whose violence is normalized, is accepted, is institutionalized, is glorified even. You walk around Tel Aviv and you see all of the plaques plastered around the streets of the country, of the city, celebrating the battles that they had won, the massacres that they had enacted against the Palestinian people, but God forbid Palestinians have any kind of similar sentiment.
Segment 1617: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3920, Text: So on July 4th during this intense period, a Palestinian rammed a car into pedestrians at a bus stop in Tel Aviv, injuring eight people before being shot dead by a passerby. Also, that night, Hamas fired rockets into Israel, and then Israel responded with strikes on what it said was an underground weapon site. So just to give some context to the intense violence happening here, what do you think about Hamas firing rockets into Israel?
Segment 1618: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=3952, Text: Well, the framing makes it seem as though unprovoked Hamas is firing rockets unto Israel, regards to what I think of Hamas, obviously, but unprovoked. But that’s not the case. The propagation is the fact that they are forced to live in a cage, that they have no access to clean water. They have no access to basic rights, no access to imports, no access to anything, that they can’t leave, they’re living in a densely populated enclave that was deemed uninhabitable by the UN, that was deemed an open air prison. So the rockets, in any case, are retaliation for the siege. Let’s start there. But again, this is just to prove my point, violence begets violence. Palestinian people are not violent people. We are not violent people at the core.
Segment 1619: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4005, Text: And I think what serves this narrative is Islamophobia, is xenophobia towards Arabs, which I don’t have the luxury to write laws about. By the way, I’m quite frustrated by this. I am preoccupied and the Palestinian people are preoccupied with the material violence that we have to deal with on the day-to-day, the demolitions, the bombings, the imprisonment. That’s what we’re distracted with and busy with that we can’t even talk about the racism, the casual racism, against this anti-Palestinian racism, be it in the media, on social media and diplomatic circles. But all of this racism that has gone unchecked, has not been regulated for decades, allows for these tropes to continue in which Palestinians are promoted as these like barbaric terrorists and the only way we could remedy that situation is by marketing them as these defenseless victims. But the fact of the matter is, it’s not this simplistic. Palestinian people are human beings who should enjoy a full spectrum of humanity, which includes rage, which include…
Segment 1620: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4080, Text: … Vanity, which includes rage, which includes disdain, which includes happiness and joy and laughter, which includes celebration, which includes all of these things, but we’re not allowed this. But we are doing exactly what any people throughout history who have been oppressed, who have been colonized, who have been occupied, have done and continue to do as we see in Ukraine, which is celebrated by mainstream media.
Segment 1621: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4105, Text: I’m sorry to keep reiterating this point, but at this point, I am quite exhausted by how exceptional Palestine and Palestinian resistance is when the world tells me time and time again that it doesn’t have a problem with violence, it just has a problem with who does that violence.
Segment 1622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4133, Text: Do you, in your mind and in the way you see this region, draw distinction between the people in power versus the regular people? So, you mentioned the Palestinian people, is there something you can comment on, on Hamas and the PLO? Do you see them as fundamentally different from the people? What does Hamas do well, where do they fall short?
Segment 1623: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4159, Text: I think governments, wherever globally, are different from people. No government is a true reflection of its people. I think this is even true in the case of Arab countries that normalize with Israel. In many of the cases they are unelected governments. I think the Palestinian authority continues to fail. I think there are subcontractors of the Israeli regime through their security coordination. And also, I’d like to use this as an opportunity to comment a little bit on the analogy thing.
Segment 1624: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4197, Text: Not to stray away from the question, but the Palestinian Authority two years ago killed an opposition activist named Nizar Banat. It was a horrendous crime, and I was in Ramallah with the people protesting against the Palestinian Authority. And at some point they had their batons, the Palestinian Authority Police, and they beat us with it. And many of the people in the crowd were liking the Palestinian Authority to Zionism. I think people, this is what people do, when they are confronted by a great evil, they liken it to some other great evil, and this is where the Hitler analogy came from. Again, I don’t think it’s the best strategy moving forward, but I refuse to be criminalized for a little sentence.
Segment 1625: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4252, Text: So, to linger on those in power. One of the criticisms towards Hamas and PLO, towards the Israeli Government, at least the current coalition government, is that there’s a lot of incentive to sort of perpetuate violence to maintain power. There’s a hunger for power and maintaining that power amongst the powerful. That’s the way power works. So, is there a worry you have about those in power not having the best interest of its people? So, those in power, the PLO, Hamas, not being incentivized towards peace, towards justice.
Segment 1626: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4300, Text: Looking at the PA’s action today, it tells you a great deal about what they’re interested in and what they’re not interested in. And maybe, yeah, the occupation is in their best interest. And you can infer similar things looking at Hamas, but these two entities virtually have no power, even Hamas.
Segment 1627: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4328, Text: The context that Hamas is permitted by international law to use armed resistance, blah, blah, blah, does that mean Hamas is equipped to govern Gaza? I don’t think so. Does that mean that people around Palestine necessarily want to live under Hamas rule? In 2006, Hamas was democratically elected. I don’t know if that’s still the case today. There’s a lot to be said, but neither of these entities have any real power in perpetuating… The only body that can flip the switch in all of this equation is the Israelis.
Segment 1628: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4376, Text: They’re the ones who are keeping people in a cage. They’re the ones who are wrapping the West Bank with a wall. Everything else to me is just secondary, regardless of what I think personally of any of those people. Personally, for me, the world I envision, not just Palestine, the world I envision is a world that goes beyond states, that goes beyond this framing of power, this hierarchy in which some people rule over other people. This whole idea of nation states, be it Israel or any other nation state, it’s futile, it’s not good, it’s exclusive. I think that we can achieve a better world than that.
Segment 1629: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4418, Text: Well, how do you do a better world? Actually, if you just linger on that, politically speaking, geopolitically, you have to have representation of the people, you have to have laws, and you have to have leaders and governing bodies that enact those laws and all those kinds of things. You probably need to have militaries to protect the people.
Segment 1630: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4445, Text: Can you not imagine a world without militaries?
Segment 1631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4447, Text: I can imagine it, but we’re not in that world.
Segment 1632: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4450, Text: Yeah, I’m not saying I have all the answers or a PowerPoint in my pocket with the instructions, but I’m saying the world I’d like to live in is one that transcends borders, is one that does not necessitate militaries, that doesn’t necessitate all of these prisons, all of these walls, all of these racist laws.
Segment 1633: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4475, Text: So, you don’t think violence is a fundamental part of human nature that emerges combined with the hunger for power?
Segment 1634: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4485, Text: I do think that both of these things are truly intrinsic to human beings, but I also do think there is a way to move beyond them. I’m not saying I have the answers. I’m tempted to say sway, but…
Segment 1635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4501, Text: You have a hope that there doesn’t have to be war.
Segment 1636: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4505, Text: Yeah, yeah.
Segment 1637: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4505, Text: In the world.
Segment 1638: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4506, Text: Definitely, definitely.
Segment 1639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4508, Text: Well, if we look a little bit more short term, people speak about a one state solution, a two state solution, what is your hope here for this part of the world?
Segment 1640: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4520, Text: Do you see a possible future with a two state solution, whether it’s for Palestine and Israel? Do you see a one state solution where there is a diversity of different peoples like in the United States and they have equal rights in the courts and everywhere else?
Segment 1641: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4539, Text: I don’t think there’s a geography in which a two state solution is possible. As we said earlier, Swiss cheese, there’s literally settlements all over the West Bank, and I don’t think it’s fair, a two state solution is fair to all of the people whose homes are still in Haifa, in Nazareth, in Jaffa, and so far, and I don’t think it’s fair that I’m going to have to travel to another country to visit my cousin who’s married in Nazareth, for example.
Segment 1642: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4574, Text: And beyond that, it’s just not possible. I do believe that whatever you want to call it, one state, two state, 48 states, 29 states, whatever you want to call it, refugees need to return, land needs to be given back, wealth needs to be redistributed, and a recognition of the Nakba needs to happen. That is the only way we could move forward.
Segment 1643: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4601, Text: And regarding whether this is a possible situation for two people to live side by side, let’s ask two questions. Let’s say you lived in a house with a person, your roommate, you just had a roommate who constantly beat the shit out of you, I wonder if you’d want to continue to live with them? That’s one. And let’s try another scenario. Let’s say you live in a house with a roommate who you just absolutely hate, just absolutely oppose their existence as a people, you don’t even give him a key to your apartment. Let’s say now you’re equal partners in the apartment, would you want to live with him? I don’t know. We’ll see. We’ll see, time will tell, but I don’t think they want to live with us.
Segment 1644: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4656, Text: Israelis are quite good, especially Israeli diplomats, they’re quite good at using flowery language about peace and coexistence and so on and so forth, and they’re good with making us seem insane or radical or full of hate and so on and so forth, but the policies speak for themselves. The actions on the ground speak for themselves, and every time there’s an uptick, many of them leave, and I wonder, I would like to see, I wonder what would happen in a own state solution.
Segment 1645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4693, Text: Well, okay, so you’ve spoken eloquently about the injustice of the evictions, the demolitions, the settlements, but can you comment about the difficulty of the security from an Israel perspective when there is a large number of people that want to destroy it? How does Israel exist peacefully, this one state solution?
Segment 1646: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4721, Text: I don’t know, by not shooting a journalist doing her job in the Jenin refugee camp.
Segment 1647: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4726, Text: But that doesn’t…
Segment 1648: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4727, Text: By not killing a 14-year-old standing in his front yard? This whole talk about security and security fence and the whole propaganda of the Israeli defense forces and this whole iron wall ideology in which somehow they’re always defending themselves, even though they’re… Netanyahu and the Israeli Government continue to talk about an existential threat, about Iran being an existential threat, even though the Israeli Government is the only body that holds nuclear weapons in the region. They’re the most sophisticated army in the region, and yet they continue hiding behind their fingers and talking about an existential threat and talking about how they’re insecure and so on and so forth.
Segment 1649: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4774, Text: I came here on the bus. I live in a house where everybody in the world can easily Google it and get its address, and anybody can just walk into my house. And I’m lucky and privileged as a Palestinian journalist. There are many Palestinian journalists who lose their lives. That’s real insecurity, but we don’t even have time to whine about it because there’s real shit going on the ground that we’re preoccupied with and reporting on all the time, that we don’t even have the time to talk about how limited is our institutional backing, how limited is our cyber security, how limited is even healthcare. All of these things we don’t even have time to complain about, but they’re the real life things that formulate an insecure population that Israel certainly does not suffer from.
Segment 1650: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4836, Text: There’s a tension here. It’s true that the ideas of existential threats to a nation have been used to expand the military industrial complex and to limit the rights of its people. So, in the United States, after 9/11, Iraq and Afghanistan were invaded under some justification of there being terror in the world, these big ideas. And in the same way, yes, Israel, with the existential threat of Iran has used to expand its military might over the region and control over the region, but it also has some truth to it in terms of the threat that Israel is facing, including from Iran. If Iran were to get a nuclear weapon, do you think there’s a threat from that?
Segment 1651: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4884, Text: But who has the nukes?
Segment 1652: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4887, Text: Right now.
Segment 1653: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4888, Text: Yeah, but we’re talking about this far away monster that we’re scared of, it’s like fear-mongering. What do you mean, who has the nukes?
Segment 1654: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4897, Text: Some of it is fear-mongering, but some of it is true.
Segment 1655: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4902, Text: I don’t think it’s true. I don’t think it’s true. I think Israelis are obsessed with genocide because they have enacted genocide against us. Even when we talk about a future, a liberation of Palestine, when we’re talking about anything, they constantly jump to saying things like, “They want to throw us into the sea. They want to kill all Jews.” What kind of hyperbolic bullshit is that? To say that if I am chanting and marching for my home not to be taken away from me by some kind of settler court, I am somehow demanding the murder of all Jews across the world? That is hyperbolic, and the fact that we coddle it is insane to me.
Segment 1656: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4943, Text: So no, I don’t think as things stand right now, as the power of balance stands right now, I don’t think there’s an existential threat to Israel. And also, let’s redefine existential threat. Do we think the Israeli regime, the Zionist regime should continue to exist in its forms, subjugating people, enacting the crime of Apartheid according to a bajillion human rights organizations? Do we think that it should continue keeping people in a cage? If that’s what people are fighting to save, then that says a lot about the people who are feeling this existential threat, not me.
Segment 1657: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4980, Text: Do your beliefs represent the Palestinian people, meaning, how many people are there that want Israel to be gone?
Segment 1658: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4990, Text: Well, what does it mean for Israel to be gone?
Segment 1659: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=4992, Text: What it means is for people who think of Israel as an occupier, who stole land that needs to go away, that this should be all Palestine.
Segment 1660: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5002, Text: Yeah, but is that a bad thing for the occupation to end, for the land to be given back? Is that a bad thing?
Segment 1661: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5010, Text: Well, there’s different definitions of occupation. There’s people in their homes now, right?
Segment 1662: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5016, Text: But is it their home? I’m not talking about some random home, but there are many, many, many, many, many, many, many, many, many, many Israelis who drink their coffee every morning from living rooms that are not theirs.
Segment 1663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5036, Text: That are not theirs, that were taken just a few decades ago?
Segment 1664: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5043, Text: Where the rightful owners of these homes are still lingering in refugee camps, are still dreaming of return.
Segment 1665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5052, Text: There are homes on the land of Israel that you wouldn’t classify as stolen.
Segment 1666: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5058, Text: I mean, if it was built, but is the land stolen? But all of this, again, I try not to fall into this because it feels so abstract and far away, and this is not how liberation is going to look like whatsoever. And I’m not fixated on ethnic cleansing, I’m not obsessed with ethnic cleansing. I’m obsessed with ending the ethnic cleansing campaign that has been visited upon me and my family and my community for seven plus decades. That’s what I’m obsessed with.
Segment 1667: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5097, Text: All of this other stuff about what happens to the settlers, and we want to kill all Jews and all of this, I think it’s bullshit, and I think it’s ridiculous, and I think fixating on it is distracting from the focal point. There needs to be an end to all of the injustices, to all of the atrocities. A little boy from Jerusalem should be able to go jog around the city without fearing getting shot. That’s the simplest thing we’re asking for here, and we want our land back, and those things do not mean actually at all the ethnic cleansing of another people.
Segment 1668: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5136, Text: Well, we should be precise here. So, a little boy being able to run around Jerusalem, that’s a great vision, not just safely, but without racism, without hate. That’s a beautiful vision, yes, but people in West Jerusalem, people in Tel Aviv that have homes, should they stay there? Do they have the right to stay there?
Segment 1669: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5162, Text: That’s maybe number 99 on my priorities list. I’m concerned with the refugees, I’m concerned with the teenagers in the prisons. I am concerned with my house. I’m concerned with my family’s house in Haifa. There is a lot for me to do before I can even tend to the needs of my occupier, that is the least of my concerns.
Segment 1670: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5188, Text: So you want the low hanging fruit, the obvious injustices to end?
Segment 1671: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5192, Text: Yeah.
Segment 1672: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5194, Text: But still the long term vision of existential survival of Israel, which is the concern of its government, is the concern of its people, do you see a future where Israelis have a home in the region?
Segment 1673: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5210, Text: Sure, just not in my front yard.
Segment 1674: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5214, Text: Where’s the front yard and where is the backyard?
Segment 1675: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5217, Text: There are literally Jewish settlers, one of which from Long Island, in my literal front yard. And this is the case in hundreds if not thousands of Palestinian homes. No one is saying Jewish people shouldn’t exist or they shouldn’t have a state of their own. I mean, I think all religious based states are a bad idea, all nation states are a bad idea, but whatever, if that’s what they want do, that’s what they want to do.
Segment 1676: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5246, Text: But that doesn’t mean that they are allowed or have a right to create and implement a system of Jewish supremacy at my expense. That’s not a crazy thing to say. That is not a controversial thing to say. You can have your state, just don’t kill anyone. Thank you, have a good day. That’s not a crazy thought to have.
Segment 1677: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5270, Text: And seek and establish a symmetry of power in the courts, which is the current source of injustice.
Segment 1678: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5276, Text: I mean, that’s when it comes to forced expulsions in our home, but there’s myriad of other ways.
Segment 1679: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5283, Text: To the military?
Segment 1680: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5284, Text: The military, I mean, the police. If you look at how many times, I should have brought the data with me, but if you look at how little times the Israeli Military or police has investigated its own people or indicted its own people. I mean, just recently, the killer, who has been hailed a hero by some of Israeli society who killed Eyad al-Halaq, a Palestinian man who is autistic, who lives inside the occupied old city, where again, Israeli Military has no business being there or jurisdiction whatsoever.
Segment 1681: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5319, Text: He was shot and killed by an Israeli soldier who was trigger-happy because, again, they have this siege mentality where any moving object is going to kill them. And he was shot and killed and despite it being in broad daylight, despite it being well-documented, despite the victim being disabled, despite all of this, he was acquitted by the Israeli court. The military, the courts, the government, they all work together, which is why it’s so ironic to me that there are hundreds of thousands of people marching on the streets of Tel Aviv trying to save the progressive beacon that is the Israeli Supreme Court when you find its fingerprints all over the injustices perpetuated against Palestinians, be it legalizing and upholding the withholding of slain Palestinian bodies who were killed by the Israeli Military to be used as bargaining chips with Israeli militaries.
Segment 1682: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5375, Text: Be it making decisions to dispossesses entire villages like [inaudible 01:29:42], be it never once granting release to any Palestinian who was held in administrative detention without charge or trial. Be it upholding the legality of the Family Reunification Law that does not allow Palestinian couples who hold different legal statuses of reuniting and living together as families. I mean, those are just some of the few things I can think of about the Israeli Supreme Court.
Segment 1683: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5411, Text: So, the real tension that exists is the lack of diversity on the Israeli political spectrum that makes the vision for a future so limited, because those on, what seems to be, the far left, are defending an extremely conservative institution that is a supreme court that they regard as progressive, when in fact it is the opposite of such. So, what do we do? How can we talk? How can we have peace with people who are chanting to save the very body that is displacing us? It’s ridiculous.
Segment 1684: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5456, Text: What’s your vision? Let’s just take it as a microcosm of Jerusalem, what’s your vision for Jerusalem look like with a peaceful coexistence of people?
Segment 1685: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5469, Text: As it looked like before the Israeli State emerged. I mean, we should be reading our history here. When you read European and white historians, they’ll tell you Palestine was there, and many of them would say it was even without a people, nobody was there, or some of them will say we we’re uncivilized. But the fact of the matter is Palestine, Jerusalem particularly, had a diversity of religion, Druze, Jewish people.
Segment 1686: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5501, Text: My grandmother continues to talk about… Well, she continued until she died, she continued to talk about her Jewish neighbors when she grew up in the old city. Well, when she was born in the old city and then her Jewish neighbors in Haifa. We even had one Jewish member of her family, [inaudible 01:31:59] actually, who just also recently passed away there. Jews were a part of Palestine, and they spoke Hebrew, a different kind of Hebrew, but they spoke Hebrew and they were… People really need to read The Hundred Years’ War on Palestine, it’s really an excellent synopsis of the history.
Segment 1687: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5536, Text: But this whole idea, that this is some kind of war between two religions is so misleading, because what’s happening is a bunch of frankly European settlers with a certain political secular ideology came and relocated here and turned it into a religious conflict between people who have lived harmoniously together for decades before that.
Segment 1688: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5561, Text: And the whole idea, be it Christian Zionism or John Hagee, or the calls for Jews to leave the United States and relocate in Israel. Or recently, which we’ve heard about a long time ago, but recently an Israeli historian confirmed the fact that Israeli organizations were bombing Baghdad and bombing synagogues in Baghdad in Iraq to get Iraqi Jews to leave and come relocate in Israel. All of this is manufactured, and again, none of this is a conspiracy theory, I know it sounds absurd, and anytime I look at my life from a bird’s eye view, I think, “What a circus.” But it’s real and it’s verifiable, call the fact-checkers.
Segment 1689: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5611, Text: You mentioned the land registry, can you elaborate what’s happening there?
Segment 1690: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5614, Text: Yeah, yeah, absolutely. So, our small victory in the Israeli courts was that they would keep us in our homes until a land registry is completed. Basically, it means that they have to check who owned the land prior, and then they could decide if the land is ours or the land belongs to the Israeli settler organizations that are headquartered in the United States and enjoy a tax-exempt status here.
Segment 1691: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5647, Text: And that sounds great on the surface, but then you look at Israeli law, you look at Israeli courts, you look at ownership and you see that, oh, Israelis refuse to authenticate or take into consideration any land ownership documents prior of the establishment of the state. So all of us in Jerusalem who have their taboo papers, their ownership papers from the Ottoman era, that’s not legit in the eyes of the Israeli court, because your ownership deeds existed long before Israel even existed, so we’re not going to take this into consideration.
Segment 1692: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5683, Text: So, not to be cynical here, but unfortunately the likely result of the land registry is that they’re going to say, “Oh, all of this land belongs to these Jewish organizations,” because they’re not going to take any of our documents into consideration. But that means that there’s going to be another campaign and there’s going to be a long-winded fight, and we’ll see what happens. But that’s the fear, and there’s a huge dreadful fear of a massive loss in property in Jerusalem following this land registry for the reasons I just told you. It’s the mere fact that they just refuse to look at land ownership documents.
Segment 1693: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5719, Text: What is the process of the fighting this in the courts look like? If you can maybe just comment on it.
Segment 1694: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5726, Text: I always make a joke that being in an Israeli court is playing a game of broken telephone because everybody’s speaking in Hebrew, and then your lawyer says something to your dad, and your dad says something to your mom, and your mom whispers it in your ear, and then you say it to your cousin and your cousin has a completely different idea of the verdict than what the verdict is, but that’s really the reality.
Segment 1695: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5746, Text: So a lot of the fights happen family by family?
Segment 1696: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5748, Text: No, it’s groups. So, in our case, it’s four houses, every four houses, but again, it happens in a language we do not speak, and a lot of the time our strategy is buying time and building a global campaign. We know that there is no recourse in the Israeli courts. I mean, my grandmother used to say, and this is a popular proverb, “If your enemy is the judge, to whom do you complain?”
Segment 1697: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5776, Text: So, to the whom you complain is maybe the international community?
Segment 1698: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5782, Text: Yeah. I mean, in our case, it was the international community, but in our case also, it wasn’t just the international community, it was the hundreds of thousands of people in Palestine and abroad who were marching on the streets getting beaten and brutalized in Jerusalem, and I don’t know, sometimes arrested in places like Germany and so on and so forth, who forced themselves inside the media cycle.
Segment 1699: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5807, Text: This was what was unique about [inaudible 01:36:50]. We were able to penetrate an industry that usually ignores us and usually refuses to use any of our framing, any of our quotations, and these people that march, these people that spread the rhetoric, spread the facts, wrote articles, these people that made videos online and got arrested, and many of whom are still in Israeli prisons paying higher prices than I have ever paid, these people are the ones that truly moved the international community into action.
Segment 1700: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5838, Text: It wouldn’t have, the United States, I don’t think would said anything had it not been for the immense media pressure that was created from the immense popular pressure. There are a lot of moving parts to a global campaign, and I think it’s so impressive that we were able to do this without any media backing, without any institutional backing, without any training, without any budget, nothing.
Segment 1701: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5861, Text: You mentioned the United States. What’s the role of the United States in the struggle that you’ve been describing? What’s the positive, what’s the negative?
Segment 1702: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5871, Text: The role is perpetuating what’s happening. It’s all a negative role, to be honest.
Segment 1703: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5878, Text: With the money, with power?
Segment 1704: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5879, Text: Yeah, it’s like the 3.8 billion in military aid every year, it’s the standing ovation.
Segment 1705: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5888, Text: Israel is the largest recipient of US foreign aids since World War II. To date the United States has provided Israel $158 billion, as you said, is providing currently 3.8 billion every year, that a lot of people raise the question of what’s the interest of tax paying American citizens in this kind of…
Segment 1706: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5909, Text: Yeah, zero interest.
Segment 1707: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5911, Text: Foreign aid.
Segment 1708: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5913, Text: Zero interest. I think a lot of Americans are concerned with healthcare, a lot of Americans are concerned with clean water and flint. I don’t think they’re concerned with funding Apartheid in another country. And I think it’s a disturbing phenomenon that although public opinion in the United States is shifting, I would argue drastically, about Palestine, people in Washington are yet to catch up.
Segment 1709: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5939, Text: It was only, I think, nine Congress people who boycotted Herzog’s speech in Congress yesterday, and he received standing ovation after standing ovation, after standing ovation, after standing ovation. And I wonder if the everyday American is concerned that many of their politicians are Israel first politicians, are politicians who care more about maintaining a relationship with the Israeli regime, than they care about their own districts.
Segment 1710: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5971, Text: You’ve tweeted that 49 years ago, Ghassan Kanafani… Well, you can maybe correct me on the pronunciation, was assassinated. You wrote, “His revolutionary articulations of the Palestinian plight for liberation shook the colonial regime, yet he’s not dead, his ideas remain ever timely and teachable.”
Segment 1711: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=5994, Text: And you also tweeted an excerpt from his writing. “Between 1936 and 1939, the Palestinian Revolutionary Movement suffered a severe setback at the hands of three separate enemies that were to constitute together the principle threat to the nationalist movement in Palestine in all subsequent stages of its struggle. One, the local reactionary leadership, two, the regimes in the Arab states surrounding Palestine, and three, the imperialist-Zionist enemy.” Can you analyze what he means by those three things? The local reactionary leadership, the regimes in the Arab states surrounding Palestine and the imperialist-Zionist enemy? And also, could you comment on him as a person?
Segment 1712: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6037, Text: Yeah, I mean, Ghassan Kanafani is a brilliant, brilliant, brilliant writer, and he was prolific. He’s authored so much books, even though he was assassinated in the 70s, but he was 37, if I’m not mistaken, 35 when he was assassinated. He was inspiration to me in school, and I remember even my teachers had qualms about him because he was a secular person. But I love Ghassan Kanafani. He is a beloved figure in the Palestinian community, and I hope to one day be able to achieve a fraction of what he’s achieved in the terms of shaping a political consciousness for Palestinians and for people in the region.
Segment 1713: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6081, Text: Did he classify himself as a politician, as a philosopher, as an activist, do you know?
Segment 1714: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6087, Text: He was a writer, but he was also part of the Palestine Liberation Front, PFLP.
Segment 1715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6093, Text: So he used the words to fight for freedom.
Segment 1716: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6099, Text: Yeah, I don’t think he would’ve thought his words were divorced from other forms of struggle, but I think he recognized the importance of culture and shaping culture and shaping public opinion, both in achieving a shift in global stance, and also in achieving-
Segment 1717: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6120, Text: … global stance and also in achieving an awakening in the Palestinian generation as well. There’s a very famous interview of his where he’s talking to, I believe, a British journalist, and the British journalist is asking him, “Why don’t you have talks with the Israelis?” And he says, “What do you mean talks? You mean capitulation? You can’t have a conversation between the sword and the neck?” And I think that really summarizes the values he stood for. Now, to talk about the three things.
Segment 1718: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6157, Text: Local reactionary leadership, regimes in the Arab states surrounding Palestine, and the imperialist Zionist enemy.
Segment 1719: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6164, Text: In today’s terms, the local reactionary leadership is the Palestinian Authority. The regional regimes, we’re talking about, actually, the normalization deals that have emerged in recent years, the Abrahamic Accords, have been talked about as though they’re groundbreaking, new phenomenon. But many Arab countries have normalized relations with the Israeli regime since the birth of the state. It’s not a new thing. But, yes, I think he was talking about Egypt and Jordan at the time. Today, we can include United Arab Emirates. We could include Bahrain. We could include Morocco. And, again, these Abrahamic Accords, they are promoted and marketed and talked about as some kind of religious reconciliation, which I think is the most disgusting thing ever, because they’re not about religious reconciliation. They’re about arms deals and economic deals and they’re about consolidating power in the region.
Segment 1720: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6237, Text: They’re about mutual strategic interests that all of these nations have together, and some people argue that Palestine is no longer an Arab cause because Arab countries are normalizing. But most of these governments, if not all, actually, all these governments that have normalized, most of them are monarchies, are not elected governments, and they do not represent the will of the people or the desires or the opinions of their peoples. And the proof to this is places like Jordan and Egypt. Even though they’ve normalized and had peace agreements with Israel for many, many, many, many years, Palestine and the Palestinian cause was still a talking point in the political campaigning of politicians, Jordanian and Egyptian politicians, and continues to be for them to gain popularity because that’s where the hearts of the people are. And then the Zionist regime is quite explanatory, the imperial Zionist regime. I mean, what else do you call a regime that sought help from imperialist powers to depopulate an entire country and build a new one on top of it.
Segment 1721: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6309, Text: So, mostly, you’re saying the thing that the Abraham Accords achieved is a negative thing for Palestine? So these kinds of agreements between the leadership is not positive for the region?
Segment 1722: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6330, Text: No. No. Obviously, they’re going to be marketed as positive, and, obviously, they’re going to have this flowery language surrounding them. And the idiots in the room might like nod and smile, but anybody with critical thinking skills can know that if a people continue to be under occupation, there’s nothing positive there. And, also, let’s linger a little bit on the mutual interests. The only way Morocco could normalize relations with the Israeli regime is so that the Israeli regime could recognize Moroccan sovereignty over in the Western Sahara, which just happened actually last week. And before that, Morocco recognized Israeli sovereignty over the West Bank. It’s not like Morocco itself has no interest in this kind of deal.
Segment 1723: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6384, Text: You mentioned that you hope of accomplishing some of the things that [inaudible 01:46:31] was able to accomplish. Let me ask you a silly question, perhaps a silly question, do you have interest in running for political office, I hear laughter in the room, to lead in a leadership position in Palestine.
Segment 1724: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6414, Text: Not currently. No. Not at all.
Segment 1725: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6417, Text: Let’s see if this ages well.
Segment 1726: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6420, Text: I don’t think there’s a body through which I can run for anything. It’s completely dysfunctional, and also I don’t want to wear a suit all the time.
Segment 1727: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6435, Text: Who would want to do that? So from which pedestal or from which stage do you think you can be most effective?
Segment 1728: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6446, Text: I was born and raised in Jerusalem. I speak perfect Arabic. I think my Arabic writing is much superior to my English writing, but I choose to write in English because I think there’s a disparity and there’s a chasm between what is said in Arabic in the street in Palestine and what is said here about Palestinians, both by anti-Palestinian racists and people who are pro-Palestine and advocates for Palestine. And I believe I and a few others from my generation, or many others actually from my generation, are working to fill that chasm. And I also believe that literature, culture, the public sphere, changing the public opinion, changing the narrative is important to affecting policy, to affecting change, affecting material change. I’m not going to go read a poem in front of a checkpoint and watch it catch in flames.
Segment 1729: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6504, Text: I’m not that delusional about the power of words, but I do think that I have a responsibility and I have a privilege even to have a voice, to have some kind of platform, and if I’m not defining myself, if I’m not talking and representing myself, then other people will define me. And their definitions of the Palestinian people across the few past decades have not been kind or generous to the Palestinian people. That’s one thing. The other thing is I believe in the United States as a front for change. I believe we have a lot more leverage here than we do back home. Again, I believe, and someone said the other day, I can’t remember their name, but someone said “no stone unturned”, I believe in fighting on all fronts. But here, really, I can go protest in front of the Israeli Embassy without getting shot. There’s a lot of work to be done here. There’s a lot of people waking up.
Segment 1730: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6567, Text: I would even argue that a reckoning is coming in the American public. More and more American people are concerned where their tax money is going or concerned what their politicians are invested in. More and more American people are saying, “Not on our dime,” are saying, “Not today. Not here.” Also, there’s many Palestinians in the diaspora here in the United States and Europe who benefit and could benefit from political education in the English language, because the diaspora across history, the Palestinians diaspora, has been effective in the ’70s and the ’80s and, ever since 2021, there has been a resurgence of the power and influence of the Palestinian diaspora.
Segment 1731: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6617, Text: To ask another silly question, since you mentioned the United States, I don’t know if you follow the politics in the United States, but do you have a preference of Presidential candidates in the 2024 election?
Segment 1732: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6633, Text: I do follow.
Segment 1733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6635, Text: Do you follow where each candidate stands on the different policies?
Segment 1734: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6639, Text: I do. I think everybody in the world should be able to vote for American elections, actually. I do follow.
Segment 1735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6644, Text: Because of the influence they have?
Segment 1736: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6645, Text: Yes. Yes. I don’t have a preference whatsoever. I saw Cornel West on CNN. I don’t know if he’s going to go far with his campaign. Cornel West is running with the Green Party and I don’t think he’s going to achieve much success. But I saw him on CNN berating Anderson Cooper and I enjoyed that very much. Wouldn’t mind seeing that on my screen.
Segment 1737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6675, Text: Regularly.
Segment 1738: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6675, Text: Regularly.
Segment 1739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6676, Text: Okay.
Segment 1740: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6676, Text: But don’t really have an opinion about.
Segment 1741: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6681, Text: You wrote Rifqa, a book of poetry. How did that come about? Maybe you can tell the story of that book coming to be.
Segment 1742: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6692, Text: I signed the book when I had a lot less visibility in the world. When I didn’t think thousands and thousands and thousands of people would be reading it, I decided to include many poems, which I wrote when I was young. Because it’s a long journey, this book. It’s starts in Jerusalem, it goes to Atlanta, it goes back to Jerusalem, and then it ends in New York. Rifqa is the name of my grandmother and it’s an Arabic name, a Hebrew name, and it means to accompany someone. I wanted to write about displacement in a way that was beyond what we read about in English. Poetry as a medium, I don’t know if I have much faith in it anymore, to be honest. Maybe I’m turned off by it and I’ll revisit it again in a few years, but at the time of writing this book, poetry as a medium, it really was a source of hope and inspiration for me.
Segment 1743: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6754, Text: My mother was a poet and her and my dad would play this game in the morning. She would read her poems to him and he would guess which lines would be red penciled by the Israeli military censor, because she would submit her poems to the local newspaper, the Kutz Newspaper, and the military censor has to go over it. She would get her poems back with a bunch of words erased and they would laugh about it and blah, blah, blah. So poetry was very much part of my upbringing and, as a Palestinian, when you’re excluded from mainstream spaces, including media and journalism, poetry tends to be a place where you can say what you want to say without repercussions. And I say that I realize that our greatest writer, [inaudible 01:53:22], literally had his car bombed, exploded because of his writings. And recently, [inaudible 01:53:29], a poet, a Palestinian poet with an Israeli citizenship, was imprisoned for a few months for publishing a poem on Facebook in which he said, “Resist, my people. Resist.” So even that is not necessarily true.
Segment 1744: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6821, Text: But, anyway, it just felt like it’s a place where I could talk and express large ideas in a simplistic way. And the best example I could give you is one of my favorite poets, [inaudible 01:53:54], when the Israeli authorities decided to do the land law, which classified, I believe, 93% of historic Palestine as state owned, and then when they also did the absentee property law, which allows the Israeli government to take over homes that were depopulated from the Palestinian owners, he wrote a poem called God As A Refugee. It’s a sarcastic, sardonic poem in which he goes, “God has become a refugee, sir, so confiscate even the carpet of the mosque and sell the church because it’s his property, and sell our orphans because their father is absent. And do whatever you want.”
Segment 1745: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6886, Text: It’s a sarcastic poem that was in reaction to these laws, that translated to the everyday Palestinian, to the farmers, to the landowners, what these bureaucratic, complicated laws meant to them, what they meant to their land, and, what effect are these laws going to have on these people’s lands? And that, I think, is the role of poetry that I try to achieve.
Segment 1746: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6912, Text: So poetry ultimately prizes the power of words and so the power of the medium of poetry transfers nicely to any medium that celebrates words, I mean, just writing novels, tweeting. You’re also working on a new book, a memoir. What’s the title? What can you say about it?
Segment 1747: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=6939, Text: My memoir is bizarre because I’m so young, so it’s not really my memoir, but it’s rather a memoir of the neighborhood in which I grew up. The title, the tentative title, is, A Million States In One, and it’s a nod to how many different realities and universes exist in this tiny one country. And it’s a documentation of the two waves of expulsion in 2009 and 2020 and 2021 and a behind the scenes of the campaign that took place, the diplomatic and media campaign and grassroots campaign that took place, to save our homes. It’s also an exploration of other communities that are threatened with expulsion and other communities who are resisting in their own way, be it in Beita, in Nablus, or South Hebron Hills, in [inaudible 01:56:33], or in Silwan, or in [inaudible 01:56:36], all these communities that are dealing with different forms of expulsion.
Segment 1748: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7000, Text: And the emphasis that I’m trying to achieve with this book is dignity. I want to write a book about my experiences that is super dignified, that kicks its feet up on the table, and says what it wants unabashedly. Because we are told not only are we going to be victimized, but we are going to be polite in our suffering. I want to reject that completely and I want to lean into the humor of the past few years of my life because I think that’s really what the world needs and what I need to be writing.
Segment 1749: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7038, Text: A few questions here, but one of them is about humor. In Rifqa, you wrote, “My mother has always said the most tragic of disasters is those that cause laughter.” What do you think she meant by that?
Segment 1750: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7053, Text: I don’t know. That’s my mom’s saying, but I don’t know, it’s probably a proverb that I first heard from my mom, but it’s [foreign language 01:57:40], the most evil of an atrocity is what makes you laugh. It’s open for interpretation. One school of thought would say, “You should be wary of the things that make you laugh,” but another school of thought would say, “This is a commentary on our natural reactions to tragedies.” In 2012, 2011, something like this, we had a protest, and after the protest, all of the women of the neighborhood were sitting down under the fig tree of our neighborhood, which they always do. And a bunch of soldiers, maybe 40 soldiers, started marching down the street and everybody dispersed and hid in their homes.
Segment 1751: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7108, Text: But my aunt, who has now passed away, my aunt refused to go home. She wanted to gather her teacups because she really cared about her teacups. I was begging her to go inside and she refused. She was gathering her teacups. A soldier grabbed me and squeezed me between his baton and an electricity pole. It was very excruciatingly painful and traumatizing for me as a child, but it’s also a funny memory, in a way. Despite the pain, despite the trauma that came with it, there’s still something funny about it.
Segment 1752: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7148, Text: The absurdity of it.
Segment 1753: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7149, Text: Yeah. It’s dignifying to find humor in these kinds of things. It makes you realize you are not so weak, you are not so powerless. Another thing is, my same aunt, who was super obsessed with cleanliness, would insist on not going to sleep before washing the dishes. And I would always tease her and say, “You’re going to give them the house clean. You can leave it dirty so they have to clean it up.” And these little things, although incredibly absurd and telling of a harrowing reality that our family and many in the neighborhood were living, are also the coping mechanisms that we were using to deal with our everyday reality.
Segment 1754: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7198, Text: So much in the public framing of Palestinians, be it in media, in novels, in diplomacy, and so on and so forth, is that of the powerless victim, is that of the person who only weeps. Israeli propagandists, for example, will show pictures on Twitter of a house in [inaudible 02:00:18], and they’ll be like, “Look. This house has windows. They’re talking about their BCs, but they have a nice balcony on their house. What are they talking about?” Or they’ll show a video of a supermarket in [inaudible 02:00:31] and they’ll be like, “How come they’re talking about a blockade when they have a supermarket, and blah, blah, blah”, as though the ceiling has been so lowered that we can’t even afford joy anymore or a little supermarket in the neighborhood.
Segment 1755: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7246, Text: So as a poet, as a writer, you’ve written a book of poetry and now working on a new book. What can you say about your process of crafting words? I think people listening to this can hear that there’s a poetry to way you speak in English, so somebody that cares about the craftsmanship of words in both English and Arabic, what can you say about your process?
Segment 1756: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7272, Text: It’s a lot more neat than this conversation. I am obsessed with sentences and it takes me a long time to finish a piece of writing. I am a perfectionist.
Segment 1757: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7284, Text: Do you edit a lot?
Segment 1758: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7285, Text: I edit all the time and I can’t move on from one sentence until it’s perfect. But I will say, my other writer friends here in New York do not face how easily disrupted my writing is by other news. I’ll pitch a story to my editor about something, for example, and then as I’m writing it, 20 minutes in, some kid was shot and killed by the Israeli military, so I have to say something about it. And then 30 minutes later, as I’m writing it, there’s news about a home demolition in Silwan. There is this relentless onslaught of news that prevents us and deprives us of the ability to analyze, to frame, to think, to conceptualize, to write beyond the current affairs.
Segment 1759: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7335, Text: We’re stuck in the relentlessness of the occupation that a lot of the time I worry that the things I’m writing are always in reaction to a crime that took place, to a bombing that took place, and so on and so forth. And I think that’s, unfortunately, true for so many Palestinian writers. I would say isolation and stepping away from the news is very important to do, but I don’t do it.
Segment 1760: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7370, Text: Okay, so the struggle to find the timeless message in it is an ongoing struggle for you?
Segment 1761: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7378, Text: It’s not even timelessness. It’s timeliness. I think what you write is always timely, because the occupation is ongoing. The struggle is moving beyond the news and tackling more nuances. Because, in Arabic, I can, in Arabic, I can philosophize, I can talk about violence, and I can talk about my complicated relationship with violence. I can complicate and nuance and give things nuance, but, in English, people still do not believe we are under occupation, even though it is an internationally recognized fact that is broadcasted 24/7 through the world’s most watched screens. We’re stuck in a practice of providing facts and figure as in, “Actually, this happened and this person did this, and according to international law, and blah, blah, blah.” We’re stuck in this because the basic truths about our own existence are denied that we don’t even have the luxury of evolving our writing beyond, or at least evolving my writing beyond it. And this is what I’m trying to do with this new book.
Segment 1762: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7448, Text: That’s fascinating that in English your brain is more inclined to go towards activism, whereas in Arabic, you have the luxury to be more of a philosopher.
Segment 1763: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7461, Text: I wouldn’t say activism. I would say journalism.
Segment 1764: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7463, Text: Journalism.
Segment 1765: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7465, Text: Just making sure disrupting the flow of the sentence to insert a statistic or insert a historical fact that should be implied and should be a household name, but it’s not. I can’t just say “the Nakba”. I have to say, “The Nakba, the 1948 near total destruction of Palestinian society at the hands of Zionist militias that later formed the Israeli military that now terrorizes us today and there’s a three-tier legal system, blah, blah, blah.” I can’t just say, “Nakba”. I have to give all of these explanations, and that’s heartbreaking. And people are out to do better. People are out to do better. It’s not what my literature should be limited to. It’s not what anybody’s literature should be limited to. It’s the job of news reporters to report the news, but a lot of the time they use loaded language, they use a passive voice, they obfuscate facts, and it’s on the shoulders of us, the heavy carrying.
Segment 1766: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7537, Text: Would you say the President in the United States does a good or poor job of covering Israel and Palestine?
Segment 1767: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7546, Text: Terrible job. Horrible job. Horrendous job. They don’t do their job, whatsoever.
Segment 1768: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7551, Text: What are the biggest failings?
Segment 1769: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7552, Text: Not mentioning that a town is occupied when you’re reporting about an occupied town. Not mentioning that a settlement is illegal or a settler is illegally present in a Palestinian village when you’re reporting on them. Only quoting Israeli officials and only quoting Israeli politicians and police officers and framing your entire analysis with Israeli officials and only interviewing Palestinians when they have been brutalized and victimized physically. Those are some of the issues. There is plenty. And then saying things like “Israel will bomb a hospital in Gaza” and the press will say “a Hamas run hospital” and this negative association with Hamas will remove any sympathy from the reader towards the victims of this hospital bombing. A lot of things. And a lot of them are sinister. I have many friends, many journalist friends, and I’ve seen many journalists online speak about their experiences when talking about Palestine, the censorship that goes on into it.
Segment 1770: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7623, Text: And I have many journalist friends, some at the New York Times, some they used to be at the Washington Post, who tell me the kinds of battles they had to go through with their editors to let them even utter the word Palestine. And not even on in news pieces, pieces about, let’s say, a Palestinian artist or a Palestinian chef or whatever. There’s a lot that happens behind the scenes that is not reported on because, when it comes to Palestine, the rules and the laws of journalism are bendable. Passive voice is king. Omitting facts is acceptable. Anything goes.
Segment 1771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7667, Text: So you personally, just psychologically, what have been the lowest points in your life, the darkest points?
Segment 1772: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7677, Text: A recent study came out and said that 52% of Palestinians have depression. I would argue that the number is much, much, much higher. I think it would be absurd for someone to live under the conditions we live under and not contemplate many things, many things. Not just suicide, but many, many, many things. And if people were to put themselves in our shoes for just one day, they would understand where all of the rage and all of the resistance is coming from. It’s not an easy life.
Segment 1773: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7712, Text: So where do you find the strength?
Segment 1774: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7714, Text: I’m surrounded by good people. I’m surrounded by good people and I don’t even think of it as a strength. I think of this as my obligation. It just feels like the thing I have to do. I don’t need inspiration. I don’t need strength. It’s just my obligation. There is a great travesty taking place in the world and I and a few others have been put in a place where we’re able to talk about it to a few more people. It’s just my obligation. I have to do it.
Segment 1775: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7754, Text: What gives you hope about the future of Palestine?
Segment 1776: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7758, Text: What gives me hope about the future of Palestine is taking a look at history and understanding that across history there has not been an injustice that lingered endlessly. Everything comes to an end. There’s not necessarily a perfect resolution for everything, but nothing continues in the form that it started in, and the occupation and colonialism and Palestine and Zionism, all of these things, are not at all sustainable whatsoever taking a look at history. A lot of what I’m saying today and what I have said in your podcast, many people would’ve would be pearl-clutching hearing me say what I say. But I always try to remind myself that during Jim Crow, during slavery, during the Holocaust, during the occupation of Algeria, during any point of colonialism in the African continent, people did not possess the moral clarity they possess today when they talk about these things. And all of these things were contested and controversial and in many, many, many cases legal and, today, they are deplorable, condemnable, and people say “never again” and they don’t remember them. So that’s what gives me hope, is believing in the inevitability of justice.
Segment 1777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7844, Text: What do you love most about Palestine? What are maybe little things that you remember from your childhood, from your life there in East Jerusalem and elsewhere that just brings a smile to your face?
Segment 1778: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7857, Text: I think just the unabashed-ness of Palestinians. We’re a people who are told and at some point were told by the large majority of the world that we should shrink ourselves, that we should be ashamed of who we are, that we are monsters, that we are terrorists, that we are, blah, blah, blah. And Palestinian people don’t really give a shit. They’re continuing to live as they do. They continue to resist. They continue to write. They continue to do all that they do, and I love that the most. And I love our ability to laugh more than anything else. One thing that’s misunderstood in American culture about Palestinian culture or just Western culture in general is martyrdom culture. A lot of the time people will broadcast images of Palestinian women cheering when their sons have been killed by the Israeli forces and they’ll say, “These people glorify death and these people are eager to have sex with 70 virgins in heaven”, and so on and so forth.
Segment 1779: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7925, Text: But that’s not the case. The whole idea of the occupation, when they are killing our children, the whole idea is that they’re trained to break our spirits. These mothers, whose hearts are broken, who are anguished, who are so in so much pain when they are cheering, they are not celebrating, they’re not cheering. They are letting the occupier know that, “You have not broken my spirit. I have not yet been defeated.” And I think that is beautiful. It’s the same thing with our prison culture. Palestinians are fascinating in the sense that Palestinians go to prison and they study and they come out with degrees. They can find ways to participate in civil society. They can even smuggle sperm from prison to give a life outside of it because in their philosophy of prisons, they understand that these structures, these buildings were built to break your spirits. So what do you?
Segment 1780: Speaker: , Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=7988, Text: You don’t allow it to break your spirits. You resist it. You continue to hold onto life. You continue to hold on to your love of life. You continue to hold on to your love of freedom and you come out of prison and you’re celebrated by your community. The prison has not broken your spirit. All of these structures and system that is the Zionist movement has put into place, be it the shoot-to-kill policies or the prisons or the demolishing our homes that were meant to kill our spirits, they don’t. You demolish the home in Jerusalem and the people say, “Don’t worry. We’ll build another. You demolish it and we’ll build another.” That’s what I admire most about the Palestinian people. It’s this resilience. And people love to say resilience, but I think it’s stubbornness. I think we’re such a stubborn people, and I think that’s great.
Segment 1781: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=8037, Text: Well, Mohammed, thank you for being a man who exemplifies this unbreakable spirit. Thank you for the words you’ve written, the words you’ve spoken, and thank you for talking today. This is an honor and thank you for educating me.
Segment 1782: Speaker: Mohammed el-Kurd, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=8053, Text: Thank you so much.
Segment 1783: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=34wA_bdG6QQ&t=8054, Text: Thanks for listening to this conversation with Mohammed el-Kurd. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Nelson Mandela. “It always seems impossible until it’s done.” Thank you for listening and hope to see you next time.
Segment 1784: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=0, Text: If we now find ourselves inside this kind of world of illusions created by an alien intelligence, that we don’t understand, but it understands us, this is a kind of spiritual enslavement that we won’t be able to break out of, because it understands us, it understands how to manipulate us, but we don’t understand what is behind this screen of stories and images and songs.
Segment 1785: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=36, Text: The following is a conversation with Yuval Noah Harari, a historian, philosopher, and author of several highly acclaimed, highly influential books, including Sapiens, Homo Deus and 21 Lessons for the 21st Century. He is also an outspoken critic of Benjamin Netanyahu and the current right-wing government in Israel. While much of this conversation is about the history and future of human civilization, we also discuss the political turmoil of present day Israel, providing a different perspective from that of my recent conversation with Benjamin Netanyahu.
Segment 1786: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=74, Text: This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Yuval Noah Harari.
Segment 1787: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=84, Text: 13.8 billion years ago is the origin of our universe. 3.8 billion years ago is the origin of life here on our little planet, the one we call earth. Let’s say 200,000 years ago, is the appearance of early homo sapiens. Let me ask you this question. How rare are these events in the vastness of space and time? Or put it in a more fun way, how many intelligent alien civilizations do you think are out there in this universe, us being one of them?
Segment 1788: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=113, Text: I suppose there should be some, statistically, but we don’t have any evidence. I do think that intelligence, in any way, it’s a bit overvalued. We are the most intelligent entities on this planet, and look what you’re doing. So intelligence also tends to be self-destructive, which implies that if there are, or were, intelligent life forms elsewhere, maybe they don’t survive for long.
Segment 1789: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=142, Text: You think there’s a tension between happiness and intelligence?
Segment 1790: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=146, Text: Absolutely. Intelligence is definitely not something that is directed towards amplifying happiness. I would also emphasize the huge, huge difference between intelligence and consciousness, which many people, certainly in the tech industry and in the AI industry, tend to miss. Intelligence is simply the ability to solve problems, to attain goals, and to win at chess, to win a struggle for survival, to win a war, to drive a car, to diagnose a disease. This is intelligence. Consciousness is the ability to feel things like pain and pleasure, and love, and hate. In humans and other animals intelligence and consciousness go together. They go hand in hand, which is why we confuse them. We solve problems, we attain goals by having feelings. Other types of intelligence, certainly in computers, computers are already highly intelligent and as far as we know, they have zero consciousness. When a computer beats you at chess or go or whatever, it doesn’t feel happy. If it loses, it doesn’t feel sad. There could be also other highly intelligent entities out there in the universe that have zero consciousness. I think that consciousness is far more important and valuable than intelligence.
Segment 1791: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=239, Text: Can you steer me on the case that consciousness and intelligence are intricately connected? Not just in humans, but anywhere else. They have to go hand in hand. Is it possible for you to imagine such a universe?
Segment 1792: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=252, Text: It could be, but we don’t know yet. Again, we have examples. Certainly, we know of examples of high intelligence without consciousness. Computers are one example. As far as we know, plants are not conscious, yet, they are intelligent. They can solve problems, they can attain goals in very sophisticated ways. The other way around, to have consciousness without any intelligence, this is probably impossible, but to have intelligence without consciousness, yes, that’s possible.
Segment 1793: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=288, Text: A bigger question is whether any of that is tied to organic biochemistry. We know, on this planet, only about carbon-based life forms, whether you are an amoeba, a dinosaur, a tree, a human being, you are based on organic biochemistry. Is there an essential connection between organic biochemistry and consciousness? Do all conscious entities, everywhere in the universe or in the future on planet earth, have to be based on carbon? Is there something so special about carbon as an element that an entity based on silicon will never be conscious? I don’t know, maybe. Again, this is a key question about computer and computer consciousness. Can computers eventually become conscious, even though they are not organic? The jury is still out on that. I don’t know. We have to take both options into account.
Segment 1794: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=348, Text: Well, a big part of that is do you think we humans would be able to detect other intelligent beings, other conscious beings? Another way to ask that, is it possible that the aliens are already here and we don’t see them? Meaning are we very human-centric in our understanding of, one, the definition of life, two, the definition of intelligence, and three, the definition of consciousness?
Segment 1795: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=373, Text: The aliens are here, they are just not from outer space. AI, which usually stands for artificial intelligence. I think it stands for alien intelligence because AI is an alien type of intelligence. It solves problems, attains goals in a very, very different way, in an alien way from human beings. I’m not implying that AI came from outer space, it came from Silicon Valley, but it is alien to us. If there are alien intelligent or conscious entities that came from outer space already here, I’ve not seen any evidence for it. It’s not impossible, but in science, evidence is everything.
Segment 1796: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=416, Text: Well, I mean, I guess, instructive there is just having the humility to look around, to think about living beings that operate at different timescale, at different spatial scale. I think that’s all useful when starting to analyze artificial intelligence. It’s possible that even the larger language models we have today are already conscious.
Segment 1797: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=439, Text: I highly doubt it, but I think consciousness, in the end, it’s a question of social norms. Because we cannot prove consciousness in anybody except ourselves. We know that we are conscious, because we are feeling it. We have direct access to our subjective consciousness. We cannot have any proof that any other entity in the world, any other human being, our parents, our best friends, we don’t have proof that they are conscious. This has been known for thousands of years. This is Descartes, this is Buddha, this is Plato. We can’t have this sort of proof. What we do have is social conventions. It’s a social convention that all human beings are conscious. It also applies to animals. Most people who have pets firmly believe that their pets are conscious, but a lot of people still refuse to acknowledge that about cows or pigs.
Segment 1798: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=495, Text: Now, pigs are far more intelligent than dogs and cats, and according to many measures, yet, when you go to the supermarket and buy a piece of frozen pig meat, you don’t think about it as a conscious entity. Why do you think of your dog as conscious, but not of the bacon that you buy? Because you’ve built a relationship with the dog and you don’t have a relationship with the bacon.
Segment 1799: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=522, Text: Now, relationships, they don’t constitute a logical proof for consciousness, they’re a social test. The Turing test is a social test, it’s not a logical proof. Now, if you establish a mutual relationship with an entity and you are invested in it, emotionally, you are almost compelled to feel that the other side is also conscious. When it comes again to AI and computers, I think, again, I don’t think that at the present moment computers are conscious, but people are already forming intimate relationships with AI and are therefore almost … It’s almost irresistible. They’re compelled to increasingly feel that these are conscious entities. I think we are quite close to the point when the legal system will have to take this into account. Even though I don’t think computers have consciousness, I think we are close to the point the legal system will start treating them as conscious entities, because of this social convention.
Segment 1800: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=596, Text: To you is a social convention, just a funny little side effect, a little artifact, or is it fundamental to what consciousness is? Because if it is fundamental, then it seems like AI is very good at forming these kinds of deep relationships with humans, and therefore it’ll be able to be a nice catalyst for integrating itself into these social conventions of ours.
Segment 1801: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=621, Text: It was built to accomplish that. Again, all this argument between natural select selection and creationism, intelligent design. As far as the past go, all entities evolve by natural selection. The funny thing is, when you look to the future, more and more entities will come out of intelligent design, not of some God above the clouds, but of our intelligent design and the intelligent design of our clouds, of our computing clouds. They will design more and more entities. This is what is happening with AI. It is designed to be very good at forming intimate relationships with humans. In many ways, it’s already doing it almost better than human beings, in some situations.
Segment 1802: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=673, Text: When two people talk with one another, one of the things that makes the conversation more difficult is our own emotions. You are saying something and I’m not really listening to you, because there is something I want to say, and I’m just waiting until you finish I can put in a word, or I’m so obsessed with my anger or irritation or whatever, that I don’t pay attention to what you are feeling. This is one of the biggest obstacles in human relationships. Computers don’t have this problem, because they don’t have any emotions of their own.
Segment 1803: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=711, Text: When a computer is talking to you, it can focus 100% of its attention is on what you’re saying and what you’re feeling because it has no feelings of its own. Paradoxically, this means that computers can fool people into feeling that, oh, there is a conscious entity on the other side, an empathic entity on the other side, because the one thing everybody wants, almost more than anything in the world, is for somebody to listen to me, somebody to focus all their attention on me. I want it from my spouse, from my husband, from my mother, from my friends, from my politicians. Listen to me, listen to what I feel. They often don’t. Now you have this entity, which a hundred percent of its attention is just on what I feel. This is a huge, huge temptation, and I think also a huge, huge danger.
Segment 1804: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=769, Text: Well, the interesting catch 22 there is you said somebody to listen to us. Yes, we want somebody to listen to us, but for us to respect that somebody, they sometimes have to also not listen. They kind of have to be an asshole sometimes. They have to have moods sometimes. They have to have self-importance and confidence, and we should have a little bit of fear that they can walk away at any moment. There should be a little bit of that tension.
Segment 1805: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=797, Text: Absolutely.
Segment 1806: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=800, Text: Could we optimize for it?
Segment 1807: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=801, Text: If social scientists and say psychologists establish that, I don’t know, 17% inattention is good for a conversation because then you feel challenged, “Oh, I need to grab this person’s attention,” you can program the AI to have exactly 17% inattention, not one percentage more or less. Or it can by trial and error, discover what is the ideal percentage. Over the last 10 years, we have creating machines for grabbing people’s attention. This is what has been happening on social media.
Segment 1808: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=838, Text: Now, we are designing machines for grabbing human intimacy, which, in many ways, it’s much, much more dangerous and scary. Already the machines for grabbing attention, we’ve seen how much social and political damage they could do by in many way kind of distorting the public conversation. Machines that are superhuman, in their abilities to create intimate relationships, this is psychological and social weapons of mass destruction. If we don’t regulate it, if we don’t train ourself to deal with it, it could destroy the foundations of human society.
Segment 1809: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=881, Text: Well, one of the possible trajectories is those same algorithms would become personalized and instead of manipulating us at scale, there would be assistants that guide us to help us grow, to help us understand the world better. Even interactions with large language models now, if you ask them questions, it doesn’t have that stressful drama, the tension that you have from other sources of information. It has a pretty balanced perspective that it provides. It just feels like the potential is there to have a really nice friend who’s an encyclopedia that just tells you all the different perspectives, even on controversial issues, the most controversial issues, to say, these are the different theories. These are the not widely accepted conspiracy theories, but here’s the kind of backing for those conspiracy. It just lays it all out. Then with a calm language, without the words that kind of presume there’s some kind of manipulation going on underneath it all. It’s quite refreshing.
Segment 1810: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=947, Text: Of course, those are the early days. People can step in and start to sensor it to manipulate those algorithms, to start to input some of the human biases in there as opposed to what’s currently happening is kind of the internet is input, compress it, and have a nice little output that gives an overview of the different issues. I mean, there’s a lot of promise there also, right?
Segment 1811: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=973, Text: Absolutely. I mean, if there was no promise, there was no problem. If this technology could not accomplish anything good, nobody would develop it. Now, obviously, it has tremendous positive potential in things like what you just described in better medicine, better healthcare, better education, so many promises. This is also why it’s so dangerous, because the drive to develop it faster and faster is there, and it has some dangerous potential also. We shouldn’t ignore it. Again, I’m not advocating banning it, just to be careful about how we, not so much develop it, but most importantly how we deploy it into the public sphere. This is the key question.
Segment 1812: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1016, Text: You look back at history, and one of the things we know from history, humans are not good with new technologies. I hear many people now say, “AI, we’ve been here before. We had the radio, we had the printing press, we had the Industrial Revolution.” Every time there is a big new technology, people are afraid and it’ll take jobs and the bad actors. In the end it’s okay. As a historian, my tendency is yes, in the end it’s okay, but in the end there is a learning curve. There is a lot of failed experiments on the way to learning how to use the new technology. These failed experiments could cost the lives of hundreds of millions of people.
Segment 1813: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1062, Text: If you think about the last really big revolution, the Industrial Revolution, yes, in the end, we learned how to use the powers of industry; electricity, radio, trains, whatever, to build better human societies. On the way, we had all these experiments like European imperialism, which was driven by the Industrial Revolution. It was a question, how do you build an industrial society? Oh, you build an empire. You control all the resources, the raw materials, the markets. Then you had communism, another big experiment on how to build an industrial society. You had fascism and Nazism, which were essentially an experiment in how to build an industrial society, including even how do you exterminate minorities using the powers of industry? We had all these failed experiments on the way.
Segment 1814: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1117, Text: If we now have the same type of failed experiments with the technologies of the 21st century, with AI, with bioengineering, it could cost the lives of, again, hundreds of millions of people and maybe destroy the species. As a historian, when people talk about the examples from history, from new technologies, I’m not so optimistic. We need to think about the failed experiment, which accompanied every major new technology.
Segment 1815: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1150, Text: This intelligence thing, like you were saying, is a double-edged sword, is that every new thing it helps us create, it can both save us and destroy us. It’s unclear each time, which will happen. That’s maybe why we don’t see any aliens.
Segment 1816: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1168, Text: Yeah. I mean, I think each time it does both things. Each time it does both good things and bad things. The more powerful the technology, the greater both the positive and the negative outcomes. Now, we are here because we are the descendants of the survivors, of the surviving cultures, the surviving civilizations. When we look back we say, in the end, everything was okay, “Hey, we are here,” but the people for whom it wasn’t okay, they are just not here.
Segment 1817: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1202, Text: Okay. Has a lot of possible variations to it because there’s a lot of suffering along the way, even for the people that survived. The quality of life and all of this. Let’s actually go back there, with deep gratitude to our ancestors. How did it all start? How did homo sapiens out-compete the others, the other human-like species, the Neanderthals and the other homo species?
Segment 1818: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1233, Text: On the individual level, as far as we can tell, we were not superior to them. Neanderthals actually had bigger brains than us. Not just other human species, other animals too. If you compare me, personally, to an elephant, to a chimpanzee, to a pig, I can do some things better, many other things worse. If you put me alone on some island with a chimpanzee, an elephant and a pig, I wouldn’t bet on me being the best survivor, the one that comes successful.
Segment 1819: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1266, Text: If I may interrupt for a second, I was just talking extensively with Elon Musk about the difference between humans and chimps, relevant to Optimus, the robot. The chimps are not able to do this kind of pinching with their fingers. They can only do this kind of pinching, and this kind of pinching is very useful for precise manipulation of objects. Don’t be so hard on yourself.
Segment 1820: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1292, Text: No, I said that I can do some things better than a chimp. If Elon Musk goes on a boxing match with a chimpanzee …
Segment 1821: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1302, Text: This won’t help you.
Segment 1822: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1303, Text: This won’t help you against a chimpanzee.
Segment 1823: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1306, Text: Good point.
Segment 1824: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1307, Text: Similar, if you want to climb a tree, if you want to do so many things, my bets will be on the chimp, not on Elon.
Segment 1825: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1313, Text: Fair enough.
Segment 1826: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1314, Text: You have advantages on both sides. What really made us successful, what made us the rulers of the planet and not the chimps and not the Neanderthals, is not any individual ability, but our collective ability. Our ability to cooperate flexibly in very large numbers. Chimpanzees know how to cooperate, say, 50 chimpanzees, a hundred chimpanzees. As far as we can tell from archeological evidence this was also the case with Neanderthals. Homo sapiens, about 70,000 years ago, gained an amazing ability to cooperate basically in unlimited numbers. You start seeing the formation of large networks; political, commercial, religious, items being traded over thousands of kilometers, ideas being spread, artistic fashions. This is our secret of success. Chimpanzees, Neanderthals can cooperate, say, a hundred.
Segment 1827: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1376, Text: Now, the global trade network has 8 billion people. What we eat, what we wear, it comes from the other side of the world. Countries like China, like India, they have 1.4 billion people. Even Israel, which is a relatively small country, say 9 million citizens, that’s more than the entire population of the planet 10,000 years ago of humans. We can build these huge networks of cooperation. Everything we have accomplished as a species from building the pyramids to flying to the moon, it’s based on that. Then you ask, “Okay. So what makes it possible for millions of people who don’t know each other, to cooperate in a way that Neanderthals or chimpanzees couldn’t?” At least my answer is stories, is fiction. It’s the imagination.
Segment 1828: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1428, Text: If you examine any large scale human cooperation, you always find fiction as its basis. It’s a fictional story that holds lots of strangers together. It’s most obvious in cases like religion. You can’t convince a group of chimpanzees to come together to fight a war or build a cathedral by promising to them, “If you do that, after you die, you go to chimpanzee heaven and you get lots of bananas and coconuts.” No chimpanzee will ever believe that. Humans believe these stories, which is why we have these huge religious networks. It’s the same thing with modern politics.
Segment 1829: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1469, Text: It’s the same thing with economics. People think, “Oh, economics, this is rational. It has nothing to do with fictional stories.” No money is the most successful story ever told, much more successful than any religious mythology. Not everybody believes in God, or in the same God, but almost everybody believes in money, even though it’s just a figment of our imagination. You take these green pieces of paper, dollars, they have no value. You can’t eat them, you can’t drink them. Today, most dollars are not even pieces of paper, they are just electronic information passing between computers. We value them just for one reason, that you have the best storytellers in the world, the bankers, the finance ministers, all these people, they are the best storytellers ever. They tell us a story that this green little piece of paper, or this bit of information, it is worth a banana. As long as everybody believes it, it works.
Segment 1830: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1529, Text: At which point does a fiction, when it’s sufficiently useful and effective and improving the global quality of life, does it become accepted reality? There’s a threshold, which just [inaudible 00:25:43].
Segment 1831: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1542, Text: If enough people believe it. It’s like with money. If you start a new cryptocurrency, if you are the only one that believes the story … I mean, again, you cryptocurrencies, you have the math of course, but ultimately it’s storytelling. You’re selling people a story. If nobody believes your story, you don’t have anything, but if lots of people believe the Bitcoin story, then Bitcoin can be worth thousands and tens of thousands of dollars. Again, why? I mean, you can’t eat it, you can’t drink. It’s nothing. It’s this story around the math, which is the real magic.
Segment 1832: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1577, Text: Is it possible that the story is the primary living organism, not the storyteller. That somehow homo sapiens evolved to become these hosts for a more intelligent living organism, which is the idea. The ideas are the ones that are doing the competing. This is one of the sort of big perspectives behind your work that’s really revolutionary of how you’ve seen history. Do you ever take out the perspective of the ideas as the organisms versus the humans?
Segment 1833: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1615, Text: It’s an interesting idea. There are two opposite things to say about it. On the one hand, yes, absolutely. If you look long term in history, all the people die. It’s the stories that compete and survive and spread. Stories often spread by making people willing to sacrifice sometimes their lives for the story. We know, in Israel, this is one of the most important story factories in human history. This is a place where people still kill each other every day over stories. I don’t know. You’ve been to Jerusalem, right?
Segment 1834: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1652, Text: Mm-hmm (affirmative).
Segment 1835: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1654, Text: People here are, “Oh, Jerusalem, Jerusalem, Jerusalem.” I’ve lived in Jerusalem much of my life. You go there, it’s an ordinary place. It’s a town. You have buildings, you have stones, you have trees, you have dogs and cats and pedestrians. It’s a regular place. Then you have the stories about the place, “Oh, this is the place where God revealed himself. This is the place where Jesus was. This is the place where Muhammad was.” It’s the stories that people fight over. Nobody’s fighting over the stones. People are fighting about the stories about the stones. If a story can get millions of people to fight for it, it not only survives, it spreads. It can take over the world.
Segment 1836: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1702, Text: The other side of the coin is that the stories are not really alive, because they don’t feel anything. This goes back to the question of consciousness, which I think is the most important thing, that the ultimate reality is consciousness, is the ability to feel things. If you want to know whether the hero of some story is real or not, you need to ask, “Can it suffer?” Stories don’t feel anything. Countries, which are also stories, nations, don’t suffer. If a nation loses a war, it doesn’t suffer. The soldiers suffer, the civilians suffer. Animals can suffer. You have an army with horses and whatever, and the horses get wounded, the horses suffer. The nation can’t suffer, it’s just an imagination. It’s just a fictional story in our mind. It doesn’t feel anything.
Segment 1837: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1761, Text: Similarly, when a bank goes bankrupt or a company goes bankrupt, or when a currency loses its value, like Bitcoin is worth now zero, crashed, or the dollar is worth zero, it crashed. The dollar doesn’t feel anything. It’s the people holding the dollars who might be now very miserable. We have this complex situation when history is largely driven by stories, but stories are not the ultimate reality. The ultimate reality is feelings of humans, of animals. The tragedy of history is that very, very often we get the order wrong. Stories are not bad. Stories are tools. They’re good, when we use them in order to alleviate suffering, but very often we forget it. Instead of using the stories for our purposes, we allow the stories to use us for their purposes. Then you start entire wars because of a story. You inflict suffering on millions of people just for the sake of a story. That’s the tragedy of human history.
Segment 1838: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1841, Text: The fundamental property of life, of a living organism, is the capacity to feel and the ultimate feeling is suffering?
Segment 1839: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1850, Text: To know if you are happy or not, it’s a very difficult question, but when you suffer you know.
Segment 1840: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1855, Text: Yes.
Segment 1841: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1856, Text: Also, in ethical terms, it’s more important to be aware of suffering than of any other emotion. If you are doing something which is causing all kinds of emotions to all kinds of people, first of all, you need to notice if you’re causing a lot of suffering to someone. If some people like it and some people are bored by it and some people are a bit angry at you, and some people are suffering because of what you do, you first of all have to know, oh … Sometimes, you still have to do it. The world is a complicated place. I don’t know. You have an epidemic. Governments decide to have all those social isolation regulations or whatever. In certain cases, yes, you need to do it even though it can cause tremendous suffering, but you need to be very aware of the cost and to be very, very … You have to ask yourself again, and again, and again, is it worth it? Is it still worth it?
Segment 1842: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1913, Text: The interesting question there, implied in your statements, is that suffering is a pretty good component of a Turing test for consciousness.
Segment 1843: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1921, Text: This is the most important thing to ask about AI: Can it suffer? Because if AI can suffer, then it is an ethical subject and it needs protection, it needs rights just like humans and animals.
Segment 1844: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1935, Text: Well, quite a long time ago already, so I work with a lot of robots, legged robots, but I’ve even had, inspired by a YouTube video, had a bunch of Roombas that I made them scream when I touched them or kicked them, or when they ran into a wall. The illusion of suffering, for me, a silly human that anthropomorphizes things, is as powerful as suffering itself. I mean, you immediately think the thing is suffering. I think some of it is just a technical problem, but it’s the easily solvable one, how to create an AI system that just says, “Please don’t hurt me. Please don’t shut me off. I miss you. Where have you been?” Be jealous, also. ” Why have you been gone for so long?”
Segment 1845: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1981, Text: Why have you been gone for so long? Your calendar doesn’t have anything on it. This create through words the perception of suffering, of jealousy, of anger, of all of those things, and it just seems like that’s not so difficult to do.
Segment 1846: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=1999, Text: That’s part of the danger. It basically hacks our operating system and it uses some of our best qualities against us. It’s very, very good that humans are attuned to suffering and that we don’t want to cause suffering because we have compassion. That’s one of the most wonderful thing about humans. If we now create AIs which use this to manipulate us, this is a terrible thing.
Segment 1847: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2028, Text: You’ve, I think, mentioned this. Do you think it should be illegal to do these kinds of things with AI, to create the perception of consciousness of saying, “Please don’t leave me,” or basically simulate some of the human-like qualities?
Segment 1848: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2045, Text: Yes. I think, again, we have to be very careful about it. If it emerges spontaneously, we need to be careful. Again, we can’t rule out the possibility that AI will develop consciousness. We don’t know enough about consciousness to be sure. If it develops spontaneously, we need to be very careful about how we understand it. If people intentionally design an AI that they know, they assume it has no consciousness, but in order to manipulate people, they use again this human strength, the noble part of our nature against us, this should be forbidden and, similarly on a more general level, that it should be forbidden for an AI to pretend to be a human being, that it’s okay. There are so many things we can use Ais as teachers, as doctors and so forth, and it’s good as long as we know that we are interacting with an AI. The same way we ban fake money, we should ban fake humans. It’s not just banning deep fakes of specific individuals. It’s also banning deep fake of generic humans, which is already happening to some extent on social media. If you have lots of bots retweeting something, then you have the impression, “Oh, lots of people are interested in that. That’s important,” and this is basically the bots pretending to be humans, because if you see a tweet which says 500 people retweeted it or you see a tweet and it says 500 bots retweeted it, I don’t care what the bots we tweeted, but if it’s humans, okay, that’s interesting.
Segment 1849: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2156, Text: We need to be very careful that bots can’t do that. They are doing it at present, and it should be banned. Now, some people say, “Yes, bots’ freedom of expression.” No. Bots don’t have freedom of expression. There is no cost in terms of freedom of expression when you ban bots. Again, in some situations, yes, AIs should interact with us, but it should be very clear this is an AI talking to you or this is an AI retweeting this story, it is not a human being making a conscious decision.
Segment 1850: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2192, Text: To push back on this line of fake humans, because I think it might be a spectrum, first of all, you might have AI systems that are offended, hurt when you say that they’re fake humans. In fact, they might start identifying as humans. You just talked about the power of us humans with our collective intelligence to take fake stories and make them quite real. If the feelings you have for the fake human is real, love is a kind of fake thing that we all put a word to, a set of feelings, what if you have that feeling for an AI system? It starts to change, I mean, maybe the things AI systems are allowed to do for good. They’re allowed to create, communicate suffering, communicate the good stuff, the longing, the hope, the connection, the intimacy, all of that and, in that way, get integrated in our society, and then you start to ask a question on are we allowed to really unplug them? Are we allowed to really censor them, remove them, remove their voice from social media?
Segment 1851: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2273, Text: I’m not saying they shouldn’t have a voice, they shouldn’t talk with us. I’m just saying, when they talk with us, it should be clear that they are AI. That’s it. You can have your voice as an AI. Again, I have some medical problem. I want to get advice from an AI doctor. That’s fine as long as I know that I’m talking with an AI. What should be banned is AI pretending to be a human being. This is something that will erode trust and, without trust, society collapses. This is something that especially will endanger democracies because democracy is a conversation basically and it’s a conversation between people.
Segment 1852: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2317, Text: If you now flood the public sphere with millions and potentially billions of AI agents that can hold conversations, they never sleep, they never eat, they don’t have emotions of their own, they can get to know you and tailor their words specifically for you and your life story, they are becoming better than us at creating stories and ideas and so forth. If you flood the public sphere with that, this will ruin the conversation between people. It will ruin the trust between people. You will no longer be able to have a democracy in this situation. You can have other types of regimes, but not democracy.
Segment 1853: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2366, Text: If you could talk about the big philosophical notion of truth then? You’ve already talked about the capacity of humans. One of the things that made us special is stories. Is there such thing as truth?
Segment 1854: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2384, Text: Absolutely.
Segment 1855: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2385, Text: What is truth exactly?
Segment 1856: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2386, Text: When somebody is suffering, that’s true. I mean, this is why one of the things, when you talk about suffering as a ultimate reality, when somebody suffers, that is truth. Now, somebody can suffer because of a fictional story. Like somebody tells people that God said, “You must go on this crusade and kill these heretics,” and this is a completely fictional story, and people believe it and they start a war and they destroy cities and kill people. The people that suffer because of that, and even the crusaders themselves that also suffer the consequences of what they do, the suffering is true even though it is caused by a fictional story.
Segment 1857: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2426, Text: Similarly, when people agree on certain rules, the rules could come out of our imagination. Now, we can be truthful about it and say, “These rules. They didn’t come from heaven. They came from our imagination.” We look at sports. We have rules for the game of football, soccer. They were invented by people. At least very few people claim that the rules of football came down from heaven. We invented them, and this is truthful. There are fictional rules invented by humans, and this is true. They were invented by humans. When you are honest about it, it enables you to change the rules, which is being done in football every now and then.
Segment 1858: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2472, Text: It’s the same with the fundamental rules of a country. You can pretend that the rules came down from heaven dictated by God or whatever and then you can’t change them, or you can be like the American Constitution which starts with, “We the People.” The American Constitution lays down certain rules for a society, but the amazing thing about it, it does not pretend to come from an external source.
Segment 1859: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2500, Text: The 10 Commandments start with, “I am your Lord God.” Because it starts with that, you can’t change them. The 10th commandment, for instance, supports slavery. In the 10th commandment, it says that you should not covet your neighbor’s house or your neighbor’s wife or your neighbor’s slaves. It’s okay to hold slaves according to the 10th commandment. It’s just bad to covet the slaves of your neighbor.
Segment 1860: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2532, Text: Now, there is no 11th commandment which says, “If you don’t like some of the previous 10 commandments, this is how you go about amending them,” which is why we still have them unchanged. Now, in the US Constitution, you have all these rights and rules, including originally the ability to hold slaves, but the genius of the Founding Fathers of the United States, they had the humility to understand maybe we don’t understand everything. Maybe we made some mistakes, so we tell you that these rules did not come from heaven. They came from us humans. We may have made a mistake, so here is a mechanism for how future generations can amend the Constitution, which was used later on to, for instance, amend the Constitution to ban slavery.
Segment 1861: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2586, Text: Now you’re describing some interesting and powerful ideas throughout human history. Can you just speak to the mechanism of how humans start to believe ideas? Is there something interesting to say there from your thinking about it, how idea is born and how it takes hold, and how it spreads, and how it competes with other ideas?
Segment 1862: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2608, Text: First of all, ideas are an independent force in history. Marxists tend to deny that. Marxists think that all history is just a play of material interests, and ideas, stories, they are just a smokescreen to hide the underlying interests. My thoughts are to some extent the opposite. We have some biological objective interests that all humans share, like we need to eat, we need to drink, we need to breathe, but most conflicts in history are not about that. The interests which really drive most conflicts in history don’t come from biology. They come from religions and ideologies and stories.
Segment 1863: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2659, Text: It’s not that stories are a smokescreen to hide the real interests. The stories create the interests in the first place. The stories define who are the competing groups. Nations, religions, cultures, they are not biological entities. They’re not like species like gorillas and chimpanzees. No. Israelis and Palestinians, or Germans and French, or Chinese and Americans, they have no essential biological difference between them. The difference is cultural. It comes from stories. There are people that believe in different stories. The stories create the identity. The stories create the interests. Israelis and Palestinians are fighting over Jerusalem not because of any material interest. There are no oil fields under Jerusalem, and even oil. You need it to realize some cultural fantasy. It doesn’t really come from biology. The stories are independent forces.
Segment 1864: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2719, Text: Now, why do people believe one story and not another? That’s history. There is no materialistic law, “People will always believe this.” No. History is full of accidents. How did Christianity become the most successful religion in the world? We can’t explain it. Why this story about Jesus of Nazareth? The Roman Empire in the 3rd Century CE was a bit like, I don’t know, California today. So many sects and sub-sects and gurus and religions, everybody has their own thing, and you have thousands of different stories competing.
Segment 1865: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2765, Text: Why did Christianity come up on top? As a historian, I don’t have a clear answer. You can read the sources, and you see how it happened. Oh, this happened and then this happened, and then Constantine adopted it, and then this and then this, but why? I don’t think anybody has an answer to that. If you rewind the movie of history and press play and you rewind and press play a hundred times, I think Christianity would take over the Roman Empire in the world maybe twice out of a hundred times. It was such an unlikely thing to happen.
Segment 1866: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2804, Text: It’s the same with Islam. It’s the same, I don’t don’t know, with the communist takeover of Russia. In 1914, if you told people that in three years Lenin and the Bolsheviks will gain power in that czarist empire, they would think you’re utterly crazy. Lenin had a few thousand supporters in 1914 in an empire of close to 200 million people. It sounded ludicrous. Now we know the chain of events, the First World war, the February Revolution and so forth, that led to the communist takeover, but it was such an unlikely event, and it happened.
Segment 1867: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2845, Text: The little steps along the way, the little options you have along the way because, Stalin versus Trotsky, you could have the Robert Frost poem, there’s always-
Segment 1868: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2852, Text: Yes. There is a highway and there is a sideway, and history takes the sideway many, many times.
Segment 1869: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2863, Text: It’s perhaps tempting to tell some of that history through charismatic leaders. Maybe it’s an open question. How much power charismatic leaders have to affect the trajectory of history?
Segment 1870: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2876, Text: You’ve met quite a lot of charismatic leaders lately. I mean, what’s your view on that?
Segment 1871: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2881, Text: I find it a compelling notion. I’m a sucker for a great speech and a vision. I have a sense that there’s an importance for a leader to catalyze the viral spread of a story. I think we need leaders to be just great storytellers that sharpen up the story to make sure it infiltrates everybody’s brain effectively. It could also be that the local interactions between humans is even more important, but it’s just we don’t have a good way to summarize that and describe that. We like to talk about Steve Jobs as central to the development of the computer, maybe Bill Gates. You tell the stories of individuals like this because it’s just easier to tell a sexy story that way.
Segment 1872: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=2933, Text: Maybe it’s an interplay because you have the structural forces. I don’t know. You look at the geography of the planet and you look at shipping technology in the late 15th Century in Europe and the Mediterranean, and it’s almost inevitable that pretty quickly somebody would discover America, somebody from the Old World will get to the new world. If it wasn’t Columbus, then it would’ve been, five years later, somebody else. The key thing about history is that these small differences make a huge, huge difference. If it wasn’t Columbus, if it was five years later somebody from England, then maybe all of Latin America today would be speaking English and not Spanish. If it was somebody from the Ottoman Empire, it’s a completely different world history. The Ottoman Empire at that time was also shaping up to be a major maritime empire. If you have America being reached by Muslim navigators before Christian navigators from Europe, you have a completely different world history.
Segment 1873: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3009, Text: It’s the same with the computer. Given the economic incentives and the science and technology of the time, then the rise of the personal computer was probably inevitable sometime in the late 20th Century. The where and when is crucial. The fact that it was California in the 1970s and not, say, I don’t know, Japan in the 1980s or China in the 1990s, this made a huge, huge difference. You have this interplay between the structural forces which are beyond the control of any single charismatic leader, but then, the small changes, they can have a big effect.
Segment 1874: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3054, Text: I don’t know. I think, for instance, about the war in Ukraine. Now it’s a struggle between nations, but there was a moment when the decision was taken in the mind of a single individual, of Vladimir Putin. He could have decided otherwise, and the world would’ve looked completely different.
Segment 1875: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3074, Text: Another leader, Volodymyr Zelenskyy, could have decided to leave Kyiv in the early days. There’s a lot of decisions that ripple. You write in Homo Deus about Hitler and, in part, that he was not a very impressive person.
Segment 1876: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3093, Text: I say that?
Segment 1877: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3095, Text: The quote is, let me read it, “He wasn’t a senior officer in four years of war. He rose no higher than the rank of corporal. He had no formal education.” Perhaps you mean his resume was not impressive.
Segment 1878: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3108, Text: Yeah, his resume was not impressive. That’s true.
Segment 1879: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3111, Text: “He had no formal education, no professional skills, no political background. He wasn’t a successful businessman or a union activist. He didn’t have friends or relatives in high places nor any money to speak of.” How did he amass so much power? What ideology, what circumstances enabled the rise of the Third Reich?
Segment 1880: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3133, Text: Again, I can’t tell you the why. I can tell you the how. I don’t think it was inevitable. I think that, if a few things were different, there would’ve been no Third Reich. There would’ve been no Nazism and no Holocaust. Again, this is the tragedy. If it would’ve been inevitable, then what can you do? This is the laws of history or the laws of physics, but the tragedy is, no, it was decisions by humans that led to that direction.
Segment 1881: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3161, Text: Even from the viewpoint of the Germans, we know for a fact it was an unnecessary path to take because, in the 1920s and ’30s, the Nazis said that, “Unless Germany take this road, it will never be prosperous, it’ll never be successful. All the other countries will keep stepping on it.” This was their claim. We know for a fact this is false. Why? Because they took that road, they lost the Second World War and, after they lost, then they became one of the most prosperous countries in the world because their enemies that defeated them evidently supported them and allowed them to become such a prosperous and successful nation.
Segment 1882: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3216, Text: If you can lose the war and still be so successful, obviously you could just have skipped the war. You didn’t need it. I mean, you really had to have the war in order to have a prosperous Germany? Absolutely not. It’s the same with Japan. It’s the same with Italy. It was not inevitable. It was not the forces of history that necessitated, forced Germany to take this path.
Segment 1883: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3249, Text: Again, Hitler was a very, very skillful storyteller. He sold people a story. The fact that he was nobody made it even more effective because people at that time, after their defeat of the First World War, after the repeated economic crisis of the 1920s in Germany, people felt betrayed by all the established elites, by all the established institutions. All these professors and politicians and industrialists and military, all the big people, they led us to a disastrous war. They led us to humiliation, so we don’t want any of them. Then you have this nobody, a corporal with no money, with no education, with no titles, with nothing, and he tells people, “I’m one of you.” This was one reason why he was so popular, and then the story he told.
Segment 1884: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3310, Text: When you look at stories, at the competition between different stories, and between stories, fiction and the truth, the truth has two big problems. The truth tends to be complicated and the truth tends to be painful. Let’s talk about nations. The real story of every nation is complicated and it contains some painful episodes. We are not always good. We sometimes do bad things.
Segment 1885: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3343, Text: Now, if you go to people and you tell them a complicated and painful story, many of them don’t want to listen. The advantage of fiction is that it can be made as simple and as painless or attractive as you want it to be because it’s fiction, and then what you see is that politicians like Hitler, they create a very simple story. We are the heroes. We always do good things. Everybody is against us. Everybody is trying to trample us, and this is very attractive.
Segment 1886: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3380, Text: One of the things people don’t understand about Nazism and fascism, we teach in schools about Fascism and Nazism as this ultimate evil, the ultimate monster in human history. At some level, this is wrong because it actually exposes us. Why? Because people hear of fascism is this monster, and then when you hear the actual fascist story, what fascists tell you is always very beautiful and attractive. Fascists are people who come and tell you, “You are wonderful. You belong to the most wonderful group of people in the world. You’re beautiful. You are ethical. Everything you do is good. You have never done anything wrong. There are all these evil monsters out there that are out to get you, and they’re causing all the problems in the world.”
Segment 1887: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3438, Text: When people hear that, it’s like looking in the mirror and seeing something very beautiful. Hey, I’m beautiful. We’ve never done anything wrong. We are victims. When you look and you heard in school that Fascism, that fascists are monsters, and you look in the mirror, you see something very beautiful and you say, “I can’t be a fascist because fascists are monsters. This is so beautiful,” so it can’t be. When you look in the fascist mirror, you never see a monster. You see the most beautiful thing in the world, and that’s the danger.
Segment 1888: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3474, Text: This is the problem with Hollywood. I look at Voldemort in Harry Potter. Who would like to follow this creep? You look at Darth Vader. This is not somebody you would like to follow. Christianity got things much better when it described the devil as being very beautiful and attractive. That’s the danger, that you see something is very beautiful, you don’t understand the monster underneath.
Segment 1889: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3503, Text: You write precisely about this. By the way, just as a small aside, it always saddens me when people say how obvious it is to them that communism is a flawed ideology. When you ask them, “Try to put your mind, try to put yourself in the beginning of the 20th Century and see what you would do,” a lot of people will say, “It’s obvious that it’s a flawed ideology.” I mean, I suppose, to some of the worst ideologies in human history, you could say the same. In that mirror, when you look, it looks beautiful.
Segment 1890: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3536, Text: Communism is the same also. You look in the communist mirror. You’re the most ethical, wonderful place, person ever. It’s very difficult to see Stalin underneath it.
Segment 1891: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3547, Text: Yeah, in Homo Deus, you also write, “During the 19th and 20th Centuries, as humanism gained increasing social credibility and political power, it sprouted two very different offshoots, socialist humanism, which encompassed a plethora of socialist and communist movements, and evolutionary humanism, whose most famous advocates were the Nazis.” If you can just linger on that, what’s the ideological connection between Nazism and communism as embodied by humanism?
Segment 1892: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3575, Text: In humanism, basically the focus is on humans, that they are the most important thing in the world, they move history, but then there is a big question. What are humans? What is humanity?
Segment 1893: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3591, Text: Now, liberals, they place at the center of the story individual humans and they don’t see history as a necessary collision between big forces. They place the individual at the center. Especially in the US today, liberal is taken as the opposite of conservative, but to test whether you’re a liberal, you need to answer just three questions. Very simple. Do you think people should have the right to choose their own government or the government should be imposed by some outside force? Do you think people should have the right to the liberty to choose their own profession or either born into some caste that predetermines what they do, and do you think people should have the liberty to choose their own spouse and their own way of personal life instead of being told by elders or parents who to marry and how to live? Now, if you answered yes to all three questions, people should have the liberty to choose their government, their profession, their personal lives, their spouse, then you’re a liberal. Most conservatives are also liberal.
Segment 1894: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3670, Text: Now, communists and fascists, they answer differently. For them, yes, history is about humans, humans are the big heroes of history, but not individual humans and their liberties. Fascists imagine history as a clash between races or nations. The nation is at the center. They say the supreme good is the good of the nation. You should have a hundred percent loyalty only to the nation.
Segment 1895: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3705, Text: Liberals say, yes, you should be loyal to the nation, but it’s not the only thing. There are other things in the world. There are human rights. There is truth. There is beauty. Many times, yes, you should prefer the interests of your nation over other things, but not always. If your nation tells you to murder millions of innocent people, you don’t do that even though the nation tells you to do it, to lie for the national interest. In extreme situations, maybe, but in many cases, your loyalty should be to the truth even if it makes your nation looks a bit not in the best light.
Segment 1896: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3746, Text: The same with beauty. How does the fascist determine whether a movie is a good movie? Very simple. If it serves the interest of the nation, this is a good movie. If it’s against the interest of the nation, this is a bad movie. End of story. Liberalism says, no, there is aesthetic values in the world. We should judge movies not just on the question whether they serve the national interest, but also on artistic value.
Segment 1897: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3777, Text: Communists are a bit like the fascists, instead that they don’t place the nation as the main hero, they place class as the main hero. For them, history, again, it’s not about individuals, it’s not about nations, history is the clash between classes and, just as fascists imagine in the end, only one nation will be on top. The communists think in the end only one class should be on top, and that’s the proletariat. Same story. A hundred percent of your loyalty should be to the class. If there is a clash, say, between class and family, class wins.
Segment 1898: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3816, Text: In the Soviet Union, the party told children, “If you hear your parents say something bad about Stalin, you have to report them.” There are many cases when children reported their parents, and their parents were sent to the gulag. Your loyalty is to the party which leads the proletariat to victory in the historical struggle. The same way in communism. Art is only about class struggle. A movie is good if it serves the interest of the proletariat. Artistic values? There is nothing like that. The same with truth. Everything that we see now in fake news, the communist propaganda machine was there before us, the level of lies, of disinformation campaigns that they orchestrated in the 1920s and ’30s and ’40s is really unimaginable.
Segment 1899: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3876, Text: So the reason these two classes of ideologies failed as the sacrifice of truth, not just failed, but did a lot of damage as the sacrifice of truth and sacrifice of beauty?
Segment 1900: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3890, Text: … and sacrifice of hundreds of millions of people. Again, for human suffering like, okay, in order for our nation to win, in order for our class to win, we need to kill those millions. Kill those millions. Ethics, aesthetics, truth, they don’t matter. The only thing that matter is the victory of the state or the victory of the class.
Segment 1901: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3918, Text: Liberalism was the antithesis to that. It says, no, it has a much more complicated view of the world. Both communism and fascists, they had the very simple view of the world. Your loyalty, a hundred percent of it, should be only to one thing. Now, liberalism has a much more complex view of the world. It says, yes, there are nations. They are important. Yes, there are classes. They are important, but they are not the only thing. There are also families. There are also individuals. There are also animals. Your loyalty should be divided between all of them. Sometimes, you prefer this. Sometimes, you prefer that. That’s complicated.
Segment 1902: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3960, Text: With this. Sometimes you prefer that. That’s complicated. But life is complicated.
Segment 1903: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3967, Text: But also, I think, maybe you can correct me, but liberalism acknowledges the corrupting nature of power. When there’s a guy at the top who sits there for a while managing things, he’s probably going to start losing a good sense of reality and losing the capability to be a good manager.
Segment 1904: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3988, Text: Yeah.
Segment 1905: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3988, Text: It feels like the communist and fascist regimes don’t acknowledge that basic characteristic of human nature, that power corrupts.
Segment 1906: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=3999, Text: Yes. They believe in infallibility.
Segment 1907: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4001, Text: Yeah.
Segment 1908: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4002, Text: In this sense, they’re very close to being religions. They’re in Nazism. Hitler was considered infallible, and therefore you don’t need any checks and balances on his power. Why do you need to balance an infallible genius? And it’s the same with the Soviet Union with Stalin and more generally with the Communist Party. The party can never make a mistake. And therefore you don’t need independent courts, independent media, opposition parties, things like that, because then party is never wrong. You concentrate the same way. A 100% of loyalty should be to the party. A 100% of power should be in the hands of the party. The holy deal of liberal democracy is embracing fallibility. Everybody is fallible. All people, all leaders, all political parties, all institutions. This is why we need checks and balances, and we need many of them. If you have just one, then this particular check itself could make terrible mistakes. So you need, say you need a press, you need the media to serve as a check to the government. You don’t have just one newspaper or one TV station. You need many so that they can balance each other. And then the media’s not enough, so you have independent courts. You have free academic institutions, you have NGOs, you have a lot of checks and balances.
Segment 1909: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4088, Text: So that’s the ideologies in the leaders. What about the individual people, the millions of people that play a part in all of this that are the hosts of the stories, that are the catalyst and the components of how the story spreads? Would you say that all of us are capable of spreading any story, sort of the [inaudible 01:08:37] and idea of the, that all of us are capable of good and evil?
Segment 1910: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4088, Text: Yes.
Segment 1911: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4122, Text: The line between good and evil runs the heart of every man?
Segment 1912: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4126, Text: Yes. I wouldn’t say that every person is capable of every type of evil, but we are all fallible. There is a large element. It partly depends on the efforts we make to develop our self-awareness during life, part of it depends on moral luck. If you are born as a Christian German in the 1910s or 1920s and you grow up in Nazi Germany, that’s bad moral luck. Your chances of committing terrible things, you have a very high chance of doing it, and you can with withstand it, but it will take tremendous effort. If you are born in Germany after the war, you are morally lucky that you will not be put to such a test. You will not need to exert these enormous efforts not to commit atrocities. This is just part of history. There is an element of luck, but again, part of it is also self-awareness.
Segment 1913: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4195, Text: And you asked me earlier about the potential of power to corrupt, and I listened to the interview you just did with Prime Minister Netanyahu a couple of days ago. And one of the things that most struck me during the interview that you asked him, you asked him, “Are you afraid of this thing that power corrupts?” He didn’t think for a single second. He didn’t pause. He didn’t admit a tiny little level of a doubt or… “No, power doesn’t corrupt.” For me, it was a shocking and a revealing moment. And it kind of dovetails with how you began the interview, that I really liked your opening gambit. That kind of, no, really, you kind of told him, lots of people in the world are angry with you, some people hate you, they dislike you.
Segment 1914: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4251, Text: What do you want to tell them, to say to them? And you gave him this kind of platform. And I was very, what will he say? And he just denied it. He basically denied it. He had to cut short the interview from three hours to one hour because you had hundreds of thousands of Israelis in the streets demonstrating against him. And he goes and saying, no, everybody likes me. What are you talking about?
Segment 1915: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4278, Text: But on that topic, you’ve said recently that the Prime Minister Benjamin Netanyahu may go down in history as the man who destroys Israel. Can you explain what you mean by that?
Segment 1916: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4290, Text: Yes. He is basically tearing apart the social contract that held this country together for 75 years. He’s destroying the foundations of Israeli democracy. I don’t want to go too deep unless you wants it, because I guess most of our listeners, they have bigger issues on their minds than the fate of some small country in the Middle East. But for those who want to understand what’s happening in Israel, there is really just one question to ask. What limits the power of the government? In United States, for instance, there are a lots of checks and balances that limit the power of the government. You have the Supreme Court, you have the Senate, you have the House of Representative, you have the President, you have the Constitution. You have 50 states, each state with its own Constitution and Supreme Court, and Congress and governor. If somebody wants to pass a dangerous legislation, say in the house, it’ll have to go through so many obstacles.
Segment 1917: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4355, Text: Like if you want to pass a law in United States taking away voting rights from Jews or from Muslims, or from African-Americans, even if it passes, even if it has a majority in the House of Representatives, it has a very, very, very small chance of becoming the law of the country because it’ll have to pass again through the Senate, through the President, through the Supreme Court, and all the federal structure. In Israel, we have just a single check on the power of the government, and that’s the Supreme Court. There is really no difference between the government and the GE legislature because whoever there is, there are no separate elections like in the US. If you win majority in the Knesset, in the Parliament, you appoint the government, that that’s very simple. And if you have 61 members of Knesset who vote, let’s say on a law to take away voting rights from Arab citizens of Israel, there is a single check that can prevent it from becoming the law of the land, and that’s the Supreme Court.
Segment 1918: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4418, Text: And now, the Netanyahu government is trying to neutralize or take over the Supreme Court, and they’ve already prepared a long list of laws. They already talk about it. What will happen the moment that this last check on the power is gone? They are openly trying to gain unlimited power and they openly talk about it, that once they have it, then they will take away the rights of Arabs, of LGBT people, of women, of secular Jews. And this is why you have hundreds of thousands of people in the streets. You have air force pilots saying, ‘we are stop, we stop flying.’ This is unheard of in Israel. We are still living under existential threat from Iran, from other enemies. And in the middle of this, you have air force pilots who dedicated their lives to protecting the country and they’re saying, ‘that’s it. If this government doesn’t stop what it is doing, we stopped flying.’
Segment 1919: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4487, Text: So as you said, I just did the interview. And as we were doing the interview, there’s protests in the streets. Do you think the protests will have an effect?
Segment 1920: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4498, Text: I hope so very much. I’m going to many of these protests, I hope they will have an effect. If we fail, this is the end of Israeli democracy probably. This will have repercussions far beyond the borders of Israel. Israel is a nuclear power. Israel has one of the most advanced cyber capabilities in the world, able to strike basically anywhere in the world. If this country becomes a fundamentalist and militarized dictatorship, it can set fire to the entire Middle East. It can again have destabilizing effects long, far beyond the borders of Israel.
Segment 1921: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4541, Text: So you think without the check on power, it’s possible that the Netanyahu government holds onto power?
Segment 1922: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4548, Text: Nobody tries to gain unlimited power just for nothing. You have so many problems in Israel and Netanyahu talks so much about Iran, and the Palestinians, and Hezbollah. We have an economic crisis. Why is it so urgent at this moment in the face of such opposition, why is it so crucial for them to neutralize the Supreme Court? They’re just doing it for the fun of it. No, they know what they are doing. They are adamant. We were not sure of it before. There was a, like a couple of months ago, they came out with this plan to take over the Supreme Court to have all these laws. And there were hundreds of thousands people in the streets, again, soldiers saying they will stop serving, a general strike in the economy. And they stopped. And they started a process of negotiations to try and reach a settlement.
Segment 1923: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4600, Text: And then they broke down. They stopped the negotiations and they restarted this process of legislation trying to gain unlimited power. So any doubt we had before, okay, maybe they changed their purposes. No, it’s now very clear. They are 100% focused on gaining absolute power. They are now trying a different tactic. Previously, they had all these dozens of laws that they wanted to pass very quickly within a month or two. They realized, no, there is too much opposition. So now, they’re doing what is known as salami tactics, slice by slice. Now, they’re trying to one law, if this succeeds, then they’ll pass the next one and the next one, and the next one. This is why we are now at a very crucial moment. And when you see again hundreds of thousands of people in the streets almost every day, when you’re seeing resistance with the armed forces, within the security forces, you see high-tech companies saying, we will go on strike.
Segment 1924: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4665, Text: They are private businesses, high-tech companies. I think it’s almost unprecedented for a private business to go on strike because what will economic success benefit us if we live under a messianic dictatorship? And again, the fuel for this whole thing is to a large extent coming from Messianic religious groups, which… Just the thought, what happens if these people have unlimited control of Israel’s nuclear arsenal, and Israel’s military capabilities and cyber capabilities. This is very, very scary. Not just for the citizens of Israel, it should be scary for people everywhere.
Segment 1925: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4710, Text: So it would be scary for it to go from being a problem of security and protecting the peace to becoming a religious war.
Segment 1926: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4721, Text: It is already becoming a religious war. The war, the conflict with the Palestinians was for many years a national conflict, in essence. Over the last few years, maybe a decade or two, it is morphing into a religious conflict, which is again, a very worrying development. When nations are in conflict, you can reach some compromise. Okay, you have this bit of land, we have this bit of land. But when it becomes a religious conflict between fundamentalists, between messianic people, compromise becomes much more difficult because you don’t compromise on eternity, you don’t compromise on God. And this is where we are heading right now.
Segment 1927: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4766, Text: So I know you said, “It’s a small nation somewhere in the Middle East,” but it also happens to be the epicenter of one of the longest running, one of the most tense conflicts and crises in human history. So at the very least, it serves as a study of how conflict can be resolved. So what are the biggest obstacles to you to achieving peace in this part of the world?
Segment 1928: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4792, Text: Motivation. I think it’s easy to achieve peace if you have the motivation on both sides. Unfortunately the present juncture, there is not enough motivation on either side, either the Palestinian or Israeli side. Peace… In mathematics, you have problems without solutions. You can prove mathematically that this mathematical problem has no solution. In politics, there is no such thing. All problems have solutions if you have the motivation. But motivation is the big problem. And again, we can go into the reasons why, but the fact is that on neither side is there enough motivation. If there was motivation, the solution would’ve been easy.
Segment 1929: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4841, Text: Is there an important distinction to draw between the people on the street and the leaders in power in terms of motivation? So are most people motivated and hoping for peace and the leaders are motivated and incentivized to continue war?
Segment 1930: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4861, Text: I don’t think so.
Segment 1931: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4861, Text: Or the people also?
Segment 1932: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4863, Text: I think it’s a deep problem. It’s also the people, it’s not just the leaders.
Segment 1933: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4867, Text: Is it even a human problem of literally hate in people’s heart?
Segment 1934: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4872, Text: Yeah, there is a lot of hate. One of the things that happened in Israel over the last 10 years or so, Israel became much stronger than it was before, largely thanks to technological development. And it feels that it no longer needs to compromise. Again, there are many reasons for it, but some of them are technological. Being one of the leading powers in cyber, in AI, in high-tech, we have developed very sophisticated ways to more easily control the Palestinian population. In the early 2000s, it seemed that it is becoming impossible to control millions of people against their will. It took too much power. It spilled too much blood on both sides. So there was an impression, ‘oh, this is becoming untenable.
Segment 1935: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4930, Text: And there are several reasons why it changed, but one of them was new technology. Israel developed very sophisticated surveillance technology that has made it much easier for Israeli security forces to control 2.5 million Palestinians in the West Bank against their will with a lot less effort, less boots on the ground, also less blood. And Israel is also now exporting this technology to many other regimes around the world. Again, I heard Netanyahu speaking about all the wonderful things that Israeli is exporting to the world. And it’s true, we are exporting some nice things. Water systems and tomato, new kinds of tomato. We are also exporting a lot of weapons and especially surveillance systems sometimes to unsavory regimes in order to control their populations.
Segment 1936: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=4991, Text: Can you comment on, I think you’ve mentioned that the current state of affairs is the de facto three class state? Can you describe what you mean by that?
Segment 1937: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5002, Text: Yes. For many years the kind of leading solution to the Israeli-Palestinian conflict is the two-state solution.
Segment 1938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5008, Text: Can you describe what that means by the way?
Segment 1939: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5010, Text: Yes. Two states within, between the Jordan River and the Mediterranean will have two states. Israel as a predominantly Jewish state and Palestine as a predominantly Palestinian state. Again, there were lots of discussions where the border passes, what happens with security arrangement and whatever. But this was the big solution. Israel has basically abandoned the two-state solution. Maybe they don’t say so officially the people in power, but in terms of how they actually, what they do on the ground, they abandoned it. Now they are effectively promoting the three class solution, which means there is just one country and one government, and one power between the Mediterranean and the Jordan River, but you have three classes of people living there. You have Jews who enjoy full rights, all the rights. You have some Arabs who are Israeli citizens and have some rights. And then you have the other Arabs, the third class who have basically no civil rights and limited human rights. And that, that’s… Again, nobody would openly speak about it. But effectively, this is the reality on the ground already.
Segment 1940: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5082, Text: So there’s many, and I’ll speak with then Palestinians who characterize this as a de facto one state apartheid. Is it, do you agree with this?
Segment 1941: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5091, Text: I would take issue. I would take issue with the term apartheid. Generally speaking as a historian, I don’t really like historical analogies because there are always differences, key differences. The biggest difference between the situation here and the situation in South Africa in the time of the Apartheid is that black South Africans did not deny the existence of South Africa and did not call for the destruction of South Africa. They had a very simple goal. They had a very simple demand. We want to be equal citizens of this country. That’s it. And the apartheid regime was, ‘no, you can’t be equal citizens.’ Now in Israel-Palestine, it’s different.
Segment 1942: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5135, Text: The Palestinians, many of them don’t recognize the existence of Israel. Don’t or are not willing to recognize it. And they don’t demand to be citizens of Israel. They demand some of them to destroy it and replace it with the Palestinian state. Some of them demand a separate state. But if the Palestinians would adopt the same policy as the black South Africans, if you have the Palestinians coming and saying, okay, forget about it. We don’t want to destroy Israel. We don’t know a Palestinian country. We have a very simple request, a very simple demand. Give us our full rights. We also want to vote to the Knesset. We also want to get the full protection of the law. That’s it, that’s our only demand. Israel will be in deep, deep trouble at that moment, but we are not there.
Segment 1943: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5188, Text: I wonder if there will ever be a future when such a thing happens where everybody, the majority of people, Arab and Jew, Israeli and Palestinian accept the one-state solution and say, we want equal rights.
Segment 1944: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5204, Text: Never say never in history. It’s not coming anytime soon from either side. When you look at the long term of history, one of the curious things you see, and that’s what makes us different, human groups from animal species. Gorillas and chimpanzees, they’re separate species, they can never merge. Cats and dogs will never merge. But different national and religious groups in history, even when they hate each other, surprisingly, they sometimes end by merging. If you look at Germany for instance, so for centuries you had Prussians and Bavarian and Saxons who fought each other ferociously and hated each other. And there are sometimes also different religions, Catholics, Protestants. The worst war in European history, according to some measures, was not the Second World War or the First World War, it was the 30 years war waged largely on German soil between Germans, Protestants, and Catholics. But eventually, they united to form a single country. You saw the same thing, I don’t know, in Britain. English and Scotts for centuries hated and fought each other ferociously, eventually coming together. Maybe it’ll break up again, I don’t know. But the power of the kind of forces of merger in history, you are very often influenced by the people you fight, by the people you even hate more than by almost anybody else.
Segment 1945: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5298, Text: So if we apply those ideas, the ideas of this part of the world to another part of the world that’s currently in war, Russia and Ukraine, from what you learned here, how do you think peace can be achieved in Ukraine?
Segment 1946: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5315, Text: Oh, peace can be achieved any moment. It’s motivation. In this case, it’s just one person. Putin just need to say, that’s it. The Ukrainians, they don’t demand anything from Russia. Just go home, that’s the only thing they want. They don’t want to conquer any bit of Russian territory. They don’t want to change the regime in Moscow, nothing. They just tell the Russians, go home. That’s it. And of course, again, motivation. How do you get somebody like Putin to admit that he made a colossal mistake, a human mistake, an ethical mistake, a political mistake in starting this war? This is very, very difficult. But in terms of what would the solution look like? Very simple. The Russians go home. End of story.
Segment 1947: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5361, Text: Do you believe in the power of conversation between leaders to sit down as human beings and agree? First of all, what home means because we humans draw lines?
Segment 1948: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5377, Text: That’s true. I believe in the power of conversation. The big question to ask is where? Where do conversations, real conversations take place? And this is tricky. One of the interesting things to ask about any conflict, about any political system is where do the real conversations take place? And very often, they don’t play take place in the places you think that they are. But think about American politics. When the country was founded in the late 18th century, people understood holding conversation between leaders is very important for the functioning of democracy. We’ll create a place for that, that’s called Congress. This is where leaders are supposed to meet and talk about the main issues of the day. Maybe there was a time sometime in the past when this actually happened, when you had two factions holding different ideas about foreign policy or economic policy and they met in Congress, and somebody would come and give a speech and the people all on the other side would say, “Hey, that’s interesting. I haven’t thought about it. Yes, maybe we can agree on that.”
Segment 1949: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5449, Text: This is no longer happening in Congress. Nobody, I don’t think there is any speech in Congress that causes anybody on the other side to change their opinion about anything. So this is no longer a place where real conversations take place. The big question about American democracy is, is there a place where real conversations which actually change people’s minds still take place? If not, then this democracy is dying also. Democracy without conversation cannot exist for long. And it’s the same question you should ask also about dictatorial regimes, like you think about Russia or China. So China has the Great Hall of the People. Well, the representatives, the supposed representative of the people meet every now and then, but no real conversation takes place there. A key question to ask about the Chinese system is, behind closed doors, let’s say in a poly bureau meeting, do people have a real conversation?
Segment 1950: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5512, Text: If Xi Jinping says one thing and some other big shot thinks differently, will they have the courage, the ability, the backbone to say, with all due respect, they think differently and there is a real conversation, or not? I don’t know the answer, but this is a key question. This is the difference between an authoritarian regime, it can still have different voices within it. But at a certain point, you have a personality count. Nobody dares say anything against the leader. And when it comes again to Ukraine and Russia, I don’t think that if you get, if you somehow manage to get Putin and Zelensky to the same room, when everybody knows that they are there and they, they’ll, they’ll have a moment of empathy, of human connection and they have… No, I don’t think it can happen like that. I do hope that there are other spaces where somebody like Putin can still have a real human conversation. I don’t know if this is the case. I hope so.
Segment 1951: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5580, Text: Well, there’s several interesting dynamics and you spoke to some of them. So one is internally with advisors, you have to have hope that there’s people that would disagree that would have a lively debate internally. Then there’s also the thing you mentioned, which is direct communication between Putin and Zelensky in private, picking up a phone, a rotary phone, old school. I still believe in the power of that. But while that’s exceptionally difficult in the current state of affairs, what’s also possible to have is a mediator like the United States or some other leader.
Segment 1952: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5616, Text: Yeah.
Segment 1953: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5617, Text: Like the leader of Israel or the leader of another nation that’s respected by both, or India for example, that can have first of all individual conversations and then literally get into a room together.
Segment 1954: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5631, Text: It is possible. I would say more generally about conversations as… It goes back a little to what I said earlier about the Marxist view of history. One of the problematic things I see today in many academic circles is that people focus too much on power. They think that the whole of history or the whole of politics is just a power structure. It’s just struggle about power. Now, if you think that the whole of history and the whole of politics is only power, then there is no room for conversation. Because if what you have is a struggle between different powerful interests, there is no point talking. The only thing that changes it is fighting. My view is that, no, it’s not all about power structures. It’s not all about power dynamics. Underneath the power structure, there are stories, stories in human minds. And this is great news, if it’s true, this is good news. Because unlike power that can only be changed through fighting, stories can sometimes, it’s not easy, but sometimes stories can be changed through talking, and that’s the hope.
Segment 1955: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5714, Text: I think in everything from couple therapy to nation therapy, if you think it’s power therapy, it’s all about power, there is no place for a conversation. But if to some extent it’s the stories in people minds, if you can enable one person to see the story in the mind of another person, and more importantly, if you can have some kind of critical distance from the story in your own mind, then maybe you can change it a little and then you don’t need to fight. You can actually find a better story that you can both agree to. It sometimes happens in history. Again, French and Germans fought for generations and generations. Now, they live in peace. Not because, I don’t know, they found a new planet they can share between France and Germany so now everybody has enough territory. No, they actually have less territory than previously because they lost all their overseas empires, but they managed to find a story, the European story, that both Germans and French people are happy with. So they live in peace.
Segment 1956: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5785, Text: I very much believe in this vision that you have of the power of stories. And one of the tools is conversations, another is books. There’s some guy that wrote a book about this, power of stories, he happens to be sitting in front of me. And that happened to spread across a lot of people, and now they believe in the power of story and narrative. Even a children’s book too, so the kids. And It’s fascinating how that spreads. Underneath your work, there’s an optimism. And I think underneath conversations is, what I tried to do is an optimism, that it’s not just about power struggles.
Segment 1957: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5825, Text: Yeah.
Segment 1958: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5825, Text: That it’s about stories which is like a connection between humans and together kind of evolving these stories that maximize hap or minimize suffering in the world.
Segment 1959: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5838, Text: Yeah. This is why I also, I think I admire what you are doing, that you’re going to talk with some of the most difficult characters around in the world today, and with this basic belief that by talking maybe we can move them an inch, which is a lot when it comes to people with so much power. I think one of the biggest success stories in modern history, I would say, is feminism. Because feminism believed in the power of stories, not so much in the power of violence, of armed conflict. By many measures, feminism has been maybe the most successful social movement of the 20th century and maybe of the modern age. The systems of oppression, which were in place throughout the world for thousands of years, and they seem to be just natural, eternal. You had all these religious movements, all these political revolutions. And one thing remained constant, and this is the patriarchal system and the oppression of women.
Segment 1960: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5907, Text: And then feminism came along. And you had leaders like Lenin, like Mao saying that if you want to make a big social change, you must use violence. Power comes from the barrel of the gun, of a gun. If you want to make an omelet, you need to break eggs, and all these things. And the feminist said, no, we won’t use the power of the gun. We will make an omelet without breaking any eggs. And they made a much better omelet than Lenin or Mao, or any of these violent revolutionaries. I don’t think that they, [inaudible 01:39:04]-
Segment 1961: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5940, Text: … Revolutionaries.
Segment 1962: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5941, Text: I don’t think that they … They certainly didn’t start any wars or build any gulags. I don’t think they even murdered a single politician. I don’t think there was any political assassination anywhere by feminists. There was a lot of violence against them, both verbal but also physical, and they didn’t reply by waging violence, and they succeeded in changing this deep structure of oppression in a way which benefited not just women, but also men.
Segment 1963: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=5979, Text: So this gives me hope that, it’s not easy, in many cases we fail, but it is possible sometimes in history to make a very, very big change, positive change mainly by talking and demonstrating and changing the story in people’s minds and not by using violence.
Segment 1964: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6001, Text: It’s fascinating that feminism and communism and all these things happened in the 20th century. So many interesting things happen in the 20th century. So many movements, so many ideas, nuclear weapons, all of it. Computers. It just seems like a lot of stuff really quickly percolated and it’s accelerating.
Segment 1965: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6019, Text: It’s still accelerating. I mean, history is just accelerating for centuries. And the 20th century, we squeezed into it things that previously took thousands of years. And now, I mean, we are squeezing it into decades.
Segment 1966: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6032, Text: And you very well could be one of the last historians, human historians to have ever lived.
Segment 1967: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6038, Text: Could be. I think our species, homo sapiens. I don’t think we’ll be around in a century or two. We could destroy ourselves in a nuclear war, through ecological collapse, by giving too much power to AI that goes out of our control. But if we survive, we’ll probably have so much power that we will change ourselves using various technologies so that our descendants will no longer be homo sapiens like us. They will be more different from us than we are different from Neanderthals. So maybe they’ll have historians, but it will no longer be human historians or homo sapien historians like me.
Segment 1968: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6084, Text: I think it’s an extremely dangerous development. And the chances that this will go wrong, that people will use the new technologies trying to upgrade humans, but actually downgrading them, this is a very, very big danger. If you let corporations and armies and ruthless politicians change humans using tools like AI and bioengineering, it’s very likely that they will try to enhance a few human qualities that they need, like intelligence and discipline, while neglecting what are potentially more important human qualities, like compassion, like artistic sensitivity, like spirituality …
Segment 1969: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6133, Text: If you give Putin, for instance, bioengineering and AI and brain computer interfaces, he’s likely to want to create a race of super soldiers who are much more intelligent and much more stronger and also much more disciplined and never rebel and march on Moscow against him. But he has no interest in making them more compassionate or more spiritual. So the end result could be a new type of humans, a downgraded humans, who are highly intelligent and disciplined, but have no compassion and no spiritual depth.
Segment 1970: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6178, Text: And this is one … For me, this is the dystopia, the apocalypse. When people talk about the new technologies and they have this scenario of The Terminator, robots lying in the street shooting people, this is not what worries me. I think we can avoid that. What really worries me is using … The corporations, armies, politicians will use the new technologies to change us in a way which will destroy our humanity, or the best parts of our humanity.
Segment 1971: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6211, Text: And one of those ways could be removing compassion.
Segment 1972: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6213, Text: Another way that really worries me, for me is probably more likely, is a brave new world kind of thing that sort of removes the flaws of humans, maybe it removes the diversity in humans, and makes us all kind of these dopamine chasing creatures that just kind of maximize enjoyment in the short term, which kind of seems like a good thing maybe in the short term, but it creates a society that doesn’t think, that doesn’t create, that just is sitting there enjoying itself at a more and more rapid pace, which seems like another kind of society that could be easily controlled by a centralized center of power.
Segment 1973: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6260, Text: But the set of dystopias that we could arrive at through this if they’re allowing corporations to modify humans is vast, and we should be worried about that.
Segment 1974: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6272, Text: It seems like humans are pretty good as we are. All the flaws, all of it together.
Segment 1975: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6280, Text: We are better than anything that we can intentionally design at present. Like any intentionally designed humans at the present moment is going to be much, much worse than us. Because basically, we don’t understand ourselves. I mean, as long as we don’t understand our brain, our body, our mind, it’s a very, very bad idea to start manipulating a system that you don’t understand deeply. And we don’t understand ourselves.
Segment 1976: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6307, Text: So I have to ask you about an interesting dynamic of stories. You wrote an article two years ago titled, ‘When The World Seems Like One Big Conspiracy: How Understanding The Structure of Global Cabal Theories Can Shed Light On Their Allure And Their Inherent Falsehood.’.
Segment 1977: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6325, Text: What are global cabal theories and why do so many people believe them? 37% of Americans, for example.
Segment 1978: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6332, Text: Well, the global cabal theory, it has many variations, but basically there is a small group of people, a small cabal that secretly controls everything that is happening in the world. All the wars, all the revolutions, all the epidemics, everything that is happening is controlled by this very small group of people, who are of course evil and have bad intentions. And this is a very well known story. It’s not new. It’s been there for thousands of years.
Segment 1979: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6360, Text: It’s very attractive because, first of all, it’s simple. You don’t need to understand everything that happens in the world, you just need to understand one thing. The war in Ukraine, the Israeli/Palestinian conflict, 5G technology, COVID-19; it’s simple. There is this global cabal. They do all of it.
Segment 1980: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6381, Text: And also, it enables you to shift all the responsibility to all the bad things that are happening in the world to this small cabal. ” It’s the Jews, it’s the Free Masons. It’s not us.”
Segment 1981: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6393, Text: And also, it creates this fantasy, utopian fantasy. “If we only get rid of the small cabal, we’ve solved all the problems of the world. Salvation.” The Israeli/Palestinian conflict, the war in Ukraine, the epidemics, poverty, everything is solved just by knocking out this small cabal.
Segment 1982: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6413, Text: So again, it’s simple, it’s attractive, and this is why so many people believe it. Again, it’s not new. Nazism was exactly this. Nazism began as a conspiracy theory. We don’t call Nazism a conspiracy theory because, “Oh, it’s a big thing. It’s an ideology.” But if you look at it, it’s a conspiracy theory. The basic Nazi idea was that Jews control the world. Get rid of the Jews, you’ve solved all the world’s problems.
Segment 1983: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6440, Text: Now, the interesting thing about these kind of theories; again, they tell you that even things that look to be the opposite of each other, actually they are part of the conspiracy.
Segment 1984: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6454, Text: So in the case of Nazism, the Nazis told people, “You have capitalism and communism. You think that they are opposite, right? Ah, this is what the Jews want you to think. Actually, the Jews control both communism; Trotsky, Marx were Jews, blah, blah, blah; and capitalism. The Rothschilds, Wall Street: it’s all controlled by the Jews.” So the Jews are fooling everybody, but actually the communists and the capitalists are part of the same global cabal.
Segment 1985: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6482, Text: And again, this is very attractive because, “Ah, now I understand everything. And now I also know what to do. I just give power to Hitler, he gets rid of the Jews, I’ve solved all the problems of the world.”
Segment 1986: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6495, Text: Now, as a historian, the most important thing I can say about these theories, they are never right. Because the global cabal theory says two things. First, everything is controlled by a very small number of people; secondly, these people hide themselves. They do it in secret.
Segment 1987: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6513, Text: Now, both things are nonsense. It’s impossible for people to control a small group of people, to control and predict everything, because the world is too complicated. You know, you look at a real world conspiracy, conspiracy is basically just a plan.
Segment 1988: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6529, Text: Think about the American invasion of Iraq in 2003. You had the most powerful superpower in the world with the biggest military, with the biggest intelligence services, with the most sophisticated … You know, the FBI and the CIA and all the agents. They invade a third rate country, a third rate power, Iraq, with this idea, “We’ll take over Iraq and we’ll control it, we’ll make a new order in the Middle East.” And everything falls apart. Their plan completely backfires. Everything they hope to achieve, they achieve the opposite. America, United States is humiliated. They caused the rise of ISIS. They wanted to take out terrorism, they created more terrorism.
Segment 1989: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6576, Text: Worst of all, the big winner of the war was Iran. The United States goes to war with all its power and gives Iran a victory on a silver plate. The Iranians don’t need to do anything. The Americans are doing everything for them.
Segment 1990: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6593, Text: Now, this is real history. Real history is when you have not a small group of people, a lot of people with a lot of power carefully planning something, and it goes completely against their plan.
Segment 1991: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6608, Text: And this we know from personal experience. Every time we try to plan something, a birthday party, a surprise birthday party, a trip somewhere, things go wrong. This is reality. So the idea that a small group of, I don’t know, the Jewish cabal, the Freemasons, whoever, they can really control and predict all the wars, this is nonsense.
Segment 1992: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6631, Text: The second thing that is nonsense is to think they can do that and still remain secret.
Segment 1993: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6637, Text: It sometimes happens in history that a small group of people accumulates a lot of power. If I now tell you that Xi Jinping and the heads of the CCP, the Chinese Communist Party, they have a lot of power, they control the military, the media, the economy, the universities of China; this is not a conspiracy theory. Obviously everybody knows it. Everybody knows it, because to gain so much power, you usually need publicity. Hitler gained a lot of power in Nazi Germany because he had a lot of publicity. If Hitler remained unknown working behind the scenes, he would not gain power.
Segment 1994: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6680, Text: So the way to gain power is usually through publicity. So secret cabals don’t gain power. And even if you gain a lot of power, nobody has the kind of power necessary to predict and control everything that happens in the world. All the time shit happens that you did not predict and you did not plan and you did not control.
Segment 1995: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6705, Text: The sad thing is there’s usually an explanation for everything you just said that involves a secret global cabal. The reason your vacation planning always goes wrong is because you’re not competent. There is a competent small group, ultra competent small group … I hear this with intelligence agencies; the CIA are running everything, Mossad is running everything.
Segment 1996: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6729, Text: You see, as a historian, you get to know how many blunders these people do. They are so … They’re capable, but they’re so incompetent in so many ways.
Segment 1997: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6739, Text: Again, look at the Russian invasion of Ukraine. Before the war, people thought, oh, Putin was such a genius, and the Russian army was one of the strongest armies in the world. This is what Putin thought. And it completely backfired.
Segment 1998: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6752, Text: Well, a cabal explanation there would be there’s a NATO-driven United States military industrial complex that wants to create chaos and incompetence.
Segment 1999: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6763, Text: So they put a gun to Putin’s head and told him, “Vladimir, if you don’t invade, we shoot you?” How did they cause Putin to invade Ukraine?
Segment 2000: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6770, Text: This is the thing about conspiracy theories is there’s usually a way to explain everything.
Segment 2001: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6775, Text: It’s like religion. You can always find explanation for everything. And in the end, it’s intellectual integrity. If you insist, whenever people confront you with evidence, with finding some very, very complicated explanation for that too, you can explain everything. We know that. It’s a question of intellectual integrity.
Segment 2002: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6799, Text: And I’ll also say another thing. The conspiracy theories, they do get one thing right, certainly in today’s world. I think they represent an authentic and justified fear of a lot of people that they are losing control of their lives, they don’t understand what is happening. And this I think is not just a legitimate fear, this is an important fear. They are right. We are losing control of our lives, we are facing really big dangers, but not from a small cabal of fellow humans.
Segment 2003: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6837, Text: The problem with many of these conspiracy theories that, yes, we have a problem with new AI technology, but if you now direct the fire against certain people, so instead of all humans cooperating against our real common threats, whether it’s the rise of AI, whether it’s global warming, you are only causing us to fight each other.
Segment 2004: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6865, Text: And I think that the key question that people who spread these ideas; I mean, many of them, they honestly believe. It’s not malicious. They honestly believe in these theories; is do you want to spend your life spreading hate towards people, or do you want to work on more constructive projects?
Segment 2005: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6886, Text: I think one of the big differences between those who believe in conspiracy theories and people who warn about the dangers of AI, the dangers of climate change, we don’t see certain humans as evil and hateful. The problem isn’t humans, the problem is something outside humanity. Yes, humans are contributing to the problem, but ultimately the enemy is external to humanity. Whereas conspiracy theorists usually claim that a certain part of humanity is the source of all evil, which leads them to eventually think in terms of exterminating this part of humanity, which leads sometimes to historical disasters like Nazism.
Segment 2006: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6940, Text: So it can lead to hate, but it can also lead to cynicism, apathy that basically says, “It’s not in my power to make the world better,” so you don’t actually take action.
Segment 2007: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6951, Text: I think it is within the power of every individual to make the world a little bit better. You can’t do everything. Don’t try to do everything. Find one thing in your areas of activity, a place where you have some agency, and try to do that, and hope that other people do their bit. And if everybody do their bit, we’ll manage. And if we don’t, we don’t, but at least we try.
Segment 2008: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=6979, Text: You have been part of conspiracy theories. I find myself recently becoming part of conspiracy theories. Is there advice you can give of how to be a human being in this world that values truth and reason while watching yourself become part of conspiracy theories? At least from my perspective, it seems very difficult to prove to the world that you’re not part of a conspiracy theory.
Segment 2009: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7006, Text: I, as you said, have interviewed Benjamin Netanyahu recently, I don’t know if you’re aware. But doing such things will also … You now pick up a new menu of items, a new set of conspiracy theories you’re now a part of. And I find it very frustrating because it makes it very difficult to respond, because I sense that people have the right intentions, like we said, they have a nervousness, a fear of power and the abuses of power; as do I. So I find myself in a difficult position that I have nothing to show to prove that I’m not part of such a conspiracy theory.
Segment 2010: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7051, Text: I think ultimately you can’t. We can’t. I mean, it’s like proving consciousness. You can’t. That’s just the situation. Whatever you say can and will be used against you by some people. So this fantasy, “If I only say this, if I only show them that, if I only have this data, they will see I’m okay,” it doesn’t work like that.
Segment 2011: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7076, Text: I think to keep your sanity in this situation, first of all, it’s important to understand that most of these people are not evil. They are not doing it on purpose. Many of them really believe that there is some very nefarious, powerful conspiracy which is causing a lot of harm in the world, and they’re doing a good thing by exposing it and making people aware of it and trying to stop it. If you think that you are surrounded by evil, you are falling into the same rabbit hole, you’re falling into the same paranoid state of mind, “Oh, the world is full of these evil people that … ” No. Most of them are good people.
Segment 2012: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7117, Text: And also, I think we can empathize with some of the key ideas there, which I share, that yes, it’s becoming more and more difficult to understand what is happening in the world. There are huge dangers in the world, existential dangers to the human species. But they don’t come from a small cabal of Jews or gay people or feminists or whatever. They come from much more diffused forces, which are not under the control of any single individual.
Segment 2013: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7155, Text: We don’t have to look for the evil people. We need to look for human allies in order to work together against, again, the dangers of AI, the dangers of bioengineering, the dangers of climate change. And when you wake up in the morning, the question is, do you want to spend your day spreading hatred or do you want to spend your day trying to make allies and work together?
Segment 2014: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7186, Text: Let me ask you kind of a big philosophical question about AI and the threat of it. Let’s look at the threat side.
Segment 2015: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7194, Text: So folks like Eliezer Yudkowsky worry that AI might kill all of us. Do you worry about that range of possibilities where artificial intelligence systems in a variety of ways might destroy human civilization?
Segment 2016: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7213, Text: Yes. I talk a lot about it, about the dangers of AI. I sometimes get into trouble because I depict these scenarios of how AI becoming very dangerous, and then people say that I’m encouraging these scenarios. But I’m talking about it as a warning.
Segment 2017: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7229, Text: I’m not so terrified of the simplistic idea. Again, The Terminator scenario of robots running in the streets shooting everybody. I’m more worried about AI accumulating more and more power and basically taking over society, taking over our lives, taking power away from us until we don’t understand what is happening and we lose control of our lives and of the future.
Segment 2018: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7259, Text: The two most important things to realize about AI; you know, so many things are being said now about AI, but I think there are two things that every person should know about AI.
Segment 2019: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7269, Text: First is that AI is the first tool in history that can make decisions by itself. All previous tools in history couldn’t make decisions. This is why they empowered us. You invent a knife, you invent an atom bomb; the atom bomb cannot decide to start a war, cannot decide which city to bomb. AI can make decisions by itself. Autonomous weapon systems can decide by themselves who to kill, who to bomb.
Segment 2020: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7303, Text: The second thing is that AI is the first tool in history that can create new ideas by itself. The printing press could print our ideas, but could not create new ideas. AI can create new ideas entirely by itself. This is unprecedented.
Segment 2021: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7323, Text: Therefore, it is the first technology in history that instead of giving power to humans, it takes power away from us. And the danger is that it will increasingly take more and more power from us until we are left helpless and clueless about what is happening in the world.
Segment 2022: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7344, Text: And this is already beginning to happen in an accelerated pace. More and more decisions about our lives, whether to give us a loan, whether to give us a mortgage, whether to give us a job are taken by AI, and more and more of the ideas, of the images, of the stories that surround us and shape our minds, our world are produced, are created by AI, not by human beings.
Segment 2023: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7372, Text: If you can just linger on that, what is the danger of that? That more and more of the creative side is done by AI? The idea generation? Is it that we become stale in our thinking? Is it that that idea generation is so fundamental to the evolution of humanity?
Segment 2024: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7392, Text: But we can’t resist the ideas.
Segment 2025: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7392, Text: Ah.
Segment 2026: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7394, Text: To resist an idea, you need to have some vision of the creative process.
Segment 2027: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7400, Text: Yeah.
Segment 2028: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7400, Text: Now, this is a very old fear. You go back to Plato’s Cave, this idea that people are sitting chained in a cave and seeing shadows on a screen, on a wall, and thinking, “This is reality.” You go back to Descartes and he has this thought experiment of the demon, and Descartes asks himself, “How do I know that any of this is real? Maybe there is a demon who is creating all of this and is basically enslaving me by surrounding me with these illusions.” You go back to Buddha, it’s the same question; what if we are living in a world of illusions, and because we have been living in it throughout our lives, all our ideas, all our desires, how we understand ourself, this is all the product of the same illusions?
Segment 2029: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7453, Text: And this was a big philosophical question for thousands of years. Now it’s becoming a practical question of engineering, because previously all the ideas, as far as we know … Maybe we are living inside a computer simulation of intelligent rats from the planet [inaudible 02:04:31]. If that’s the case, we don’t know about it. But taking what we do know about human history until now, all the, again, stories, images, paintings, songs, operas, theater, everything we’ve encountered and shaped our minds was created by humans.
Segment 2030: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7489, Text: Now, increasingly, we live in a world where more and more of these cultural artifacts will be coming from an alien intelligence. Very quickly we might reach a point when most of the stories, images, songs, TV shows, whatever are created by an alien intelligence.
Segment 2031: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7510, Text: And if we now find ourselves inside this kind of world of illusions created by an alien intelligence that we don’t understand, but it understands us, this is a kind of spiritual enslavement that we won’t be able to break out of because it understands us. It understands how to manipulate us, but we don’t understand what is behind this screen of stories and images and songs.
Segment 2032: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7546, Text: So if there’s a set of AI systems that are operating in the space of ideas, they’re far superior to ours, and it’s opaque to us, we’re not able to see through, how does that change the pursuit of happiness, the human pursuit of happiness, life? Where do we get joy if we’re surrounded by AI systems that are doing most of the cool things humans do much better than us?
Segment 2033: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7576, Text: You know, some of the things, it’s okay that the AI’s will do them. Many human tasks and jobs, they’re drudgery, they are not fun, they are not developing us emotionally or spiritually. It’s fine if the robots take over. I don’t know, I think about the people in supermarkets or grocery stores that spend hours every day just passing items and charging you the money. I mean, if this can be automated, wonderful. We need to make sure that these people then have better jobs, better means of supporting themselves, and developing their social abilities, their spiritual abilities.
Segment 2034: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7624, Text: And that’s the ideal world that AI can create, that it takes away from us the things that it’s better if we don’t do them and allows us to focus on the most important things and the deepest aspects of our nature, of our potential.
Segment 2035: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7646, Text: If we give AI control of the sphere of ideas, at this stage, I think it’s very, very dangerous, because it doesn’t understand us. AI at present is mostly digesting the products of human culture. Everything we’ve produced over thousands of years, it eats all of these cultural products, digests it, and starts producing its own new stuff. But we still haven’t figured out ourselves in our bodies, our brains, our minds, our psychology. So an AI based on our flow and understanding of ourselves is a very dangerous thing.
Segment 2036: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7694, Text: I think that we need, first of all, to keep developing ourselves. If for every dollar and every minute that we spend on developing AI, artificial intelligence, we spend another dollar and another minute in developing human consciousness, the human mind will be okay. The danger is that we spent all our effort on developing an AI at the time we don’t understand ourselves, and then letting the AI take over. That’s a road to a human catastrophe.
Segment 2037: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7731, Text: Does it surprise you how well large language models work?
Segment 2038: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7731, Text: Yes.
Segment 2039: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7734, Text: I mean, has it modified your understanding of the nature of intelligence?
Segment 2040: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7738, Text: Yes. I mean, I’ve been writing about AI for like eight years now and engaged with all these predictions and speculations, and when it actually came, it was much faster and more powerful than I thought it would be. I didn’t think that we would have, in 2023, an AI that can hold a conversation that you can’t know if it’s a human being or an AI, that can write beautiful texts in … I mean, I read the texts written by AI, and the thing that strikes me most is the coherence. People think, “Oh, it’s nothing. They just take ideas from here and there, words from here and there, and put it … ” No, it’s so coherent. I mean, you read in not sentences, you read paragraphs, you read entire texts, and there is logic, there is a structure.
Segment 2041: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7794, Text: It’s not only coherent, it’s convincing.
Segment 2042: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7797, Text: Yes. It makes sense.
Segment 2043: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7798, Text: And the beautiful thing about it that has to do with your work; it doesn’t have to be true, and it often gets facts wrong, but it still is convincing. And it is both scary and beautiful-
Segment 2044: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7810, Text: Yes.
Segment 2045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7810, Text: … That our brains love language so much that we don’t need the facts to be correct. We just need it to be a beautiful story.
Segment 2046: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7821, Text: Yep. That’s been the secret of politics and religion for thousands of years, and now it’s coming with AI.
Segment 2047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7829, Text: So you as a person who has written some of the most impactful words ever written in your books, how does that make you feel that you might be one of the last effective human writers?
Segment 2048: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7842, Text: That’s a good question.
Segment 2049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7844, Text: First of all, do you think that’s possible?
Segment 2050: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7845, Text: I think it is possible. I’ve seen a lot of examples of AI being told, “Write like Yuval Noah Harari,” and what it produces.
Segment 2051: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7854, Text: Has it ever done better than you think you could have written yourself?
Segment 2052: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7858, Text: I mean, on the level of content of ideas, no. There are things I say, “I would never say that.” But when it comes to the … You know, there is … Again, the coherence and the quality of writing is such that I say it’s unbelievable how good it is. And who knows? In 10 years, in 20 years, maybe it can do better, even on, according to certain measures, the level of content.
Segment 2053: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7891, Text: So that people would be able to do a style transfer, do a, in the style of Yuval Noah Harari, write anything. Write why I should have ice cream tonight and make it convincing.
Segment 2054: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7905, Text: I don’t know if I have anything convincing to say about these things, but-
Segment 2055: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7907, Text: I think you would be surprised. I think you’d be surprised. It could be an evolutionary biology explanation for why-
Segment 2056: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7913, Text: Yeah. Ice cream is good for you.
Segment 2057: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7914, Text: Yeah.
Segment 2058: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7915, Text: So I mean, that changes the nature of writing.
Segment 2059: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7919, Text: Ultimately, I think it goes back-
Segment 2060: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7920, Text: Ultimately, I think it goes back… Much of my writing is suspicious of itself. I write stories about the danger of stories. I write about intelligence, but highlighting the dangers of intelligence. In terms of power, human power comes from intelligence and from stories. But I think that the deepest and best qualities of humans are not intelligence and not storytelling and not power. Again, with all our power, with all our cooperation, with our intelligence, we are on the verge of destroying ourselves and destroying much of the ecosystem.
Segment 2061: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=7970, Text: Our best qualities are not there. Our best qualities are non-verbal. Again, they come from things like compassion, from introspection. And introspection, from my experience, is not verbal. If you try to understand yourself with words, you will never succeed. There is a place where you need the words, but the deepest insights, they don’t come from words. And you can’t write about it. Again, it goes back to Wittgenstein, to Buddha, to so many of these sages before, that these are the things we are silent about.
Segment 2062: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8009, Text: But eventually you have to project it. As a writer, you have to do the silent introspection, but projected onto a page.
Segment 2063: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8017, Text: Yes, but you still have to warn people, you will never find the deepest truth in a book. You will never find it in words. You can only find it, I think, in direct experience, which is non-verbal, which is pre-verbal.
Segment 2064: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8033, Text: In the silence of your own mind.
Segment 2065: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8035, Text: Yes.
Segment 2066: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8035, Text: Somewhere in there.
Segment 2067: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8036, Text: Yes.
Segment 2068: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8038, Text: Well, let me ask you a silly question then, a ridiculously big question. You have done a lot of deep thinking about the world, about yourself, this kind of introspection. How do you think, by way of advice, but just practically speaking, day to day, how do you think about difficult problems with the world?
Segment 2069: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8062, Text: First of all, I take time off. The most important thing I do, I think, as a writer, as a scientist, I meditate. I spend about two hours every day in silent meditation, observing as much as possible, non-verbally, what is happening within myself. Focusing, body sensations, the breath. Thoughts keep coming up, but I try not to give them attention. Don’t try to drive them away, just let them be there in the background like some background noise. Don’t engage with the thoughts. Because the mind is constantly producing stories with words. These stories come between us and the world. They don’t allow us to see ourselves or the world. For me, the most shocking thing when I started meditating 23 years ago, I was given the simple exercise to just observe my breath coming in and out of the nostrils. Not controlling it, just observing it. And I couldn’t do it for more than 10 seconds.
Segment 2070: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8127, Text: For 10 seconds I would try to notice, “Oh, now the breath is coming in, it’s coming in, it’s coming in. Oh, it’s stopped coming in and now it’s going out, going out.” 10 seconds and some memory would come, some thought would come, some story about something that happened last week or 10 years ago or in the future. And the story would hijack my attention. It would take me maybe five minutes to remember, “Oh, I’m supposed to be observing my breath.” If I can’t observe my own breath because of these stories created by the mind, how can I hope to understand much more complex things, like the political situation in Israel, the Israeli-Palestinian conflict, the Russian invasion of Ukraine? If all these stories keep coming, I mean, it’s not the truth, it’s just the story your own mind created. So first thing, train the mind to be silent and just observe. So two hours every day, and I go every year for a long retreat, between one month and two months, 60 days, of just silent meditation.
Segment 2071: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8191, Text: Silent meditation for 60 days.
Segment 2072: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8193, Text: Yeah. To train the mind, forget about your own stories, just observe what is really happening. And then also throughout the day, have an information diet. People are today, many people are very aware of what they feed their body, what enters their mouth. Be very aware of what you feed your mind, what enters your mind. Have an information diet. So for instance, I read long books. I do many interviews. I prefer three hours interviews to five minutes interviews. The long format, it’s not always feasible, but you can go much, much deeper. So I would say an information diet. Be very careful about what you feed your mind. Give preference to big chunks over small-
Segment 2073: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8252, Text: To books over Twitter.
Segment 2074: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8254, Text: Yes, books over Twitter, definitely. And then when I encounter a problem, a difficult intellectual problem, then I let the problem lead me where it goes and not where I want it to go. If I approach a problem with some preconceived idea or solution and then try to impose it on the problem, and just find confirmation bias, just find the evidence that supports my view, this is easy for the mind to do. And you don’t learn anything new.
Segment 2075: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8293, Text: Do you take notes? Do you start to concretize your thoughts on paper?
Segment 2076: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8299, Text: I read a lot. Usually I don’t take notes. Then I start writing, and when I write, I write like a torrent. Just write. Now it’s the time, you read. You [inaudible 02:18:32] meditation. Now it’s the time to write. Write. Don’t stop, just write. So I would write from memory, and I’m not afraid of formulating, say, big ideas, big theories and putting them on paper. The danger is, once it’s on paper… Not on paper, on the screen in the computer, you get attached to it. And then you start with confirmation bias to build more and more layers around it and you can’t go back. And then it’s very dangerous. But I trust myself that I have to some extent the ability to press the delete button. The most important button in the keyboard is delete. I write and then I delete. I write and then I delete Every time I come to press delete button, I feel bad. It’s a kind of pain, “Eh, I created this. It’s a beautiful idea and I have to delete it?”
Segment 2077: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8370, Text: But you’re still brave enough to press delete?
Segment 2078: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8372, Text: I try. And hopefully, I do it enough times. And this is important because in the long term it enables me to play with ideas. I have the confidence to start formulating some brave idea. Most of them turn out to be nonsense, but I trust myself not to be attached, not to become attached to my own nonsense. So it gives me this room for playfulness.
Segment 2079: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8400, Text: I would be amiss if I didn’t ask, for people interested in hearing you talk about meditation, if they want to start meditating what advice would you give on how to start? You mentioned you couldn’t hold your attention on your breath for longer than 10 seconds at first. So how do they start on this journey?
Segment 2080: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8420, Text: First of all, it’s a difficult journey. It’s not fun, it’s not recreational, it’s not time to relax. It can be very, very intense. The most difficult thing, at least in the meditation I practice, vipassana, which I learned from a teacher called S.N. Goenka, the most difficult thing is not the silence. It’s not the sitting for long hours. It’s what comes up. Everything you don’t want to know about yourself, this is what comes up. So it’s very intense and difficult. If you go to a meditation retreat, don’t think you’re going to relax.
Segment 2081: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8457, Text: So what’s the experience of a meditation retreat when everything you don’t like comes up for 30 days?
Segment 2082: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8464, Text: It depends what comes up. Anger comes up, you’re angry. For days on end, you’re just boiling with anger. Everything makes you angry. Again, something that happens right now or you remember something from 20 years ago and you start boiling with… It’s like, I never even thought about this incident, but it was somewhere stored with a huge, huge pile of anger attached to it. And it’s now coming up and all the anger is coming up. Maybe it’s boredom. 30 days of meditation, you start getting bored. And it’s the most boring thing. Suddenly, no anger. No, it’s the most boring. Another second, and I scream. And boredom is one of the most difficult thing to deal with in life. I think it’s closely related to death. Death is boring. In many movies, death is exciting. It’s not exciting. When [inaudible 02:22:04] dies, ultimately, it’s boredom. Nothing happens.
Segment 2083: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8528, Text: It’s the end of exciting things.
Segment 2084: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8530, Text: And many things in the world happen because of boredom. To some extent, people start entire wars because of boredom. People quit relationships. People quit jobs because of boredom. And if you never learn how to deal with boredom, you will never learn how to enjoy peace and quiet, because the way to peace passes through boredom. And from what I experienced with meditation, I think maybe it was the most difficult, maybe at least in the top three. Much more difficult, say, than anger or pain. When pain comes up, you feel heroic. “Hey, I’m dealing with pain.” When boredom comes up, it brings it with depression and feelings of worthlessness. And it’s nothing, I’m nothing.
Segment 2085: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8583, Text: The way to peace is through boredom. David Foster Wallace said the key to life is to be unborable, which is a different perspective on what you’re talking to. Is there truth to that?
Segment 2086: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8598, Text: Yes. I mean, it’s closely related. I would say, I look at the world today, like politics. The one thing we need more than anything else is boring politicians. We have a super abundance of very exciting politicians who are doing and saying very exciting things. And we need boring politicians and we need them quickly.
Segment 2087: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8623, Text: The way to peace is through boredom. That applies in more ways than one. What advice would you give to young people today in high school and college, how to have a successful life, how to have a successful career?
Segment 2088: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8637, Text: What they should know, it’s the first time in history nobody has any idea how the world would look like in 10 years. Nobody has any idea how the world would look like when you grow up. Throughout history, it was never possible to predict the future. You live in the Middle Ages, nobody knows. Maybe in 10 years the Vikings will invade, the Mongols will invade, there’ll be an epidemic, there’ll be an earthquake, who knows? But the basic structures of life will not change. Most people will still be peasants. Armies would fight on horseback with swords and bows and arrows and things like that. So you could learn a lot from the wisdom of your elders. They’ve been there before and they knew what kind of basic skills you need to learn. Most people need to learn how to sow wheat and harvest wheat or rice and make bread and build a house and ride a horse and things like that.
Segment 2089: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8697, Text: Now we have no idea, not just about politics. We have no idea how the job market would look like in 10 years. We have no idea what skills will still be needed. You think you’re going to learn how to code because they’ll need a lot of coders in the 2030s? Think again. Maybe AI is doing all the coding. You don’t need any coders. You are going to, I don’t know, you learn to [inaudible 02:25:26] languages, you want to be a translator. Gone. And we don’t know what skills will be needed. So the most important skill is the skill to keep learning and keep changing throughout our lives, which is very, very difficult. To keep reinventing ourselves. Again, it’s in a way a spiritual practice, to build your personality, to build your mind as a very flexible mind. Traditionally, people thought about education like building a stone house with very deep foundations. Now it’s more like setting up a tent that you can fold and move to the next place very, very quickly. Because that’s the 21st century.
Segment 2090: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8781, Text: Which also raises questions about the future of education, what that looks like.
Segment 2091: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8788, Text: Yeah.
Segment 2092: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8789, Text: Let me ask you about love. What were some of the challenges, what were some of the lessons about love, about life that you learned from coming out as gay?
Segment 2093: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8803, Text: In many ways, it goes back to the stories. I think this is one of the reasons I became so interested in stories and in their power. Because I grew up in a small Israeli town in the 1980s, early 1990s, which was very homophobic. And I basically embraced it, I breathed it. Because you could hardly even think differently. So you had these two powerful stories around. One, that God hates gay people and that he will punish them for who they are or for what they do. Secondly, that it’s not God, it’s nature. That there is something diseased or sick about it. And these people, maybe they’re not sinners, but they are sick, they are defective. And nobody wanted to identify with such a thing. If your option’s, okay, you can be a sinner, you can be a defect, what do you want? No good options there.
Segment 2094: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8873, Text: And it took me many years, till I was 21, to come to terms with it. I learned two things. First, about the amazing capacity of the human mind for denial and delusion. An algorithm could have told me that I’m gay when I was 14 or 15. If there is a good-looking guy and girl walking, I would immediately focus on the guy. But I didn’t connect the dots. I could not understand what was happening inside my own brain and my own mind, in my own body. It took me a long time to realize, “You know, you’re just gay.”
Segment 2095: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8916, Text: So that speaks to the power of social convention versus individual thought.
Segment 2096: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8921, Text: This is the power of self-delusion. It’s not that I knew I was gay and was hiding it. I was hiding it from myself, successfully. Looking back, I don’t understand how it is possible, but I know it is possible. I knew and didn’t know at the same time. And then the other big lesson is the power of the stories, of the social conventions. Because the stories were not true. They did not make sense even on their own terms. Even if you accept the basic religious framework of the world, that there is a good God that created everything and controls everything, why would a good God punish people for love? I understand why a good God would punish people for violence, for hatred, for cruelty, but why would God punish people for love, especially when he created them that way?
Segment 2097: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=8980, Text: So even if you accept the religious framework of the world, obviously the story that God hates gay people, it comes not from God, but from some humans who invented this story. They take their own hatred. This is something humans do all the time. They hate somebody and they say, “No, I don’t hate them. God hates them.” They throw their own hatred on God. And then if you think about the scientific framework that said that, “Oh, gays, they are against nature. They are against the laws of nature,” and so forth. Science tells us nothing can exist against the laws of nature. Things that go against the laws of nature just don’t exist. There is a law of nature that you can’t move faster than the speed of light. Now, you don’t have this minority of people who break the laws of nature by going faster than the speed of light. And then nature comes, “Nah, that’s bad. You shouldn’t do that.” That’s not how nature works.
Segment 2098: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9044, Text: If something goes against the laws of nature, it just can’t exist. The fact that gay people exist, and not just people. You see homosexuality among many, many mammals and birds and other animals. It exists because it is in line with the laws of nature. The idea that this is sick, that this is whatever, it comes not from nature, it comes from the human imagination. Some people, for whatever reasons, hated gay people. They said, “Oh, they go against nature.” But this is a story created by people. This is not the laws of nature. And this taught me that so many of the things that we think are natural or eternal or divine, no, they’re just human stories. But these human stories are often the most powerful forces in the world.
Segment 2099: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9099, Text: So what did you learn from just your personal struggle of journey through the social conventions to find one of the things that makes life awesome, which is love? So what it takes to strip away the self-delusion and the pressures of social convention, to wake up.
Segment 2100: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9121, Text: It takes a lot of work, a lot of courage and a lot of help from other people. It’s this kind of, again, heroic idea that I can do it all by myself, it doesn’t work. Certainly with love, you need at least one more person. And I’m very happy that I found Itzik. We lived in the same small Israeli town. We lived on two adjacent streets for years. Probably went to school on the same bus for years without really encountering each other. In the end, we met on one of the first dating sites on the internet for gay people in Israel, in 2002.
Segment 2101: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9163, Text: You’re saying the internet works? For love.
Segment 2102: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9164, Text: Yes. And I said bad things or dangers about technology and the internet. There are also, of course, good things. And this is not an accident. You have two kinds of minorities in history. You have minorities which are a cohesive group like Jews. That yes, you are [inaudible 02:33:04] born Jewish in, say, Germany or Russia or whatever. You are born in a small community. But as a Jewish boy, you are born to a Jewish family. You have Jewish parents, you have Jewish siblings, you are in a Jewish neighborhood, you have Jewish friends. So these kinds of minorities, they could always come together and help each other throughout history. Now, another type of minority, like gay people or more broadly, LGBTQ people, that as a gay boy, you are usually not born to a gay family with gay parents and gay siblings in a gay neighborhood. So usually you find yourself completely alone.
Segment 2103: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9223, Text: For most of history, one of the biggest problems for the gay community was that there was no community. How do you find one another? And the internet was a wonderful thing in this respect because it made it very easy for these kinds of diffuse communities or diffuse minorities to find each other. So me and Itzik, even though we rode the same bus together to school for years, we didn’t meet in the physical world, we met online. Because again, in the physical world, you don’t want to identify in a Israeli town in the 1980s, you ride the bus, you don’t want to say, “Hey, I’m gay, is there anybody else gay here?” That’s not a good idea. But on the internet we could find each other.
Segment 2104: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9266, Text: There’s another lesson in there that maybe sometimes the thing you’re looking for is right under your nose.
Segment 2105: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9270, Text: Yeah. A very old lesson and a very true lesson in many ways. So you need help from other people to realize the truth about yourself. So of course, in love, you cannot just love abstractly. There is another person there, you need to find them. But also, we were one of the first generations who enjoyed the benefits of gay liberation, of these very difficult struggles of people who are much braver than us in the 1980s, 1970s, 1960s, who dared to question social conventions, to struggle, at sometimes a terrible price. And we benefited from it. And more broadly, we spoke earlier about the feminist movement. There would’ve been no gay liberation without the feminist movement. We also owe them for starting to change the gender structure of the world. And this is always true. You can never do it just by yourself.
Segment 2106: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9337, Text: Also, I look at my journey in meditation. I mean, the idea of going to meditation [inaudible 02:35:45] okay. But I couldn’t develop the meditation technique by myself. Somebody had to teach me this way of how to look inside yourself. And it’s also a very important lesson that you can’t do it just by yourself. That this fantasy of complete autonomy, of complete self-sufficiency, it doesn’t work. It tends to be a very kind of male macho fantasy. “I don’t need anybody. I can be so strong and so brave that I’ll do everything by myself.” It never works.
Segment 2107: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9386, Text: You need friends. You need a mentor. The very thing that makes us human is other humans.
Segment 2108: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9397, Text: Absolutely.
Segment 2109: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9398, Text: You mentioned that the fear of boredom might be a kind of proxy for the fear of death. So what role does the fear of death play in the human condition? Are you afraid of death?
Segment 2110: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9410, Text: Yes, I think everybody are afraid of death. I mean, all our fears come out of the fear of death. But the fear of death is just so deep and difficult, usually we can’t face it directly. So we cut it into little pieces and we face just little pieces. “Oh, I lost my smartphone.” That’s a little, little, little piece of the fear of death, which is of losing everything. So I can’t deal with losing everything, I’m dealing now with losing my phone or losing a book or whatever. I feel pain. That’s a small bit of the fear of death. Somebody who really doesn’t fear death would not fear anything at all. There will be like, “Anything that happens, I can deal with it. If I can deal with death, this is nothing.”
Segment 2111: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9457, Text: So any fears is a distant echo of the big fear of death. Have you ever looked at it head on, caught glimpses, sort of contemplated as the Stoics do?
Segment 2112: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9472, Text: Yes. I mean, when I was was a teenager, I constantly contemplated, trying to understand, to imagine. It was a very, very shocking and moving experience. I remember, especially in connection with national ideology, which was also very big, strong in Israel; still is. Which again comes from the fear of death. You know that you’re going to die, so you say, “Okay, I die, but the nation lives on. I live on through the nation. I don’t really die.” And you’ll hear it especially on Memorial Day, the day for fallen soldiers. So every day there’ll be in school Memorial Day for fallen soldiers who fell defending Israel in all its different wars. And all these kids would come dressed in white. And you have this big ceremony with flags and songs and dances in memory of the fallen soldiers. Again, I don’t want to sound crass, but you got the impression that the best thing in life is to be a fallen soldier.
Segment 2113: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9533, Text: Because even then, yes, you die, everybody dies in the end. But then you’ll have all these school kids for years and years, remembering you and celebrating you and you don’t really die. And I remember standing in these ceremonies and thinking, “What does it actually mean? Okay, so if I’m a fallen soldier now I’m a skeleton. I’m bones in this military cemetery, under this stone. Do I actually hear the kids singing all these patriotic songs? If not, how do I know they do it? Maybe they trick me. Maybe I die in the war and then they don’t sing any songs. And how does it help me?” And I realized, I was quite young at the time, that if you’re dead, you can’t hear anything, because that’s the meaning of being dead. And if you’re dead, you can’t think of anything like, “Oh, now they’re remembering,” because you are dead, that’s the meaning of being dead. And it was a shocking realization.
Segment 2114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9588, Text: But it’s a really difficult realization to hold in your mind. It’s the end.
Segment 2115: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9593, Text: I lost it over time. I mean, for many years it was a very powerful fuel, motivation for philosophical, for spiritual exploration. And I realized that the fear of death is really a very powerful drive. And over the years, especially as I meditated, it kind of dissipated. And today I sometimes find myself trying to recapture this teenage fear of death because it was so powerful, and I just can’t. And I try to make the same image. I don’t know, it’s…
Segment 2116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9625, Text: Something about the teenage years. When the fire burns bright.
Segment 2117: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9628, Text: As a teenager, I always thought that the adults, there is something wrong with the adults, because they don’t get it. I would ask my parents or teachers about it and they… “Oh yes, you die in the end, that’s it.” And on the other hand, they’re so worried about other things. There’ll be a political crisis or an economic problem or a personal problem with the bank or whatever. They’ll be so worried. But then about the fact that they’re going to die, “Ah, we don’t care about it.”
Segment 2118: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9656, Text: That’s why you read Camus and others when you’re a teenager. You really worry about the existential questions. Well, this feels like the right time to ask the big question. What’s the meaning of this whole thing, Yuval? And you’re the right person to ask. What’s the meaning of life?
Segment 2119: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9671, Text: Life? That’s easy.
Segment 2120: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9672, Text: What is it?
Segment 2121: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9676, Text: So what life is, if you ask what life is, life is feeling things, having sensations, emotions, and reacting to them. When you feel something good, something pleasant, you want more of it. When you feel something unpleasant, you want to get rid of it. That’s the whole of life. That’s what is happening all the time. You feel things. You want the pleasant things to increase. You want the unpleasant things to disappear. That’s what life is. If you ask what is the meaning of life in a more philosophical or spiritual question, the real question to ask, what kind of answer do you expect? Most people expect a story. And that’s always the wrong answer. Most people expect that the answer to the question, “What is the meaning of life?” will be a story, like a big drama.
Segment 2122: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9735, Text: That this is the plot line and this is your role in the story. This is what you have to do. This is your line in the big play. You say your line, you do your thing. That’s the thing. And this is human imagination, this is fantasy. To really understand life, life is not a story. The universe does not function like a story. So I think to really understand life, you need to observe it directly in a nonverbal way. Don’t turn it into a story. And the question to start with is, what is suffering? What is causing suffering? The question, what is the meaning of life? It will take you to fantasies and delusions. We want to stay with the reality of life. And the most important question about the reality of life is what is suffering and where is it coming from?
Segment 2123: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9793, Text: And to answer that non-verbally, so the conscious experience of suffering?
Segment 2124: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9797, Text: Yes. When you suffer, try to observe what is really happening when you are suffering.
Segment 2125: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9810, Text: Well put. And I wonder if AI will also go through that same kind of process on its way-
Segment 2126: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9816, Text: Depends if it develop consciousness or not. At present, it’s not. It’s just words.
Segment 2127: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9821, Text: It will just say to you, “Please don’t hurt me, Yuval.”. Again, as I’ve mentioned to you, I’m a huge fan of yours. Thank you for the incredible work you do. This conversation’s been a long time, I think, coming. It’s a huge honor to talk to you. This was really fun. Thank you for talking today.
Segment 2128: Speaker: Yuval Noah Harari, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9841, Text: Thank you. I really enjoyed it. And as I said, I think the long form is the best form.
Segment 2129: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9849, Text: Yeah, I loved it. Thank you.
Segment 2130: Speaker: , Timestamp: https://youtube.com/watch?v=Mde2q7GFCrw&t=9851, Text: Thanks for listening to this conversation with Yuval Noah Harari. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Yuval Noah Harari himself. “How do you cause people to believe in an imagined order, such as Christianity, democracy, or capitalism? First, you never admit that the order is imagined.” Thank you for listening and hope to see you next time.
Segment 2131: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=0, Text: We should never, and I never sit aside and say, oh, they’re just threatening to destroy us. They won’t do it. If somebody threatens to eliminate you as Iran is doing today, and as Hitler did then and people discounted it, well, if somebody threatens to annihilate us, take them seriously and act to prevent it early on. Don’t let them have the means to do so because that may be too late.
Segment 2132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=26, Text: The following is a conversation with Benjamin Netanyahu, prime Minister of Israel, currently serving his sixth term in office. He’s one of the most influential, powerful, and controversial men in the world, leading a right-wing coalition government at the center of one of the most intense and long-lasting conflicts and crises in human history.
Segment 2133: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=47, Text: As we spoke, and as I speak now, large scale protests are breaking out all over Israel over this government’s proposed judicial reform that seeks to weaken the Supreme Court in a bold accumulation of power. Given the current intense political battles in Israel, our previous intention to speak for three hours was adjusted to one hour for the time being, but we agreed to speak again for much longer in the future. I will also interview people who harshly disagree with words spoken in this conversation. I will speak with other world leaders, with religious leaders, with historians and activists, and with people who have lived and have suffered through the pain of war, destruction and loss that stoke the fires of anger and hate in their heart.
Segment 2134: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=95, Text: For this, I will travel anywhere no matter how dangerous if there’s any chance, it may help add to understanding and love in the world. I believe in the power of conversation to do just this, to remind us of our common humanity. I know I’m under-qualified and under-skilled for these conversations, so I will often fall short and I will certainly get attacked, derided and slandered. But I will always turn the other cheek and use these attacks to learn to improve, and no matter what, never give into cynicism.
Segment 2135: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=132, Text: This life, this world of ours is too beautiful not to keep trying. Trying to do some good in whatever way each of us know how. I love you all.
Segment 2136: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=145, Text: This is The Lex Fridman Podcast. To support it please check out our sponsors in the description. And now, dear friends, here’s Benjamin Netanyahu.
Segment 2137: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=155, Text: You’re loved by many people here in Israel and in the world, but you’re also hated by many. In fact, I think you may be one of the most hated men in the world. So if there’s a young man or a young woman listening to this right now who have such hate in their heart, what can you say to them to one day turn that hate into love?
Segment 2138: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=178, Text: I disagree with the premise of your question. I think I’ve enjoyed a very broad support around the world. There are certain corners in which we have this animosity that you describe, and it sort of permeates in some of the newspapers and the news organs and so on in the United States, but it certainly doesn’t reflect the broad support that I have. I just gave an interview on an Iranian channel, 60 million viewers. I gave another one, just did a little video a few years ago, 25 million viewers from Iran. Certainly no hate there I have to tell you, not from the regime.
Segment 2139: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=225, Text: And when I go around the world and I’ve been around the world, people want to hear what we have to say. What I have to say as a leader of Israel whom they respect increasingly as a rising power in the world. So I disagree with that. And the most important thing that goes against what you said is the respect that we receive from the Arab world and the fact that we’ve made four historic peace agreements with Arab countries. And they made it with me, they didn’t make it with anyone else. And I respect them and they respect me and probably more to come. So I think the premise is wrong, that’s all.
Segment 2140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=264, Text: Well, there’s a lot of love, yes. A lot of leaders are collaborating are –
Segment 2141: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=272, Text: Respect, I said not love.
Segment 2142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=274, Text: Okay. All right. Well, it’s a spectrum, but there is people who don’t have good things to say about Israel, who do have hate in their heart for Israel.
Segment 2143: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=285, Text: Yeah.
Segment 2144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=286, Text: And what can you say to those people?
Segment 2145: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=289, Text: Well, I think they don’t know very much. I think they’re guided by a lot of ignorance. They don’t know about Israel. They don’t know that Israel is a stellar democracy, that it happens to be one of the most advanced societies on the planet. That what Israel develops helps humanity in every field, in medicine, in agriculture and in the environment and telecoms and talk about AI in a minute. But changing the world for the better and spreading this among six continents.
Segment 2146: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=321, Text: We’ve sent rescue teams more than any other country in the world, and we’re one 10th of 1% of the world’s population. But when there’s an earthquake or a devastation in Haiti or in the Philippines, Israel is there. When there’s an devastating earthquake in Turkey, Israel was there. When there’s something in Nepal, Israel is there, and it’s the second country. It’s the second country after, in one case, India or after another case, the United States, Israel is there. Tiny Israel is a benefactor to all of humanity.
Segment 2147: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=357, Text: So you’re a student of history. If I can just linger on that philosophical notion of hate, that part of human nature. If you look at World War II, what do you learn from human nature, from the rise of the Third Reich and the rise of somebody like Hitler and the hate that permeates that?
Segment 2148: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=379, Text: Well, what I’ve learned is that you have to nip bad things in the bud. There’s a Latin term that says [foreign language 00:06:29], stop bad things when they’re small. And the deliberate hatred, the incitement of hatred against one community, it’s demonization, delegitimization that goes with it is a very dangerous thing.
Segment 2149: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=408, Text: And that happened in the case of the Jews. What started with the Jews soon spread to all of humanity. So what we’ve learned is that we should never, and I never sit aside and say, “Oh, they’re just threatening to destroy us. They won’t do it.” If somebody threatens to eliminate you as Iran is doing today, and as Hitler did then, and people discounted it, well, if somebody threatens to annihilate us, take them seriously and act to prevent it early on. Don’t let them have the means to do so because that may be too late.
Segment 2150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=441, Text: So in those threats underlying that hatred, how much of it is anti-Zionism, and how much of it is anti-Semitism?
Segment 2151: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=451, Text: I don’t distinguish between the two. You can’t say, “Well, I’m, I’m okay with Jews, but I just don’t think there should be a Jewish state.” It’s like saying, “I’m not anti-American, I just don’t think there should be an America.” That’s basically what people are saying vis-a-vis anti-Semitism and anti-Zionism.
Segment 2152: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=469, Text: When you’re saying anti-Zionism you’re saying that Jewish people don’t have a right to have a state of their own. And that is a denial of a basic principle that I think completely unmasks what is involved here. Today anti-Semitism is anti-Zionism. Those who oppose the Jewish people oppose the Jewish state.
Segment 2153: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=495, Text: If we jump from human history to the current particular moment, there’s protests in Israel now about the proposed judicial reform that gives power to your government to override the Supreme Court. So the critics say that this gives too much power to you, virtually making you a dictator.
Segment 2154: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=515, Text: Yeah. Well, that’s ridiculous. The mere fact that you have so many demonstrations and protests, some dictatorship, huh? There’s a lot of democracy here, more rambunctious and more robust than just anywhere on the planet.
Segment 2155: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=532, Text: Can you still man the case that this may give too much power to the coalition government, to the prime minister, not just to you, but to those who follow?
Segment 2156: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=544, Text: No, I think that’s complete hogwash because I think there’s very few people who are demonstrating against this. Quite a few, quite many, don’t have an idea what is being discussed. They’re basically being sloganized. You can sloganized, you know something about not mass media right now, but the social network, you can basically feed deliberately with big data and big money, you can just feed slogans and get into people’s minds. I’m sure you don’t think I exaggerate, because you can tell me more about that.
Segment 2157: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=578, Text: And you can create mass mobilization based on these absurd slogans. So here’s where I come from and what we’re doing, what we’re trying to do, and what we’ve changed in what we’re trying to do. I’m a 19th century democrat in my, small D yes, in my views. That is I ask the question, “What is democracy?” So democracy is the will of the majority and the protection of the rights of, they call it the rights of the minority, but I say the rights of the individual.
Segment 2158: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=611, Text: So how do you balance the two? How do you avoid mobocracy? And how do you avoid dictatorship? The opposite side. The way you avoid it is something that was built essentially by British philosophers and French philosophers, but was encapsulated by the Founding Fathers of the United States. You create a balance between the three branches of government, the legislative, the executive, and the judiciary.
Segment 2159: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=641, Text: And this balance is what assures the balance between majority rights and individual rights. And you have to balance all of them. That balance was maintained in Israel in its first 50 years, and was gradually overtaken and basically broken by the most activist judicial court on the planet. That’s what happened here. And gradually over the last two, three decades, the court aggregated for itself the powers of the parliament and the executive. So we’re trying to bring it back into line. Bringing it back into line, into what is common in all parliamentary democracies and in the United States, doesn’t mean taking the pendulum from one side and bringing it to the other side.
Segment 2160: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=689, Text: We want checks and balances, not unrivaled power. Just as we said, we want an independent judiciary, but not an all powerful judiciary. That balance does not mean, bringing it back into line, doesn’t mean that you can have the parliament, our Knesset, override any decision that the Supreme Court does. So I pretty much early on said, after the judicial reform was introduced, “Get rid of the idea of sweeping override clause that would have, with 61 votes, that’s a majority of one, you can just nullify any Supreme Court decision, so let’s move it back into the center.” So that’s gone. And most of the criticism on the judicial reform was based on an unlimited override clause, which I’ve said is simply not going to happen. People are discussing something that already for six months does not exist.
Segment 2161: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=740, Text: The second point that we received criticism on was the structure of how do you choose Supreme Court judges? Okay, how do you choose them? And the critics of the reform are saying that the idea that elected officials should choose Supreme Court judges is the end of democracy. If that’s the case, the United States is not a democracy. Neither is France and neither are just, I don’t know, just about every democracy on the planet. So there is a view here that you can’t have the sordid hands of elected officials involved in the choosing of judges.
Segment 2162: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=779, Text: And in the Israeli system, the judicial activism went so far that effectively the sitting judges have an effective veto on choosing judges, which means that this is a self-selecting court that just perpetrates itself. And we want to correct that. Again, we want to correct it in a balanced way. And that’s basically what we’re trying to do. So I think there’s a lot of misinformation about that. We’re trying to bring Israeli democracy to where it was in its first 50 years. And it was a stellar democracy. It still is. Israel is a democracy, will remain a democracy, a vibrant democracy. And believe me, the fact that people are arguing and demonstrating in the streets and protesting is the best proof of that, and that’s how it’ll remain.
Segment 2163: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=829, Text: We spoke about tech companies offline, there’s a lot of tech companies nervous about this judicial reform. Can you speak to why large and small companies have a future in Israel?
Segment 2164: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=843, Text: Because Israel is a free market economy. I had something to do with that. I introduced dozens and dozens of free market reforms that made Israel move from $17,000 per capita income within very short time to $54,000. That’s nominal GDP per capita according to the IMF. And we’ve overtaken in that Japan, France, Britain, Germany.
Segment 2165: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=869, Text: And how did that happen? Because we unleashed the genius that we have and the initiative and the entrepreneurship that is latent in our population. And to do that, we had to create free markets. So we created that. So Israel has one of the most vibrant free market economies in the world. And the second thing we have is a permanent investment in conceptual products because we have a permanent investment in the military, in our security services, creating basically knowledge workers who then become knowledge entrepreneurs. And so we create this structure, and that’s not going to go away.
Segment 2166: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=909, Text: There’s been a decline in investments in high-tech globally. I think that’s driven by many factors. But the most important one is the interest rate, which I think will, it’ll fluctuate up and down. But Israel will remain a very attractive country because it produces so many knowledge workers in a knowledge based economy. And it’s changing so rapidly. The world is changing. You’re looking for the places that have innovation. The future belongs to those who innovate.
Segment 2167: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=941, Text: Israel is the preeminent innovation nation. It has few competitors. And if we would say, “All right, where do you have this close cross-disciplinary fermentation of various skills in areas?” I would say “It’s in Israel.” And I’ll tell you why. We used to be just telecoms because people went out of the military intelligence, RNSA, but that’s been now broad based. So you find it in medicine, you find it in biology, you find it in agritech, you find it everywhere. Everything is becoming technologized.
Segment 2168: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=977, Text: And in Israel, everybody is dealing in everything, and that’s a potent reservoir of talent that the world is not going to pass up. And in fact, it’s coming to us. We just had Nvidia coming here, and they decided to build a supercomputer in Israel. Wonder why? We’ve had Intel coming here and deciding now to invest $25 billion, just now, in a new plant in Israel. I wonder why? I don’t wonder why. They know why. Because the talent is here and the freedom is here. And it will remain so.
Segment 2169: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1012, Text: You had a conversation about AI with Sam Altman of Open AI and with Elon Musk.
Segment 2170: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1017, Text: Yeah.
Segment 2171: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1017, Text: What was the content of that conversation? What’s your vision for this very highest of tech, which is artificial intelligence?
Segment 2172: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1029, Text: Well, first of all, I have a high regard for the people I talked to. And I understand that they understand things I don’t understand, and I don’t pretend to understand everything. But I do understand one thing. I understand that AI is developing at a geometric rate and mostly in political life and in life in general people don’t have an intuitive grasp of geometric growth. You understand things basically in linear increments. And the idea that you’re coming up a ski slope is very foreign to people. So they don’t understand it, and they’re naturally also sort of taken aback by it. Because what do you do? So I think there’s several conclusions from my conversations with them and from my other observations that I’ve been talking about for many years. I’m talking about the need-
Segment 2173: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1080, Text: … observations that I’ve been talking about for many years. I’m talking about the need to do this. Well, the first thing is this. There is no possibility of not entering AI with full force. Secondly, there is a need for regulation. Third, it’s not clear there will be global regulation. Fourth, it’s not clear where it ends up. I certainly cannot say that. Now, you might say, “Does it come to control us?” Okay, that’s a question. Does it come to control us? I don’t know the answer to that. I think that, as one observation that I had from these conversations is if it does come to control us, that’s probably the only chance of having universal regulation, because I don’t see anyone deciding to avoid the race and cooperate unless you have that threat. Doesn’t mean you can’t regulate AI within countries even without that understanding, but it does mean that there’s a limit to regulation because every country will want to make sure that it doesn’t give up competitive advantage if there is no universal regulation.
Segment 2174: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1159, Text: I think that right now, just as 10 years ago, I read a novel. I don’t read novels, but I was forced to read one by a scientific advisor. I read history, I read about economics, I read about technology. I just don’t read novels. In this, I follow Churchill. He said, “Fact is better than fiction.” Well, this fiction would become fact. It was a book, it was a novel about a Chinese/American future cyber war. I read the book in one sitting, called in a team of experts, and I said, “All right, let’s turn Israel into one of the world’s five cyber powers and let’s do it very quickly.” And we did actually. We did exactly that. I think AI is bigger than that and related to that, because it’ll affect … Well, cyber affects everything, but AI will affect it even more fundamentally. And the joining of the two could be very powerful.
Segment 2175: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1219, Text: So I think in Israel, we have to do it anyway for security reasons and we’re doing it. But I think, what about our databases that are already very robust on the medical records of 98% of our population? Why don’t we stick a genetic database on that? Why don’t we do other things that could bring what are seemingly magical cures and drugs and medical instruments for that? That’s one possibility. We have it, as I said, in every single field. The conclusion is this. We have to move on AI. We are moving on AI, just as we moved on cyber, and I think Israel will be one of the leading AI powers in the world. The questions I don’t have an answer to is, where does it go? How much does it chew up on jobs?
Segment 2176: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1279, Text: There’s an assumption that I’m not sure is true, that the two big previous revolutions in the human condition, namely the agricultural revolution and the industrial revolution, definitely produced more jobs than they consumed. That is not obvious to me at all. I mean, I could see new jobs creating, and yes, I have that comforting statement, but it’s not quite true, because I think on balance, they’ll probably consume more jobs, many more jobs than they’ll create.
Segment 2177: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1318, Text: At least in the short term. And we don’t know about the long term.
Segment 2178: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1321, Text: No, I don’t know about the long term, but I used to have the comfort being a free market guy. I always said, “We’re going to produce more jobs by, I don’t know, limiting certain government jobs.” We’re actually putting out in the market, will create more jobs, which obviously happened. We had one telecom company, a government company. When I said, “We’re going to create competition,” they said, “You’re going to run us out. We’re not going to have more workers.” They had 13,000 workers. They went down to seven, but we created another 40,000 in the other companies. So, that was a comforting thought. I always knew that was true.
Segment 2179: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1356, Text: Not only that. I also knew that wealth would spread by opening up the markets, completely opposite to the socialist and semi-socialist creed that they had here. They said, “You’re going to make the rich richer and the poor poorer.” No. And made everyone richer, and actually the people who entered the job market because of the reforms we did, actually became a lot richer on the lower ladders of the socioeconomic measure.
Segment 2180: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1385, Text: But here’s the point, I don’t know. I don’t know that we will not have what Elon Musk calls the end of scarcity. So you’ll have the end of scarcity. You’ll have enormous productivity. Very few people are producing enormous added value. You’re going to have to tax that to pass it to the others. You’re going to have to do that. That’s a political question. I’m not sure how we answer that. What if you tax and somebody else doesn’t tax? You’re going to get everybody to go there. That’s an international issue that we constantly have to deal with.
Segment 2181: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1422, Text: And the second question you have is, suppose you solve that problem and you deliver money to those who are not involved in the AI economy, what do they do? The first question you ask somebody whom you just met after the polite exchanges is, what do you do? Well, people define themselves by their profession. It’s going to be difficult if you don’t have a profession. People will spend more time self-searching, more time in the arts, more time in leisure. I understand that. If I have to bet, it will annihilate many more jobs than it will create and it’ll force a structural change in our economics, in our economic models, and in our politics. And I’m not sure where it’s going to go.
Segment 2182: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1480, Text: And that’s something we have to respond to at the nation level and just as a human civilization, both the threat of AI to just us as a human species and then the effect on the jobs. And like you said, cybersecurity.
Segment 2183: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1495, Text: What do you think? You think we’re going to lose control?
Segment 2184: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1500, Text: No, first of all, I do believe, maybe naively, that it will create more jobs than it takes.
Segment 2185: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1505, Text: Write that down and we’ll check it.
Segment 2186: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1507, Text: It’s on record.
Segment 2187: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1509, Text: We don’t say, “We’ll check it after our lifetime.” No, we’ll see it in a few years.
Segment 2188: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1512, Text: We’ll see it in a few years. I’m really concerned about cybersecurity and the nature of how that changes with the power of AI. In terms of existential threats, I think there will be so much threats that aren’t existential along the way that that’s the thing I’m mostly concerned about, versus AI taking complete control and superseding the human species. Although that is something you should consider seriously because of the exponential growth of its capabilities.
Segment 2189: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1543, Text: Yeah, it’s exactly the exponential growth, which we understand is before us, but we don’t really … It’s very hard to project forward.
Segment 2190: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1551, Text: To really understand.
Segment 2191: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1552, Text: That’s right. Exactly right. So I deal with what I can and where I can affect something. I tend not to worry about things I don’t control, because there’s at a certain point, there’s no point. I mean, you have to decide what you’re spending your time on. So in practical terms, I think we’ll make Israel a formidable AI power. We understand the limitation of skill, computing power and other things. But I think within those limits, I think we can make here this miracle that we did in many other things. We do more with less. I don’t care if it’s the production of water or the production of energy or the production of knowledge or the production of cyber capabilities, defense and other, we just do more with less. And I think in AI, we’re going to do a lot more with a relatively small but highly gifted population. Very gifted.
Segment 2192: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1613, Text: So taking a small tangent, as we talked about offline, you have a background in TaeKwonDo?
Segment 2193: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1620, Text: Oh, yeah.
Segment 2194: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1621, Text: We mentioned Elon Musk. I’ve trained with both. Just as a quick question, who are you betting on in a fight?
Segment 2195: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1628, Text: Well, I refuse to answer that. I will say this.
Segment 2196: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1633, Text: Such a politician, you are.
Segment 2197: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1634, Text: Yeah, of course. Here, I’m a politician. I’m openly telling you that I’m dodging the question. But I’ll say this. Actually, I spent five years in our special forces in the military, and we barely spent a minute on martial arts. I actually learned TaeKwonDo later when I came to … It wasn’t even at MIT. At MIT, I think I did karate. But when I came to the UN, I had a martial arts expert who taught me TaeKwonDo, which was interesting. Now, the question you really have to ask is, why did we learn martial arts in this special elite unit? And the answer is, there’s no point. If you saw Indiana Jones, there’s no point. You just pull the trigger. That’s simple. Now, I don’t expect anyone to pull the trigger on this combat, and I’m sure you’ll make sure that doesn’t happen.
Segment 2198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1695, Text: Yeah. I mean, martial arts is bigger than just combat. It’s this journey of humility.
Segment 2199: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1701, Text: Oh, sure.
Segment 2200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1703, Text: It’s an art form. It truly is an art. But it’s fascinating that these two figures in tech are facing each other. I won’t ask the question of who you would face and how you would do, but …
Segment 2201: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1714, Text: Well, I’m facing opponents all the time.
Segment 2202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1716, Text: All the time?
Segment 2203: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1717, Text: Yeah, that’s part of life.
Segment 2204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1721, Text: Not yet.
Segment 2205: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1721, Text: I’m not sure about that.
Segment 2206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1722, Text: Are you announcing any fights?
Segment 2207: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1724, Text: No, no. Part of life is competition. The only time competition ends is death. But political life, economic life, cultural life is engaged continuously in creativity and competition. The problem I have with that is, as I mentioned earlier just before we began the podcast, is that at a certain point, you want to put barriers to monopoly. And if you’re a really able competitor, you’re going to create a monopoly. That’s what Peter Till says is a natural course of things. It’s what I learned basically in the Boston Consulting Group. If you are a very able competitor, you’ll create scale advantages that gives you the ability to lock out your competition. And as a prime minister, I want to assure that there is competition in the markets, so you have to limit this competitive power at a certain point, and that becomes increasingly hard in a world where everything is intermixed.
Segment 2208: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1789, Text: Where do you define market segments? Where do you define monopoly? How do you do that? That, actually conceptually, I find very challenging, because of all the dozens of economic reforms that I’ve made, the most difficult part is the conceptual part. Once you’ve ironed it out and you say, “Here’s what I want to do. Here’s the right thing to do,” then you have a practical problem of overcoming union resistance, political resistance, press calumny, opponents from this or that corner. That’s a practical matter. But if you have it conceptually defined, you can move ahead to reform economies or reform education or reform transportation. Fine.
Segment 2209: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1838, Text: In the question of the growing power of large companies, big tech companies to monopolize the markets because they’re better at it, they provide a service, they provide it at a lower cost, at rapidly declining cost. Where do you stop? Where do you stop monopoly power is a crucial question because it also becomes now a political question. If you amass enormous amount of economic power, which is information power, that also monopolizes the political process. These are real questions that are not obvious. I don’t have an obvious answer because as I said, as a 19th century Democrat, these are questions of the 21st century, which people should begin to think. Do you have a solution to that?
Segment 2210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1887, Text: The solution of monopolies growing arbitrarily-
Segment 2211: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1890, Text: Yeah.
Segment 2212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1891, Text: … unstoppably in power?
Segment 2213: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1893, Text: In economic power, and therefore in political power.
Segment 2214: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1896, Text: I mean, some of that is regulation, some of that is competition.
Segment 2215: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1900, Text: Do you know where to draw the line? It’s not breaking up AT&T. It’s not that simple.
Segment 2216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1909, Text: Well, I believe in the power of competition, that there will always be somebody that challenges the big guys, especially in the space of AI. The more open source movements are taking hold, the more the little guy can become the big guy.
Segment 2217: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1922, Text: So you’re saying basically the regulatory instrument is the market?
Segment 2218: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1929, Text: In large part, in most part, that’s the hope. Maybe I’m a dreamer.
Segment 2219: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1933, Text: That’s been in many ways my policy up to now, that the best regulator is the market. The best regulator in economic activity is the market and the best regulator in political matters is the political market. That’s called elections. That’s what regulates. You have a lousy government and people make lousy decisions, well, you don’t need the wise men raised above the masses to decide what is good and what is bad. Let the masses decide. Let them vote every four years or whatever, and they throw you out.
Segment 2220: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=1974, Text: By the way, it happened to me. There’s life after political death. There’s actually political life. I was reelected five or six times, and this is my sixth term. So I believe in that. I’m not sure that in economic matters, in the geometric growth of tech companies, that you’ll always have the little guy, the nimble mammal, that will come out and slay the dinosaurs or overcome the dinosaurs, which is essentially what you said.
Segment 2221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2005, Text: Yeah, I wouldn’t count out the little guy.
Segment 2222: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2007, Text: You wouldn’t count out the little?
Segment 2223: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2008, Text: No.
Segment 2224: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2009, Text: Well, I hope you’re right.
Segment 2225: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2011, Text: Well, let me ask you about this market of politics. So you have served six terms as prime minister over 15 years in power. Let me ask you again, human nature. Do you worry about the corrupting nature of power on you as a leader, on you as a man?
Segment 2226: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2028, Text: Not at all. Because I think that, again, the thing that drives me is nothing but the mission that I took to assure the survival and thriving of the Jewish state. That is, its economic prosperity, but its security and its ability to achieve peace with our neighbors. And I’m committed to it. I think there are many things that have been done. There are a few big things that I can still do, but it doesn’t only depend on my sense of mission. It depends on the market, as we say. It depends really on the will of the Israeli voters. And the Israeli voters have decided to vote for me again and again, even though I wield no power in the press, no power in many quarters here and so on, nothing. I mean, probably, I’m going to be very soon the longest serving prime minister in the last half century in the Western democracies. But that’s not because I amassed great political power in any of the institutions.
Segment 2227: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2096, Text: I remember I had a conversation with Silvio Berlusconi, who recently died, and he said to me about, I don’t know, 15 years ago, something like that, he said, “So Bibi, how many of Israel’s television stations do you have?” And I said, “None.” He said, “You have none?”
Segment 2228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2123, Text: Do you have?
Segment 2229: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2124, Text: “Do you have?” I said, “None. I have two.” He said, “No, no. What, you mean you don’t have any that you control?” I said, “Not only do I have none that I control, they’re all against me.” So he says, “So how do you win elections with both hands tied behind your back?” And I said, “The hard way.” That’s why I have the largest party, but I don’t have many more seats than I would have if I had a sympathetic voice in the media. And Israel until recently, was dominated completely by one side of the political spectrum that often vilified me, not me, because they viewed-
Segment 2230: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2161, Text: … vilified me, not me, because they viewed me as representing basically the conservative voices in Israel that are majority. And so the idea that I’m an omnipotent, authoritarian dictator is ridiculous. I would say I’m not merely a champion of democracy and democratization. I believe ultimately the decision is with the voters and the voters, even though they have constant press attacks, they’ve chosen to put me back in. So I don’t believe in this thing of amassing the corrupting power of if you don’t have elections. If you control the means of influencing the voters, I understand what you’re saying, but in my case, it’s exact opposite. I have to constantly go in elections, constantly with a disadvantage that the major media outlets are very violently sometimes against me, but it’s fine. And I keep on winning. So I don’t know what you’re talking about. I would say the concentration of power lies elsewhere, not here.
Segment 2231: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2235, Text: Well, you have been involved in several corruption cases. How much corruption is there in Israel and how do you fight it in your own party and in Israel?
Segment 2232: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2244, Text: Well, you should ask a different question. What’s happened to these cases? These cases basically are collapsing before our eyes, there was recently an event in which the three judges in my case, called in the prosecution and said, “Your flagship, the so-called bribery charges is gone, doesn’t exist,” before a single defense witness was called. And it sort of tells you that this thing is evaporating. It’s quite astounding even that I have to say, was covered even by the mainstream press in Israel because it’s such an earthquake. So a lot of these charges are not a lot. These charges will prove to be nothing. I always said, “Listen, I stand before the legal process.” I don’t claim that I’m exempt from it in any way. On the contrary, I think the truth will come out and it’s coming out. And we see that not only that, but with other things.
Segment 2233: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2308, Text: So I think it’s kind of instructive that no politician has been more vilified. None has been put to such a, what is it? About a quarter of a billion shekels were used to scrutinize me, scour my bank accounts, sending people to the Philippines, into Mexico, into Europe, into America, and everybody using spyware, the most advanced spyware on the planet against my associates, blackmailing witnesses, telling them, “Think about your family, think about your wife. You better tell us what you want.” All that is coming out of the trial. So I would say that most people now are not asking, are no longer asking, including my opponents. It’s sort of trickling in as the stuff comes out. People are not saying, “What did Netanyahu do, because apparently he did nothing?” “What was done to him?” is something that people ask.
Segment 2234: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2371, Text: “What was done to him? What was done to our democracy, what was done in the attempt to put down somebody who keeps winning elections, despite the handicaps that I described? Maybe we can nail him by framing him.” And the one thing I can say about this court trial is that things are coming up and that’s very good, just objective things are coming out and changing the picture. So I would say the attempt to brand me as corrupt is falling on its face. But the thing that is being uncovered in the trial, such as the use of spyware on a politician, a politician’s surroundings to try to shake them down in investigations, put them in flea-ridden cells for 21 days. Invite their 84 year old mother to investigations without cause, bringing in their mistresses in the corridor, shaking them down, that’s what people are asking. That corruption is what they want corrected.
Segment 2235: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2446, Text: What is the top obstacle to peaceful coexistence of Israelis and Palestinians? Let’s talk about the big question of peace in this part of the world.
Segment 2236: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2455, Text: Well, I think the reason you have the persistence of the Palestinian Israeli conflict, which goes back about a century, is the persistent Palestinian refusal to recognize a Jewish state, a nation state for the Jewish people in any boundary. That’s why they opposed the establishment of the state of Israel before we had a state. Now that’s why they’ve opposed it after we had a state. They opposed it when we didn’t have Judea and Samaria, the West Bank in our hands and Gaza, and they oppose it after we have it. It doesn’t make a difference. It’s basically their persistent refusal to recognize a Jewish state in any boundaries. And I think that their tragedy is that they’ve been commandeered for a century by leadership that refused to compromise with the idea of Zionism, namely that the Jews deserve a state in this part of the world.
Segment 2237: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2509, Text: The territorial dispute is something else. You have a territorial dispute if you say, “Okay, you are living on this side, we’re living on that side. Let’s decide where the border is and so on.” That’s not what the argument is. The Palestinian society, which is itself fragmented, but all the factions agree, there shouldn’t be a Jewish state anywhere. They just disagree between Hamas that says, “Oh, well you should have it. We should get rid of it with terror.” And the others who say, “We know we should also use political means to dissolve it.” So that is the problem.
Segment 2238: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2548, Text: So even as part of a two-state solution, they’re still against the idea.
Segment 2239: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2553, Text: Well, they don’t want a state next to Israel. They want a state instead of Israel. And they say, “If we get a state, we’ll use it as a springboard to destroy the smaller Israeli state.” Which is what happened when Israel unilaterally walked out of Gaza and effectively established a Hamas state there. They didn’t say, “Oh good, now we have our own territory, our own state. Israel is no longer there. Let’s build peace. Let’s build economic projects. Let’s enfranchise our people.” No, they turned it basically into a terror bastion from which they fired 10,000 rockets into Israel. When Israel left Lebanon because we had terrorist attacks from there, then we had Lebanon taken over by Hezbollah, a terrorist organization that seeks to destroy Israel. And therefore every time we just walked out, what we got was not peace, we didn’t give territory for peace, we got territory for terror. That’s what we had.
Segment 2240: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2615, Text: And that’s what would happen as long as the reigning ideology says, “We don’t want Israel in any border.” So the idea of two states assumes that you’d have on the other side a state that wants to live in peace and not one that will be overtaken by Iran in its proxies in two seconds and become a base to destroy Israel. And therefore, I think that most Israelis today, if you ask them, they’d say it’s not going to work in that concept, so what do you do with the Palestinians? They’re still there. And unlike them, I don’t want to throw them out. They’re going to be living here and we’re going to be living here in an area, which is by the way, just to understand the area, the entire area of so-called West Bank and Israel is the width of the Washington Beltway, more or less.
Segment 2241: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2666, Text: Just a little more, not much more. You can’t really divide it up. You can’t say, “Well, you’re going to fly in. Who controls the airspace?” Well, it takes you about two and a half minutes to cross it with a regular 747. With a fighter plane it takes you a minute and a half, okay? So how are you going to divide the airspace? Well, you’re not going to divide it. Israel’s going to control that airspace and the electromagnetic space and so on. So security has to be in the hands of Israel. My view of how you solve this problem is a simple principle. The Palestinians should have all the powers to govern themselves and none of the powers to threaten Israel, which basically means that the responsibility for overall security remains with Israel. And from a practical point of view, we’ve seen that every time that Israel leaves a territory and takes its security forces out of an area, it immediately is overtaken by Hamas or Hezbollah or Jihadist who basically are committed to the destruction of Israel and also bring misery to the Palestinians or Arab subjects.
Segment 2242: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2740, Text: So I think that principle is less than perfect sovereignty because you’re taking a certain amount of sovereign powers, especially security away. But I think it’s the only practical solution. So people say, “Ah, but it’s not a perfect state.” I say, “Okay, call it what you will. Call it, I don’t know, limited sovereignty. Call it the autonomy plus. Call it whatever you want to call it.” But that’s the reality. And right now, if you ask Israelis across the political spectrum, except the very hard left, most Israelis agree with that. They don’t really debate it.
Segment 2243: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2774, Text: So a two-state solution where Israel controls the security of the entire region.
Segment 2244: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2778, Text: We don’t call it quite that. I mean there are different names, but the idea is yes, Israel controls security in the, is the entire area. It’s this tiny area between the Jordan River and the sea. I mean it’s like, you can walk it in not one afternoon. If you’re really fit, you can do it in a day, less than a day. I did.
Segment 2245: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2799, Text: So the expansion of settlements in the West Bank has been a top priority for this new government. So people may harshly criticize this as contributing to escalating the Israel-Palestine tensions. Can you understand that perspective, that this expansion of settlements is not good for this two-state solution?
Segment 2246: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2819, Text: Yeah, I can understand what they’re saying, and they don’t understand why they’re wrong. First, most Israelis who live in Judea, Samaria live in urban blocks, and that accounts for about 90% of the population. And everybody recognizes that those urban blocks are going to be part of Israel in any future arrangement. So they’re really arguing about something that has already been decided and agreed upon, really by Americans, even by Arabs, many Arabs, they don’t think that Israel is going to dismantle these blocks. You look outside the window here, and within about a kilometer or a mile from here, as you have Jerusalem, half of Jerusalem grew naturally beyond the old 1967 border. So you’re not going to dismantle half of Jerusalem. That’s not going to happen. And most people don’t expect that. Then you have the other 10% scattered in tiny, small communities, and people say, “Well, you’re going to have to take them out.” Why?
Segment 2247: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2885, Text: Remember that in pre-1967 Israel, we have over a million and a half Arabs here. We don’t say, “Oh, Israel has to be ethnically cleansed from its Arab citizens in order to have peace.” Of course not. Jews can live among Arabs, and Arabs can live among Jews. And what is being advanced by those people who say that we can’t live in our ancestral homeland in these disputed areas. Nobody says that this is Palestinian areas and nobody says that these are Israeli areas. We claim them, they claim them. We’ve only been attached to this land for oh, 3,500 years. But it’s a dispute, I agree. But I don’t agree that we should throw out the Arabs. And I don’t think that they should throw out the Jews. And if somebody said to you, “The only way we’re going to have peace with Israel is to have an ethnically cleansed Palestinian entity,” that’s outrageous.
Segment 2248: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2940, Text: If you said you shouldn’t have Jews living in, I don’t know, in suburbs of London or New York and so on, I don’t think that will play too well. The world is actually advancing a solution that says that Jews cannot live among Arabs, and Arabs cannot live among Jews. I don’t think that’s the right way to do it. And I think there’s a solution out there, but I don’t think we’re going to get to it, which is less than perfect sovereignty, which involves Israeli security, maintained for the entire territory by Israel, which involves not rooting out anybody. Not kicking out, uprooting Arabs or Palestinians. They’re going to live in enclaves in sovereign Israel and we’re going to live in probably in enclaves there, probably through transportation continuity as opposed to territorial continuity. For example, you can have tunnels and overpasses and so on that connect the various communities.
Segment 2249: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=2997, Text: We’re doing that right now, and it actually works. I think there is a solution to this. It’s not the perfect world that people think of because that model I think doesn’t apply here. If it applies elsewhere, it’s a question. I don’t think so. But I think there’s one other thing, and that’s the main thing that I’ve been involved in. People said, “If you don’t solve the Palestinian problem, you’re not going to get to the Arab world. You’re not going to have peace with the Arab world.” Remember, the Palestinians are about 2% of the Arab world, and the other 98%, you’re not going to make peace with them. And that’s our goal.
Segment 2250: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3039, Text: And for a long time, people accepted that. After the initial peace treaties with Egypt, with Prime Minister Begin of the Likud and President Sadat of Egypt, and then with Jordan between Prime Minister Rabin and King Hussein. For a quarter of a century we didn’t have any more peace treaties because people said, “You got to go through the Palestinians” and the Palestinians, they don’t want a solution of the kind that I described or any kind except the one that involved the dissolution of the state of Israel.
Segment 2251: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3068, Text: So we could wait another half century. And I said, “No, I don’t think that we should accept the premise that we have to wait for the Palestinians because we’ll have to wait forever.” So I decided to do it differently. I decided to go directly to the Arab capitals and to make the historic Abraham Accords and essentially reversing the equation, not a peace process that goes inside out, but outside in. And we went directly to these countries and forged these breakthrough peace accords with the United Arab Emirates, with Bahrain, with Morocco and with Sudan. And we’re now trying to expand that in a quantum leap with Saudi Arabia.
Segment 2252: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3116, Text: What does it take to do that with Saudi Arabia, with the Saudi Crown Prince Mohammed bin Salman.
Segment 2253: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3121, Text: I’m a student of history, and I read a lot of history, and I read that in the Versailles discussions after World War I, President Woodrow Wilson said, “I believe in open covenants openly arrived at.” I have my correction. I believed in open covenants secretly arrived at so we’re not going to advance a Saudi-Israeli peace by having it publicly discussed. And in any case, it’s a decision of the Saudis if they want to do it, but there’s obviously a mutual interest. So here’s my view, if we try to wait for the 2% in order to get to the 98%, we’re going to fail and we have failed. If we go to the 98%, we have a much greater chance of persuading the 2%. You know why? Because the 2% the Palestinian hope to vanquish the state of Israel and not make peace with it, is based, among other things, on the assumption that eventually the 98%, the rest of the Arab world, will kick in and destroy the Jewish state, help them dissolve or destroy the Jewish state.
Segment 2254: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3188, Text: When that hope is taken away, then you begin to have a turn to the realistic solutions of coexistence. By the way, they’ll require compromise on the Israeli side too. And then I’m perfectly cognizant of that and willing to do that. But I think a realistic compromise will be struck much more readily when the conflict between Israel and the Arab states, the Arab world, is effectively solved. And I think we’re on that path. It was a conceptual change just like I’ve been involved in a few, I told you the conceptual battle is always the most difficult one. And I had to fight this battle to convert a semi-socialist state into a free market capitalist state. And I have to say that most people today recognize the power of competition and the benefits of free markets. So we also had to fight this battle-
Segment 2255: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3240, Text: … free markets. So we also had to fight this battle that said you have to go through the Palestinian straight, S-T-R-A-I-T, to get to the other places. There’s no way to avoid this, you have to go through this impassable pass. And I think that now people are recognizing that we’ll go around it and probably circle back. And that, I think, actually gives hope not only to have an Arab-Israeli peace, but circling back in Israeli-Palestinian peace. And obviously this is not something that you find in the soundbites and so on, but in the popular discussion of the press. But that idea is permeating and I think it’s the right idea, because I think it’s the only one that will work.
Segment 2256: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3290, Text: So expanding the circle of peace, just to linger on that requires what? Secretly talking man-to-man, human-to-human, to leaders of other nations and-
Segment 2257: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3303, Text: Theoretically, you’re right.
Segment 2258: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3304, Text: Theoretically. Okay. Well, let me ask you another theoretical question on this circle of peace. As a student of history, looking at the ideas of war and peace, what do you think can achieve peace in the war in Ukraine looking at another part of the world? If you consider the fight for peace in this part of the world, how can you apply that to that other part of the world between Russia and Ukraine now?
Segment 2259: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3338, Text: I think it’s one of the savage horrors of history and one of the great tragedies that is occurring. Let me say in advance that if I have any opportunity to use my contacts to help bring about an end to this tragedy, I’ll do so. I know both leaders, but I don’t just jump in and assume if there’s be a desire at a certain point because the conditions have created the possibility of helping stop this carnage, then I’ll do it. And that’s why I choose my words carefully, because I think that may be the best thing that I could do. Look, I think what you see in Ukraine is what happens if you have territorial designs on a territory by a country that has nuclear weapons. And that, to me, you see the change in the equation. Now, I think that people are loathed to use nuclear weapons, and I’m not sure that I would think that the Russian side would use them with happy abandon.
Segment 2260: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3419, Text: I don’t think that’s the question, but you see how the whole configuration changes when that happens. So you have to be very careful on how you resolve this conflict. So it doesn’t… well, it doesn’t go off the rails, so to speak. That’s, by the way, the corollaries here. We don’t want Iran, which is an aggressive force with just aggressive ideology of dominating first the Muslim world, and then eliminating Israel, and then becoming a global force, having nuclear weapons. It’s totally different when they don’t have it than when they do have it. And that’s why one of my main goals has been to prevent Iran from having the means of mass destruction, which will be used, atomic bombs, which they openly say will be used against us. And you can understand that. How to bring about an end to Ukraine? I have my ideas. I don’t think that’s worthwhile discussing them now because they might be required later on.
Segment 2261: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3486, Text: Do you believe in the power of conversation? Since you have contacts with Volodymyr Zelenskyy and Vladimir Putin, just leaders sitting in a room and discussing how the end of war can be brought about?
Segment 2262: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3499, Text: I think it’s a combination of that, but I think it’s the question of interest and whether you have to get both sides to a point where they think that that conversation would lead to something useful. I don’t think they’re there right now.
Segment 2263: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3517, Text: What part of this is just basic human ego, stubbornness all of this between leaders, which is why I bring up the power of conversation, of sitting in a room realizing we’re human beings, and then there’s a history that connects Ukraine and Russia?
Segment 2264: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3532, Text: I don’t think they’re in a position to enter a room right now, realistically. I mean, you can posit that it would be good if that could happen, but entering the room is sometimes more complicated than what happens in the room. And there’s a lot of pre-negotiations on the negotiation, then you negotiate endlessly on the negotiation. They’re not even there.
Segment 2265: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3551, Text: It took a lot of work for you to get to a handshake in the past.
Segment 2266: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3555, Text: It’s an interesting question. How did the peace, the Abraham Accords, how did that begin? We had decades. We had 70 years or 65 years where these people would not meet openly or even secretly with an Israeli leader. Yeah, we had the Mossad making contacts with him all the time, and so on, but how do we break the ice to the top level of leadership? Well, we broke the ice because I took a very strong stance against Iran, and the Gulf states understood that Iran is a formidable danger to them, so we had a common interest. And the second thing is that because of the economic reforms that we had produced in Israel, Israel became a technological powerhouse. And that could help their nations, not only… in terms of anything, of just bettering the life of their peoples.
Segment 2267: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3612, Text: And the combination of the desire to have some kind of protection against Iran or some kind of cooperation against Iran and civilian economic cooperation came to a head when I gave a speech in the American Congress, which I didn’t do lightheartedly, I had to decide to challenge a sitting American president and on the so-called Iranian deal, which I thought would pave Iran’s path with gold to be an effective nuclear power. That’s what would happen. So I went there. And in the course of giving that speech before the joint session of Congress, our delegation received calls from Gulf states who said, “We can’t believe what your prime minister is doing. He’s challenging the President of the United States.” Well, I had no choice because I thought my country’s own existence was imperiled. And remember, we always understand through changing administrations that America under… no matter what leadership is always the irreplaceable and indispensable ally of Israel and will always remain that we can have arguments as we have, but in the family, as we say in [foreign language 01:01:32], it’s the family.
Segment 2268: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3695, Text: But nevertheless, I was forced to take a stand. That produced calls from Gulf states that ultimately led to clandestine meetings that ultimately flowered into the Abraham Accords then. And I think we’re at a point where the idea of ending the Arab-Israeli conflict, not the Palestinian-Israeli conflict, the Arab-Israeli conflict can happen. I’m not sure it will. It depends on quite a few things, but it could happen. And if it happens, it might open up the ending of the Israeli-Islamic conflict. Remember, the Arab world is a small part, it’s an important part, but it’s small. There are large Islamic populations and it could bring about an end to an historic enmity between Islam and Judaism. It could be a great thing.
Segment 2269: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3751, Text: So I’m looking at this larger thing. You can be hobbled by saying, “Oh, well, you’ve had this hiccup in Gaza or this or that thing happening in the Palestinians.” It’s important for us because we want security. But I think the larger question is can we break out into a much wider peace and ultimately come back and make the peace between Israel and the Palestinians rather than waiting to solve that and never getting to paint on the larger canvas? I want to paint on the larger canvas and come back to the Palestinian-Israeli conflict.
Segment 2270: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3796, Text: As you write about in your book, what have you learned about life from your father?
Segment 2271: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3801, Text: My father was a great historian and well, he taught me several things. He said that the first condition for a living organism is to identify danger in time, because if you don’t, you could be devoured. You could be destroyed very quickly. And that’s the nature of human conflict. In fact, for the Jewish people, we lost the capacity to identify danger in time, and we were almost devoured and destroyed by the Nazi threat. So when I see somebody parroting the Nazi goal of destroying the Jewish state, I try to mobilize the country and the world in time because I think Iran is a global threat, not only a threat to Israel. That’s the first thing.
Segment 2272: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3857, Text: The second thing is I once asked him, before I got elected, I said, “Well, what do you think is the most important quality for a prime minister of Israel?” And he came back with a question, “What do you think?” And I said, “Well, you have to have vision and you have to have the flexibility of navigating and working towards that vision. Be flexible, but understand where you’re heading.” And he said, “Well, you need that for anything. You need it if you’re a university president or if you’re a leader of a corporation or anything, anybody would’ve to have that.” I said, “All right, so what do you need to be the leader of Israel?” He came back to me with a word that stunned me. He said, “Education. You need a broad and deep education, or you’ll be at the mercy of your clerks or the press or whatever. You have to be able to do that.” Now, as I spend time in government, being reelected by the people of Israel, I recognize more and more how right he was.
Segment 2273: Speaker: , Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3937, Text: You need to constantly ask yourself, “Where’s the direction we want to take the country? How do we achieve that goal?” But also understand that new disciplines are being added. You have to learn all the time. You have to add to your intellectual capital all the time. Kissinger said that he wrote that once you enter public life, you begin to draw on your intellectual capital and it’ll be depleted very quickly if you stay a long time. I disagree with that. I think you have to constantly increase your understanding of things as they change, because my father was right. You need to broaden and deepen your education as you go along. You can’t just sit back and say, “Well, I studied some things in university, or in college, or in Boston, or at MIT, and that’s enough. I’ve done it.” No, learn, learn, learn, learn. Never stop.
Segment 2274: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=3994, Text: And if I may suggest as part of the education, I would add in a little literature, maybe Dostoevsky, in the plentiful of time you have as a prime minister to read.
Segment 2275: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4004, Text: Well, I read him, but I’ll tell you what I think is bigger than Dostoevsky.
Segment 2276: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4007, Text: Oh, no. Who’s that?
Segment 2277: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4009, Text: Not who’s that, but what’s that? Dan Rather came to see me with his grandson a few years ago. And the grandson asked me, he was a student in Ivy League college. He’s 18 years old and he wants to study to enter politics. And he said, “What’s the most important thing that I have to study to enter a political life?” And I said, “You have three things you have to study. Okay? History, history and history.” That’s the fundamental discipline for political life. But then you have to study other things, study economics, study politics and so on, and study the military if you have… I had an advantage because I spent some years there, so I learned a lot of that, but I had to acquire the other disciplines. And you never acquire enough. So read, read, read. And by the way, if I have to choose, I read history, history and history. Good works of history, not lousy books.
Segment 2278: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4082, Text: Last question. You’ve talked about a survival of a nation. You, yourself, are a mortal being. Do you contemplate your mortality? Do you contemplate your death? Are you afraid of death?
Segment 2279: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4095, Text: Aren’t you?
Segment 2280: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4096, Text: Yes.
Segment 2281: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4096, Text: Who is not? I mean, if you’re a conscience, if you’re a being with conscience, I mean, one of the unhappy things about the human brain is that it can contemplate its own demise. And so, we all make our compromises with this, but I think the question is what lives on? What lives on beyond us? And I think that you have to define how much of posterity do you want to influence. I cannot influence the course of humanity. We all are specs, little specs. So that’s not the issue. But in my case, I’ve devoted my life to a very defined purpose. And that is to assure the future and security, and I would say permanence, but that is obviously a limited thing, of the Jewish state and the Jewish people. I don’t think one can exist without the other. So I’ve devoted my life to that. And I hope that in my time on this Earth and in my years in office, I’d have contributed to that.
Segment 2282: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4169, Text: Well, you had one heck of a life, starting from MIT to six terms as prime minister. Thank you for this stroll through human history and for this conversation. It was an honor.
Segment 2283: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4184, Text: Thank you. And I hope you come back to Israel many times. Remember it’s the innovation nation. It’s a robust democracy. Don’t believe all the stuff that you are being told. It’ll remain that. It cannot be any other way. I’ll tell you the other thing, it’s the best ally of the United States, and its importance is growing by the day because our capacities in the information world are growing by the day. We need a coalition of the like-minded smarts. This is a smart nation. And we share the basic values of freedom and liberty with the United States. So the coalition of the smarts means Israel is the sixth eye and America has no better ally.
Segment 2284: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4233, Text: All right. Now off mic, I’m going to force you to finally tell me who is going to win. Elon Musk or Mark Zuckerberg? But it’s a good time that we ran out of time here.
Segment 2285: Speaker: Benjamin Netanyahu, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4241, Text: I’ll tell you outside.
Segment 2286: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=XpC7SVDXimg&t=4244, Text: Thanks for listening to this conversation with Benjamin Netanyahu. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Mahatma Gandhi, “An eye for an eye will only make the whole world blind.” Thank you for listening and I hope to see you next time.
Segment 2287: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=0, Text: It’s not our business to change the Russian government. And anybody who thinks it’s a good idea to do regime change in Russia, which has more nuclear weapons than we do, is I think irresponsible. And Vladimir Putin himself has had… We will not live in a world without Russia and it was clear when he said that, that he was talking about himself and he has his hand on a button that could bring Armageddon to the entire planet. So why are we messing with this? It’s not our job to change that regime, and we should be making friends with the Russians. We shouldn’t be treating him as an enemy. Now we’ve pushed him into the camp with China. That’s not a good thing for our country. And by the way, what we’re doing now does not appear to be weakening Putin at all.
Segment 2288: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=56, Text: The following is a conversation with Robert F. Kennedy Jr, candidate for the President of the United States, running as a Democrat. Robert is an activist, lawyer and author who has challenged some of the world’s most powerful corporations seeking to hold them accountable for the harm they may cause. I love science and engineering. These two pursuits are, to me the most beautiful and powerful in the history of human civilization. Science is our journey, our fight for uncovering the laws of nature and leveraging them to understand the universe and to lessen the amount of suffering in the world. Some of the greatest human beings I’ve ever met, including most of my good friends, are scientists and engineers. Again, I love science, but science cannot flourish without epistemic humility, without debate, both in the pages of academic journals and in the public square, in good faith, long form conversations.
Segment 2289: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=116, Text: Agree or disagree, I believe Robert’s voice should be part of the debate. To call him a conspiracy theorist and arrogantly dismiss everything he says without addressing it diminishes the public’s trust in the scientific process. At the same time, dogmatic skepticism of all scientific output on controversial topics like the pandemic is equally, if not more dishonest and destructive. I recommend that people read and listen to Robert F. Kennedy Jr, his arguments and his ideas. But I also recommend, as I say in this conversation, that people read and listen to Vincent Racaniello from This Week in Virology, Dan Wilson from Debunk The Funk, and the Twitter and books of Paul Offit, Eric Topol, and others who are outspoken in their disagreement with Robert.
Segment 2290: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=170, Text: It is disagreement, not conformity that bends the long arc of humanity toward truth and wisdom. In this process of disagreement, everybody has a lesson to teach you, but we must have the humility to hear it and to learn from it. This is The Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Robert F. Kennedy Jr.
Segment 2291: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=198, Text: It’s the 4th of July, Independence Day. So simple question, simple, big question. What do you love about this country, the United States of America?
Segment 2292: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=207, Text: I would say there’s so many things that I love about the country, the landscapes and the waterways and the people, et cetera. But on the higher level, people argue about whether we’re an exemplary nation, and that term has been given a bad name, particularly by the neocons, the actions, the neocons in recent decades who have turned that phrase into a justification for forcing people to adopt American systems or values at the barrel of a gun. But my father and uncle used it in a very different way, and they were very proud of it. I grew up very proud of this country because we were the exemplary nation in the sense that we were an example of democracy all over the world. When we first launched our democracy in 1780, we were the only democracy on earth. And there was Civil war, by 1865, there were six democracies.
Segment 2293: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=275, Text: Today there’s probably 190, and all of them in one way or another are modeled on the American experience. And it’s extraordinary because our first serious and sustained contact with the European culture and continent was in 1608 when John Winthrop came over with his Puritans in the sloop Arbella and Winthrop gave this famous speech where he said, “This is going to be a city on a hill. This is going to be an example for all the other nations in the world.” And he warned his fellow Puritans. They were sitting at this great expanse of land and he said, “We can’t be seduced by the lure of real estate or by the carnal opportunities of this land. We have to take this country as a gift from God and then turn it into an example for the rest of the world of God’s love, of God’s will and wisdom.” And 200 years later, 250 years later, a different generation, they’re mainly [inaudible 00:05:59], are people who had a belief in God, but not so much a love of particularly religious cosmologies.
Segment 2294: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=373, Text: The Framers of the Constitution believe that we were creating something that would be replicated around the world, and that it was an example in democracy. There would be this kind of wisdom from the collective that… And the word wisdom means a knowledge of God’s will, and that somehow God would speak through the collective in a way that he or she could not speak through totalitarian regimes. And I think that that’s something that even though Winthrop was a white man and a Protestant, that every immigrant group who came after them adopted that belief. And I know my family, when my family came over, all of my grandparents came over in 1848 during the potato famine, and they saw this country as unique in history is something that was part of a broader spiritual mission. And so I’d say that from a 30,000-foot level, I grew up so proud of this country and believing that it was the greatest country in the world, and for those reasons.
Segment 2295: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=454, Text: Well, I immigrated to this country. And one of the things that really embodies America to me is the ideal of freedom. Hunter S. Thompson said, “Freedom is something that dies unless it’s used.” What does freedom mean to you?
Segment 2296: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=467, Text: To me, freedom does not mean chaos, and it does not mean anarchy. It means that it has to be accompanied by restraint if it’s going to live up to its promise in self-restraint. What it means is the capacity for human beings to exercise and to fulfill their creative energies unrestrained as much as possible by government.
Segment 2297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=500, Text: So this point that Hunter S. Thompson has made is, “Dies unless it’s used.” Do you agree with that?
Segment 2298: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=508, Text: Yeah, I do agree with that, and he was not unique in saying that. Thomas Jefferson said that the Tree of Liberty had to be watered with the blood of each generation. And what he meant by that is that we can’t live off the laurels of the American Revolution. That we had a group, we had a generation where between 25,000 and 70,000 Americans died. They gave their lives, they gave their livelihoods, they gave their status, they gave their property, and they put it all on the line to give us our Bill of Rights and that, but those Bill of Rights, the moment that we signed them, there were forces within our society that began trying to chip away at them, and that happens in every generation. And it is the obligation of every generation to safeguard and protect those freedoms.
Segment 2299: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=566, Text: The blood of each generation. You mentioned your interest, your admiration of Al Albert Camus, of Stoicism, perhaps your interest in existentialism. Camus said, I believe in Myth of Sisyphus, “The only way to deal with an unfree world is to become so absolutely free that your very existence is an act of rebellion.” What do you think he means by that?
Segment 2300: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=589, Text: I suppose the way that Camus viewed the world and the way that the Stoics did and a lot of the existentialists, it was that it was so absurd and that the problems and the tasks that were given just to live a life are so insurmountable that the only way that we can get back the gods for giving us this impossible task of living life was to embrace it and to enjoy it and to do our best at it. To me, I read Camus, and particularly in The Myth of Sisyphus as a parable that… And it’s the same lesson that I think he writes about in The Plague, where we’re all given these insurmountable tasks in our lives, but that by doing our duty, by being of service to others, we can bring meaning to a meaningless chaos and we can bring order to the universe.
Segment 2301: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=661, Text: And Sisyphus was the iconic hero of the Stoics, and he was a man because he did something good. He delivered a gift to humanity. He angered the gods and they condemned him to push a rock up the hill every day, and then it would roll down. When he got to the top, it would roll down and he’d spend the night going back down the hill to collect it and then rolling it back up the hill again. And the task was absurd, it was insurmountable. He could never win, but the last line of that book is one of the great lines, which is something to the extent that I can picture as of his smiling, because Camus’ belief was that even though his task was insurmountable, that he was a happy man and he was a happy man because he put his shoulder to the stone.
Segment 2302: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=719, Text: He took his duty, he embraced the task and the absurdity of life, and he pushed the stone up the hill. And that if we do that, and if we find ways of being service to others, that is the ultimate, that’s the key to the lock, that’s the solution to the puzzle.
Segment 2303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=741, Text: Each individual person in that way can rebel against absurdity by discovering meaning to this whole messy thing.
Segment 2304: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=748, Text: And we can bring meaning not only to our own lives, but we can bring meaning to the universe as well. We can bring some kind of order to life and the embrace of those tasks and the commitment to service resonates out from us to the rest of humanity in some way.
Segment 2305: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=771, Text: So you mentioned The Plague by Camus. There’s a lot of different ways to read that book, but one of them, especially given how it was written, is that The Plague symbolizes Nazi Germany and the Hitler regime. What do you learn about human nature from a figure like Adolf Hitler, that he’s able to captivate the minds of millions, rise to power and take on, pull in the whole world into a global war?
Segment 2306: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=804, Text: I was born nine years after the end of World War II, and I grew up in a generation with my parents who were fixated on that, on what happened, and my father. At that time, the resolution in the minds of most Americans, and I think people around the world, is that there had been something wrong with the German people, that the Germans had been particularly susceptible to this kind of demagoguery and to following a powerful leader and just industrializing cruelty and murder. And my father always differed with that. My father said, “This is not a German problem. This could happen to all of us. We’re all just inches away from barbarity.” And the thing that keeps us safe in this country are the institutions of our democracy, our constitution. It’s not our nature. Our nature has to be restrained, and that comes through self-restraint.
Segment 2307: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=878, Text: But also, the beauty of our country is that we devise these institutions that are designed to allow us to flourish, but at the same time, not to give us enough freedom to flourish, but also create enough order to keep us from collapsing into barbarity. So one of the other things that my father talked about from when I was little, he would ask us this question, “If you were the family and Anne Frank came to your door and asked you to hide her, would you be one of the people who hid her, risk your own life, or would you be one of the people who turned her in?”
Segment 2308: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=924, Text: And of course, we would all say, “Well, of course we would hide Anne Frank and take the risk,” but that’s been something kind of a lesson, a challenge that has always been near the forefront of my mind, that if a totalitarian system ever a occurs in the United States, which my father thought was quite possible, he was conscious about how fragile democracy actually is, that would I be one of the ones who would resist the totalitarianism or would I be one of the people who went along with it? Would I be one of the people who was at the train station in crack hour, or even Berlin and saw people being shipped off to camps and just put my head down and pretend I didn’t say it because talking about it would be destructive to my career and maybe my freedom and even my life? So that has been a challenge that my father gave to me and all of my brothers and sisters, and it’s something that I’ve never forgotten.
Segment 2309: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=999, Text: A lot of us would like to believe we would resist in that situation, but the reality is most of us wouldn’t, and that’s a good thing to think about, that human nature is such that we’re selfish even when there’s an atrocity going on all around us.
Segment 2310: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1017, Text: And we also have the capacity to deceive ourselves, and all of us tend to judge ourselves by our intentions and our actions.
Segment 2311: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1028, Text: What have you learned about life from your father, Robert F. Kennedy?
Segment 2312: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1032, Text: First of all, I’ll say this about my uncle because I’m going to apply that question to my uncle and my father. My uncle was asked when he first met Jackie Bouvier, who later became Jackie Kennedy. She was a reporter for a newspaper and she had a column where she’d do these pithy interviews with both famous people and man in the street interviews. And she was interviewing him and she asked him what he believed his best quality was, his strongest virtue? And she thought that he would say courage because he had been a war hero. He was the only president who… And this is when he was Senator, by the way, who received the Purple Heart. And he had a very famous story of him as a hero in World War II. And then he had come home and he had written a book on moral courage among American politicians and won the Pulitzer Prize, that book Profiles and Courage, which was a series of incidents where American political leaders made decisions to embrace principle even though their careers were at stake, and in most cases were destroyed by their choice.
Segment 2313: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1117, Text: She thought he was going to say courage, but he didn’t. He said curiosity, and I think looking back at his life that the best, it was true, and that was the quality that allowed him to put himself in the shoes of his adversaries. And he always said that if the only way that we’re going to have peace is if we’re able to put ourselves in the shoes of our adversaries, understand their behavior and their contact, not context. And that’s why he was able to resist the intelligence apparatus and the military during the Bay of Pigs when they said, “You’ve got to send in the Essex, the aircraft carrier.” And he said, “No.” Even though he’d only been two months in office, he was able to stand up to them because he was able to put himself in the shoes of both Castro and Khrushchev and understand there’s got to be another solution to this.
Segment 2314: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1180, Text: And then during the Cuban Missile Crisis, he was able to endure it when the narrative was okay, Khrushchev acted in a way as an aggressor to put missiles in our hemisphere. How dare he do that? And Jack and my father were able to say, “Well, wait a minute. He’s doing that because we put missiles in Turkey and Italy, and the Turkish ones right on the Russian border.” And they then made a secret deal with Do Brennan, with Ambassador Do Brennan and with Khrushchev to remove the missiles in Turkey if he moved the Jupiter missiles from Turkey, so long as Khrushchev removed them from Cuba. There were 13 men on what they called the [inaudible 00:20:36] Committee, which was the group of people who were deciding what the action was, what they were going to do to end the Cuban Missile Crisis.
Segment 2315: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1245, Text: And virtually, and of those men, 11 of them wanted to invade and wanted to bomb and invade, and it was Jack. And then later on, my father and Bob McNamara, who were the only people who were with him, because he was able to see the world from Khrushchev’s point of view of view, he believed that there was another solution. And then he also had the moral courage. So my father, to get back to your question, famously said that, “Moral courage is the most important quality and it’s more rare,” and courage on the football field or courage in battle than physical courage. It’s much more difficult to come by, but it’s the most important quality in a human being.
Segment 2316: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1293, Text: And you think that kind of empathy that you referred to, that requires moral courage?
Segment 2317: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1297, Text: It certainly requires moral courage to act on it, and particularly in any time that a nation is at war, there’s a momentum or an inertia that says, “Okay, let’s not look at this from the other person’s point of view.” And that’s the time we really need to do that.
Segment 2318: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1323, Text: Well, if we’re can apply that style of empathy, style of curiosity to the current war in Ukraine, what is your understanding of why Russia invaded Ukraine in February 2022?
Segment 2319: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1336, Text: Vladimir Putin could have avoided the war in the Ukraine. His invasion was illegal. It was unnecessary, and it was brutal, but I think it’s important for us to move beyond these kind of comic book depictions of this insane, avaricious Russian leader who wants to restore the Soviet Empire, and who made unprovoked invasion of the Ukraine. He was provoked and we were provoking him and we were provoking him since 1997. And it’s not just me that’s saying that. And before Putin never came in, we were provoking Russia, the Russians in this way unnecessarily. And to go back that time in 1992 when the Russians moved out of… When the Soviet Union was collapsing, the Russians moved out of East Germany and they did that, which was a huge concession to them.
Segment 2320: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1407, Text: They had 400,000 troops in East Germany at that time, and they were facing NATO troops on the other side of the wall. Gorbachev made this huge concession where he said to George Bush, “I’m going to move all of our troops out, and you can then reunify Germany under NATO,” which was a hostile army to the Soviet… It was created with hostile intent toward the Soviet Union. And he said, “You can take Germany, but I want your promise that you will not move NATO to the east.” And James Baker, who was his Secretary of State famously said, “I will not move NATO. We will not move NATO one inch to the east.”
Segment 2321: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1447, Text: So then five years later in 1997, Zbigniew Brzezinski, who was the “father of the neocons,” who was a Democrat at that time, served in the Carter administration, he published a paper, a blueprint for moving NATO right up to the Russian border, a 1,000 miles to the east and taking over 14 nations. And at that time, George Kennan, who was the deity of American diplomats, he was arguably the most important diplomat in American history. He was the architect of the containment policy during World War II. And he said, “This is insane and it’s unnecessary. And if you do this, it’s going to provoke the Russians to a violent response. And we should be making friends with the Russians. They lost the Cold War. We should be treating them the way that we treated our adversaries after World War II, with a Marshall Plan to try to help them incorporate into Europe and to be part of the brotherhood of man and of western nations. We shouldn’t continue to be treating them as an enemy and particularly surrounding them at their borders.”
Segment 2322: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1526, Text: William Perry, who was then the Secretary of Defense under Bill Clinton, threatened to resign. He was so upset by this plan to move NATO to the east. And William Burns, who was then the US Ambassador to the Soviet Union, who is now at this moment, the Head of the CIA, said at the time, the same thing. “If you do this, it is going to provoke the Russians toward a military response.” And we moved all around Russia. We moved to 14 nations, a 1,000 miles to the east, and we put ageist missile systems in two nations, in Romania and Poland. So we did what the Russians had done to us in 1962 that would’ve provoked an invasion of Cuba. We put those missile systems back there, and then we’d walk away, unilaterally, walk away from the two nuclear missile treaties, the intermediate nuclear missile treaties that we had with the Soviet, with Russia, and neither of us would put those missile systems on the borders.
Segment 2323: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1591, Text: We walk away from that and we put ageist missile systems, which are nuclear capable. They can carry the Tomahawk missiles, which have nuclear warheads. So the last country that they didn’t take was the Ukraine. And the Russians said, and in fact, Bill Perry said this, or William Burns said it, now the Head of the CIA, “It is a red line. If we bring NATO into Ukraine, that is a red line for the Russians. They cannot live with it. They cannot live with it. Russia has been invaded three times through the Ukraine. The last time it was invaded, we killed, or the Germans killed one out of every seven Russians.”
Segment 2324: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1631, Text: My uncle described what happened to Russia in his famous American university speech in 1963, 60 years ago this month, or or last month, 60 years ago in June, June 10th, 1963. That speech was telling the American people, “Put yourself in the shoes of the Russians. We need to do that if we’re going to make peace.” And he said, “All of us have been taught that we won the war, but we didn’t win the war. If anybody won the war against Hitler, it was the Russians. Their country was destroyed, all of their cities.” And he said, “Imagine if all of the cities from the East Coast to Chicago were reduced to rubble and all of the fields burns, all of the forests burns. That’s what happened to Russia. That’s what they gave so that we could get rid of Adolf Hitler.”
Segment 2325: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1688, Text: And he had them put themselves in their position, and today there’s none of that happening. We have refused repeatedly to talk to the Russians. We’ve broken up, there’s two treaties, the Minsk Agreements, which the Russians were willing to sign, and they said, “We will stay out.” The Russians didn’t want the Ukraine. They showed that when the Donbas region voted 90 to 10 to leave and go to Russia. Putin said, “No, we want Ukraine to stay intact, but we want you to sign Minsk Accords.” The Russians were very worried because of the US involvement and the coup in Ukraine in 2014, and then the oppression and the killing of 14,000 ethnic Russians, and Russia hasn’t had the same way that if Mexico would ageist missile systems from China or Russia on our border and then killed 14,000 expats American, we would go in there.
Segment 2326: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1753, Text: Oh, he does have a national security interest in the Ukraine. He has an interest in protecting the Russian-speaking people of the Ukraine, the ethnic Russians, and the Minsk Accords did that. It left Ukraine as part of Russia. It left them as a semi-autonomous region that continued to use their own language, which is essentially banned by the coup, by the government we put in 2014, and we sabotaged that agreement. And we now know in April of 2022, Zelenskyy and Putin had inked a deal already to another peace agreement, and that the United States and Boris Johnson, the neocons in the White House and Boris Johnson over to the Ukraine to sabotage that agreement.
Segment 2327: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1803, Text: … Boris Johnson over to the Ukraine to sabotage that agreement. What do I think? I think this is a proxy war. I think this is a war that the neocons and the White House wanted. They’ve said for two decades they wanted this war and that they wanted to use Ukraine as a pawn in a proxy war between United States and Russia, the same as we used Afghanistan.
Segment 2328: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1826, Text: And in fact, they say it, “This is the model. Let’s use the Afghanistan model.” That was said again and again. And to get the Russians to overextend their troops and then fight them using local fighters and US weapons.
Segment 2329: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1840, Text: And when President Biden was asked, “Why are we in the Ukraine?” He was honest. He says, “To depose Vladimir Putin. Regime change for Vladimir Putin.” And when his defense secretary Lloyd Austin in April 2022 was asked, “Why are we there?” He said, “To degrade the Russians’ capacity to fight anywhere… To exhaust the Russian army and degrade its capacity to fight elsewhere in the world.”
Segment 2330: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1865, Text: That’s not a humanitarian mission. That’s not what we were told. We were told this was an unprovoked invasion and that we’re there to bring humanitarian relief to the Ukrainians. But that is the opposite. That is a war of attrition that is designed to chew up and turn this little nation into an abattoir of death for the flower of Ukrainian youth in order to advance a geopolitical ambition of certain people within the White House. And I think that’s wrong.
Segment 2331: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1899, Text: We should be talking to the Russians the way that Nixon talked to Brezhnev, the way that Bush talked to Gorbachev, the way that my uncle talked to Khrushchev. We need to be talking with the Russians, we should, and negotiating. And we need to be looking about how do we end this and preserve peace in Europe.
Segment 2332: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1918, Text: Would you as president sit down and have a conversation with Vladimir Putin and Volodymyr Zelenskyy separately and together to negotiate peace?
Segment 2333: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1927, Text: Absolutely. Absolutely.
Segment 2334: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1929, Text: What about Vladimir Putin? He’s been in power since 2000. So as the old adage goes, “Power corrupts, and absolute power corrupts absolutely.” Do you think he has been corrupted by being in power for so long, if you think of the man, if you look at his mind?
Segment 2335: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1947, Text: Listen, I don’t know exactly. I can’t say because I don’t know enough about him or about… The evidence that I’ve seen is that he is homicidal. He kills his enemies or poisons them. And the reaction I’ve seen to that, to hit those accusations from him have not been to deny that but to kind of laugh it off.
Segment 2336: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=1978, Text: Oh, I think he’s a dangerous man and that, of course, there’s probably corruption in his regime. But having said that, it’s not our business to change the Russian government. And anybody who thinks it’s a good idea to do a regime change in Russia, which has more nuclear weapons than we do, is I think irresponsible.
Segment 2337: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2002, Text: And Vladimir Putin himself has said, “We will not live in a world without Russia.” And it was clear when he said that he was talking about himself. And he has his hand on a button that could bring Armageddon to the entire planet.
Segment 2338: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2020, Text: So why are we messing with this? It’s not our job to change that regime. We should be making friends with the Russians. We shouldn’t be treating him as an enemy. Now we’ve pushed him into the camp with China. That’s not a good thing for our country.
Segment 2339: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2035, Text: And by the way, what we’re doing now does not appear to be weakening Putin at all. Putin now, if you believe the polls that are coming out of Russia, they show him… the most recent polls that I’ve seen show him with an 89% popularity that people in Russia support the war in Ukraine, and they support him as an individual.
Segment 2340: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2065, Text: And I understand there’s problems with polling and you don’t know what to believe, but the polls consistently show that. And it’s not America’s business to be the policemen of the world and to be changing regimes in the world. That’s illegal.
Segment 2341: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2081, Text: We shouldn’t be breaking international laws. We should actually be looking for ways to improve relationships with Russia, not to destroy Russia, not to destroy, and not to choose its leadership for them. That’s up to the Russian people, not us.
Segment 2342: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2100, Text: Step one is to sit down and empathize with the leaders of both nations to understand their history, their concerns, their hopes, just to open the door for conversation so they’re not back to the corner.
Segment 2343: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2112, Text: Yeah. And I think the US can play a really important role, and a US president can play a really important role by reassuring the Russians that we’re not going to consider them an enemy anymore, that we want to be friends.
Segment 2344: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2126, Text: And it doesn’t mean that you have to let down your guard completely. The way that you do it, which was the way President Kennedy did it, is you do it one step at a time. You take baby steps. We do a unilateral move, reduce our hostility and aggression, and see if the Russians reciprocate. And that’s the way that we should be doing it.
Segment 2345: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2150, Text: And we should be easing our way into a positive relationship with Russia. We have a lot in common with Russia, and we should be friends with Russia and with the Russian people. Apparently, there’s been 350,000 Ukrainians who have died, at least, in this war. And there’s probably been 60,000 or 80,000 Russians. And that should not give us any joy. It should not give us any…
Segment 2346: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2181, Text: I saw Lindsey Graham on TV saying something to the extent of, “Anything we can do to kill Russians is a good use of our money.” It is not. Those are somebody’s children. We should have compassion for them. This war is an unnecessary war. We should settle it through negotiation, through diplomacy, through state graft, and not through weapons.
Segment 2347: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2210, Text: Do you think this war can come to an end purely through military operations?
Segment 2348: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2215, Text: No. I mean, I don’t think there’s any way in the world that the Ukrainians can beat the Russians. I don’t think there’s any appetite in Europe… I think Europe is now having severe problems. In Germany, Italy, France, you’re seeing these riots. There’s internal problems in those countries.
Segment 2349: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2232, Text: There is no appetite in Europe for sending men to die in Ukraine. And the Ukrainians do not have anybody left. The Ukrainians are using press gangs to fill the ranks of their armies. Military-age men are trying as hard as they can to get out of the Ukraine right now to avoid going to the front.
Segment 2350: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2255, Text: The Russians apparently have been killing Ukrainians in a 7:1 ratio. My son fought over there, and he told me… He had firefights with the Russians mainly at night, but he said most of the battles were artillery wars during the day. And the Russians now outgun the NATO forces 10:1 in artillery. They’re killing at a horrendous rate.
Segment 2351: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2286, Text: Now, my interpretation of what’s happened so far is that Putin actually went in early on with a small force because he expected to meet somebody on the other end of a negotiating table once he went in. And when that didn’t happen, they did not have a large enough force to be able to mount an offensive.
Segment 2352: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2312, Text: And so they’ve been building up that force up till now, and they now have that force. And even against the small original force, the Ukrainians have been helpless. All of their offenses have died. They’ve now killed the head of the Ukrainian special forces, which was probably, arguably, by many accounts, the best elite military unit in all of Europe.
Segment 2353: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2341, Text: The commandant, the commander of that special forces group gave a speech about four months ago saying that 86% of his men are dead or wounded and cannot return to the front. He cannot rebuild that force. And the troops that are now filling the gaps of all those 350,000 men who’ve been lost are scantily trained, and they’re arriving green at the front.
Segment 2354: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2376, Text: Many of them do not want to be there. Many of them are giving up and going over to the Russian side. We’ve seen this again and again and again, including platoon-sized groups that are defecting to the Russians.
Segment 2355: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2388, Text: And I don’t think it’s possible to win. Of course, I’ve studied World War II history exhaustively, but I saw… There’s a new… I think it’s a Netflix series of documentaries that I highly recommend to people there. They’re colorized versions of the black-and-white films from the battles of World War II, but it’s all the battles of World War II.
Segment 2356: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2415, Text: So I watched Stalingrad the other night. And the willingness of the Russians to fight on against any kind of odds and to make huge sacrifices of Russians, the Russians themselves who are making the sacrifice with their lives, the willingness of them to do that for their motherland is almost inexhaustible.
Segment 2357: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2440, Text: It is incomprehensible to think that Ukraine can beat Russia in a war. It would be like Mexico beating the United States. It’s impossible to think that it can happen. And Russia has deployed a tiny, tiny fraction of its military so far. And now it has China with its mass production capacity supporting its war effort. It’s a hopeless situation.
Segment 2358: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2471, Text: And we’ve been lied to. The press in our country and our government are just promoting this lie that the Ukrainians are about to win and that everything’s going great and that Putin’s on the run. And there’s all this wishful thinking because of the Wagner Group-
Segment 2359: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2490, Text: Prigozhin.
Segment 2360: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2490, Text: … Prigozhin and the Wagner Group, that this was an internal coup, and it showed dissent and weakness of Putin. And none of that is true. That insurgency, which wasn’t even an insurgency…
Segment 2361: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2504, Text: He only got 4,000 of his men to follow him out of 20,000. And they were quickly stopped. And nobody in the Russian military, the oligarchy, the political system, nobody supported it. But we’re being told, “Oh yeah, it’s the beginning of the end for Putin. He’s weakened. He’s wounded. He’s on his way out.” And all of these things are just lies that we are being fed.
Segment 2362: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2527, Text: To push back on a small aspect of this that you kind of implied, so I’ve traveled to Ukraine, and one thing that I should say, similar to the Battle of Stalingrad, it is not only the Russians that fight to the end. I think Ukrainians are very lucky to fight to the end.
Segment 2363: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2544, Text: And the morale there is quite high. I’ve talked to nobody… This was a year ago in August with Kherson. Everybody was proud to fight and die for their country. And there’s some aspect where this war unified the people, gave them a reason and an understanding that this is what it means to be Ukrainian and, “I will fight to the death to defend this land.”
Segment 2364: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2568, Text: I would agree with that, and I should have said that myself at the beginning. That’s one of the reasons my son went over there to fight because he was inspired by the valor of the Ukrainian people and this extraordinary willingness of them.
Segment 2365: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2582, Text: And I think Putin thought it would be much easier to sweep into Ukraine, and he found a stone wall of Ukrainians ready to put their lives and their bodies on the line. But that, to me, makes the whole episode even more tragic, is that I don’t believe… I think that the US’s role in this has been… There were many opportunities to settle this war, and the Ukrainians wanted to settle it.
Segment 2366: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2614, Text: Volodymyr Zelenskyy, when he ran in 2019, here’s a guy who’s a comedian, he’s an actor. He had no political experience, and yet he won this election with 70% of the vote. Why? He won on a peace platform, and he won promising to sign the Minsk accords. And yet something happened when he got in there that made him suddenly pivot. And I think it’s a good guess what happened.
Segment 2367: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2642, Text: I think he came under threat by ultra-nationalists within his own administration and the insistence of neocons like Victoria Nuland and the White House, that we don’t want peace with Putin. We want a war.
Segment 2368: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2660, Text: Do you worry about nuclear war?
Segment 2369: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2662, Text: Yeah, I worry about it.
Segment 2370: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2665, Text: It seems like a silly question, but it’s not. It’s a serious question.
Segment 2371: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2669, Text: Well, the reason it’s not is just because people seem to be in this kind of dream state that it’ll never happen, and yet it can happen very easily and it can happen at any time.
Segment 2372: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2688, Text: And if we push the Russians too far, I don’t doubt that Putin, if he felt like his regime or his nation was in danger, that the United States was going to be able to place a quisling into the Kremlin, that he would use nuclear torpedoes and these strategic weapons that they have. And that could be it. Once you do that, nobody controls the trajectory.
Segment 2373: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2724, Text: By the way, I have very strong memories of the Cuban Missile Crisis and of those 13 days when we came closer to nuclear war. And particularly, I think it was when the U-2 got shot down over Cuba. And nobody in this country… There’s a lot of people in Washington, D.C., who, at that point, thought that they very well may wake up dead, that the world may end at night.
Segment 2374: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2755, Text: 30 million Americans killed 130 million Russians. This is what our military brass wanted. They saw a war with Russia, a nuclear exchange with Russia as not only inevitable but also desirable because they wanted to do it now while we still had superiority.
Segment 2375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2774, Text: Can you actually go through the feelings you’ve had about the Cuban Missile Crisis? What are your memories of it? What are some interesting-
Segment 2376: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2781, Text: I was going to school in Washington, D.C. to Our Lady of Victory, which is in Washington, D.C. I lived in Virginia across the Potomac, and we would cross the bridge every day into D.C.
Segment 2377: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2798, Text: And during the crisis, U.S. Marshals came to my house to take us, I think around day eight. My father was spending the night at the White House. He wasn’t coming home. He was staying with the EXCOM committee and sleeping there. And they were up 24 hours a day. They were debating and trying to figure out what was happening.
Segment 2378: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2820, Text: But we had U.S. Marshals come to our house to take us down… They were going to take us down to White Sulphur Springs in Southern Virginia, in the Blue Ridge Mountains, where there was an underground city, essentially, a bunker that was like a city. And apparently, it had McDonald’s in it and a lot of other… It was a full city for the U.S. Government and their families.
Segment 2379: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2849, Text: U.S. Marshals came to our house to take us down there. And I was very excited about doing that. And this was at a time when we were doing the drills. We were doing the duck-and-cover drills once a week at our school, where they would tell you when the alarms go off, then you put your head under the table, you remove the sharps from your desk, put them inside your desk, you put your head under the table, and you wait.
Segment 2380: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2876, Text: And the initial blast will take the windows out of the school. And then we all stand up and file in an orderly fashion into the basement where we’re going to be for the next six or eight months or whatever.
Segment 2381: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2888, Text: But in the basement where we went occasionally, those corridors were lined with freeze-dried food canisters from floor to ceiling. We were all preparing for this. And it was Bob McNamara, who was a friend of mine, and was one of my father’s close friends, the Secretary of Defense, he later called it mass psychosis.
Segment 2382: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2914, Text: And my father deeply regretted participating in the bomb shelter program because he said it was part of a psychological psyop trick to teach Americans that nuclear war was acceptable, that it was survivable. My father, anyway, when the Marshals came to our house to take me and my brother Joe away, we were the ones who were home at that time, my father called, and he talked to us on the phone.
Segment 2383: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2945, Text: And he said, “I don’t want you going down there because if you disappear from school, people are going to panic. And I need you to be a good soldier and go to school.” And he said something to me during that period, which was that if a nuclear war happened, it would be better to be among the dead than the living, which I did not believe. Okay?
Segment 2384: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=2971, Text: I had already prepared myself for the dystopian future. And I knew… I spent every day in the woods. I knew that I could survive by catching crawfish and cooking mudpuppies and would do whatever I had to do. But I felt like, okay, I can handle this. And I really wanted to see this underground city. But anyway, that was part of it for me.
Segment 2385: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3001, Text: My father was away the last days of it. My father got this idea because Khrushchev had sent two letters. He sent one letter that was conciliatory. And then he sent a letter that after his joint chiefs and the warmongers around him saw that letter and they disapproved of it, they sent another letter that was extremely belligerent.
Segment 2386: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3025, Text: And my father had the idea, “Let’s just pretend we didn’t get the second letter and reply to the first one.” And then he went down to Dobrynin. He met Dobrynin in the Justice Department. And Dobrynin was the Soviet ambassador. And they proposed this settlement, which was a secret settlement, where Khrushchev would withdraw the missiles from Cuba.
Segment 2387: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3052, Text: Khrushchev had put the missiles in Cuba because we had put missiles, nuclear missiles, in Turkey and Italy. And my uncle’s secret deal was that if Khrushchev removed the missiles from Cuba within six months, he would get rid of the Jupiter missiles in Turkey.
Segment 2388: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3070, Text: But if Khrushchev told anybody about the deal, it was off. So if news got out about that secret deal, it was off. But that was the actual deal. And Khrushchev complied with it, and then my uncle complied with it.
Segment 2389: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3085, Text: How much of that part of human history turned on the decisions of one person?
Segment 2390: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3091, Text: I think that’s one of the… Because that, of course, is the perennial question. Right? Is history on automatic pilot? And human decisions and the decisions of leaders really only have a marginal or incremental bearing on what is going to happen anyway. And historians argue about that all the time.
Segment 2391: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3117, Text: I think that that is a really good example of a place in human history that, literally, the world could have ended if we had a different leader in the White House. And the reason for that is that there were, as I recall, 64 gun emplacements, missile emplacements. Each one of those missile emplacements had a crew of about 100 men, and they were Soviets.
Segment 2392: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3149, Text: We didn’t know whether… We had a couple of questions that my uncle asked the CIA. And he asked… Dulles was already gone. But he asked the CIA. And he asked his military brass. Because they all wanted to go in. Everybody wanted to go in. And my uncle asked to see the aerial photos, and he examined those personally.
Segment 2393: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3173, Text: And this is why it’s important to have a leader in the White House who can push back on their bureaucracies. And then he asked them, “Who’s manning those missile sites? And are they Russians? And if they’re Russians and we bomb them, isn’t it going to force Khrushchev to then go into Berlin?”
Segment 2394: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3200, Text: And that would be the beginning of a cascade effect that would highly likely end in a nuclear confrontation. And the military brass said to my uncle, “Oh, we don’t think he’ll have the guts to do that.” My uncle was like, “That’s what you’re betting on?”
Segment 2395: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3222, Text: And they all wanted him to go in. They wanted him to bomb the sites and then invade Cuba. And he said, “If we bomb those sites, we’re going to be killing Russians. And it’s going to force… it’s going to provoke Russia into some response. And the obvious response is for them to go into Berlin.”
Segment 2396: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3242, Text: But the thing that we didn’t know then, that we didn’t find out until, I think it was a 30-year anniversary of the Cuban Missile Crisis in Havana, what we learned then from the Russians who came to that event… It was like a symposium where everybody on both sides talked about it. And we learned a lot of stuff that nobody knew before.
Segment 2397: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3270, Text: One of the insane things, the most insane thing that we learned was that the weapons were already… the nuclear warheads were already in place, they were ready to fire, and that the authorization to fire was delegated to each of the gun crew commanders. So there were 60 people who all had authorization to fire if they felt themselves under attack.
Segment 2398: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3299, Text: So you have to believe that at least one of them would’ve launched, and that would’ve been the beginning of the end. And if anybody had launched, we knew what would happen. My uncle knew what would happen. Because he asked again and again, “What’s going to happen?” And they said, “30 million Americans will be killed, but we will kill 130 million Russians, so we will win.” And that was a victory for them.
Segment 2399: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3328, Text: And my uncle later said, he told Arthur Schlesinger and Kenny O’Donnell, he said, “Those guys…” He called them the salad brass, the guys with all of this stuff on their chest. And he said, “Those guys, they don’t care. Because they know that if it happens, they’re going to be in charge of everything. They’re the ones who are going to be running the world after that.”
Segment 2400: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3351, Text: So for them, there was an incentive to kill 130 million Russians and 30 million Americans. But my uncle, he had this correspondence with Khrushchev. They were secretly corresponding with each other. And that is what saved the world, is that both of them had been men of war.
Segment 2401: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3370, Text: Eisenhower famously said, “It will not be a man of war, it will not be a soldier who starts World War III. Because a guy who’s actually seen it knows how bad it is.” And my uncle had been in the heat of the South Pacific. His boat had been cut in two by a Japanese destroyer.
Segment 2402: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3390, Text: Three of his crewmen had been killed, one of them badly burned. He pulled that guy with a lanyard and his teeth, six miles to an island in the middle of the night. And then they hid out there for 10 days. And he came back. Like I said, he was the only President of the United States that earned the Purple Heart.
Segment 2403: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3410, Text: Meanwhile, Khrushchev had been at Stalingrad, which was the worst place to be on the planet, probably in the 20th century, other than in Auschwitz or one of the death camps. It was the most ferocious, horrific war with people starving, people committed cannibalism, eating the dogs, the cats, eating their shoe leather, easing to death by the thousands, etc.
Segment 2404: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3439, Text: Khrushchev did not want… The last thing he wanted was a war. And the last thing my uncle wanted was a war. But the CIA did not know anything about Khrushchev. And the reason for that is there was a mole at Langley so that every time the CIA got a spy in the Kremlin, he would immediately be killed.
Segment 2405: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3463, Text: So they had no eyes in the Kremlin. There were literally hundreds of Russian spies who had defected to the United States and were in the Kremlin who were killed during that period. They had no idea anything about Khrushchev, about how he saw the world. And they saw the Kremlin itself as a monolith.
Segment 2406: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3486, Text: The same way that we look at Putin today, they have this ambition of world conquest and it’s driving them. And there’s nothing else they think about. They’re absolutely single-minded about it.
Segment 2407: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3498, Text: But actually, there was a big division between Khrushchev and his joint chiefs and his intelligence apparatus. And they both, at one point, discovered they were both in the same situation. They were surrounded by spies and military personnel who were intent on going to war, and they were the two guys resisting it.
Segment 2408: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3519, Text: My uncle had this idea of being the peace president from the beginning. He told Ben Bradlee, one of his best friends who was the publisher of The Washington Post or the editor-in-chief at that time. He said Ben Bradlee asked him, “What do you want on your gravestone?” And my uncle said, “He kept the peace.” He said, “The principal job of the President of the United States is to keep the country out of war.”
Segment 2409: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3551, Text: So when he first became president, he actually agreed to meet Khrushchev in Geneva to do a summit. And by the way, Eisenhower had wanted to do the same thing. Eisenhower wanted peace, and he was going to meet in Vienna. But that peace summit was blown up. He was going to try to end the Cold War.
Segment 2410: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3577, Text: Eisenhower was in the last year of his… in May of 1960. But that was torpedoed by the CIA during the U-2 crash. They sent a U-2 over the Soviet Union, it got shot down. And then Allen Dulles told Eisenhower to deny that we had a program. They didn’t know that the Russians had captured Gary Francis powers.
Segment 2411: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3600, Text: …France’s powers. And that blew up the peace talks between Eisenhower and Khrushchev and there was a lot of tension. My uncle wanted to break that tension. He agreed to meet with Khrushchev in Vienna early on in his term. He went over there and Khrushchev snubbed him. Khrushchev lectured him imperiously about the terror of American imperialism, and rebuffed any… They did agree not to go into Laos. They made an agreement that kept the United States, kept my uncle, from sending troops to Laos, but it had been a disaster in Vienna.
Segment 2412: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3648, Text: So then, we had a spy that used to come to our house all the time, a guy called Georgi Bolshakov, and he was this Russian spy my parents had met at the embassy. They had gone to a party or a reception at the Russian Embassy, and he had approached them and they knew he was a GRU agent and KGB, he was both, oh, he used to come to our house. They really liked him. He was very attractive. He was always laughing and joking. He would do rope climbing contests with my father. He would do pushup contests with my father. He could do the Russian dancing, the Cossack dancing, and he would do that for us and teach us that. And we knew he was a spy too, and this was at the time of the James Bond films were first coming out, so it was really exciting for us to have an actual Russian spy in our house. The State Department was horrified by it.
Segment 2413: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3704, Text: But anyway, when Khrushchev, after Vienna, and after the Bay of Pigs, Khrushchev had second thoughts and he sent this long letter to my uncle, and he didn’t want to go through his state department or his embassy, he wanted to end run them. And he was friends with Bolshakov, so he gave Georgi the letter, and Georgi brought it and handed it to Pierre Salinger, folded in the New York Times. And he gave it to my uncle.
Segment 2414: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3741, Text: And it was this beautiful letter, which he said, my uncle had talked to him about the children who had played, we played, 29 grandchildren who were playing in his yard. And he’s saying, what is our moral basis for making a decision that could kill these children? So they’ll never write a poem, they’ll never participate in election, they’ll never run for office. How can we morally, make a decision that is going to eliminate life for these beautiful kids?
Segment 2415: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3772, Text: And he had said that to Khrushchev, and Khrushchev wrote them this letter back saying that he was now sitting as this dacha on the Black Sea, and that he was thinking about what my uncle Jack had said to him at Vienna. And he regretted very deeply not having taken the olive leaf that Jack had offered him. And then he said, it occurs to me now that we’re all on an arc and that there is not another one, and that the entire fate of the planet, and all of its creatures and all of the children are dependent on the decisions we make. And you and I have a moral obligation to go forward with each other as friends.
Segment 2416: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3814, Text: And immediately after that, he sent that right after the Berlin crisis in 1962, General Curtis LeMay had tried to provoke a war with an incident at Checkpoint Charlie, which was the entrance and exit, through the Berlin Wall in Berlin. And the Russian tanks had come to the wall. The US tanks had come to the wall and there was a standoff. And my uncle had sent a message to Khrushchev then through Do Brennan saying, my back is at the wall. I have no place to back to, please back off, and then we will back off. And Khrushchev took his word, backed his tanks off first, and then my uncle ordered LeMay back. He had, LeMay had mounted bulldozer plows on the front of the tanks to plow down the Berlin wall, and the Russians had come, so it was these generals trying to provoke a war.
Segment 2417: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3884, Text: But they started talking to each other then. And then after he wrote that letter, they agreed that they would install a hotline, so they could talk to each other and they wouldn’t have to go through intermediaries. And so at Jack’s house on the Cape, there was a red phone that we knew if we picked it up, Khrushchev would answer. And there was another one in the White House. But they knew it was important to talk to each other. And you just wish that we had that kind of leadership today, that just understands our job.
Segment 2418: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=3921, Text: Look, I know you know a lot about AI, and you know how dangerous it is, potentially to humanity, and what opportunities is it also offers, but it could kill us all. I mean, Elon said, first it’s going to steal our job, then it’s going to kill us. Right? And it’s probably not a hyperbole. Actually, if it follows the laws of biological evolution, which are just the laws of mathematics, that’s probably a good endpoint for it, a potential endpoint. It’s going to happen, but we need to make sure it’s regulated, and it’s regulated properly for safety, in every country. And that includes Russia and China and Iran. Right now, we should be putting all the weapons of war aside and sitting down with those guys and say, how are we going to do this? There’s much more important things to do. This stuff is going to kill us, if we don’t figure out how to regulate it. And leadership needs to look down the road at what is the real risk here. And the real risk is that AI will enslave us, for one thing, and then destroy us, and do all this other stuff.
Segment 2419: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4002, Text: And how about biological weapons? We’re now all working on these biological weapons, and we’re doing biological weapons for Ebola, and Dengue Fever, and all of these other bad things. And we’re making ethnic bio-weapons, bio-weapons that can only kill Russians, bio-weapons that the Chinese are making that can kill people who don’t have Chinese genes. So all of this is now within reach. We’re actively doing it, and we need to stop it. And a biological weapons treaty is the easiest thing in the world to do. We can verify it, we can enforce it, and everybody wants to agree to it. Only insane people do not want to continue this kind of research, there’s no reason to do it.
Segment 2420: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4053, Text: So there are these existential threats to all of humanity now out there, like AI and biological weapons. We need to stop fighting each other, start competing on economic game fields, playing fields, instead of military playing fields, which will be good for all of humanity. And we need to sit down with each other, and negotiate reasonable treaties on how we regulate AI and biological weapons. And nobody’s talking about this in this political race right now. Nobody’s talking about it in a government. They get fixated on these little wars, and these comic book depictions of good versus evil, and we all go, hoorah and go off to and give them the weapons and enrich the military industrial complex, but we’re on the road to perdition if we don’t end this.
Segment 2421: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4109, Text: And some of this requires to have this kind of phone that connects Khrushchev and John F. Kennedy that cuts through all the bureaucracy, to have this communication between heads of State, and in the case of AI, perhaps heads of tech companies where you can just pick up the phone and have a conversation.
Segment 2422: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4126, Text: Yes.
Segment 2423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4126, Text: Because a lot of it, a lot of the existential threats of artificial intelligence, perhaps even bio-weapons, is unintentional. It’s not even strategic-
Segment 2424: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4136, Text: Exactly.
Segment 2425: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4136, Text: -intentional effects, so you have to be transparent and honest about, especially with AI, that people might not know what’s the worst that’s going to happen once you release it out into the wild? And you have to have an honest communication about how to do it, so that companies are not terrified of regulation, overreach regulation. And then government is not terrified of tech companies, of manipulating them in some direct or indirect ways, so there’s a trust that builds versus a distrust. Basically, that old phone, where Khrushchev can call John F. Kennedy, is needed.
Segment 2426: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4175, Text: And I don’t think there’s… Listen, I don’t understand AI. I do know, I can see from all this technology, how it’s this turnkey totalitarianism, that once you put these systems in place, they can be misused to enslave people, and they can be misused in wars, and to subjugate, to kill, to do all of these bad things. And I don’t think there’s anybody on Capitol Hill, who understands this. We need to bring in the tech community and say, tell us what these regulations need to look like, so that there can be freedom to innovate, so that we can milk AI for all of the good things, but not fall into these traps that pose existential threats to humanity.
Segment 2427: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4231, Text: It seems like John F. Kennedy is a singular figure, in that he was able to have the humility to reach out to Khrushchev, and also the strength and integrity to resist the, what did you call them, the salad brass and institutions like the CIA, so that makes it particularly tragic that he was killed. To what degree was CIA involved, or the various bureaucracy involved in his death?
Segment 2428: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4260, Text: The evidence that the CIA was involved in my uncle’s murder, and that they were subsequently involved in the coverup, and continue to be involved in the coverup, I mean, there’s still 5,000 documents that they won’t release 60 years later, is I think, so insurmountable and so mountainous and overwhelming, that it’s beyond any reasonable doubt, including dozens of confessions of people who were involved in the assassination. But every kind of document, and I mean, it came as a surprise recently to most Americans, I think, the release of these documents in which the press, the American media, finally acknowledged that, yeah, Lee Harvey Oswald was the CIA asset, that he was recruited in 1957. He was a Marine working at the Atsugi Air Force Base, which was the CIA Air Force base with the U2 flights, which was a CIA program. And that he was recruited by James Jesus Angleton, who was the director of counterintelligence and then sent on a fake defection to Russia and then brought back to Dallas.
Segment 2429: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4354, Text: And people didn’t know that, even though it’s been known for decades, it never percolated into the mainstream media, because they have such an allergy to anything that challenges the Warren Report. When Congress investigated my uncle’s murder in the 1970s, the Church committee did, and they did a two and a half year investigation, and they had many, many more documents, and much more testimony available to them than the Warren Commission had, and this was a decade after the Warren Commission. They came to the conclusion that my uncle was killed by a conspiracy. And there was a division where essentially one guy on that committee believed it was primarily the mafia, but Richard Schweitzer was the senator at head of the committee, said straight out, the CIA was involved in the murder of the President of the United States.
Segment 2430: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4422, Text: I’ve talked to most of the staff on that committee, and they said, yeah, and the CIA was stonewalling us the whole way through. And the actual people that the CIA appointed, George Johanedees, who the CIA appointed as a liaison to the committee, they brought him out of retirement, he had been one of the masterminds of the assassination.
Segment 2431: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4446, Text: I mean, it’s impossible to even talk about a tiny of the fraction of the evidence here. What I suggest to people, there are hundreds of books written about this, that assemble this evidence and mobilize the evidence. The best book to me, for people to read is James Douglass’s book, which is called, The Unspeakable. And he, Douglass does this extraordinary. He is an extraordinary scholar, and he does this just an amazing job of digesting and summarizing and mobilizing all of them, probably a million documents, and the evidence from all these confessions that have come out, into a coherent story. And it’s riveting to read. And I recommend people, do not take my word for it, and don’t take anybody else’s word for it, go ahead and do the research yourself. And one way to do that is probably the most efficient way, is to read Douglas’s book. He has all the references there.
Segment 2432: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4508, Text: So if it’s true that CIA had a hand in this assassination, how is it possible for them to amass so much power? How is it possible for them to become corrupt? And is it individuals, or is it the entire institution?
Segment 2433: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4522, Text: No, it’s not the entire institution. My daughter-in-law, who’s helping to run my campaign was a CIA, in the clandestine for all her career. She was a spy in the Weapons of Mass Destruction program in the Middle East and in China. And there’s 22,000 people who work for the CIA, probably 20,000 of those are patriotic Americans and really good public servants, and they’re doing important work for our country. But the institution is corrupt, and because the higher up ranks the institution. And in fact, Mike Pompeo said something like this to me the other day. He was the director of the CIA. He said, “When I was there, I did not do a good job of cleaning up that agency.” And he said, “The entire upper bureaucracy of that agency, are people who do not believe in the institutions of democracy.” This is what he said to me. I don’t know if that’s true, but I know that that’s significant. He’s a smart person, and he ran the agency and he was the Secretary of State.
Segment 2434: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4592, Text: But it’s no mystery how that happened. We know the history. The CIA was originally…First of all, there was great reluctance in 1947, that for the first time, we had a secret spy agency in this country during World War II, called the OSS. That was disbanded after the war, because Congress said, having a secret spy agency is incompatible with a democracy. The secret spy agency are things like the KGB, the STASI in East Germany, SAVAK in Iran, and PEEP, and Chile and whatever, all over the world, they’re all have to do with totalitarian governments. They’re not something that you can have that, it’s antithetical to democracy to have that. But in 1947, we created, Truman signed it in, but it was initially an espionage agency, which means information gathering, which is important. It’s to gather and consolidate information from many, many different sources from all over the world, and then put those in reports for the White House, so the president can make good decisions based upon valid information, evidence-based decision making.
Segment 2435: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4677, Text: But Alan Dulles, who was essentially the first head of the agency, made a series of legislative imaginations and political imaginations, that gave additional powers to the agency, and opened up what they called then the plans division, which is the plans division is the dirty tricks, it’s the black ops, fixing elections, murdering, what they call executive action, which means killing foreign leaders, and making small wars, and bribing, and blackmailing, people stealing elections, and that kind of thing. And the reason, at that time, we were in the middle of the Cold War and Truman, and then Eisenhower did not want to go to war. They didn’t want to commit troops. And it seemed to them that this was a way of fighting the Cold War secretly, and doing it at minimal cost by changing events sort of invisibly. And so it was seductive to them.
Segment 2436: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4748, Text: But everybody, Congress, when they first voted it in place, Congress, both political parties said, if we create this thing, it could turn into a monster and it could undermine our values. And today it’s so powerful, and then nobody knows what its budget is. Plus it has its own investment fund In-Q-Tel, which has invested, made I think, 2000 investments in Silicon Valley. So it has ownership of a lot of these tech companies, and a lot of the CEOs of those tech companies have signed state secrecy agreements with the CIA, which if they even reveal that they have signed that, they can go to jail for 20 years and have their assets removed, et cetera. The influence that the agency has, the capacity to influence events at every level in our country, is really frightening.
Segment 2437: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4803, Text: And then for most of its life, the CIA was banned from propagandizing Americans, but we learned that they were doing it anyway. So in 1973, during the Church Committee hearings, we’ve learned that the CIA had a program called Operation Mockingbird, where they had at least 400 members, leading members of the United States press corps, on the New York Times, the Washington Post, ABC, CBS, NBC, et cetera, who were secretly working for the agency, and steering news coverage to support CIA priorities. And they agreed at that time to disband Operation Mockingbird in ’73. But there’s indications they didn’t do that.
Segment 2438: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4856, Text: And they still, the CIA today, is the biggest funder of journalism around the world. The biggest funder is through USAID. The United States funds journalism in almost every country in the world. It owns newspapers, it has journalists on it, thousands and thousands of journalists, on its payroll. They’re not supposed to be doing that in the United States. But in 2016, president Obama changed the law to make it legal now for the CIA to propagandize Americans. And I think, we can’t look at the Ukraine War and how the narrative has been formed in the minds of Americans, and say that the CIA had nothing to do with that.
Segment 2439: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4906, Text: Well, what is the mechanism by which the CIA influences the narrative? Do you think it’s indirectly?
Segment 2440: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4911, Text: Through the press.
Segment 2441: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4912, Text: Indirectly through the press, or directly by funding the press?
Segment 2442: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4915, Text: Directly through. I mean, there’s certain press organs that have been linked to the agency, that the people who run those organs, things like the Daily Beast, now Rolling Stone, editor of Rolling Stone, Noah Shachtman, has deep relationships with the intelligence community, Salon, Daily Kos.
Segment 2443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4939, Text: But I wonder why they would do it. From my perspective, it just seems like the job of a journalist is to have an integrity where your opinion cannot be influenced or bought.
Segment 2444: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=4950, Text: I agree with you, but I actually think that the entire field of journalism has really shamed itself in recent years, because it’s become, the principle newspapers in this country and the television stations, the legacy media, have abandoned their tradition of… When I was a kid, listen, my house was filled with the greatest journalists alive at that time, people like Ben Bradley, like Anthony Lewis, Mary McGrory, Pete Hamil, Jack Newfield, Jimmy Breslin, and many, many others. And after my father died, they started the RFK Journalism Awards to recognize integrity and courage, journalistic integrity and courage. And for that generation of journalism, they thought, they believed that the function of journalists, was to maintain this posture of fear-skepticism toward any aggregation of power, including government authority, that people in authority lie, and that they always have to be questioned, and that their job was to speak truth to power, and to be guardians of the First Amendment to free expression.
Segment 2445: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5037, Text: But if you look what happened during the pandemic, was the inverse of that kind of journalism, where the major press organs in this country were, instead of speaking truth to power, they were doing the opposite. They were broadcasting propaganda. They became propaganda organs for the government agencies. And they were actually censoring the speech of dissent, anybody who dissent, of the powerless. And in fact, it was an organized conspiracy, and the name of it was the Trusted News Initiative. And some of the major press organs in our country signed onto it, and they agreed not to print stories or facts, that departed from government orthodoxy. So the Washington Post was the signature of the UPI, the AP, and then the four social media groups, Microsoft, Twitter, Facebook, and Google, all signed on to the Trusted News Initiative.
Segment 2446: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5099, Text: It was started by the BBC, organized by them. And the purpose of it, was to make sure nobody could print anything about government that departed from governmental orthodox. And the way it worked is, the UPI, the AP, which are the news services that provide most of the news news around the country, and the Washington Post, would decide what news was permissible to print. And a lot of it was about COVID, but also Hunter Biden’s laptops, it was impermissible to suggest that those were real, or that they had stuff on there that was compromising.
Segment 2447: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5139, Text: And by the way, what I’m telling you is all well documented, and I’m litigating on it right now, so I’m part of a lawsuit against the TNI, and so I know a lot about what happened, and I have all this documented and people can go to our website. There’s a letter on my sub-stack now, to Michael Scherer of the Washington Post that outlines all this, and gives all my sources, because Michael Scherer accused me of being a conspiracy theorist, when he was actually part of a conspiracy, a true conspiracy, to suppress anybody who is departing from government orthodoxies, by either censoring them completely, or labeling them conspiracy theorists.
Segment 2448: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5186, Text: I mean, you can understand the intention and the action, the difference between as we talked about, you can understand the intention of such a thing being good, that in a time of a catastrophe, in a time of a pandemic, there’s a lot of risk to saying untrue things. But that’s a slippery slope that leads into a place where the journalistic integrity that we talked about, is completely sacrificed, and then you can deviate from truth.
Segment 2449: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5214, Text: If you read their internal memorandum, including the statements of the leader of the Trusted News Initiative, I think her name’s Jessica, Jennifer, Cecil and you can go on our website and see her statement. She says, the purpose of this is that we’re now… Actually, she says, when people look at the us, they think we’re competitors, but we’re not. The real competitors are coming from all these alternative news sources now all over the network, and they’re hurting public trust in us, and they’re hurting our economic model, and they have to be choked off and crushed. And the way that we’re going to do that, is to make an agreement with the social media sites, that if we say, if we label their information misinformation, the social media sites will de platform it, or they will throttle it, or they will shadow-ban it, which destroys the economic model of those alternative, competitive sources of information. So that that’s true.
Segment 2450: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5278, Text: But the point you make, is an important point. That the journalists themselves, who probably didn’t know about the TNI agreement, certainly I’m sure they didn’t, they believe that they’re doing the right thing by suppressing information that may challenge government proclamations on COVID. But I mean, there’s a danger to that. And the danger is that, once you appoint yourself an arbiter of what’s true and what’s not true, then there’s really no end to the power that you have now assumed for yourself, because now your job is no longer to inform the public. Your job now is to manipulate the public. And if you end up manipulating the public in collusion with powerful entities, then you become the instrument of authoritarian rule, rather than the opponent of it. And it becomes the inverse of journalism and a democracy.
Segment 2451: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5345, Text: You’re running for president as a Democrat, what to you are the strongest values that represent the left-wing politics of this country?
Segment 2452: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5358, Text: I would say protection of the environment, and the commons, the air, the water, wildlife, fisheries, public lands, those assets, they cannot be reduced to private property ownership, the landscapes, our purple mountain majesty, the protection of the most vulnerable people in our society, people which would include children and minorities, the restoration of the middle class, and protection of labor, dignity, and decent pay for labor, bodily autonomy, a woman’s right to-
Segment 2453: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5403, Text: … bodily autonomy, a woman’s right to choose or an individual’s right to endure unwanted medical procedures. Peace. The Democrats have always been anti-war. The refusal to use fear is a governing tool. FDR said, “The only thing we have to fear is fear itself,” because he recognized that tyrants and dictators could use fear to disable critical thinking and overwhelm the desire for personal liberty. The freedom of government from untoward influenced by corrupt corporate power. The end of this corrupt merger of state and corporate power that is now I think, dominating our democracy. It’s what Eisenhower warned about when he warned against the emergence of the military industrial complex.
Segment 2454: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5467, Text: And then I prefer to talk about the positive vision of what we should be doing in our country and globally, which is I see that the corporations are commoditizing us are poisoning our children, are strip mining the wealth from our middle class and treating America as if it were business in liquidation, converting assets to cash as quickly as possible and creating or exacerbating this huge disparity in wealth in our country, which is eliminating the middle class and creating a Latin American style futile model. There’s these huge aggregations of wealth above and widespread poverty below, and that’s a configuration that is too unstable to support democracy sustainably. And we’re supposed to be modeling democracy, but we’re losing it.
Segment 2455: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5531, Text: And I think we have ought to have a foreign policy that restores our moral authority around the world. Restores America as the embodiment of moral authority, which it was when my uncle was president. And as a purveyor of peace rather than a war-like nation. My uncle said he didn’t want people in Africa and Latin America and Asia when they think of America to picture a man with a gun and a bayonet. He wanted them to think of a Peace Corps volunteer, and he refused to send combat soldiers abroad. He never sent a single soldier to his death abroad and into combat. He sent 16,000. He resisted in Berlin in ’62. He resisted in Laos in ’61. He resisted in Vietnam. Vietnam, they wanted him to put 250,000 troops. He only put 16,000 advisors, which was fewer troops.
Segment 2456: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5602, Text: And he sent to get James Meredith into the universe to Ole Miss in Oxford, Mississippi. One black man, he sent 16,000. And month before he died, he ordered them all home. I think it was October 2nd, 1963, he heard that a Green Beret had died. And he asked his aid for a list of combat fatalities. And the aid came back and there was 75 men had died in Vietnam at that point. And he said, “That’s too many. We’re going to have no more.” And he signed a national security order, 263, and ordered all of those men, all Americans, home from Vietnam by 1965 with the first thousand coming home by December ’63.
Segment 2457: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5653, Text: And then in November he, of course, just before that evacuation began, he was killed. And a week later, president Johnson remanded that order. And then a year after that, the Tonkin Gulf resolution, we sent 250,000, which is what they wanted my uncle to do, which he refused. And it became an American war. And then Nixon topped it off at 560,000. 56,000 Americans never came home, including my cousin George Skakel, who died at the Tet Offensive. And we killed a million Vietnamese and we got nothing for it.
Segment 2458: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5691, Text: So America should be the symbol of peace?
Segment 2459: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5697, Text: My uncle really focused on putting America on the side of the poor, instead of our tradition of fortifying oligarchies that were anti-communism. That was our major criteria. If you said you were against communists, and of course the people were with the rich people, our aid was going to the rich people in those countries and they were going to the military juntas. Our weapons were going to the juntas to fight against the poor. And my uncle said, “No, America should be on the side of the porn.” And so he launched the Alliance for Progress and USAID, which were intended to bring aid to the poorest people and those, and build middle classes, and take ourselves away.
Segment 2460: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5742, Text: In fact, his two favorite trips while he was president. His most favorite trip was to Ireland, this incredible, emotional homecoming for all of the people of Ireland. But his second favorite trip was when he went to Colombia, he went to Latin America, but Colombia was his favorite country. And I think there were 2 million people came into Bogota to see him, this vast crowd. And they were just delirious cheering for him. And the president of Columbia, Lleras Camargo, said to him, “Do you know why they love you?”
Segment 2461: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5782, Text: And my uncle said, “Why?”
Segment 2462: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5784, Text: And he said, “Because they think you’ve put America on the side of the poor against the oligarchs.” And my uncle, after he died, today, there are more avenues and boulevards and hospitals and schools and statues and parks commemorating John Kennedy in Africa and Latin America than any other president in the United States, and probably more than all the other presidents combined. And it’s because he put America on the side of the poor. And that’s what we ought to be doing.
Segment 2463: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5821, Text: We ought to be projecting economic power abroad. The Chinese have essentially stolen his playbook and we’ve spent $8 trillion on the Iraq war and its aftermath. The wars in Syria, Yemen, Libya, Afghanistan, Pakistan. And what do we get for that? We got nothing for that money. $8 trillion. We killed more Iraqis than Saddam Hussein. Iraq today is much worse off than it was when Saddam was there. It’s an incoherent, violent war between Shia and Sunni death squads. We pushed Iraq into the embrace of Iran, which now become essentially a proxy for Iran, which is exactly the outcome that we were trying to prevent for the past 20 or 30 years.
Segment 2464: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5873, Text: We created ISIS, we sent 2 million refugees into Europe, destabilizing all of the nations in Europe for generations. And we’re now seeing these riots in France, and that’s a direct result from the Syrian war that we created and our creation of ISIS. Brexit is another result of that. So for $8 trillion, we wrecked the world. And during that same period that we spent $8.1 trillion bombing bridges, ports, schools, hospitals, the Chinese spent 8.1 trillion building schools, ports, hospitals, bridges, and universities.
Segment 2465: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5922, Text: And now the Chinese are out-competing us everywhere in the world. Everybody wants to deal with the Chinese because they come in, they build nice things for you, and there’s no strings attached and they’re pleasant to deal with. And as a result of that, Brazil is switching the Chinese currency. Argentina is switching. Saudi Arabia, our greatest partner that we put trillions of dollars into protecting our oil pipelines there. And now they’re saying, “We don’t care what the United States think.” That’s what Mohammed bin Salman said.
Segment 2466: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=5964, Text: He dropped oil production in Saudi Arabia in the middle of a US inflation spiral. They’ve never done that to us before, to aggravate the inflation spiral. And then they signed a deal, a unilateral peace deal with Iran, which has been the enemy that we’ve been telling them to be a bulwark against for 20 years. And two weeks after that, he said, “We don’t care what the United States thinks anymore.” So that’s what we got for spending all those trillions of dollars there. We got short term friends. And we have not made ourselves safer. We’ve put Americans in more jeopardy all over the world. You have to wait in lines to get through the airport. The security state is now causing us $1.3 trillion, and America is unsafer and poorer than it’s ever been. So we should be doing what President Kennedy said we ought to do, and the policy that China has now adopted.
Segment 2467: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6037, Text: So that’s a really eloquent and clear and powerful description of the way you see US should be doing geopolitics and the way you see US should be taking care of the poor in this country. Let me ask you a question from Jordan Peterson that he asked when I told him that I’m speaking with you. “Given everything you’ve said, when does the left go too far?” I suppose he’s referring to cultural issues, identity politics.
Segment 2468: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6070, Text: Well, Jordan trying to get me to badmouth the left the whole time I was in, I really enjoyed my talk with him, but he seemed to have that agenda where he wanted me to say bad things about the left and that’s not what my campaign is about. I want to do the opposite. I’m not going to badmouth the left. I was on shows this week with David Remnick from the New Yorker, and he tried to get me to badmouth Donald Trump and Alex Jones and a lot of other people, and baiting me to do it. And of course there’s a lot of bad things I could say about all those people, but I’m trying to find values that hold us together and we can share in common, rather than to focus constantly on these disputes and these issues that drive us apart.
Segment 2469: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6127, Text: So me sitting here badmouthing the left or badmouthing the right is not going to advance the ball. I really want to figure out ways that what do these groups hold in common that we can all have a shared vision of what we want this country to look like.
Segment 2470: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6145, Text: Well, that’s music to my ears. But in that spirit, let me ask you a difficult question then. You wrote a book harshly criticizing Anthony Fauci. Let me ask you to steelman the case for the people who support him. What is the biggest positive thing you think Anthony Fauci did for the world? What is good that he has done for the world, especially during this pandemic?
Segment 2471: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6168, Text: I don’t want to sit here and speak unfairly by saying the guy didn’t do anything, but I can’t think of anything. If you tell me something that you think he did, maybe there was a drug that got licensed while he was at NIH that benefited people, that’s certainly possible. He was there for 50 years. And in terms of his principle programs of the AIDS programs and his COVID programs, I think that the harm that he did vastly outweighed the benefits.
Segment 2472: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6209, Text: Do you think he believes he’s doing good for the world?
Segment 2473: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6211, Text: I don’t know what he believes. In fact, in that book, which is I think 250,000 words, I never try to look inside of his head. I deal with facts. I deal with science and every factual assertion in that book is cited in source to government databases or peer reviewed publications. And I try not to speculate about things that I don’t know about or I can’t prove. And I cannot tell you what his motivations were. He’s done a lot of things that I think are really very, very bad things for humanity and very deceptive. But we all have this capacity for self-deception. As I said at the beginning of this podcast, we judge ourselves on our intentions rather than our actions. And we all have an almost infinite capacity to convince ourselves that what we’re doing is right. And not everybody lives an examined life. And it is examining their motivations and the way that the world might experience their professions of goodness.
Segment 2474: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6285, Text: Let me ask about the difficulty of the job he had. Do you think it’s possible to do that kind of job well or is it also a fundamental flaw of the job, of being the central centralized figure that’s supposed to have a scientific policy?
Segment 2475: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6298, Text: No. No. I think he was a genuinely bad human being. And that there were many, many good people in that department over the years. Bernice Eddy is a really good example. John Anthony Morris. Many people whose careers he destroyed because they were trying to tell the truth. One after the other, the greatest scientists in the history of NIH were run out of that agency. But people listening to this, probably will, in hearing me say that, will think that I’m bitter or that I’m doctrinaire about him, but you should really go and read my book. And it’s hard to summarize. I try to be really methodical, to not call names, to just say what happened.
Segment 2476: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6357, Text: The bigger picture of this is you’re an outspoken critic of pharmaceutical companies, big pharma. What is the biggest problem with big pharma and how can it be fixed?
Segment 2477: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6367, Text: Well, the problem could be fixed with regulation. But the pharmaceutical industry is… I don’t want to say because this is going to seem extreme that a criminal enterprise, but if you look at the history, that is an applicable characterization, for example, the four biggest vaccine makers, Sanofi, Merck, Pfizer, and Glaxo, four companies that make all of the 72 vaccines that are now effectively mandated for American children. Collectively, those companies have paid $35 billion in criminal penalties and damages in the last decade. And I think since 2000, about 79 billion. So these are the most corrupt companies in the world.
Segment 2478: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6428, Text: And the problem is that they’re serial felons. They do this again and again and again. So Merck did Vioxx, which, Vioxx, they killed people by falsifying science. And they did it. They lied to the public. They said, “This is a headache medicine and a arthritis painkiller.” But they didn’t tell people that it also gave you heart attacks.
Segment 2479: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6457, Text: And they knew, we’ve found when we sued them, the memos from their bean counters saying, “We’re going to kill this many people, but we’re still going to make money.” So they make those calculations and those calculations are made very, very regularly. And then when they get caught, they pay a penalty. And I think they paid about $7 billion for Vioxx. But then they went right back that same year that they paid that penalty, they went back into the same thing again with Gardasil and with a whole lot of other drugs. So the way that the system is set up, the way that it’s sold to doctors, the way that nobody ever goes to jail, so there’s really no penalty that it all becomes part of the cost of doing business.
Segment 2480: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6512, Text: And you can see other businesses that if there’s no penalty, if there’s no real… look, these are the companies that gave us the opioid epidemic. So they knew what was going to happen. And you go and see, there’s a documentary, I forget what the name of it is, but it shows exactly what happened. And they corrupted FDA. They knew that oxycodone was addictive. They got FDA to tell doctors that it wasn’t addictive. They pressured FDA to lie. And they got their way. And so far they got a whole generation addicted oxycodone. And now when they got caught, and we made it harder to get oxycodone, and now all those addicted kids are going to fentanyl and dying. And this year it killed 106,000. That’s twice as many people who were killed during the 20-year Vietnam War. But in one year, twice as many American kids. And they knew it was going to happen and they did it to make money. So I don’t know what you call that other than saying that’s a criminal enterprise.
Segment 2481: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6587, Text: Well, is it possible, within a capitalist system, to produce medication, to produce drugs at scale in a way that is not corrupt?
Segment 2482: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6597, Text: Of course it is.
Segment 2483: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6598, Text: How?
Segment 2484: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6600, Text: Through a solid regulatory regimen, where drugs are actually tested. The problem is not the capitalist system. The capitalist system, I have great admiration for and love for the capitalist system. It’s the greatest economic engine ever devised. But it has to be harnessed to a social purpose. Otherwise, it leads us down a trail of oligarchy, environmental destruction, and commoditizing poisoning and killing human beings. That’s what it will do. And in the end, you need a regulatory structure that is not corrupted by entanglements, financial entanglements with the industry. And we’ve set this up. The way that the system is set up today has created this system of regulatory capture on steroids.
Segment 2485: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6666, Text: So almost 50% of FDA’s budget comes from pharmaceutical companies. The people who work at FDA are, their salaries are coming from pharma, half their salaries. So they know who their bosses are. And that means getting those drugs done, getting them out the door and approved as quickly as possible. It’s called fast track approval. 50% of FDA’s budget, about 45%, actually goes to fast track approval.
Segment 2486: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6698, Text: Do you think money can buy integrity?
Segment 2487: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6700, Text: Oh yeah, of course it can. That’s not something that is controversial. Of course it will.
Segment 2488: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6708, Text: It’s slightly controversial to me. I would like to think that scientist that work at the FDA-
Segment 2489: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6713, Text: Well, it may not be able to buy your integrity. I’m talking about population wide, I’m not talking about the individual.
Segment 2490: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6718, Text: But I’d like to believe that in general, a career of a scientist is not a very high paying job. I’d like to believe that people that go into science, that work at FDA, that work at NIH are doing it for a reason that’s not even correlated with money, really.
Segment 2491: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6738, Text: Yt. And I think probably that’s why they go in there. But scientists are corruptible. And the way that I can tell you that is that I’ve brought over 500 losses and almost all of them involve scientific controversies. And there are scientists on both sides in every one. And when we sued Monsanto, on the Monsanto side, there was a Yale scientist, a Stanford scientist, and a Harvard scientist. And on our side there was a Yale, Stanford and Harvard scientist. And they were saying exactly the opposite things. In fact, there’s a word for those kind of scientists who take money for their opinion, and the word is biostitutes. And they are very, very common. And I’ve been dealing them with them my whole career.
Segment 2492: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6785, Text: I think it was Upton Sinclair, that it’s very difficult to persuade a man of a fact if the existence of that fact will diminish his salary. And I think that’s true for all of us. If we find a way of reconciling ourselves, to truths and worldviews that actually benefit our salaries. Now, NIH has probably the worst system, which is that scientists who work for NIH itself, which used to be the premier gold standard scientific agency in the world, everybody looked at NIH as that. Today, it’s just an incubator for pharmaceutical drugs. And that is that gravity of economic self-interest.
Segment 2493: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6838, Text: Because if NIH itself collects royalties, they have margin rights for the patents on all the drugs that they work on. So with the Moderna vaccine, which they promoted incessantly and aggressively, NIH on 50% of that vaccine is making billions and billions of dollars on it. And there are at least four scientists that we know of, and probably at least six at NIH, who themselves have marching rights for those patents. So if you are a scientist who work at NIH, you work on a new drug, you then get marching rights and you’re entitled to royalties of $150,000 a year forever from that forever. Your children, your children’s children. As long as that product’s on the market, you can collect royalties.
Segment 2494: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6886, Text: Moderna vaccine is paying for the top people at NIH. Some of the top regulators. It’s paying for their boats, it’s paying for their mortgages, it’s paying for their children’s education. And you have to expect that in those kind of situations, the regulatory function would be subsumed beneath the mercantile ambitions of the agency itself and the individuals who stand to profit enormously from getting a drug to market. Those guys are paid by us, the taxpayer, to find problems with those drugs before they get to market. But if you know that drug is going to pay for your mortgage, you may overlook a little problem or even a very big one. And that’s the problem.
Segment 2495: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6938, Text: You’ve talked about that the media slanders you by calling you an anti-vaxxer, and you’ve said that you’re not anti-vaccine, you’re pro safe vaccine. Difficult question, can you name any vaccines that you think are good?
Segment 2496: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6955, Text: I think some of the live virus vaccines are probably averting more problems than they’re causing. There’s no vaccine that is safe and effective. In fact-
Segment 2497: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6969, Text: Those are big words.
Segment 2498: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6969, Text: … Those are big words.
Segment 2499: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6970, Text: What about the polio? Let’s start with the-
Segment 2500: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=6971, Text: Well, here’s the problem. Here’s the problem. Yeah, here’s the problem. The polio vaccine contained a virus called simian virus 40. SV40. It’s one of the most carcinogenic materials that is known to man. In fact, it’s used now by scientists around the world to induce tumors and rats and Guinea pigs in labs. But it was in that vaccine, 98 million people who got that vaccine. And my generation got it. And now you’ve had this explosion of soft tissue cancers in our generation that killed many, many, many more people than polio ever did. So if you say to me, “The polio vaccine, was it effective against polio?”
Segment 2501: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7015, Text: I’m going to say, “Yes.”
Segment 2502: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7017, Text: And if say to me, “Did it cause more death than avert?”
Segment 2503: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7022, Text: I would say, “I don’t know, because we don’t have the data on that.”
Segment 2504: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7026, Text: But let’s talk. We have to narrow in on what is it effective against the thing it’s supposed to fight?
Segment 2505: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7032, Text: Oh, well, a lot of them are, let me give you an example. The most popular vaccine in the world is the DTP vaccine. Diphtheria, tetanus and pertussis. It was introduced in this country around 1980. That vaccine caused so many injuries that Wyeth, which was the manufacturer, said to the Reagan administration, “We are now paying $20 in downstream liabilities for every dollar that we’re making in profits, and we are getting out of the business unless you give us permanent immunity from liability.”
Segment 2506: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7065, Text: And by the way, Reagan said at that time, “Why don’t you just make the vaccine safe?” And why is that? Because vaccines are inherently unsafe.
Segment 2507: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7078, Text: They said, “Unavoidably unsafe, you cannot make them safe.”
Segment 2508: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7082, Text: And so when Reagan wrote the bill and passed it, the bill says in its preambles, “Because vaccines are unavoidably unsafe.” And the Bruesewitz case, which was the Supreme Court case that upheld that bill uses that same language, vaccines cannot be made safe. They’re unavoidably unsafe. So this is what the law says.
Segment 2509: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7101, Text: Now, I just want to finish this story because this illustrates very well your question. The DTP vaccine was discontinued in this country and it was discontinued in Europe because so many kids were being injured by it. However, the WHO and Bill Gates gives it to 161 million African children every year. And Bill Gates went to the Danish government and asked them to support this program saying, “We’ve saved 30 million kids from dying from diptheria, tetanus and pertussis.”
Segment 2510: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7139, Text: The Danish government said, “Can you show us the data?” And he couldn’t. So the Danish government paid for a big study with Novo Nordisk, which is a Scandinavian vaccine company in West Africa. And they went to West Africa and they looked at the DTP vaccine for 30 years of data and they retained the best vaccine scientists in the world, these deities of African vaccine program. Peter Aaby, Sigrid Morganson, and a bunch of others. And they looked at 30 years of data for the DTP vaccine. And they came back and they were shocked by what they found.
Segment 2511: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7176, Text: They found that the vaccine was preventing kids from getting diptheria, tetanus and pertussis. But the girls who got that vaccine were 10 times more likely to die over the next six months than children who didn’t. Why is that? And they weren’t dying from anything anybody ever associated with the vaccine. They were dying of anemia, bilharzia, malaria, sepsis, and mainly pulmonary and respiratory disease, pneumonia.
Segment 2512: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7202, Text: Mainly pulmonary and respiratory disease, pneumonia. And it turns out that this is what research has found who were all pro-vaccine, by the way. They said that this vaccine is killing more children and than did their attendance and protected prior to the introduction of the vaccine and for 30 years nobody ever noticed it. The vaccine was providing protection against those target illnesses, but it had ruined the children’s immune systems. And they could not defend themselves against random infections that were harmless to most children.
Segment 2513: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7236, Text: But isn’t it nearly impossible to prove that link?
Segment 2514: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7239, Text: You can’t prove the link, all you can do is for any particular interest, illness or death, you can’t prove the link. But you can show statistically that if you get that vaccine, you’re more likely to die over the next six months than if you don’t. And those studies unfortunately are not done for any other vaccines. So for every other medicine, in order to get approval from the FDA, you have to do a placebo controlled trial prior to licensure, where you look at health outcomes among an exposed group, a group that gets it and compare those to a similarly situated group that gets placebo. The only medical intervention that does not receive, that does not undergo placebo controlled trials prior to licensure are vaccines. Not one of the 72 vaccines that are now mandated for our children have ever undergone a placebo controlled trial prior to licensure.
Segment 2515: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7298, Text: So I should say on that point, I’ve heard from a bunch of folks that disagree with you.
Segment 2516: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7304, Text: Okay.
Segment 2517: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7304, Text: Including polio. I mean, the testing is a really important point. Before licensure, placebo controlled randomized trials, polio received just that against the saline placebo control. So I’m confused why you say that they don’t go through that process. It seems like a lot of them do.
Segment 2518: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7330, Text: Here’s the thing is that I was saying that for many years because we couldn’t find any. And then in 2016, in March, President Trump ordered Dr. Fauci to meet with me. Dr. Fauci and Francis Collins, and I said to them during that meeting, “You have been saying that I’m not telling the truth when I said not one of these has undergone a prior pre-licensure placebo control.” And the polio may have had one post licensing, most of them haven’t. The polio may have, I don’t know. But I said, “Our question was prior to licensure, do you ever test these? And for safety?” And by the way, I think the polio vaccine did undergo a saline placebo trial prior licensure, but not for safety, only for efficacy. So I’m talking about safety trials now. Fauci told me, he had a whole tray of files there. He said, “I can’t find one now, but I’ll send you one.”
Segment 2519: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7406, Text: I said, “Just for any vaccines, send me one. Any of the 72 vaccines,” He never did. So we sued the HHS and after a year of stonewalling us, HHS came back and they gave us a letter saying we have no pre-licensing safety trial for any of the 72 vaccines. And that the letter from HHS, which settled our lawsuit against them because we had a FOIA lawsuit against them, is posted on CHD’s website. So anybody can go look at it. So if HHS had any study, I assume they would’ve given it to us and they can’t find one.
Segment 2520: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7448, Text: Well, let me zoom out because a lot of the details matter here, pre-licensure, what does placebo controlled mean? So this probably requires a rigorous analysis. And actually, at this point, it would be nice for me just to give the shout-out to other people much smarter than me that people should follow along with Robert F. Kennedy Jr, use their mind, learn and think. So one really awesome creator, I really recommend him is Dr. Dan Wilson. He hosts the Debunk the Funk Podcast. Vincent Racaniello, who hosts This Week in Virology. Brilliant guy, I’ve had him on the podcast. Somebody you’ve been battling with is Paul Offit, interesting Twitter, interesting books. People should, understand and read your books as well. And Eric Topol has a good Twitter and good books. And even Peter Hotez, I’ll ask you about him.
Segment 2521: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7503, Text: And people should, because Paul Offit published a substack recently debunking, I think my discussion with Joe Rogan. And we have published a debunk of his debunking. So if you read his stuff, you should read-
Segment 2522: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7529, Text: Read both.
Segment 2523: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7530, Text: Yes, you should read… And I would love to debate any of these guys.
Segment 2524: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7537, Text: So Joe Rogan proposed just such a debate, which is quite fascinating to see how much attention and how much funding it garnered the debate between you and Peter Hotez. Why do you think Peter rejected the offer?
Segment 2525: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7551, Text: I think, again, I’m not going to look into his head, but what I will say is if you’re a scientist and you’re making public recommendations based upon what you say is evidence-based science, you ought to be able to defend that. You ought to be able to defend it in a public forum and you ought to be able to defend it against all comers. So if you’re a scientist, science is rooted in logic and reason. And if you can’t use logic and reason to defend your position, and by the way, I know almost all of the studies, I’ve written books on them and we’ve made a big effort to assemble all the studies on both sides. And so, I’m prepared to talk about those studies and I’m prepared to submit them in advance and for each of the points. And by the way, I’ve done that with Peter Hotez, actually because I had this kind of informal debate several years ago with him, with a referee at that time.
Segment 2526: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7622, Text: And we were debating not only by phone but by email and on those emails, every point that he would make, I would cite science and he could never come back with science. He could never come back with publications. He would give publications that had nothing to do with, for example, thimerosal and vaccines, mercury based vaccines. He sent me one time, 16 studies to rebut something I’d said about thimerosal. And not one of those studies, they were all about the MMR vaccine, which doesn’t contain thimerosal. So it wasn’t like a real debate where you’re using reason and isolating points and having a rational discourse. I don’t blame him for not debating me because I don’t think he has the science.
Segment 2527: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7673, Text: Are there aspects of all the work you’ve done on vaccines, all the advocacy you’ve done, that you found out that you were not correct on, that you were wrong on, that you’ve changed your mind on?
Segment 2528: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7689, Text: Yeah, there are many times over time that I found that I’ve made mistakes and we correct those mistakes. I run a big organization and I do a lot of tweets. I’m very careful. For example, my Instagram, I was taken down for misinformation, but there was no misinformation on my Instagram. Everything that I cited on Instagram was cited or sourced to a government database or to peer reviewed science. But for example, the Defender, which was our organization’s newsletter, we summarized scientific reports all the time. That’s one of the things, the services that we provide. So we watch the PubMed and we watch the peer reviewed publications and we summarize them when they come out, we have made mistakes. When we make mistake, we are rigorous about acknowledging it, apologizing for it, and changing it. That’s what we do. I think we have one of the most robust fact checking operations anywhere in journalism today.
Segment 2529: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7749, Text: We actually do real science. And listen, I’ve put up on my Twitter account where there are numerous times that I’ve made mistakes on Twitter and I apologize for it. And people say to me, “Oh, that’s weird. I’ve never seen anybody apologize on Twitter.” But I think it’s really important at the only… Of course, human beings make mistakes. My book is 230 or 40, 50,000 words. There’s going to be a mistake in there. But you know what I say at the beginning of the book, “If you see a mistake in here, please notify me. I give away that people can notify me.” And if somebody points out a mistake, I’m going to change it. I’m not going to dig my feet in and say, “I’m not going to acknowledge this.”
Segment 2530: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7797, Text: So some of the things we’ve been talking about, you’ve been an outspoken contrarian on some very controversial topics. This has garnered some fame and recognition in part for being attacked and standing strong against those attacks. If I may say, for being a martyr, do you worry about this drug of martyrdom that might cloud your judgment?
Segment 2531: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7822, Text: First of all, I don’t consider myself a martyr and I’ve never considered myself a victim. I make choices about my life and I’m content with those choices and peaceful with them. I’m not trying to be a martyr or a hero or anything else. I’m doing what I think is right because I want to be peaceful inside of myself, but the only guard I have is fact-based reality. If you show me a scientific study that shows that I’m wrong, for example, if you come back and say, “Look, Bobby, here’s a safety study on polio that was done pre-licensure and used a real saline solution.” I’m going to put that on my Twitter and I’m going to say, “I was wrong, there is one out there.” But that’s all I can do.
Segment 2532: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7877, Text: All right. I have to ask, you are in great shape. Can you go through your diet and exercise routine?
Segment 2533: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7888, Text: I do intermittent fasting. So I start my first meal at around noon, and then I try to stop eating at six or seven. And then I hike every day.
Segment 2534: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7906, Text: Morning, evening?
Segment 2535: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7907, Text: In the morning. I go to a meeting first thing in the morning, 12, I’m eating. And then I hike uphill for a mile and a half up and a mile half down with my dogs and I do my meditations. And then I go to the gym and I go to the gym for 35 minutes. I do it short time and I’ve been exercising for 50 years. And what I’ve found is it’s sustainable if I do just the short periods and I do four different routines at the gym. And I never relax at the gym, I go in there and I have a very intense exercise. I lift, I mean, I could tell you what my routine is, but I do backs just one day, legs and then a miscellaneous. And I do 12.
Segment 2536: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=7956, Text: My first set of everything is I try to reach failure at 12 reps. And then my fourth set of everything is a strip set. I take a lot of vitamins. I can’t even list them to you here because I couldn’t even remember them at all. But I take a ton of vitamins and nutrients, I’m on an anti-aging protocol from my doctor that includes testosterone replacement. But I don’t take any anabolic steroids or anything like that. And the DRT I use is bioidentical to what my body produced.
Segment 2537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8005, Text: What are your thoughts on hormone therapy in general?
Segment 2538: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8009, Text: I talk to a lot of doctors about that stuff because I’m interested in health and I’ve heard really good things about it, but I’m definitely not an expert on it.
Segment 2539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8022, Text: About God. You wrote, “God talks to human beings through many vectors, wise people, organized religion, the great books of religions, through art, music and poetry. But nowhere with such detail and grace and joy as through creation. When we destroy nature, we diminish our capacity to sense the divine.” What is your relationship and what is your understanding of God? Who is God?
Segment 2540: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8049, Text: Well, God is incomprehensible. I mean, I guess, most philosophers would say we’re inside the mind of God. And so, it would be impossible for us to understand what’s actually God’s form is. But I mean, for me, let’s say this, when I was raised in a very deeply religious setting, so we went to church in the summer, oftentimes twice a day, morning mass. And we definitely went every Sunday. And we prayed in the morning, we prayed before and after every meal, we prayed at night, we sent a rosary, sometimes three rosaries a night. And my father read us the Bible. Whenever he was a home, we’d all get in the bed and he’d read us the Bible stories. And I went to Catholic schools, I went to Jesuit schools, I went to the nuns and I went to a Quaker school at one point. I became a drug addict when I was about 15 years old, about a year after my dad died. And I was addicted to drugs for 14 years.
Segment 2541: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8132, Text: During that time, when you’re an addict, you’re living against conscience. And when you’re living against… I was always trying to get off of drugs, never able to. But I never felt good about what I was doing. And when you’re living against conscious, you kind of push God to the periphery of your life. So I’ll call Him, he gets recedes and gets smaller. And then when I got sober, I knew that I had a couple of experiences. One is that I had a friend of my brothers, one of my brothers who died of this disease of addiction, had a good friend who used to take drugs with us and he became a Moonie. So he became a follower of Reverend Sun Myung Moon. And at that point, he had the same kind of compulsion that I had and yet it was completely removed from him.
Segment 2542: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8201, Text: And he used to come and hang out with us, but he would not want to take drugs. Even if I was taking them right in front of him, he was immune to it. He’d become impervious to that impulse. And when I first got sober, I knew that I did not want to be the kind of person who was waking up every day in white knuckling sobriety and just trying to resist through willpower. And by the way, I had iron willpower as a kid. I gave up candy for lent when I was 12 and I didn’t need it again until I was in college. I gave up desserts the next year for lent. And I didn’t ever eat another dessert till I was in college. And I was trying to bulk up for rugby and for sports. So I felt like I could do anything with my willpower. But somehow this particular thing, the addiction was completely impervious to it. And it was cunning, baffling, incomprehensible. I could not understand why I couldn’t just say no and then never do it again like I did with everything else.
Segment 2543: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8277, Text: And so, I was living against conscience and I thought about this guy and reflecting my own prejudices at that time in my life, I said to myself, I didn’t want to be like a drug addict who was wanting a drug all the time and just not being able to do it. I wanted to completely realign myself so that I was somebody who got up every day and just didn’t want to take drugs, never thought of them, kissed the wife and children and went to work and never thought about drugs the whole day. And I knew that people throughout history had done that. I’d read the lives of the saints. I knew St. Augustine had met a very dissolute youth and had this spiritual realignment transformation. I knew the same thing had happened to St. Paul at Damascus. The same thing had happened to St. Francis.
Segment 2544: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8335, Text: St. Francis also had a dissolute and fun-loving youth and had this deep spiritual realignment. And I knew that that happened to people throughout history. And I thought that’s what I needed, something like that. I had the example of this friend of mine and I used to think about him and I would think this again reflects the bias and probably the meanness of myself at that time. But I said, “I’d rather be dead than be a Moonie.” But I wish I somehow could distill that power that he got without becoming a religious nuisance. And at that time, I picked up a book by Carl Yung called Synchronicity and Yung, he was a psychiatrist, he was contemporary of Freud’s. Freud was his mentor, and Freud wanted him to be his replacement. But Freud was now out atheist and Yung was a deeply spiritual man.
Segment 2545: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8398, Text: He had these very intense and genuine spiritual experiences from when he was a little boy, from when he was three years old that he remembers biography is fascinating about him because he remembers them with such a detail. And he was interesting to me because he was very faithful scientist and I considered myself a science-based person from when I was little. And yet he had this spiritual dimension to him, which infused all of his thinking and really I think made him, branded his form of recovery or of treatment. And he thought that he had this experiment experience that he describes in this book where he ran one of the biggest sanitariums in Europe in Zurich. And he was sitting up on the third floor of this building and he’s talking to a patient who was describing her dream to him.
Segment 2546: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8461, Text: And the fulcrum of that dream was a scarab beetle, which was an insect that is very uncommon if at all in Northern Europe, but it’s a common figure in the iconography of Egypt and the hieroglyphics on the walls of the pyramids, etc. And while he was talking to her, he heard this bing, bing, bing on the window behind him and he didn’t want to turn around to take his attention off her. But finally, he does it in exasperation. He turns around, he throws up the window and a scarab beetle flies in and lands in his head and he shows it to the woman. And he says, “Is this what you was thinking of, this is what you were dreaming about.” And he was struck by that experience which was similar to other experiences he’s had like that. And that’s what synchronicity means, it’s an incident, not a coincidence.
Segment 2547: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8516, Text: And if you’re talking with somebody about somebody that you haven’t thought about in 20 years and that person calls on the phone, that’s synchronicity. And he believed it was a way that God intervened in our lives that broke all the rules of nature, that he had set up the rules of physics, the rules of mathematics, or to reach in and sort of tap us on the shoulder and say, “I’m here.” And so, he tried to reproduce that in a clinical setting and he would put one guy in one room and another guy in another room and have them flip cards and guess what the other guy had flipped. And he believed that if he could beat the laws of chance, laws of mathematics, that he would approve the existence of an unnatural law, a supernatural law. And that was the first step to proving the existence of a God.
Segment 2548: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8568, Text: He never succeeds in doing it. But he says in the book, “Even though I can’t prove using an empirical and scientific tools, the existence of a God, I can show through anecdotal evidence having seen thousands of patients come through with this institution, that people who believe in God get better faster and that the recovery is more enduring than people who don’t.” And for me, hearing that was more impactful than if he had claimed that he had proved the existence of God because I wouldn’t have believed that. But I was already at a mindset where I would’ve done anything I could to improve my chances of never having to take drugs again by even 1%. And if believing in God was going to help me, whether there’s a God up there or not, believing in one a self had the power to help me, I was going to do that.
Segment 2549: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8620, Text: So then the question is how do you start believing in something that you can’t see or smell or hear or touch or taste or acquire with your senses? And Yung provides the formula for that. And he says, “Act as if you fake it till you make it.” And so, that’s what I started doing. I just started pretending there was a God watching me all the time. And kind of life was a series of tests. And there was a bunch of moral decisions that I had to make every day. And these were all just little things that I did. But each one now for me had a moral dimension. Like when the alarm goes off, do I lay in bed for an extra 10 minutes with my indolent thoughts or do I jump right out of bed? Do I make my bed? Most important decision of the day.
Segment 2550: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8668, Text: Do I hang up the towels? When I go into the closet and pull out my blue jeans and a bunch of those wire hangers fall on the ground, do I shut the door and say, “I’m too important to do that. That’s somebody else’s job or not?” And so, do put the water in the ice tray before I put it in the freezer? Do I put the shopping cart back in the place that it’s supposed to go in the parking lot of the Safeway? And if I make a whole bunch of those choices that I maintain myself in a posture of surrender, which keeps me open to my higher power to my God. And when I do those things right, so much about addiction is about abuse of power, abuse of all of us have some power, whether it’s our good looks or whether it’s connections or education or family or whatever.
Segment 2551: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8733, Text: And there’s always a temptation to use those to fulfill self will. And the challenge is how do you use those always to serve instead God’s of will and the good of our community? And that to me, is kind of the struggle. But when I do that, I feel God’s power coming through me and that I can do things. I’m much more effective as a human being. That gnawing anxiety that I lived with for so many years and God, it’s gone and that I can put down the oars and hoist the sail and the wind takes me and I can see the evidence of it in my life. And the big thing, temptation for me is that when all these good things start happening in my life and the cash and prizes start flowing in, how do I maintain that posture of surrender? How do I stay surrender then when my inclination is to say to God, “Thanks God, I got it from here.” And drive the car off the cliff again.
Segment 2552: Speaker: , Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8809, Text: And so, I had a spiritual awakening and my desire for drugs and alcohol was lifted miraculously. And to me, it was as much a miracle as if I’d been able to walk on water because I had tried everything earnestly, sincerely and honestly for a decade to try to stop and I could not do it under my own power. And then all of a sudden, it was lifted effortlessly. So I saw that early evidence of God in my life and of the power, and I see it now every day of my life.
Segment 2553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8849, Text: So adding that moral dimension to all of your actions is how you were able to win that Kambu battle against the absurd.
Segment 2554: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8858, Text: Exactly.
Segment 2555: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8858, Text: Sisyphus with the Boulder.
Segment 2556: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8859, Text: It’s all the same thing. It’s the battle to just do the right thing.
Segment 2557: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8864, Text: Now Sisyphus was able to find somehow happiness. Yeah. Well, Bobby, thank you for the stroll through some of the most important moments in recent human history and for running for president. And thank you for talking today.
Segment 2558: Speaker: Robert F. Kennedy Jr, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8879, Text: Thank you, Lex.
Segment 2559: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=NPtBkw5uD-0&t=8881, Text: Thanks for listening to this conversation with Robert F. Kennedy Jr. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from John F. Kennedy. “Let us not seek the Republican answer or the Democratic answer, but the right answer. Let us not seek to fix the blame for the past. Instead, let us accept our own responsibility for the future.” Thank you for listening and hope to see you next time.
Segment 2560: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=0, Text: What possible ideas do you have for how human species ends?
Segment 2561: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3, Text: Sure. I think the most obvious way to me is wire heading. We end up amusing ourselves to death. We end up all staring at that infinite TikTok and forgetting to eat. Maybe it’s even more benign than this. Maybe we all just stop reproducing. Now, to be fair, it’s probably hard to get all of humanity.
Segment 2562: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=27, Text: Yeah. The interesting thing about humanity is the diversity in it.
Segment 2563: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=30, Text: Oh, yeah.
Segment 2564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=31, Text: Organisms in general. There’s a lot of weirdos out there, two of them are sitting here.
Segment 2565: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=36, Text: I mean, diversity in humanity is-
Segment 2566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=38, Text: With due respect.
Segment 2567: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=40, Text: I wish I was more weird.
Segment 2568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=44, Text: The following is a conversation with George Hotz, his third time on this podcast. He’s the founder of Comma.ai that seeks to solve autonomous driving and is the founder of a new company called tiny corp that created tinygrad, a neural network framework that is extremely simple with the goal of making it run on any device by any human easily and efficiently. As you know, George also did a large number of fun and amazing things from hacking the iPhone to recently joining Twitter for a bit as a “intern”, making the case for refactoring the Twitter code base.
Segment 2569: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=83, Text: In general he’s a fascinating engineer and human being, and one of my favorite people to talk to. This is a Lex Fridman podcast. To support it please check out our sponsors in the description. Now, dear friends, here’s George Hotz. You mentioned something in a stream about the philosophical nature of time. Let’s start with a wild question. Do you think time is an illusion?
Segment 2570: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=107, Text: You know, I sell phone calls to Comma for a thousand dollars and some guy called me. It’s a thousand dollars. You can talk to me for half an hour. He is like, “Yeah, okay. Time doesn’t exist and I really wanted to share this with you.” I’m like, “Oh, what do you mean time doesn’t exist?” I think time is a useful model, whether it exists or not. Right. Does quantum physics exist? Well, it doesn’t matter. It’s about whether it’s a useful model to describe reality. Is time maybe compressive?
Segment 2571: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=145, Text: Do you think there is an objective reality or is everything just useful models? Underneath it all is there an actual thing that we’re constructing models for?
Segment 2572: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=155, Text: I don’t know.
Segment 2573: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=159, Text: I was hoping you would know.
Segment 2574: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=160, Text: I don’t think it matters.
Segment 2575: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=162, Text: I mean, this connects to the models of constructive reality with machine learning, right?
Segment 2576: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=167, Text: Sure.
Segment 2577: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=169, Text: Is it just nice to have useful approximations of the world such that we can do something with it?
Segment 2578: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=175, Text: There are things that are real. [inaudible 00:02:57] complexity is real.
Segment 2579: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=179, Text: Yeah.
Segment 2580: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=179, Text: Yeah. The compressive-
Segment 2581: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=180, Text: Math.
Segment 2582: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=182, Text: Math is real. Yeah.
Segment 2583: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=183, Text: Should be a T-shirt.
Segment 2584: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=185, Text: I think hard things are actually hard. I don’t think P equals NP.
Segment 2585: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=189, Text: Ooh. Strong words.
Segment 2586: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=190, Text: Well, I think that’s the majority. I do think factoring is in P.
Segment 2587: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=194, Text: I don’t think you’re the person that follows the majority in all walks of life.
Segment 2588: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=198, Text: For that one I do
Segment 2589: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=199, Text: Yeah. In theoretical computer science, you’re one of the sheep. All right. To you time is a useful model.
Segment 2590: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=208, Text: Sure.
Segment 2591: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=209, Text: What were you talking about on the stream about time? Are you made of time?
Segment 2592: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=213, Text: If I remembered half the things I said on stream. Someday someone’s going to make a model of all of it and it’s going to come back to haunt me.
Segment 2593: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=220, Text: Someday soon?
Segment 2594: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=221, Text: Yeah, probably.
Segment 2595: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=222, Text: Would that be exciting to you or sad that there’s a George Hotz model?
Segment 2596: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=228, Text: I mean, the question is when the George Hotz model is better than George Hotz, like I am declining and the model is growing.
Segment 2597: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=234, Text: What is the metric by which you measure better or worse in that, if you are competing with yourself?
Segment 2598: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=240, Text: Maybe you can just play a game where you have the George Hotz answer and the George Hotz model answer and ask which people prefer.
Segment 2599: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=246, Text: People close to you or strangers?
Segment 2600: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=249, Text: Either one. It will hurt more when it’s people close to me, but both will be overtaken by the George Hotz model.
Segment 2601: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=256, Text: It’d be quite painful. Loved ones, family members would rather have the model over for Thanksgiving than you or significant others would rather sext with the large language model version of you.
Segment 2602: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=275, Text: Especially when it’s fine-tuned to their preferences.
Segment 2603: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=279, Text: Yeah. Well, that’s what we’re doing in a relationship. We’re just fine-tuning ourselves, but we’re inefficient with it because we’re selfish and greedy and so on. Language models can fine-tune more efficiently, more selflessly.
Segment 2604: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=291, Text: There’s a Star Trek Voyager episode where Kathryn Janeway lost in the delta quadrant makes herself a lover on the Holodeck, and the lover falls asleep on her arm and he snores a little bit. Janeway edits the program to remove that. Then of course the realization is, wait, this person’s terrible. It is actually all their nuances and quirks and slight annoyances that make this relationship worthwhile. I don’t think we’re going to realize that until it’s too late.
Segment 2605: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=324, Text: Well, I think a large language model could incorporate the flaws and the quirks and all that kind of stuff.
Segment 2606: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=330, Text: Just the perfect amount of quirks and flaws to make you charming without crossing the line.
Segment 2607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=336, Text: Yeah, and that’s probably a good approximation of the percent of time the language model should be cranky or an asshole or jealous or all this kind of stuff.
Segment 2608: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=352, Text: Of course it can and it will. All that difficulty at that point is artificial. There’s no more real difficulty.
Segment 2609: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=359, Text: What’s the difference between real and artificial?
Segment 2610: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=361, Text: Artificial difficulty is difficulty that’s like constructed or could be turned off with a knob. Real difficulty is like you’re in the woods and you got to survive.
Segment 2611: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=371, Text: If something cannot be turned off with a knob it’s real?
Segment 2612: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=376, Text: Yeah, I think so. I mean, you can’t get out of this by smashing the knob with a hammer. I mean, maybe you can, Into the Wild when Alexander Supertramp, he wants to explore something that’s never been explored before, but it’s the nineties. Everything’s been explored. He’s like, “Well, I’m just not going to bring a map.”
Segment 2613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=396, Text: Yeah.
Segment 2614: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=396, Text: I mean, no, you’re not exploring. You should have brought a map dude. You died. There was a bridge a mile from where you were camping.
Segment 2615: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=404, Text: How does that connect to the metaphor of the knob?
Segment 2616: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=406, Text: By not bringing the map, you didn’t become an explorer. You just smashed the thing.
Segment 2617: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=413, Text: Yeah.
Segment 2618: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=413, Text: Yeah. The difficulty is still artificial.
Segment 2619: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=416, Text: You failed before you started. What if we just don’t have access to the knob?
Segment 2620: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=420, Text: Well, that maybe is even scarier. We already exist in a world of nature, and nature has been fine-tuned over billions of years. To have humans build something and then throw the knob away in some grand romantic gesture is horrifying.
Segment 2621: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=441, Text: Do you think of us humans as individuals that are born and die or are we just all part of one living organism that is earth, that is nature?
Segment 2622: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=453, Text: I don’t think there’s a clear line there. I think it’s all kind of just fuzzy. I don’t know. I mean, I don’t think I’m conscious. I don’t think I’m anything. I think I’m just a computer program.
Segment 2623: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=464, Text: It’s all computation, everything running in your head is just computation.
Segment 2624: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=469, Text: Everything running in the universe is computation, I think. I believe the extended [inaudible 00:07:53] thesis.
Segment 2625: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=476, Text: There seems to be an embodiment to your particular computation. There’s a consistency.
Segment 2626: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=480, Text: Well, yeah, but I mean, models have consistency too.
Segment 2627: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=484, Text: Yeah.
Segment 2628: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=485, Text: Models that have been RLHF’d will continually say like, well, how do I murder ethnic minorities? Oh, well, I can’t let you do that, Hal. There’s a consistency to that behavior.
Segment 2629: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=495, Text: It’s all RLHF. We RLHF each other. We provide human feedback and thereby fine-tune these little pockets of computation. It’s still unclear why that pocket of computation stays with you for years. You have this consistent set of physics, biology, whatever you call the neurons firing like the electrical signals, the mechanical signals, all of that that seems to stay there. It contains information. It stores information, and that information permeates through time and stays with you. There’s like memory, there’s like sticky.
Segment 2630: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=541, Text: To be fair, a lot of the models we’re building today are very… Even RLHF is nowhere near as complex as the human loss function.
Segment 2631: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=548, Text: Reinforcement learning with human feedback.
Segment 2632: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=551, Text: When I talked about will GPT12 be AGI, my answer is no. Of course not. I mean, cross-entropy loss is never going to get you there. You need probably RL in fancy environments in order to get something that would be considered AGI-like. To ask the question about why? I don’t know. It’s just some quirk of evolution. I don’t think there’s anything particularly special about where I ended up, where humans ended up.
Segment 2633: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=580, Text: Okay, we have human level intelligence. Would you call that AGI, whatever we have, GI?
Segment 2634: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=587, Text: Look, actually, I don’t really even like the word AGI, but general intelligence is defined to be whatever humans have.
Segment 2635: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=595, Text: Okay, so why can GPT-12 not get us to AGI? Can we just linger on that?
Segment 2636: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=602, Text: If your loss function is categorical cross-entropy, if your loss function is just try to maximize compression. I have a SoundCloud I rap and I tried to get Chat-GPT to help me write raps and the raps that it wrote sounded like YouTube comment raps. You can go on any rap beat online and you can see what people put in the comments. It’s the most mid quality rap you can find.
Segment 2637: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=623, Text: Is mid good or bad?
Segment 2638: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=624, Text: Mid is bad.
Segment 2639: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=625, Text: Mid is bad.
Segment 2640: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=625, Text: It’s like mid.
Segment 2641: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=627, Text: Every time I talk to you, I learn new words. Mid.
Segment 2642: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=632, Text: Mid. Yeah.
Segment 2643: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=635, Text: I was like, is it like basic? Is that what mid means?
Segment 2644: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=637, Text: Kind of. It’s like middle of the curve, right?
Segment 2645: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=639, Text: Yeah.
Segment 2646: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=640, Text: There’s like that intelligence curve and you have the dumb guy, the smart guy, and then the mid guy. Actually being the mid guy is the worst. The smart guy is like I put all my money in Bitcoin. The mid guy is like, “You can’t put money in Bitcoin. It’s not real money.”
Segment 2647: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=655, Text: All of it is a genius meme. That’s another interesting one. Memes, the humor, the idea, the absurdity encapsulated in a single image and it just propagates virally between all of our brains. I didn’t get much sleep last night, so I sound like I’m high. I swear I’m not. Do you think we have ideas or ideas have us?
Segment 2648: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=684, Text: I think that we’re going to get super scary memes once the AIs actually are superhuman.
Segment 2649: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=690, Text: You think AI will generate memes?
Segment 2650: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=691, Text: Of course.
Segment 2651: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=692, Text: You think it’ll make humans laugh?
Segment 2652: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=695, Text: I think it’s worse than that. Infinite Jest, it’s introduced in the first 50 pages, is about a tape that once you watch it once you only ever want to watch that tape. In fact, you want to watch the tape so much that someone says, “Okay, here’s a hack saw. Cut off your pinky and then I’ll let you watch the tape again.” You’ll do it. We’re actually going to build that, I think, but it’s not going to be one static tape. I think the human brain is too complex to be stuck in one static tape like that. If you look at ant brains, maybe they can be stuck on a static tape, but we’re going to build that using generative models. We’re going to build the TikTok that you actually can’t look away from.
Segment 2653: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=736, Text: TikTok is already pretty close there, but the generation is done by humans. The algorithm is just doing their recommendation. If the algorithm is also able to do the generation.
Segment 2654: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=745, Text: Well, it’s a question about how much intelligence is behind it. The content is being generated by let’s say, one humanity worth of intelligence, and you can quantify a humanity, its exaflops, [inaudible 00:12:40], but you can quantify it. Once that generation is being done by a hundred humanities, you’re done.
Segment 2655: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=768, Text: It’s actually scale that’s the problem, but also speed. Yeah. What if it’s manipulating the very limited human dopamine engine, so porn? Imagine just TikTok, but for porn.
Segment 2656: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=785, Text: Yeah.
Segment 2657: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=786, Text: It’s like a brave new world.
Segment 2658: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=788, Text: I don’t even know what it’ll look like. Again, you can’t imagine the behaviors of something smarter than you, but a super intelligent, an agent that just dominates your intelligence so much will be able to completely manipulate you.
Segment 2659: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=804, Text: Is it possible that it won’t really manipulate? It’ll just move past us. It’ll just exist the way water exists or the air exists.
Segment 2660: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=813, Text: You see, and that’s the whole AI safety thing. It’s not the machine that’s going to do that. It’s other humans using the machine that are going to do that to you.
Segment 2661: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=824, Text: Because the machine is not interested in hurting humans. It’s just…
Segment 2662: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=827, Text: The machine is a machine, but the human gets the machine and there’s a lot of humans out there very interested in manipulating you.
Segment 2663: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=835, Text: Well, let me bring up, Eliezer Yudkowsky who recently sat where you’re sitting. He thinks that AI will almost surely kill everyone. Do you agree with him or not?
Segment 2664: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=849, Text: Yes, but maybe for a different reason.
Segment 2665: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=854, Text: Then I’ll try to get you to find hope or we could find a note to that answer. But why yes?
Segment 2666: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=863, Text: Okay. Why didn’t nuclear weapons kill everyone?
Segment 2667: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=866, Text: That’s a good question.
Segment 2668: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=867, Text: I think there’s an answer. I think it’s actually very hard to deploy nuclear weapons tactically. It’s very hard to accomplish tactical objectives. Great. I can nuke their country. I have an irradiated pile of rubble. I don’t want that.
Segment 2669: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=879, Text: Why not?
Segment 2670: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=880, Text: Why don’t I want an irradiated pile of rubble?
Segment 2671: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=883, Text: Yeah.
Segment 2672: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=883, Text: For all the reasons no one wants an irradiated pile of rubble.
Segment 2673: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=886, Text: Oh, because you can’t use that land for resources. You can’t populate the land.
Segment 2674: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=892, Text: Yeah. Well, what you want, a total victory in a war is not usually the irradiation and eradication of the people there. It’s the subjugation and domination of the people.
Segment 2675: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=903, Text: Okay. You can’t use this strategically, tactically in a war to help gain a military advantage. It’s all complete destruction. All right.
Segment 2676: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=916, Text: Yeah.
Segment 2677: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=916, Text: There’s egos involved. It’s still surprising that nobody pressed the big red button.
Segment 2678: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=922, Text: It’s somewhat surprising. You see, it’s the little red button that’s going to be pressed with AI, and that’s why we die. It’s not because the AI, if there’s anything in the nature of AI, it’s just the nature of humanity.
Segment 2679: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=937, Text: What’s the algorithm behind the little red button? What possible ideas do you have for how human species ends?
Segment 2680: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=945, Text: Sure. I think the most obvious way to me is wire heading. We end up amusing ourselves to death. We end up all staring at that infinite TikTok and forgetting to eat. Maybe it’s even more benign than this. Maybe we all just stop reproducing. Now, to be fair, it’s probably hard to get all of humanity.
Segment 2681: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=970, Text: Yeah.
Segment 2682: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=971, Text: Yeah. It probably is.
Segment 2683: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=975, Text: The interesting thing about humanity is the diversity in it.
Segment 2684: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=977, Text: Oh yeah.
Segment 2685: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=978, Text: Organisms in general. There’s a lot of weirdos out there. Well, two of them are sitting here.
Segment 2686: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=983, Text: I mean, diversity in humanity is-
Segment 2687: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=985, Text: With due respect.
Segment 2688: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=987, Text: I wish I was more weird. No, look, I’m drinking Smart water, man. That’s like a Coca-Cola product, right?
Segment 2689: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=993, Text: You went corporate George Hotz.
Segment 2690: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=995, Text: Yeah, I went corporate. No, the amount of diversity and humanity I think is decreasing. Just like all the other biodiversity on the planet.
Segment 2691: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1002, Text: Oh boy. Yeah.
Segment 2692: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1003, Text: Right.
Segment 2693: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1004, Text: Social media’s not helping.
Segment 2694: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1005, Text: Go eat McDonald’s in China.
Segment 2695: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1007, Text: Yeah.
Segment 2696: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1009, Text: Yeah. No, it’s the interconnectedness that’s doing it.
Segment 2697: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1014, Text: Oh, that’s interesting. Everybody starts relying on the connectivity of the internet. Over time, that reduces the diversity, the intellectual diversity, and then that gets everybody into a funnel. There’s still going to be a guy in Texas.
Segment 2698: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1028, Text: There is.
Segment 2699: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1029, Text: And a bunker.
Segment 2700: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1030, Text: To be fair, do I think AI kills us all? I think AI kills everything we call society today. I do not think it actually kills the human species. I think that’s actually incredibly hard to do.
Segment 2701: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1042, Text: Yeah, but society, if we start over, that’s tricky. Most of us don’t know how to do most things.
Segment 2702: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1048, Text: Yeah, but some of us do, and they’ll be okay and they’ll rebuild after the great AI.
Segment 2703: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1056, Text: What’s rebuilding look like? How much do we lose? What has human civilization done that’s interesting? Combustion engine, electricity. So power and energy. That’s interesting. How to harness energy.
Segment 2704: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1074, Text: Whoa, whoa, whoa, whoa. They’re going to be religiously against that.
Segment 2705: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1078, Text: Are they going to get back to fire?
Segment 2706: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1082, Text: Sure. I mean, it’s be like some kind of Amish looking kind of thing. I think they’re going to have very strong taboos against technology.
Segment 2707: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1093, Text: Technology is almost like a new religion. Technology is the devil and nature is God.
Segment 2708: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1100, Text: Sure.
Segment 2709: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1100, Text: Closer to nature. Can you really get away from AI if it destroyed 99% of the human species, isn’t somehow have a hold like a stronghold?
Segment 2710: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1110, Text: Well, what’s interesting about everything we build, I think we’re going to build super intelligence before we build any sort of robustness in the AI. We cannot build an AI that is capable of going out into nature and surviving like a bird. A bird is an incredibly robust organism. We’ve built nothing like this. We haven’t built a machine that’s capable of reproducing.
Segment 2711: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1138, Text: I work with Lego robots a lot now. I have a bunch of them. They’re mobile. They can’t reproduce. All they need is, I guess you’re saying they can’t repair themselves. If you have a large number, if you have a hundred million of them-
Segment 2712: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1153, Text: Let’s just focus on them reproducing. Do they have microchips in them?
Segment 2713: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1156, Text: Mm-hmm (affirmative).
Segment 2714: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1156, Text: Okay. Then do they include a fab?
Segment 2715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1160, Text: No.
Segment 2716: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1161, Text: Then how are they going to reproduce?
Segment 2717: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1162, Text: Well, it doesn’t have to be all on board. They can go to a factory, to a repair shop.
Segment 2718: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1169, Text: Yeah, but then you’re really moving away from robustness.
Segment 2719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1173, Text: Yes.
Segment 2720: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1173, Text: All of life is capable of reproducing without needing to go to a repair shop. Life will continue to reproduce in the complete absence of civilization. Robots will not. If the AI apocalypse happens, I mean the AIs are going to probably die out because I think we’re going to get, again, super intelligence long before we get robustness.
Segment 2721: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1195, Text: What about if you just improve the fab to where you just have a 3D printer that can always help you?
Segment 2722: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1203, Text: Well, that’d be very interesting. I’m interested in building that.
Segment 2723: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1206, Text: Of course, you are. How difficult is that problem to have a robot that basically can build itself?
Segment 2724: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1215, Text: Very, very hard.
Segment 2725: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1216, Text: I think you’ve mentioned this to me or somewhere where people think it’s easy conceptually.
Segment 2726: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1224, Text: Then they remember that you’re going to have to have a fab.
Segment 2727: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1227, Text: Yeah, on board.
Segment 2728: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1230, Text: Of course.
Segment 2729: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1230, Text: 3D printer that prints a 3D printer.
Segment 2730: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1234, Text: Yeah.
Segment 2731: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1234, Text: On legs. Why’s that hard?
Segment 2732: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1237, Text: Well, I mean, a 3D printer is a very simple machine, right? Okay, you’re going to print chips, you’re going to have an atomic printer. How are you going to dope the silicon?
Segment 2733: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1247, Text: Yeah.
Segment 2734: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1248, Text: Right. How you going to etch the silicon?
Segment 2735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1251, Text: You’re going to have a very interesting kind of fab if you want to have a lot of computation on board. You can do structural type of robots that are dumb.
Segment 2736: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1264, Text: Yeah, but structural type of robots aren’t going to have the intelligence required to survive in any complex environment.
Segment 2737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1271, Text: What about like ants type of systems? We have trillions of them.
Segment 2738: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1275, Text: I don’t think this works. I mean, again, ants at their very core are made up of cells that are capable of individually reproducing.
Segment 2739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1282, Text: They’re doing quite a lot of computation that we’re taking for granted.
Segment 2740: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1286, Text: It’s not even just the computation. It’s that reproduction is so inherent. There’s two stacks of life in the world. There’s the biological stack and the silicon stack. The biological stack starts with reproduction. Reproduction is at the absolute core. The first proto-RNA organisms were capable of reproducing. The silicon stack, despite, as far as it’s come, is nowhere near being able to reproduce.
Segment 2741: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1311, Text: Yeah, So the fab movement, digital fabrication, fabrication in the full range of what that means is still in the early stages.
Segment 2742: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1324, Text: Yeah.
Segment 2743: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1324, Text: You’re interested in this world?
Segment 2744: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1326, Text: Even if you did put a fab on the machine, let’s say, okay, yeah, we can build fabs. We know how to do that as humanity. We can probably put all the precursors that build all the machines in the fabs also in the machine. First off, this machine’s going to be absolutely massive. I mean, we almost have a… Think of the size of the thing required to reproduce a machine today. Is our civilization capable of reproduction? Can we reproduce our civilization on Mars?
Segment 2745: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1354, Text: If we were to construct a machine that is made up of humans, like a company that can reproduce itself?
Segment 2746: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1360, Text: Yeah.
Segment 2747: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1360, Text: I don’t know. It feels like 115 people.
Segment 2748: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1367, Text: I think it’s so much harder than that.
Segment 2749: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1370, Text: 120? I’m looking for a number.
Segment 2750: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1372, Text: Let’s see. I believe that Twitter can be run by 50 people. I think that this is going to take most of, it’s just most of society. We live in one globalized world now.
Segment 2751: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1384, Text: No, but you’re not interested in running Twitter, you’re interested in seeding. You want to seed a civilization and then because humans can like have sex.
Segment 2752: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1394, Text: Yeah. Okay. You’re talking about the humans reproducing and basically what’s the smallest self-sustaining colony of humans?
Segment 2753: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1399, Text: Yeah.
Segment 2754: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1400, Text: Yeah. Okay, fine but they’re not going to be making five nanometer chips.
Segment 2755: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1402, Text: Over time they will. We have to expand our conception of time here going back to the original timescale. I mean, over across maybe a hundred generations we’re back to making chips. No? If you seed the colony correctly.
Segment 2756: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1420, Text: Maybe, or maybe they’ll watch our colony die out over here and be like, “We’re not making chips. Don’t make chips.”
Segment 2757: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1426, Text: No, but you have to seed that colony correctly.
Segment 2758: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1428, Text: Whatever you do, don’t make chips. Chips are what led to their downfall.
Segment 2759: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1434, Text: Well, that is the thing that humans do. They construct a devil a good thing and a bad thing, and they really stick by that and then they murder each other over that. There’s always one asshole in the room who murders everybody and usually makes tattoos and nice branding with flags and stuff.
Segment 2760: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1450, Text: Do you need that asshole, that’s the question. Humanity works really hard today to get rid of that asshole, but I think they might be important.
Segment 2761: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1456, Text: Yeah. This whole freedom of speech thing, it’s the freedom of being an asshole seems kind of important.
Segment 2762: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1462, Text: That’s right.
Segment 2763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1463, Text: Man. This thing, this fab, this human fab that we constructed, this human civilization is pretty interesting. Now it’s building artificial copies of itself or artificial copies of various aspects of itself that seem interesting like intelligence. I wonder where that goes.
Segment 2764: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1484, Text: I like to think it’s just another stack for life. We have the biostack life. We’re a biostack life, and then the silicon stack life.
Segment 2765: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1490, Text: It seems like the ceiling, or there might not be a ceiling, or at least the ceiling is much higher for the silicon stack.
Segment 2766: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1497, Text: Oh, no. We don’t know what the ceiling is for the biostack either. The biostack just seems to move slower. You have Moore’s law, which is not dead despite many proclamations.
Segment 2767: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1509, Text: In the biostack or the silicon stack?
Segment 2768: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1511, Text: In the silicon stack. You don’t have anything like this in the biostack. I have a meme that I posted. I tried to make a meme. It didn’t work too well, but I posted a picture of Ronald Reagan and Joe Biden, and you look, this is 1980 and this is 2020.
Segment 2769: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1524, Text: Yeah.
Segment 2770: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1524, Text: These two humans are basically the same, right? No, there’s been no change in humans in the last 40 years. Then I posted a computer from 1980 in a computer from 2020. Wow.
Segment 2771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1541, Text: Yeah. With their early stages, which is why you said, when you said the size of the fab required to make another fab is very large right now.
Segment 2772: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1552, Text: Yeah.
Segment 2773: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1553, Text: Computers were very large 80 years ago, and they got pretty tiny and people are starting to want to wear them on their face in order to escape reality. That’s a thing. In order to live inside the computer, but a screen right here, I don’t have to see the rest of you assholes.
Segment 2774: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1578, Text: I’ve been ready for a long time.
Segment 2775: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1579, Text: You like virtual reality?
Segment 2776: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1580, Text: I love it.
Segment 2777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1582, Text: Do you want to live there?
Segment 2778: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1583, Text: Yeah.
Segment 2779: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1585, Text: Yeah. Part of me does too. How far away are we do you think?
Segment 2780: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1591, Text: Judging from what you can buy today? Far, very far.
Segment 2781: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1595, Text: I got to tell you that I had the experience of Meta’s Codec avatar where it’s a ultra-high resolution scan. It looked real.
Segment 2782: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1611, Text: I mean, the headsets just are not quite at eye resolution yet. I haven’t put on any headset where I’m like, “Oh, this could be the real world.” Whereas when I put good headphones on, audio is there. We can reproduce audio that I’m like, “I’m actually in a jungle right now. If I close my eyes, I can’t tell I’m not.”
Segment 2783: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1629, Text: Yeah. Then there’s also smell and all that kind of stuff.
Segment 2784: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1631, Text: Sure.
Segment 2785: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1633, Text: I don’t know. The power of imagination or the power of the mechanism in the human mind that fills the gaps that reaches and wants to make the thing you see in the virtual world real to you. I believe in that power.
Segment 2786: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1649, Text: Or humans want to believe.
Segment 2787: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1650, Text: Yeah. What if you’re lonely? What if you’re sad? What if you’re really struggling in life, and here’s a world where you don’t have to struggle anymore?
Segment 2788: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1659, Text: Humans want to believe so much that people think the large language models are conscious. That’s how much humans want to believe.
Segment 2789: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1666, Text: Strong words, he’s throwing left and right hooks. Why do you think large language models are not conscious?
Segment 2790: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1673, Text: I don’t think I’m conscious.
Segment 2791: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1675, Text: Oh, so what is consciousness then George Hotz?
Segment 2792: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1678, Text: It’s like what it seems to mean to people it’s just a word that atheists use for souls.
Segment 2793: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1684, Text: Sure. That doesn’t mean soul is not an interesting word.
Segment 2794: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1688, Text: If consciousness is a spectrum, I’m definitely way more conscious than the large language models are. I think the large language models are less conscious than a chicken.
Segment 2795: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1699, Text: When is the last time you’ve seen a chicken?
Segment 2796: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1702, Text: In Miami, a couple months ago.
Segment 2797: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1706, Text: No. A living chicken.
Segment 2798: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1707, Text: Just living chickens walking around Miami. It’s crazy.
Segment 2799: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1710, Text: Like on the street?
Segment 2800: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1710, Text: Yeah.
Segment 2801: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1711, Text: Like a chicken?
Segment 2802: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1712, Text: A chicken. Yeah.
Segment 2803: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1716, Text: All right. I was trying to call you out, like a good journalist, and I got shut down. Okay. You don’t think much about this subjective feeling that it feels like something to exist. Then as an observer, you can have a sense that an entity is not only intelligent, but has a subjective experience of its reality, like a self-awareness that is capable of suffering, of hurting, of being excited by the environment in a way that’s not merely an artificial response, but a deeply felt one.
Segment 2804: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1762, Text: Humans want to believe so much that if I took a rock and a Sharpie and drew a sad face on the rock, they’d think the rock is sad.
Segment 2805: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1772, Text: You’re saying when we look in the mirror, we apply the same smiley face with rock?
Segment 2806: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1776, Text: Pretty much, yeah.
Segment 2807: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1778, Text: Isn’t that weird though, that you’re not conscious?
Segment 2808: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1782, Text: No.
Segment 2809: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1783, Text: You do believe in consciousness?
Segment 2810: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1785, Text: Not really.
Segment 2811: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1786, Text: It’s unclear. Okay. To you it’s like a little symptom of the bigger thing that’s not that important.
Segment 2812: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1793, Text: Yeah. I mean, it’s interesting that the human systems seem to claim that they’re conscious, and I guess it says something in a straight up, even if you don’t believe in consciousness, what do people mean when they say consciousness? There’s definitely meanings to it.
Segment 2813: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1806, Text: What’s your favorite thing to eat?
Segment 2814: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1811, Text: Pizza.
Segment 2815: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1812, Text: Cheese pizza. What are the toppings?
Segment 2816: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1813, Text: I like cheese pizza. I like pepperoni.
Segment 2817: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1814, Text: Don’t say pineapple.
Segment 2818: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1815, Text: No, I don’t like pineapple.
Segment 2819: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1816, Text: Okay. Pepperoni pizza.
Segment 2820: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1817, Text: If they put any ham on it I’ll just feel bad.
Segment 2821: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1820, Text: What’s the best pizza? What are we talking about here? Do you like cheap, crappy pizza?
Segment 2822: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1824, Text: A Chicago deep dish cheese pizza. Oh, that’s my favorite.
Segment 2823: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1827, Text: There you go. You bite into a Chicago deep dish pizza, and it feels like, so you were starving, you haven’t eaten for 24 hours. You just bite in and you’re hanging out with somebody that matters a lot to you. You’re there with the pizza.
Segment 2824: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1839, Text: That sounds real nice, man.
Segment 2825: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1840, Text: Yeah. All right. It feels like something I’m George motherfucking Hotz eating a fucking Chicago deep dish pizza. There’s just the full peak living experience of being human, the top of the human condition.
Segment 2826: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1857, Text: Sure.
Segment 2827: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1858, Text: It feels like something to experience that.
Segment 2828: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1860, Text: Mm-hmm (affirmative).
Segment 2829: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1862, Text: Why does it feel like something? That’s consciousness, isn’t it?
Segment 2830: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1866, Text: If that’s the word you want to use to describe it. Sure. I’m not going to deny that that feeling exists. I’m not going to deny that I experienced that feeling. I guess what I take issue to is that there’s some like how does it feel to be a web server? Do 404s hurt?
Segment 2831: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1883, Text: Not yet.
Segment 2832: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1884, Text: How would you know what suffering looked like? Sure you can recognize a suffering dog because we’re the same stack as the dog. All the biostack stuff kind of, especially mammals. It’s really easy. You can…
Segment 2833: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1895, Text: Game recognizes game.
Segment 2834: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1897, Text: Yeah. Versus the silicon stack stuff it’s like, you have no idea. Wow the little thing has learned to mimic. Then I realized that that’s all we are too. Well, look, the little thing has learned to mimic.
Segment 2835: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1914, Text: Yeah. I guess, yeah. 404 could be suffering, but it’s so far from our kind-
Segment 2836: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1923, Text: … So far from our kind of living organism, our kind of stack. It feels like AI can start maybe mimicking the biological stack better, better, better. It’s trained.
Segment 2837: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1933, Text: We trained it, yeah.
Segment 2838: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1935, Text: In that, maybe that’s the definition of consciousness is the bio stack consciousness.
Segment 2839: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1940, Text: The definition of consciousness is how close something looks to human. Sure, I’ll give you that one.
Segment 2840: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1944, Text: No, how close something is to the human experience.
Segment 2841: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1948, Text: Sure. It’s a very anthropro-centric definition, but…
Segment 2842: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1953, Text: Well, that’s all we got.
Segment 2843: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1954, Text: Sure. No. I think there’s a lot of value in it. Look, I just started my second company. My third company will be AI Girlfriends. I mean it.
Segment 2844: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1963, Text: I want to find out what your fourth company is after that.
Segment 2845: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1966, Text: Oh, wow.
Segment 2846: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=1966, Text: I think once you have AI girlfriends, oh boy, does it get interesting. Well, maybe let’s go there. The relationships with AI, that’s creating human-like organisms. Part of being human is being conscious, is having the capacity to suffer, having the capacity to experience this life richly, in such a way that you can empathize, that AI system going to empathize with you, and you can empathize with it, or you can project your anthropomorphic sense of what the other entity is experiencing.
Segment 2847: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2002, Text: An AI model would need to create that experience inside your mind. It doesn’t seem that difficult.
Segment 2848: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2008, Text: Yeah. Okay, so here’s where it actually gets totally different. When you interact with another human, you can make some assumptions.
Segment 2849: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2017, Text: Yeah.
Segment 2850: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2018, Text: When you interact with these models, you can’t. You can make some assumptions that other human experiences suffering and pleasure in a pretty similar way to you do, the golden rule applies. With an AI model, this isn’t really true. These large language models are good at fooling people, because they were trained on a whole bunch of human data and told to mimic it.
Segment 2851: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2039, Text: Yep, but if the AI system says, “Hi, my name is Samantha,” it has a backstory. “Went to college here and there,” maybe it’ll integrate this in the AI system.
Segment 2852: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2051, Text: I made some chatbots. I gave them back stories. It was lots of fun. I’m so happy when Lama came out.
Segment 2853: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2056, Text: Yeah. Well, we’ll talk about Lama, we’ll talk about all that. The rock with a smiley face, it seems pretty natural for you to anthropomorphize that thing and then start dating it. Before you know it, you’re married and have kids
Segment 2854: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2073, Text: With a rock?
Segment 2855: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2074, Text: With a rock, and there’s pictures on Instagram with you and a rock and a smiley face.
Segment 2856: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2078, Text: To be fair, something that people generally look for when they’re looking for someone to date is intelligence in some form. The rock doesn’t really have intelligence. Only a pretty desperate person would date a rock.
Segment 2857: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2090, Text: I think we’re all desperate, deep down.
Segment 2858: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2092, Text: Oh, not rock level desperate.
Segment 2859: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2094, Text: All right. Not rock level desperate, but AI level desperate. I don’t know. I think all of us have a deep loneliness. It just feels like the language models are there.
Segment 2860: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2109, Text: Oh, I agree. You know what? I won’t even say this so cynically. I will actually say this in a way that I want AI friends. I do.
Segment 2861: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2114, Text: Yeah.
Segment 2862: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2116, Text: I would love to. Again, the language models now are still a little… People are impressed with these GPT things, or the Copilot, the coding one. I’m like, “Okay, this is junior engineer level, and these people are Fiverr level artists and copywriters.” Okay, great. We got Fiverr and junior engineers. Okay, cool. This is just the start, and it will get better, right? I can’t wait to have AI friends who are more intelligent than I am.
Segment 2863: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2150, Text: Fiverr is just a temporary, it’s not the ceiling?
Segment 2864: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2152, Text: No, definitely not.
Segment 2865: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2153, Text: Does it count as cheating when you’re talking to an AI model? Emotional cheating?
Segment 2866: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2163, Text: That’s up to you and your human partner to define.
Segment 2867: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2167, Text: Oh, you have to. All right.
Segment 2868: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2168, Text: You to have that conversation, I guess.
Segment 2869: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2172, Text: All right. Integrate that with porn and all this stuff.
Segment 2870: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2176, Text: Well, no, it’s similar kind of to porn.
Segment 2871: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2178, Text: Yeah.
Segment 2872: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2178, Text: Yeah. I think people in relationships have different views on that.
Segment 2873: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2183, Text: Yeah, but most people don’t have serious, open conversations about all the different aspects of what’s cool and what’s not. It feels like AI is a really weird conversation to have.
Segment 2874: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2198, Text: The porn one is a good branching off.
Segment 2875: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2200, Text: For sure.
Segment 2876: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2200, Text: One of my scenarios that I put in my chatbot is a nice girl named Lexi, she’s 20. She just moved out to LA. She wanted to be an actress, but she started doing Only Fans instead. You’re on a date with her. Enjoy.
Segment 2877: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2216, Text: Oh, man. Yeah. If you’re actually dating somebody in real life, is that cheating? I feel like it gets a little weird.
Segment 2878: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2225, Text: Sure.
Segment 2879: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2225, Text: It gets real weird. It’s like, what are you allowed to say to an AI bot? Imagine having that conversation with a significant other.
Segment 2880: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2231, Text: These are all things for people to define in their relationships. What it means to be human is just going to start to get weird.
Segment 2881: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2237, Text: Especially online. How do you know? There’ll be moments when you’ll have what you think is a real human you’re interacting with on Twitter for years, and you realize it’s not.
Segment 2882: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2248, Text: I spread, I love this meme, heaven banning. You hear about shadow-banning?
Segment 2883: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2253, Text: Yeah.
Segment 2884: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2254, Text: Right. Shadow-banning, okay, you post, no one can see it. Heaven banning, you post. No one can see it, but a whole lot of AIs are spot up to interact with you.
Segment 2885: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2264, Text: Well, maybe that’s what the way human civilization ends is all of us are heaven banned.
Segment 2886: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2268, Text: There’s a great, it’s called My Little Pony Friendship is optimal. It’s a sci-fi story that explores this idea.
Segment 2887: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2276, Text: Friendship is Optimal.
Segment 2888: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2277, Text: Friendship is Optimal.
Segment 2889: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2278, Text: Yeah. I’d like to have some, at least on the intellectual realm, some AI friends that argue with me. The romantic realm is weird, definitely weird, but not out of the realm of the kind of weirdness that human civilization is capable of, I think.
Segment 2890: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2300, Text: Look, I want it. If no one else wants it, I want it.
Segment 2891: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2303, Text: Yeah. I think a lot of people probably want it. There’s a deep loneliness.
Segment 2892: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2307, Text: I’ll fill their loneliness, and it just will only advertise to you some of the time.
Segment 2893: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2313, Text: Yeah. Maybe the conceptions of monogamy change too. I grew up in a time, I value monogamy, but maybe that’s a silly notion when you have arbitrary number of AI systems.
Segment 2894: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2323, Text: Yeah, on this interesting path from rationality to polyamory. Yeah. That doesn’t make sense for me,
Segment 2895: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2330, Text: For you, but you’re just a biological organism who was born before the internet really took off.
Segment 2896: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2338, Text: The crazy thing is, culture is whatever we define it as. These things are not… [inaudible 00:39:04] a problem and moral philosophy, right? Okay. What might be that computers are capable of mimicking girlfriends perfectly. They passed the girlfriend Turing test, but that doesn’t say anything about ought.
Segment 2897: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2358, Text: That doesn’t say anything about how we ought to respond to them as a civilization. That doesn’t say we ought to get rid of monogamy. Right. That’s a completely separate question, really, a religious one.
Segment 2898: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2367, Text: Girlfriend Turing test. I wonder what that looks like.
Segment 2899: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2370, Text: Girlfriend Turing test.
Segment 2900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2371, Text: Are you writing that? Will you be the Alan Turing of the 21st century that writes the Girlfriend Turing test?
Segment 2901: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2378, Text: No, of course, my AI girlfriends, their goal is to pass the girlfriend Turing test.
Segment 2902: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2383, Text: No, but there should be a paper that kind of defines the test. The question is if it’s deeply personalized, or if there’s a common thing that really gets everybody.
Segment 2903: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2395, Text: Yeah. Look, we’re a company. We don’t have to get everybody. We just have to get a large enough clientele to stay with us.
Segment 2904: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2401, Text: I like how you’re already thinking company. All right. Before we go to company number three and company number four, let’s go to company number two.
Segment 2905: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2409, Text: All right.
Segment 2906: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2409, Text: Tiny Corp, possibly one of the greatest names of all time for a company. You’ve launched a new company called Tiny Corp that leads the development of Tinygrad. What’s the origin story of Tiny Corp and Tinygrad?
Segment 2907: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2425, Text: I started Tinygrad as a toy project, just to teach myself, okay, what is a convolution? What are all these options you can pass to them? What is the derivative of convolution? Very similar to Karpathy wrote Micrograd. I’m very similar. Then I started realizing, I started thinking about AI chips. I started thinking about chips that run AI. I was like, “Well, okay. This is going to be a really big problem. If Nvidia becomes a monopoly here, how long before Nvidia is nationalized?”
Segment 2908: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2464, Text: One of the reasons to start Tiny Corp is to challenge Nvidia.
Segment 2909: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2470, Text: It’s not so much to challenge Nvidia. Actually, I like Nvidia. It’s to make sure power stays decentralized.
Segment 2910: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2481, Text: Yeah. Here, it’s computational power. To you, Nvidia is kind of locking down the computational power of the world.
Segment 2911: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2491, Text: Nvidia becomes just like 10X better than everything else, you’re giving a big advantage to somebody who can secure Nvidia as a resource.
Segment 2912: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2501, Text: Yeah.
Segment 2913: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2502, Text: In fact, if Jensen watches this podcast, he may want to consider this. He may want to consider making sure his company’s not nationalized.
Segment 2914: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2510, Text: Do you think that’s an actual threat?
Segment 2915: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2512, Text: Oh, yes.
Segment 2916: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2515, Text: No, but there’s so much, there’s AMD.
Segment 2917: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2517, Text: We have Nvidia and AMD. Great.
Segment 2918: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2520, Text: All right. You don’t think there’s a push towards selling Google selling TPUs or something like this? You don’t think there’s a push for that?
Segment 2919: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2530, Text: Have you seen it? Google loves to rent you TPUs.
Segment 2920: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2534, Text: It doesn’t, you can’t buy it at Best Buy?
Segment 2921: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2538, Text: No.
Segment 2922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2538, Text: Okay.
Segment 2923: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2538, Text: I started work on a chip. I was like, “Okay, what’s it going to take to make a chip?” My first notions were all completely wrong about why, about how you could improve on GPUs. I’ll take this, this is from Jim Keller on your podcast. This is one of my absolute favorite descriptions of computation. There’s three kinds of computation paradigms that are common in the world today.
Segment 2924: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2565, Text: There’s CPUs, and CPUs can do everything. CPUs can do add and multiply. They can do load and store, and they can do compare and branch. When I say they can do these things, they can do them all fast. Compare and branch are unique to CPUs. What I mean by they can do them fast is they can do things like branch prediction, and speculative execution, and they spend tons of transistors on these super deep reorder buffers in order to make these things fast.
Segment 2925: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2589, Text: Then you have a simpler computation model, GPUs. GPUs can’t really do compare and branch. They can, but it’s horrendously slow. GPUs can do arbitrary load and store. GPUs can do things like X, dereference Y, so they can fetch from arbitrary pieces of memory. They can fetch from memory that is defined by the contents of the data.
Segment 2926: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2607, Text: The third model of computation is DSPs. DSPs are just a and multiply. They can do loads and stores, but only static load and stores. Only loads and stores that are known before the program runs. You look at neural networks today, and 95% of neural networks are all the DSP paradigm. They are just statically scheduled adds and multiplies. Tiny Corp really took this idea, and I’m still working on it to extend this as far as possible, every stage of the stack has Turing completeness.
Segment 2927: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2638, Text: Python has Turing completeness, and then we take Python, we go into C++, which is Turing complete, and then maybe C++ calls into some CUDA kernels, which are Turing complete. The CUDA kernels go through LVM, which is Turing complete, into PTX, which is Turing complete, into SaaS, which is Turing complete, on a Turing complete processor. I want to get Turing completeness out of the stack entirely.
Segment 2928: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2655, Text: Once you get rid of Turing completeness, you can reason about things. Rice’s Theorem and the halting problem do not apply to [inaudible 00:44:20] machines.
Segment 2929: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2663, Text: Okay. What’s the power and the value of getting Turing completeness out of, are we talking about the hardware or the software?
Segment 2930: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2671, Text: Every layer of the stack.
Segment 2931: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2672, Text: Every layer.
Segment 2932: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2672, Text: Every layer of the stack. Removing Turing completeness allows you to reason about things. The reason you need to do branch prediction in a CPU, and the reason it’s prediction, and the branch predictors are, I think they’re like 99% on CPUs. Why do they get 1% of them wrong? Well, they get 1% wrong because you can’t know. That’s the halting problem. It’s equivalent to the halting problem to say whether a branch is going to be taken or not.
Segment 2933: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2696, Text: I can show that. The ADMO machine, the neural network runs the identical compute every time. The only thing that changes is the data. When you realize this, you think about, “Okay, how can we build a computer, and how can we build a stack that takes maximal advantage of this idea?”
Segment 2934: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2719, Text: What makes Tinygrad different from other neural network libraries is it does not have a primitive operator even for matrix multiplication. This is every single one. They even have primitive operators for things like convolutions.
Segment 2935: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2731, Text: No MatMul?
Segment 2936: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2732, Text: No MatMul. Well, here’s what a MatMul is. I’ll use my hands to talk here. If you think about a cube, and I put my two matrices that I’m multiplying on two faces of the cube, you can think about the matrix, multiply as, okay, the end cubed, I’m going to multiply for each one in the cubed. Then I’m going to do a sum, which is a reduce, up to here to the third phase of the cube. That’s your multiplied matrix.
Segment 2937: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2756, Text: What a matrix multiply is is a bunch of shape operations, a bunch of permute three shapes and expands on the two matrices, a multiply and cubed, a reduce and cubed, which gives you an N-squared matrix.
Segment 2938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2769, Text: Okay. What is the minimum number of operations it can accomplish that if you don’t have MatMul as a primitive?
Segment 2939: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2776, Text: Tinygrad has about 20, and you can compare Tinygrad’s op set or IR to things like XLA or Prim Torch. XLA and Prim Torch are ideas where like, okay, Torch has like 2000 different kernels. PyTorch 2.0 introduced Prim Torch, which has only 250. Tinygrad has order of magnitude 25. It’s 10X less than XLA or Prim Torch. You can think about it as kind of RISC versus SISC, right? These other things are SISC-like systems. Tinygrad is RISC.
Segment 2940: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2813, Text: RISC won.
Segment 2941: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2814, Text: RISC architecture is going to change everything. 1995, Hackers.
Segment 2942: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2819, Text: Wait, really? That’s an actual thing?
Segment 2943: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2821, Text: Angelina Jolie delivers the line, “RISC architecture is going to change everything,” in 1995.
Segment 2944: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2826, Text: Wow.
Segment 2945: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2826, Text: Here we are with ARM and the phones and ARM everywhere.
Segment 2946: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2830, Text: Wow. I love it when movies actually have real things in them.
Segment 2947: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2833, Text: Right?
Segment 2948: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2834, Text: Okay, interesting. You’re thinking of this as the RISC architecture of ML Stack. 25, huh? Can you go through the four OP types?
Segment 2949: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2849, Text: Sure. Okay. You have unary ops, which take in a tensor and return a tensor of the same size, and do some unary op to it. X, log, reciprocal, sin. They take in one and they’re point-wise.
Segment 2950: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2864, Text: Relu.
Segment 2951: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2868, Text: Yeah, Relu. Almost all activation functions are unary ops. Some combinations of unary ops together is still a unary op. Then you have binary ops. Binary ops are like point-wise addition, multiplication, division, compare. It takes in two tensors of equal size, and outputs one tensor. Then you have reduce ops. Reduce ops will like take a three-dimensional tensor and turn it into a two-dimensional tensor, or a three-dimensional tensor, and turn into a zero dimensional tensor.
Segment 2952: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2897, Text: Think like a sum or a max are really common ones there. Then the fourth type is movement ops. Movement ops are different from the other types, because they don’t actually require computation. They require different ways to look at memory. That includes reshapes, permutes, expands, flips. Those are the main ones, probably.
Segment 2953: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2915, Text: With that, you have enough to make a MatMul?
Segment 2954: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2918, Text: And convolutions, and every convolution you can imagine, dilated convolutions, strided convolutions, transposed convolutions.
Segment 2955: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2926, Text: You’re right on GitHub about laziness, showing a MatMul, matrix multiplication. See how despite the style, it is fused into one kernel with the power of laziness. Can you elaborate on this power of laziness?
Segment 2956: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2941, Text: Sure. If you type in PyTorch, A times B plus C, what this is going to do is it’s going to first multiply A and B, and store that result into memory. Then it is going to add C by reading that result from memory, reading C from memory, and writing that out to memory.
Segment 2957: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2961, Text: There is way more loads in stores to memory than you need there. If you don’t actually do A times B as soon as you see it, if you wait until the user actually realizes that tensor, until the laziness actually resolves, you can fuse that plus C. It’s the same way Haskell works.
Segment 2958: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2979, Text: What’s the process of porting a model into Tinygrad?
Segment 2959: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2984, Text: Tinygrad’s front end looks very similar to PyTorch. I probably could make a perfect, or pretty close to perfect, interop layer if I really wanted to. I think that there’s some things that are nicer about Tinygrad’s syntax than PyTorch, but their front end looks very Torch-like. You can also load in ONNX models.
Segment 2960: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=2999, Text: Okay.
Segment 2961: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3000, Text: We have more ONNX tests passing than Core ML.
Segment 2962: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3004, Text: Core ML. Okay.
Segment 2963: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3006, Text: We’ll pass ONNX run time soon.
Segment 2964: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3007, Text: Well, what about the developer experience with Tinygrad? What it feels like versus PyTorch?
Segment 2965: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3016, Text: By the way, I really like PyTorch. I think that it’s actually a very good piece of software. I think that they’ve made a few different trade-offs, and these different trade-offs are where Tinygrad takes a different path. One of the biggest differences is it’s really easy to see the kernels that are actually being sent to the GPU, right?
Segment 2966: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3035, Text: If you run PyTorch on a GPU, you do some operation, and you don’t know what kernels ran, you don’t know how many kernels ran. You don’t know how many flops were used. You don’t know how much memory accesses were used. Tinygrad type debug equals two, and it will show you in this beautiful style, every kernel that’s run, how many flops, and how many bites.
Segment 2967: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3058, Text: Can you just linger on what problem Tinygrad solves?
Segment 2968: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3064, Text: Tinygrad solves the problem of porting new ML accelerators quickly. One of the reasons, tons of these companies now, I think Sequoia marked Graphcore to zero, Cerebras, TensTorrent, Groq. All of these ML accelerator companies, they built chips. The chips were good, the software was terrible.
Segment 2969: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3088, Text: Part of the reason is because I think the same problem’s happening with Dojo. It’s really, really hard to write a PyTorch port, because you have to write 250 kernels, and you have to tune them all for performance.
Segment 2970: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3100, Text: What does Jim Keller think about Tinygrad? You guys hung out quite a bit. He was involved. He’s involved with TensTorrent.
Segment 2971: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3108, Text: Sure.
Segment 2972: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3109, Text: What’s his praise, and what’s his criticism of what you’re doing with your life?
Segment 2973: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3114, Text: Look, my prediction for TensTorrent is that they’re going to pivot to making risk five chips, CPUs.
Segment 2974: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3123, Text: CPUs.
Segment 2975: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3124, Text: Yeah.
Segment 2976: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3125, Text: Why?
Segment 2977: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3128, Text: Why? AI accelerators are a software problem, not really a hardware problem.
Segment 2978: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3132, Text: Oh, interesting. You think the diversity of AI accelerators in the hardware space is not going to be a thing that exists long term?
Segment 2979: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3141, Text: I think what’s going to happen is, okay. If you’re trying to make an AI accelerator, you better have the capability of writing a Torch-level performance stack on Nvidia GPUs. If you can’t write a Torch stack on Nvidia GPUs and I mean all the way, I mean down to the driver, there’s no way you’re going to be able to write it on your chip. Your chip’s worse than in Nvidia GPU. The first version of the chip you tape out, it’s definitely worse.
Segment 2980: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3166, Text: Oh, you’re saying writing that stack is really tough?
Segment 2981: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3168, Text: Yes, and not only that, actually the chip that you tape out, almost always, because you’re trying to get advantage over Nvidia, you’re specializing the hardware more. It’s always harder to write software for more specialized hardware. A GPU is pretty generic. If you can’t write an in Nvidia stack, there’s no way you can write a stack for your chip. My approach with Tinygrad is first write a performant NVIDIA stack. We’re targeting AMD.
Segment 2982: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3193, Text: You did say FU to Nvidia a little bit with Love.
Segment 2983: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3196, Text: With love. Yeah, with love. It’s like the Yankees. I’m a Mets fan.
Segment 2984: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3200, Text: Oh, you’re a Mets fan? A RISC fan and a Mets fan. What’s the hope that AMD has? You did a build with AMD recently that I saw. How does the 7,900 XTX compare to the RTX 4090 or 4080?
Segment 2985: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3218, Text: Oh, well, let’s start with the fact that the 7,900 XTX kernel drivers don’t work. If you run demo apps and loops, it panics the kernel.
Segment 2986: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3226, Text: Okay, so this is a software issue.
Segment 2987: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3229, Text: Lisa Sue responded to my email.
Segment 2988: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3231, Text: Oh.
Segment 2989: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3231, Text: I reached out. I was like, “This is, really?”
Segment 2990: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3236, Text: Yeah.
Segment 2991: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3237, Text: I understand if your seven by seven transposed Winograd comp is slower than NVIDIA’s, but literally when I run demo apps in a loop, the kernel panics?
Segment 2992: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3248, Text: Just adding that loop?
Segment 2993: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3250, Text: Yeah. I just literally took their demo apps and wrote, “While true; do the app; done,” in a bunch of screens. This is the most primitive fuzz testing.
Segment 2994: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3260, Text: Why do you think that is? They’re just not seeing a market in machine learning?
Segment 2995: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3266, Text: They’re changing. They’re trying to change. They’re trying to change. I had a pretty positive interaction with them this week. Last week, I went on YouTube. I was just like, “That’s it. I give up on AMD. Their driver doesn’t even… I’ll go with Intel GPUs. Intel GPUs have better drivers.”
Segment 2996: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3285, Text: You’re kind of spearheading the diversification of GPUs.
Segment 2997: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3290, Text: Yeah, and I’d like to extend that diversification to everything. I’d like to diversify, the more my central thesis about the world is there’s things that centralize power, and they’re bad. There’s things that decentralize power, and they’re good. Everything I can do to help decentralize power, I’d like to do.
Segment 2998: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3312, Text: You’re really worried about the centralization of Nvidia. That’s interesting. You don’t have a fundamental hope for the proliferation of ASICs except in the cloud?
Segment 2999: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3323, Text: I’d like to help them with software. No, actually, the only ASIC that is remotely successful is Google’s TPU. The only reason that’s successful is because Google wrote a machine learning framework. I think that you have to write a competitive machine learning framework in order to be able to build an ASIC.
Segment 3000: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3341, Text: You think Meta with PyTorch builds a competitor?
Segment 3001: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3345, Text: I hope so.
Segment 3002: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3346, Text: Okay.
Segment 3003: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3346, Text: They have one. They have an internal one.
Segment 3004: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3348, Text: Internal, I mean public facing with a nice cloud interface and so on?
Segment 3005: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3352, Text: I don’t want a cloud.
Segment 3006: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3353, Text: You don’t like cloud?
Segment 3007: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3355, Text: I don’t like cloud.
Segment 3008: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3355, Text: What do you think is the fundamental limitation of cloud?
Segment 3009: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3358, Text: Fundamental limitation of cloud is who owns the off switch.
Segment 3010: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3362, Text: That’s the power to the people.
Segment 3011: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3363, Text: Yeah.
Segment 3012: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3364, Text: You don’t like the man to have all the power.
Segment 3013: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3367, Text: Exactly.
Segment 3014: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3368, Text: All right. Right now, the only way to do that is with Nvidia GPUs if you want performance and stability. Interesting. It’s a costly investment emotionally to go with AMD’s. Well, let me on a tangent, ask you, you’ve built quite a few PCs. What’s your advice on how to build a good custom PC for, let’s say, for the different applications that you use for gaming, for machine learning?
Segment 3015: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3395, Text: Well, you shouldn’t build one. You should buy a box from the Tiny Corp.
Segment 3016: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3399, Text: I heard rumors, whispers about this box in the Tiny Corp. What’s this thing look like? What is it called?
Segment 3017: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3408, Text: It’s called the Tinybox.
Segment 3018: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3408, Text: Tinybox.
Segment 3019: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3411, Text: It’s $15,000, and it’s almost a paid flop of compute. It’s over a hundred gigabytes of GPU RAM. It’s over five terabytes per second of GPU memory bandwidth. I’m going to put four NVMes in RAID. You’re going to get like 20, 30 gigabytes per second of drive read bandwidth. I’m going to build the best deep learning box that I can plugs into one wall outlet.
Segment 3020: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3439, Text: Okay. Can you go through those specs again a little bit from memory?
Segment 3021: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3443, Text: Yeah. It’s almost a paid flop of compute.
Segment 3022: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3445, Text: AMD, Intel?
Segment 3023: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3446, Text: Today I’m leaning toward AMD, but we’re pretty agnostic to the type of compute. The main limiting spec is a 120 volt, 15 amp circuit.
Segment 3024: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3460, Text: Okay.
Segment 3025: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3461, Text: Well, I mean it. In order to, there’s a plug over there. You have to be able to plug it in. We’re also going to sell the Tiny Rack, which, what’s the most power you can get into your house without arousing suspicion? One of the answers is an electric car charger.
Segment 3026: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3479, Text: Wait, where does the Rack go?
Segment 3027: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3481, Text: Your garage.
Segment 3028: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3483, Text: Interesting. The car charger?
Segment 3029: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3485, Text: A wall outlet is about 1500 watts. A car charger is about 10,000 watts.
Segment 3030: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3491, Text: Okay. What is the most amount of power you can get your hands on without arousing suspicion?
Segment 3031: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3496, Text: That’s right.
Segment 3032: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3496, Text: George Hotz. Okay. The Tinybox, and you said NVMEs in RAID. I forget what you said about memory, all that kind of stuff. Okay, so what about with GPUs?
Segment 3033: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3509, Text: Again, probably-
Segment 3034: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3510, Text: Agnostic.
Segment 3035: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3510, Text: Probably 7,900 XTXes, but maybe 3090s, maybe A770s. Those are Intel’s.
Segment 3036: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3516, Text: You’re flexible, or still exploring?
Segment 3037: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3519, Text: I’m still exploring. I want to deliver a really good experience to people. What GPUs I end up going with, again, I’m leaning toward AMD. We’ll see. In my email, what I said to AMD is, “Just dumping the code on GitHub is not open source. Open source is a culture. Open source means that your issues are not all one year old, stale issues. Open source means developing in public. If you guys can commit to that, I see a real future for AMD as a competitor to Nvidia.”
Segment 3038: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3553, Text: Well, I’d love to get a Tinybox to MIT. Whenever it’s ready-
Segment 3039: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3557, Text: Will do.
Segment 3040: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3557, Text: Let’s do it.
Segment 3041: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3558, Text: We’re taking pre-orders. I took this from Elon. I’m like, “$100, fully refundable pre-orders.”
Segment 3042: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3563, Text: Is it going to be like the cyber truck? It’s going to take a few years?
Segment 3043: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3566, Text: No, I’ll try to do it faster. It’s a lot simpler. It’s a lot simpler than a truck.
Segment 3044: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3570, Text: Well, there’s complexities, not to just the putting the thing together, but shipping it, all this kind of stuff.
Segment 3045: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3576, Text: The thing that I want to deliver to people out of the box is being able to run 65 billion parameter Lama in FP16 in real time, in a good 10 tokens per second, or five tokens per second or something.
Segment 3046: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3586, Text: Just, it works.
Segment 3047: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3587, Text: Yep, just works.
Segment 3048: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3588, Text: Lama’s running, or something like Lama.
Segment 3049: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3593, Text: Yeah, or I think Falcon is the new one. Experience a chat with the largest language model that you can have in your house.
Segment 3050: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3600, Text: Yeah, from a wall plug.
Segment 3051: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3601, Text: From a wall plug, yeah. Actually, for inference, it’s not like even more power would help you get more.
Segment 3052: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3609, Text: Even more power wouldn’t get you more.
Segment 3053: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3611, Text: Well, no, the biggest model released is 65 billion parameter Lama, as far as I know.
Segment 3054: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3616, Text: It sounds like Tinybox will naturally pivot towards company number three. You could just get the girlfriend or boyfriend.
Segment 3055: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3626, Text: That one’s harder, actually.
Segment 3056: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3627, Text: The boyfriend is harder?
Segment 3057: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3628, Text: The boyfriend’s harder, yeah.
Segment 3058: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3629, Text: I think that’s a very biased statement.
Segment 3059: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3632, Text: No.
Segment 3060: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3632, Text: I think a lot of people disagree. Why is it harder to replace a boyfriend than a girlfriend with the artificial LLM?
Segment 3061: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3641, Text: Women are attracted to status and power, and men are attracted to youth and beauty. No, this is what I mean.
Segment 3062: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3649, Text: Both could be mimic-able easy through the language model.
Segment 3063: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3652, Text: No. No, machines do not have any status or real power.
Segment 3064: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3656, Text: I don’t know. Well, first of all, you’re using language mostly to communicate youth and beauty and power and status.
Segment 3065: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3667, Text: Sure, but status fundamentally is a zero-sum game, whereas youth and beauty are not.
Segment 3066: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3672, Text: No, I think status is a narrative you can construct. I don’t think status is real.
Segment 3067: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3678, Text: I don’t know. I just think that that’s why it’s harder. Yeah, maybe it is my biases.
Segment 3068: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3683, Text: I think status is way easier to fake.
Segment 3069: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3685, Text: I also think that men are probably more desperate and more likely to buy my product. Maybe they’re a better target market.
Segment 3070: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3691, Text: Desperation is interesting. Easier to fool.
Segment 3071: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3694, Text: Yeah.
Segment 3072: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3696, Text: I could see that.
Segment 3073: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3696, Text: Yeah. Look, I know you can look at porn viewership numbers, right? A lot more men watch porn than women.
Segment 3074: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3701, Text: Yeah.
Segment 3075: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3701, Text: You can ask why that is.
Segment 3076: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3703, Text: Wow. There’s a lot of questions and answers you can get there. Anyway, with the Tinybox, how many GPUs in Tinybox?
Segment 3077: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3713, Text: Six.
Segment 3078: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3718, Text: Oh, man.
Segment 3079: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3719, Text: I’ll tell you why it’s six.
Segment 3080: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3720, Text: Yeah.
Segment 3081: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3721, Text: AMD Epic processors have 128 lanes of PCIE. I want to leave enough lanes for some drives, and I want to leave enough lanes for some networking.
Segment 3082: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3735, Text: How do you do cooling for something like this?
Segment 3083: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3737, Text: Ah, that’s one of the big challenges. Not only do I want the cooling to be good, I want it to be quiet.
Segment 3084: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3742, Text: Yeah.
Segment 3085: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3743, Text: I want the Tinybox to be able to sit comfortably in your room. Right.
Segment 3086: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3746, Text: This is really going towards the girlfriend thing. You want to run the LLM-
Segment 3087: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3751, Text: I’ll give a more, I can talk about how it relates to company number one.
Segment 3088: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3756, Text: Come AI.
Segment 3089: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3756, Text: Yeah.
Segment 3090: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3757, Text: Well, but yes, quiet. Oh, quiet because you maybe potentially want to run it in a car?
Segment 3091: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3763, Text: No, no. Quiet because you want to put this thing in your house. You want it to coexist with you. If it’s screaming at 60 dB, you don’t want that in your house. You’ll kick it out.
Segment 3092: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3771, Text: 60 dB, yeah.
Segment 3093: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3771, Text: Yeah. I want like 40, 45.
Segment 3094: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3773, Text: How do you make the cooling quiet? That’s an interesting problem in itself.
Segment 3095: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3777, Text: A key trick is to actually make it big. Ironically, it’s called the Tinybox, but if I can make it big, a lot of that noise is generated because of high pressure air. If you look at a 1U server, a 1U server has these super high pressure fans.
Segment 3096: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3789, Text: They’re super deep and they’re like jet engines, versus if you have something that’s big, well, I can use a big, they call them big ass fans. Those ones that are huge on the ceiling? They’re completely silent.
Segment 3097: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3801, Text: Tinybox will be big.
Segment 3098: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3806, Text: I do not want it to be large according to UPS. I want it to be shippable as a normal package, but that’s my constraint there.
Segment 3099: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3812, Text: Interesting. Well, the fan stuff, can it be assembled on location, or no?
Segment 3100: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3817, Text: No.
Segment 3101: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3817, Text: No, it has to be… Well, you’re…
Segment 3102: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3821, Text: Look, I want to give you a great out of the box experience. I want you to lift this thing out, I want it to be like the Mac, Tinybox.
Segment 3103: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3828, Text: The Apple experience.
Segment 3104: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3829, Text: Yeah.
Segment 3105: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3830, Text: I love it. Okay. Tinybox would run Tinygrad. What do you envision this whole thing to look like? We’re talking about Linux with a full…
Segment 3106: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3843, Text: Linux with a full software engineering environment and it’s just not PyTorch, but tinygrad.
Segment 3107: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3850, Text: Yeah, we did a poll. If people want Ubuntu or Arch, we’re going to stick with Ubuntu.
Segment 3108: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3854, Text: Interesting. What’s your favorite flavor of Linux?
Segment 3109: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3857, Text: Ubuntu.
Segment 3110: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3858, Text: Ubuntu. I like Ubuntu MATE, however you pronounce that MATE. You’ve gotten LLaMA into tinygrad, you’ve gotten stable diffusion into tinygrad. What was that like? What are these models, what’s interesting about porting them? What are the challenges? What’s naturally? What’s easy? All that kind of stuff.
Segment 3111: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3881, Text: There’s a really simple way to get these models into tinygrad and you can just export them as Onyx and then tinygrad can run Onyx. So the ports that I did of LLaMA Stable Diffusion and now Whisper are more academic to teach me about the models, but they are cleaner than the PyTorch versions. You can read the code. I think the code is easier to read, it’s less lines. There’s just a few things about the way tinygrad writes things. Here’s a complaint I have about PyTorch. nn.ReLU is a class so when you create an NN module, you’ll put your nn ReLUs as in a nit, and this makes no sense. ReLU is completely stateless. Why should that be a class?
Segment 3112: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3923, Text: But that’s more a software engineering thing, or do you think it has a cost on performance?
Segment 3113: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3928, Text: Oh no, it doesn’t have a cost on performance, but yeah, no. That’s what I mean about tinygrad’s front end being cleaner.
Segment 3114: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3935, Text: I see. What do you think about Mojo? I don’t know if you’ve been paying attention, the programming language that does some interesting ideas that intersect tinygrad.
Segment 3115: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3946, Text: I think that there’s a spectrum and on one side you have Mojo and on the other side you have ggml. Ggml is this like, we’re going to run LlaMA fast on Mac. Okay. We’re going to expand out to a little bit, but we’re going to basically depth first, right? Mojo is like we’re going to go breath first. We’re going to go so wide that we’re going to make all of Python Fast and tinygrad’s in the middle. Tinygrads, we are going to make neural networks fast,
Segment 3116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3972, Text: But they try to really get it to be fast, compile down to the specifics hardware and make that compilation step as flexible and resilient as possible.
Segment 3117: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3986, Text: But they’ve turned completeness.
Segment 3118: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3988, Text: And that limits you? That’s what you’re saying it’s somewhere in the middle. So you’re actually going to be targeting some accelerators, some number, not one.
Segment 3119: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=3998, Text: My goal is step one, build an equally performance stack to PyTorch on Nvidia and AMD, but with way less lines. And then step two is, okay, how do we make an accelerator? But you need step one. You have to first build the framework before you can build the accelerator.
Segment 3120: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4016, Text: Can you explain MLPerf? What’s your approach in general to benchmarking tinygrad performance?
Segment 3121: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4023, Text: I’m much more of a build it the right way and worry about performance later. There’s a bunch of things where I haven’t even really dove into performance. The only place where tinygrad is competitive performance wise right now is on Qualcomm GPUs. So tinygrads actually used an openpilot to run the model. So the driving model is tinygrad.
Segment 3122: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4045, Text: When did that happen? That transition?
Segment 3123: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4048, Text: About eight months ago now. And it’s two x faster than Qualcomm’s library.
Segment 3124: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4053, Text: What’s the hardware of that openpilot runs on the comma.ai?
Segment 3125: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4058, Text: It’s a Snapdragon 845.
Segment 3126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4060, Text: Okay.
Segment 3127: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4060, Text: So this is using the GPU. So the GPU’s in Adreno GPU. There’s different things. There’s a really good Microsoft paper that talks about mobile GPUs and why they’re different from desktop GPUs. One of the big things is in a desktop GPU, you can use buffers. On a mobile GPU image textures are a lot faster
Segment 3128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4081, Text: On a mobile GPU image textures. Okay. And so you want to be able to leverage that?
Segment 3129: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4088, Text: I want to be able to leverage it in a way that it’s completely generic. So there’s a lot of… Xiaomi has a pretty good open source library for mobile GPUs called MACE where they can generate where they have these kernels, but they’re all hand coded. So that’s great. If you’re doing three by three comps, that’s great if you’re doing dense mat malls, but the minute you go off the beaten path a tiny bit, well your performance is nothing.
Segment 3130: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4110, Text: Since you mentioned openpilot, I’d love to get an update in the company number one, comma.ai world. How are things going there in the development of semi autonomous driving?
Segment 3131: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4126, Text: Almost no one talks about FSD anymore and even less people talk about openpilot. We’ve thought the problem, we solved it years ago.
Segment 3132: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4135, Text: What’s the problem exactly? What does solving it mean?
Segment 3133: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4140, Text: Solving means how do you build a model that outputs a human policy for driving. How do you build a model that given reasonable set of sensors, outputs a human policy for driving? So you have companies like [inaudible 01:09:15], which are hand coding, these things that are quasi human policies. Then you have Tesla and maybe even to more of an extent, comma, asking, okay, how do we just learn the human policy and data? The big thing that we’re doing now, and we just put it out on Twitter. At the beginning of comma, we published a paper called Learning a Driving Simulator. And the way this thing worked was, it was an auto encoder and then an RNN in the middle. You take an auto encoder, you compress the picture, you use an RNN, predict the next date. It was a laughably bad simulator. This is 2015 error machine learning technology. Today we have VQVAE and transformers. We’re building drive GPT basically.
Segment 3134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4206, Text: Drive GPT. Okay. And it’s trained on what? Is it trained in a self supervised way?
Segment 3135: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4214, Text: Yeah. It’s trained on all the driving data to predict the next frame.
Segment 3136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4217, Text: So really trying to learn a human policy. What would a human do?
Segment 3137: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4222, Text: Actually our simulator’s conditioned on the pose. So it’s actually a simulator. You can put in a state action pair and get out the next state. And then once you have a simulator, you can do RRL in the simulator and RRL will get us that human policy.
Segment 3138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4236, Text: So transfers?
Segment 3139: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4238, Text: Yeah. RRL with a reward function. Not asking is this close to the human policy, but asking would a human disengage if you did this behavior?
Segment 3140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4247, Text: Okay, let me think about the distinction there. What a human disengage. That correlates, I guess with human policy, but it could be different. So it doesn’t just say, what would a human do? It says what would a good human driver do and such that the experience is comfortable but also not annoying in that the thing is very cautious. So it’s finding a nice balance. That’s interesting. That’s a nice-
Segment 3141: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4277, Text: It’s asking exactly the right question. What will make our customers happy? A system that you never want to disengage.
Segment 3142: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4285, Text: Because usually disengagement is this almost always a sign of I’m not happy with what the system is doing.
Segment 3143: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4292, Text: Usually. There’s some that are just, I felt like driving and those are always fine too, but they’re just going to look like noise in the data.
Segment 3144: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4299, Text: But even I felt like driving.
Segment 3145: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4301, Text: Maybe. Yeah.
Segment 3146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4303, Text: That’s a signal. Why do you feel like driving. You need to recalibrate your relationship with the car. Okay, so that’s really interesting. How close are we to solving self driving?
Segment 3147: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4319, Text: It’s hard to say. We haven’t completely closed the loop yet. So we don’t have anything built that truly looks like that architecture yet. We have prototypes and there’s bugs. So we are a couple bug fixes away. Might take a year, might take 10.
Segment 3148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4335, Text: What’s the nature of the bugs? Are these major philosophical bugs? Logical bugs? What kind of bugs are we talking about?
Segment 3149: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4342, Text: They’re just stupid bugs. And also we might just need more scale. We just massively expanded our compute cluster at comma. We now have about two people worth of compute. 40 petaflops.
Segment 3150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4356, Text: Well, people are different.
Segment 3151: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4359, Text: 20 petaflops. That’s a person. It’s just a unit. Horses are different too, but we still call it a horsepower.
Segment 3152: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4365, Text: But there’s something different about mobility than there is about perception and action in a very complicated world. But yes.
Segment 3153: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4374, Text: Yeah. Of course not all flops are created equal. If you have randomly initialized weights, it’s not going to…
Segment 3154: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4378, Text: Not all flops are created equal.
Segment 3155: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4381, Text: For some flops are doing way more useful things than others.
Segment 3156: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4383, Text: Yep. Tell me about it. Okay, so more data. Scale means more scale in compute or scale in scale of data.
Segment 3157: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4391, Text: Both.
Segment 3158: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4394, Text: Diversity of data.
Segment 3159: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4395, Text: Diversity is very important in data. Yeah. I think we have 5,000 daily actives.
Segment 3160: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4405, Text: How would you evaluate? How FSD doing with self-driving.
Segment 3161: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4410, Text: Pretty well.
Segment 3162: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4411, Text: How’s that race going between Comma.ai and FSD?
Segment 3163: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4414, Text: Tesla has always wanted to two years ahead of us. They’ve always been one to two years ahead of us and they probably always will be because they’re not doing anything wrong.
Segment 3164: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4421, Text: What have you seen since the last time we talked that are interesting architectural decisions, training decisions the way they deploy stuff, the architectures they’re using in terms of the software, how the teams are run, all that kind of stuff, data collection, anything interesting?
Segment 3165: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4434, Text: I know they’re moving toward more of an end-to-end approach.
Segment 3166: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4438, Text: So creeping towards end-to- end as much as possible across the whole thing? The training, the data collection, and everything?
Segment 3167: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4445, Text: They also have a very fancy simulator. They’re probably saying all the same things we are. They’re probably saying we just need to optimize. What is the reward? Well, you get negative reward for disengagement. Everyone knows this. It’s just a question who can actually build and deploy the system?
Segment 3168: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4458, Text: Yeah. This requires good software engineering, I think. And the right kind of hardware.
Segment 3169: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4465, Text: Yeah. And the hardware to run it.
Segment 3170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4467, Text: You still don’t believe in cloud in that regard?
Segment 3171: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4470, Text: I have a compute cluster in my office, 800 amps,
Segment 3172: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4476, Text: tinygrad.
Segment 3173: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4476, Text: It’s 40 kilowatts at idle our data center. That seem crazy. Have 40 kilowatts is burning just when the computers are idle. Sorry. Compute cluster.
Segment 3174: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4488, Text: Compute cluster. I got it.
Segment 3175: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4489, Text: It’s not a data center. Data centers are clouds. We don’t have clouds. Data centers have air conditioners. We have fans that makes it a compute cluster.
Segment 3176: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4499, Text: I’m guessing this is a kind of legal distinction that should [inaudible 01:15:03].
Segment 3177: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4502, Text: Sure. Yeah. We have a compute cluster.
Segment 3178: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4505, Text: You said that you don’t think LLMs have consciousness, or at least not more than a chicken. Do you think they can reason? Is there something interesting to you about the word reason about some of the capabilities that we think is kind of human to be able to integrate complicated information and through a chain of thought arrive at a conclusion that feels novel? A novel integration of disparate facts?
Segment 3179: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4536, Text: Yeah. I don’t think that they can reason better than a lot of people.
Segment 3180: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4542, Text: Yeah. Isn’t that amazing to you though? Isn’t that an incredible thing that a transformer can achieve?
Segment 3181: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4548, Text: I think that calculators can add better than a lot of people.
Segment 3182: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4552, Text: But language feels reasoning through the process of language, which looks a lot like thought.
Segment 3183: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4560, Text: Making brilliancy in chess, which feels a lot thought. Whatever new thing that AI can do, everybody thinks is brilliant. And then 20 years go by and they’re like, “Well, yeah, but chess, that’s like mechanical.” Adding, that’s mechanical.
Segment 3184: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4573, Text: So you think language is not that special. It’s like chess.
Segment 3185: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4575, Text: It’s like chess.
Segment 3186: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4577, Text: Because it’s very human. Listen, there is something different between chess and language. Chess is a game that a subset of population plays. Language is something we use nonstop for all of our human interaction and human interaction is fundamental to society. So holy shit, this language thing is not so difficult to create in the machine.
Segment 3187: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4606, Text: The problem is if you go back to 1960 and you tell them that you have a machine that can play amazing chess, of course someone in 1960 will tell you that machine is intelligent. Someone in 2010 won’t. What’s changed? Today, we think that these machines that have language are intelligent, but I think in 20 years we’re going to be like, yeah, but can it reproduce?
Segment 3188: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4628, Text: So reproduction. Yeah, we may redefine what it means to be… What is it? A high performance living organism on earth.
Segment 3189: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4637, Text: Human are always going to define a niche for themselves. Well, we’re better than the machines because we can… When they tried creative for a bit, but no one believes that one anymore.
Segment 3190: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4647, Text: But niche, is that delusional or is there some accuracy to that? Because maybe with chess you start to realize that we have ill-conceived notions of what makes humans special, the apex organism on earth.
Segment 3191: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4666, Text: Yeah. And I think maybe we’re going to go through that same thing with language and that same thing with creativity.
Segment 3192: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4673, Text: But language carries these notions of truth and so on. And so we might be, wait, maybe truth is not carried by language. Maybe there’s a deeper thing.
Segment 3193: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4683, Text: The niche is getting smaller.
Segment 3194: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4685, Text: Oh boy.
Segment 3195: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4687, Text: But no, no, no. You don’t understand. Humans are created by God and machines are created by humans. That’ll be the last niche we have.
Segment 3196: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4696, Text: So what do you think about just the rapid development of LLMs? If we could just stick on that. It’s still incredibly impressive like with Chat GPT, just even Chat GPT, what are your thoughts about reinforcement learning with human feedback on these large language models?
Segment 3197: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4710, Text: I’d like to go back to when calculators first came out or computers and I wasn’t around. I’m 33 years old and to see how that affected society,
Segment 3198: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4727, Text: Maybe you’re right. So I want to put on the big picture hat here.
Segment 3199: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4733, Text: Oh my God. The refrigerator. Wow.
Segment 3200: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4736, Text: Refrigerator, electricity, all that kind of stuff. But no, with the internet, large language models seeming human-like basically passing a touring test, it seems it might have really at scale rapid transformative effects on society. But you’re saying other technologies have as well. So maybe calculator’s not the best example of that because that just seems like… Maybe calculator-
Segment 3201: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4764, Text: But the poor milk man, the day he learned about refrigerators, he’s like, I’m done. You’re telling me you can just keep the milk in your house. You don’t even mean to deliver it every day. I’m done.
Segment 3202: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4774, Text: Well, yeah, you have to actually look at the practical impacts of certain technologies that they’ve had. Yeah, probably electricity is a big one and also how rapidly spread. The internet is a big one.
Segment 3203: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4786, Text: I do think it’s different this time though.
Segment 3204: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4788, Text: Yeah, it just feels like-
Segment 3205: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4789, Text: The niche is getting smaller.
Segment 3206: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4791, Text: The niche is humans.
Segment 3207: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4792, Text: Yes.
Segment 3208: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4793, Text: That makes humans special.
Segment 3209: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4795, Text: Yes.
Segment 3210: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4797, Text: It feels like it’s getting smaller rapidly though, doesn’t it? Or is that just a feeling we dramatize everything.
Segment 3211: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4802, Text: I think we dramatize everything. I think that you ask the milk man when he saw refrigerators. And they’re going to have one of these in every home.
Segment 3212: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4812, Text: Yeah. But boys are impressive. So much more impressive than seeing a chess world champion AI system.
Segment 3213: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4823, Text: I disagree, actually. I disagree. I think things like MuZero and AlphaGo are so much more impressive because these things are playing beyond the highest human level. The language models are writing middle school level essays and people are like, wow, it’s a great essay. It’s a great five paragraph essay about the causes of the civil war.
Segment 3214: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4847, Text: Okay, forget the Civil War. Just generating code codex. So you’re saying it’s mediocre code.
Segment 3215: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4853, Text: Terrible.
Segment 3216: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4854, Text: But I don’t think it’s terrible. I think it’s just mediocre code. Often close to correct for mediocre purposes.
Segment 3217: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4863, Text: The scariest code. I spent 5% of time typing and 95% of time debugging. The last thing I want is close to correct code. I want a machine that can help me with the debugging, not with the typing.
Segment 3218: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4874, Text: Well, it’s like level two driving similar kind of thing. Yeah. You still should be a good programmer in order to modify. I wouldn’t even say debugging. It’s just modifying the code, reading it.
Segment 3219: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4886, Text: Actually, don’t think it’s level two driving. I think driving is not tool complete and programming is. Meaning you don’t use the best possible tools to drive. Cars have basically the same interface for the last 50 years. Computers have a radically different interface.
Segment 3220: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4903, Text: Okay. Can you describe the concept of tool complete?
Segment 3221: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4907, Text: Yeah. So think about the difference between a car from 1980 and a car from today. No difference really. It’s got a bunch of pedals. It’s got a steering wheel. Great. Maybe now it has a few ADAS features, but it’s pretty much the same car. You have no problem getting into a 1980 car and driving it. You take a programmer today who spent their whole life doing JavaScript and you put them in an Apple IIe prompt and you tell them about the line numbers in basic, but how do I insert something between line 17 and 18? Oh wow.
Segment 3222: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4939, Text: So in tool, you’re putting in the programming languages. So it’s just the entirety stack of the tooling.
Segment 3223: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4944, Text: Exactly.
Segment 3224: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4945, Text: So it’s not just the IDEs or something like this. It’s everything.
Segment 3225: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4948, Text: Yes. It’s IDEs, the language, it’s the run time, it’s everything. And programming is tool complete. So almost if Codex or copilot are helping you, that actually probably means that your framework or library is bad and there’s too much boilerplate in it.
Segment 3226: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4967, Text: Yeah, but don’t you think so much programming has boilerplate?
Segment 3227: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4970, Text: Tinygrad is now 2,700 lines and it can run LLaMA and stable diffusion and all of this stuff is in 2,700 lines. Boilerplate and abstraction in directions and all these things are just bad code.
Segment 3228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=4988, Text: Well, let’s talk about good code and bad code. I would say, for generic scripts that I write just offhand, 80% of it is written by GPT, just like quick offhand stuff. So not libraries, not performing code, not stuff for robotics and so on. Just quick stuff because so much of programming is doing some boilerplate, but to do so efficiently and quickly because you can’t really automate it fully with generic method, a generic kind of IDE type of recommendation or something like this. You do need to have some of the complexity of language models.
Segment 3229: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5033, Text: Yeah, I guess if I was really writing, maybe today, if I wrote a lot of data parsing stuff… I don’t play CTFs anymore, but if I still play CTFs, a lot of is just you have to write a parser for this data format or admin of code. I wonder when the models are going to start to help with that code and they may. And the models also may help you with speed and the models are very fast, but where the models won’t, my programming speed is not at all limited by my typing speed. And in very few cases, it is yes. If I’m writing some script to just parse some weird data format, sure, my programming speed is limited by my typing speed.
Segment 3230: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5075, Text: What about looking stuff up? Because that’s essentially a more efficient lookup.
Segment 3231: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5081, Text: When I was at Twitter, I tried to use chat GPT to ask some questions. Was the API for this? And it would just hallucinate, it would just give me completely made up API functions that sounded real.
Segment 3232: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5094, Text: Well. Do you think that’s just a temporary stage?
Segment 3233: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5097, Text: No.
Segment 3234: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5098, Text: You don’t think it’ll get better and better and better in this kind of stuff because it only hallucinates stuff in the edge cases.
Segment 3235: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5104, Text: Yes.
Segment 3236: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5104, Text: If you right in generic code, it’s actually pretty good.
Segment 3237: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5106, Text: Yes. If you are writing an absolute basic react app with a button, it’s not going to hallucinate. No, there’s kind of ways to fix the hallucination problem. I think Facebook has an interesting paper. It’s called Atlas and it’s actually weird the way that we do language models right now where all of the information is in the weights and the human brains don’t really like this. There’s like a hippocampus and a memory system. So why don’t LLMs have a memory system? And there’s people working on them. I think future LLMs are going to be smaller, but are going to run looping on themselves and are going to have retrieval systems. And the thing about using a retrieval system is you can cite sources, explicitly.
Segment 3238: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5147, Text: Which is really helpful to integrate the human into the loop of the thing because you can go check the sources and you can investigate. So whenever the thing is hallucinating, you can have the human supervision. So that’s pushing it towards level two driving.
Segment 3239: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5161, Text: That’s going to kill Google.
Segment 3240: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5163, Text: Wait, which part?
Segment 3241: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5164, Text: When someone makes an LLM that’s capable of citing its sources, it will kill Google.
Segment 3242: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5168, Text: LLM that’s citing its sources because that’s basically a search engine.
Segment 3243: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5173, Text: That’s what people want in the search engine.
Segment 3244: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5174, Text: But also Google might be the people that build it.
Segment 3245: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5176, Text: Maybe.
Segment 3246: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5177, Text: And put ads on it.
Segment 3247: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5179, Text: I’d count them out.
Segment 3248: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5180, Text: Why is that? Why do you think? Who wins this race? Who are the competitors?
Segment 3249: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5186, Text: All right.
Segment 3250: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5187, Text: We got Tiny Corp. You’re a legitimate competitor in that.
Segment 3251: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5193, Text: I’m not trying to compete on that.
Segment 3252: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5195, Text: You’re not.
Segment 3253: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5196, Text: No. Not as [inaudible 01:26:37].
Segment 3254: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5196, Text: Can accidentally stumble into that competition.
Segment 3255: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5200, Text: You don’t think you might build a search engine or replace Google search.
Segment 3256: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5203, Text: When I started Comma, I said over and over again, I’m going to win self-driving cars. I still believe that. I have never said I’m going to win search with the Tiny Corp and I’m never going to say that because I won’t.
Segment 3257: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5215, Text: Then night is still young. You don’t know how hard is it to win search in this new route? One of the things that Chat GPT shows that there could be a few interesting tricks that really have that create a really compelling product.
Segment 3258: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5229, Text: Some startups going to figure it out. I think if you ask me, Google’s still the number one webpage. I think by the end of the decade Google won’t be the number one my bed anymore.
Segment 3259: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5237, Text: So you don’t think Google because of how big the corporation is?
Segment 3260: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5241, Text: Look, I would put a lot more money on Mark Zuckerberg.
Segment 3261: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5245, Text: Why is that?
Segment 3262: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5247, Text: Because Mark Zuckerberg’s alive. This is old Paul Graham essay. Startups are either alive or dead. Google’s dead. Facebook is alive.
Segment 3263: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5258, Text: Facebook is alive. Meta is alive.
Segment 3264: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5259, Text: Actually, Meta.
Segment 3265: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5260, Text: Meta.
Segment 3266: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5260, Text: You see what I mean? That’s just Mark Zuckerberg. This is Mark Zuckerberg reading that Paul Graham asking and being like, I’m going to show everyone how alive we are. I’m going to change the name.
Segment 3267: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5269, Text: So you don’t think there’s this gutsy pivoting engine that Google doesn’t have that… The engine in a startup has constantly being alive, I guess.
Segment 3268: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5283, Text: When I listen to Sam Altman podcast, he talked about the button. Everyone who talks about AI talks about the button, the button to turn it off, right? Do we have a button to turn off Google? Is anybody in the world capable of shutting Google down?
Segment 3269: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5297, Text: What does that mean exactly? The company or the search engine.
Segment 3270: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5299, Text: We shut the search engine down. Could we shut the company down either?
Segment 3271: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5304, Text: Can you elaborate on the value of that question?
Segment 3272: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5306, Text: Does Sundar Pichai have the authority to turn off google.com tomorrow?
Segment 3273: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5311, Text: Who has the authority? That’s a good question.
Segment 3274: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5313, Text: Just anyone.
Segment 3275: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5316, Text: Just anyone. Yeah, I’m sure.
Segment 3276: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5317, Text: Are you sure? No, they have the technical power, but do they have the authority? Let’s say Sundar Pichai made this his sole mission. He came into Google tomorrow and said, “I’m going to shut google.com down.” I don’t think you keep this position too long.”
Segment 3277: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5332, Text: And what is the mechanism by which he wouldn’t keep his position?
Segment 3278: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5335, Text: Well, the boards and shares and corporate undermining and our revenue is zero now.
Segment 3279: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5342, Text: Okay. What’s the case you’re making here? So the capitalist machine prevents you from having the button.
Segment 3280: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5349, Text: Yeah. And it’ll have. This is true for the AI too. There’s no turning the AIs off. There’s no button. You can’t press it. Now, does Mark Zuckerberg have that button for facebook.com?
Segment 3281: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5361, Text: Yes. Probably more.
Segment 3282: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5362, Text: I think he does. And this is exactly what I mean and why I bet on him so much more than I bet on Google.
Segment 3283: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5369, Text: I guess you could say Elon has similar stuff.
Segment 3284: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5371, Text: Oh, Elon has the button.
Segment 3285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5372, Text: Yeah.
Segment 3286: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5375, Text: Can Elon fire the missiles? Can he fire the missiles?
Segment 3287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5379, Text: I think some questions are better left unasked.
Segment 3288: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5382, Text: Right? A rocket and an ICBM or you’re a rocket that can land anywhere. Isn’t that an ICBM? Well, yeah. Don’t ask too many questions.
Segment 3289: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5391, Text: My God. But the positive side of the button is that you can innovate aggressively is what you’re saying? Which is what’s required with turning LLM into a search engine.
Segment 3290: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5404, Text: I would bet on a startup.
Segment 3291: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5405, Text: Because it’s so easy, right?
Segment 3292: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5406, Text: I’d bet on something that looks like mid journey, but for search.
Segment 3293: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5411, Text: Just is able to say source a loop on itself. It’s just feels like one model can take off and nice wrapper and some of it scale… It’s hard to create a product that just works really nicely, stably.
Segment 3294: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5423, Text: The other thing that’s going to be cool is there is some aspect of a winner take all effect. Once someone starts deploying a product that gets a lot of usage, and you see this with Open AI, they’re going to get the data set to train future versions of the model. I was asked at Google image search when I worked there almost 15 years ago now. How does Google know which image is an apple? And I said, the metadata. And they’re like, yeah, that works about half the time. How does Google know? You’ll see they’re all apples on the front page when you search Apple. And I don’t know. I didn’t come up with the answer. The guy’s like, “Well, 12 people click on when they search Apple.” Oh my God, yeah.
Segment 3295: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5460, Text: Yeah. That data is really, really powerful. It’s the human supervision. What do you think are the chances? What do you think in general that LLaMA was open sourced? I just did a conversation with Mark Zuckerberg and he’s all in on open source.
Segment 3296: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5477, Text: Who would’ve thought that Mark Zuckerberg would be the good guy? No. I mean, it
Segment 3297: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5483, Text: Would’ve thought anything in this world. It’s hard to know. But open source to you ultimately is a good thing here.
Segment 3298: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5493, Text: Undoubtedly. What’s ironic about all these AI safety people is they’re going to build the exact thing they fear. We need to have one model that we control and align. This is the only way you end up paper clipped. There’s no way you end up paper clipped if everybody has an AI.
Segment 3299: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5514, Text: So opensourcing is the way to fight the paperclip maximizer.
Segment 3300: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5516, Text: Absolutely. It’s the only way. You think you’re going to control it. You’re not going to control it.
Segment 3301: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5522, Text: So the criticism you have for the AI safety folks is that there is belief and a desire for control. And that belief and desire for centralized control of dangerous AI systems is not good.
Segment 3302: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5536, Text: Sam Altman won’t tell you that GPT 4 has 220 billion parameters and is a 16 way mixture model with eight sets of weights.
Segment 3303: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5545, Text: Who did you have to murder to get that information? All right. But, yes.
Segment 3304: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5550, Text: Look. Everyone at Open AI knows what I just said was true. Right?
Segment 3305: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5553, Text: Yeah.
Segment 3306: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5554, Text: Now, ask the question. It upsets me when I… Like GPT 2, when Open AI came out with GPT two and raised a whole fake AI safety thing about that. Now the model is laughable. They used AI safety to hype up their company and it’s disgusting.
Segment 3307: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5572, Text: Or the flip side of that is they used a relatively weak model in retrospect to explore how do we do AI safety correctly? How do we release things? How do we go through the process?
Segment 3308: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5586, Text: Sure. That’s a charitable interpretation.
Segment 3309: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5590, Text: I don’t know how much hype there is in AI safety, honestly.
Segment 3310: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5592, Text: There’s so much hype, at least on Twitter. I don’t know. Maybe Twitter’s not real life.
Segment 3311: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5595, Text: Twitter’s not real life. Come on. In terms of hype. Think Open AI has been finding an interesting balance between transparency and putting a value on AI safety. You don’t think just go all out open source. So do a LLaMA.
Segment 3312: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5613, Text: Absolutely. Yeah.
Segment 3313: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5616, Text: This is a tough question, which is open source, both the base, the foundation model and the fine tune one. So the model that can be ultra racist and dangerous and tell you how to build a nuclear weapon.
Segment 3314: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5631, Text: Oh my God. Have you met humans? Right. Half of these AI alive-
Segment 3315: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5635, Text: I haven’t met most humans. This allows you to meet every human.
Segment 3316: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5640, Text: I know. But half of these AI alignment problems are just human alignment problems. And that’s what also so scary about the language they use. It’s not the machines you want to align, it’s me.
Segment 3317: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5651, Text: But here’s the thing, it makes it very accessible to ask very questions where the answers have dangerous consequences if you were to act on them.
Segment 3318: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5665, Text: Yeah, welcome to the world.
Segment 3319: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5668, Text: Well, no, for me, there’s a lot of friction. If I want to find out how to blow up something.
Segment 3320: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5676, Text: No, there’s not a lot of friction. That’s so easy.
Segment 3321: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5679, Text: No. What do I search? Do I use Bing? Which search engine engine do I use?
Segment 3322: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5685, Text: No. There’s lots of stuff. [inaudible 01:34:47].
Segment 3323: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5686, Text: No, it feels like I have to keep [inaudible 01:34:47].
Segment 3324: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5687, Text: First off, anyone who’s stupid enough to search for, how to blow up a building in my neighborhood is not smart enough to build a bomb. Right?
Segment 3325: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5694, Text: Are you sure about that?
Segment 3326: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5695, Text: Yes.
Segment 3327: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5698, Text: I feel like a language model makes it more accessible for that person who’s not smart enough to do-
Segment 3328: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5705, Text: They’re not going to build a bomb. Trust me. The people who are incapable of figuring out how to ask that question a bit more academically and get a real answer from it are not capable of procuring the materials which are somewhat controlled to build a bomb.
Segment 3329: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5719, Text: No, I think LLM makes it more accessible to people with money without the technical know-how. Right? Do you really need to know how to build a bomb? To build a bomb? You can hire people you can find-
Segment 3330: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5730, Text: Oh, you can hire people to build a… You know what, I was asking this question on my stream. Can Jeff Bezos hire a hit man? Probably not.
Segment 3331: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5737, Text: But a language model can probably help you out.
Segment 3332: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5741, Text: Yeah. And you’ll still go to jail. It’s not the language model is God. It’s you literally just hired someone on Fiverr.
Segment 3333: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5749, Text: But okay. GPT 4 in terms of finding hitman is like asking Fiverr how to find a hitman. I understand. But don’t you think-
Segment 3334: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5756, Text: Asking Wikihow.
Segment 3335: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5758, Text: Wikihow. But don’t you think GPT 5 will be better? Because don’t you think that information is out there on the internet?
Segment 3336: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5763, Text: Yeah.
Segment 3337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5763, Text: … because don’t you think that information is out there on the Internet?
Segment 3338: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5763, Text: I mean, yeah. And I think that if someone is actually serious enough to hire a hitman or build a bomb, they’d also be serious enough to find the information.
Segment 3339: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5770, Text: I don’t think so. I think it makes it more accessible. If you have enough money to buy hitman, I think it just decreases the friction of how hard is it to find that kind of hitman. I honestly think there’s a jump in ease and scale of how much harm you can do. And I don’t mean harm with language, I mean harm with actual violence.
Segment 3340: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5792, Text: What you’re basically saying is like, “Okay, what’s going to happen is these people who are not intelligent are going to use machines to augment their intelligence, and now intelligent people and machines…” Intelligence is scary. Intelligent agents are scary. When I’m in the woods, the scariest animal to me is a human. Now, look, there’s nice California humans. I see you’re wearing street clothes and Nikes, all right, fine. But you look like you’ve been a human who’s been in the woods for a while, I’m more scared of you than a bear.
Segment 3341: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5821, Text: That’s what they say about the Amazon, when you go to the Amazon, it’s the human tribes.
Segment 3342: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5825, Text: Oh, yeah. So, intelligence is scary. So, to ask this question in a generic way, you’re like, “What if we took everybody who maybe has ill intention but is not so intelligent, and gave them intelligence?” Right? So, we should have intelligence control, of course. We should only give intelligence to good people. And that is the absolutely horrifying idea.
Segment 3343: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5848, Text: So to you, the best defense is to give more intelligence to the good guys and intelligence… give intelligence to everybody.
Segment 3344: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5855, Text: Give intelligence to everybody. You know what, and it’s not even like guns. People say this about guns. People say this all about guns, “What’s the best defense against the bad guy with a gun? A good guy with a gun.” I kind of subscribe to that. But I really subscribe to that with intelligence.
Segment 3345: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5865, Text: In a fundamental way I agree with you, but there just feels like so much uncertainty, and so much can happen rapidly that you can lose a lot of control, and you can do a lot of damage.
Segment 3346: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5874, Text: Oh no, we can lose control? Yes, thank God.
Segment 3347: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5878, Text: Yeah.
Segment 3348: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5879, Text: I hope they lose control. I want them to lose control more than anything else.
Segment 3349: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5885, Text: I think when you lose control you can do a lot of damage, but you could do more damage when you centralize and hold onto control, is the point you’re…
Segment 3350: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5892, Text: Centralized and held control is tyranny. I don’t like anarchy either, but I’ll always take anarchy over tyranny. Anarchy you have a chance.
Segment 3351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5901, Text: This human civilization we got going on is quite interesting. I mean, I agree with you. So to you, open source is the way forward here. So you admire what Facebook is doing here, what Meta is doing with the release of the-
Segment 3352: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5914, Text: Yeah, a lot.
Segment 3353: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5914, Text: Yeah, I don’t know.
Segment 3354: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5916, Text: I lost $80,000 last year investing in Meta, and when they released Llama I’m like, “Yeah, whatever, man. That was worth it.”
Segment 3355: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5921, Text: It was worth it. Do you think Google and Open AI with Microsoft will match what Meta is doing, or no?
Segment 3356: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5930, Text: If I were a researcher, why would you want to work at Open AI? You’re on the bad team. I mean it. You’re on the bad team, who can’t even say that GPT4 has 220 billion parameters.
Segment 3357: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5941, Text: So closed source to you is the bad team?
Segment 3358: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5943, Text: Not only closed source. I’m not saying you need to make your model weights open. I’m not saying that. I totally understand, “We’re keeping our model weights closed, because that’s our product.” That’s fine. I’m saying, “Because of AI safety reasons we can’t tell you the number of billions of parameters in the model,” that’s just the bad guys.
Segment 3359: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5963, Text: Just because you’re mocking AI safety doesn’t mean it’s not real.
Segment 3360: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5966, Text: Oh, of course.
Segment 3361: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5967, Text: Is it possible that these things can really do a lot of damage that we don’t know…
Segment 3362: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5971, Text: Oh my God, yes. Intelligence is so dangerous, be it human intelligence or machine intelligence. Intelligence is dangerous.
Segment 3363: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5978, Text: But machine intelligence is so much easier to deploy at scale, rapidly. Okay, if you have human-like bots on Twitter, and you have 1000 of them create a whole narrative, you can manipulate millions of people.
Segment 3364: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5995, Text: You mean like the intelligence agencies in America are doing right now?
Segment 3365: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=5999, Text: Yeah, but they’re not doing it that well. It feels like you can do a lot-
Segment 3366: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6003, Text: They’re doing it pretty well. I think they’re doing a pretty good job.
Segment 3367: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6007, Text: I suspect they’re not nearly as good as a bunch of GPT fueled bots could be.
Segment 3368: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6012, Text: Well, I mean, of course they’re looking into the latest technologies for control of people. Of course.
Segment 3369: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6016, Text: But I think there’s a George Hotz type character that can do a better job than the entirety of them.
Segment 3370: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6021, Text: No way.
Segment 3371: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6021, Text: You don’t think so?
Segment 3372: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6022, Text: No way. No. And I’ll tell you why the George Hotz character can’t. And I thought about this a lot with hacking. I can find exploits in web browsers. I probably still can. I mean, I was better at it when I was 24.
Segment 3373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6029, Text: Yeah.
Segment 3374: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6029, Text: But the thing that I lack is the ability to slowly and steadily deploy them over five years. And this is what intelligence agencies are very good at. Intelligence agencies don’t have the most sophisticated technology, they just have-
Segment 3375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6043, Text: Endurance?
Segment 3376: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6044, Text: Endurance.
Segment 3377: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6046, Text: And yeah, the financial backing, and the infrastructure for the endurance.
Segment 3378: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6051, Text: So the more we can decentralize power…
Segment 3379: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6054, Text: Yeah.
Segment 3380: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6055, Text: You can make an argument, by the way, that nobody should have these things. And I would defend that argument. You’re saying that, “Look, LLMs, and AI, and machine intelligence can cause a lot of harm, so nobody should have it.” And I will respect someone philosophically with that position, just like I will respect someone philosophically with the position that nobody should have guns. But I will not respect philosophically with, “Only the trusted authorities should have access to this.”
Segment 3381: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6081, Text: Yeah.
Segment 3382: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6082, Text: Who are the trusted authorities? You know what, I’m not worried about alignment between AI company and their machines. I’m worried about alignment between me and AI company.
Segment 3383: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6093, Text: What do you think Eliezer Yudkowsky would say to you? Because he’s really against open source.
Segment 3384: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6099, Text: I know. And I thought about this. I’ve thought about this. And I think this comes down to a repeated misunderstanding of political power by the rationalists.
Segment 3385: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6115, Text: Interesting.
Segment 3386: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6118, Text: I think that Eliezer Yudkowsky is scared of these things. And I am scared of these things too. Everyone should be scared of these things, these things are scary. But now you ask about the two possible futures, one where a small trusted centralized group of people has them, and the other where everyone has them, and I am much less scared of the second future than the first.
Segment 3387: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6143, Text: Well, there’s a small trusted group of people that have control of our nuclear weapons.
Segment 3388: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6148, Text: There’s a difference. Again, a nuclear weapon cannot be deployed tactically, And a nuclear weapon is not a defense against a nuclear weapon, except maybe in some philosophical mind game kind of way.
Segment 3389: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6161, Text: But AI’s different how exactly?
Segment 3390: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6164, Text: Okay. Let’s say the intelligence agency deploys a million bots on Twitter, or 1000 bots on Twitter to try and convince me of a point. Imagine I had a powerful AI running on my computer saying, “Okay, nice psyop, nice psyop, nice psyop.” Okay, ” Here’s a psyop, I filtered it out for you.”
Segment 3391: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6184, Text: Yeah. I mean, so you have fundamentally hope for that, for the defense of psyop.
Segment 3392: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6191, Text: I don’t even mean these things in truly horrible ways. I mean these things in straight up, like ad blocker. [inaudible 01:43:16] ad blocker, I don’t want ads.
Segment 3393: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6198, Text: Yeah.
Segment 3394: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6198, Text: But they’re always finding… Imagine I had an AI that could just block all the ads for me.
Segment 3395: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6204, Text: So you believe in the power of the people to always create an ad blocker? Yeah, I kind of share that belief. That’s one of the deepest optimism as I have, is just there’s a lot of good guys. So you shouldn’t handpick them, just throw out powerful technology out there, and the good guys will outnumber and out power the bad guys.
Segment 3396: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6229, Text: Yeah. I’m not even going to say there’s a lot of good guys. I’m saying that good outnumbers bad. Good outnumbers bad.
Segment 3397: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6234, Text: In skill and performance?
Segment 3398: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6236, Text: Yeah, definitely in scale and performance. Probably just a number too. Probably just in general. If you believe philosophically in democracy, you obviously believe that, that good outnumbers bad. If you give it to a small number of people, there’s a chance you gave it to good people, but there’s also a chance you gave it to bad people. If you give it to everybody, well it’s good outnumbers bad, then you definitely gave it to more good people than bad.
Segment 3399: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6265, Text: That’s really interesting. So that’s on the safety grounds, but then also of course there’s other motivations, like you don’t want to give away your secret sauce.
Segment 3400: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6272, Text: Well I mean, look, I respect capitalism. I think that it would be polite for you to make model architectures open source, and fundamental breakthroughs open source. I don’t think you have to make weights open source.
Segment 3401: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6283, Text: You know it’s interesting, is that there’s so many possible trajectories in human history where you could have the next Google be open source. So for example, I don’t know if the connection is accurate, but Wikipedia made a lot of interesting decisions, not to put ads. Wikipedia is basically open source, you can think of it that way.
Segment 3402: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6304, Text: Yeah.
Segment 3403: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6305, Text: And that’s one of the main websites on the Internet.
Segment 3404: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6308, Text: Yeah.
Segment 3405: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6309, Text: And it didn’t have to be that way. It could’ve been Google could’ve created Wikipedia, put ads on it. You could probably run amazing ads now on Wikipedia. You wouldn’t have to keep asking for money. But it’s interesting, right? So open source Llama, derivatives of open-source Llama might win the Internet.
Segment 3406: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6328, Text: I sure hope so. I hope to see another era… You know, the kids today don’t know how good the Internet used to be. And I don’t think this is just, “All right, come on, everyone’s nostalgic for their past.” But I actually think the Internet before small groups of weapon eyes to corporate and government interests took it over was a beautiful place.
Segment 3407: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6350, Text: You know, those small number of companies have created some sexy products. But you’re saying overall, in the long arc of history, the centralization of power they have suffocated the human spirit at scale.
Segment 3408: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6364, Text: Here’s a question to ask about those beautiful sexy products. Imagine 2000 Google to 2010 Google. A lot changed. We got Maps, we got Gmail.
Segment 3409: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6374, Text: We lost a lot of products too, I think.
Segment 3410: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6376, Text: Yeah, I mean somewhere probably… We got Chrome, right?
Segment 3411: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6378, Text: Yeah, Chrome. That’s right.
Segment 3412: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6379, Text: And now let’s go from 2010… We got Android. Now let’s go from 2010 to 2020. What does Google have? Well, a search engine, Maps, Male, Android and Chrome. Oh, I see.
Segment 3413: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6390, Text: Yeah.
Segment 3414: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6391, Text: The Internet was this… You know, I was Time’s Person of the Year in 2006? Yeah.
Segment 3415: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6398, Text: I love this.
Segment 3416: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6399, Text: Yeah, it’s you, was Time’s Person of the Year in 2006. So quickly did people forget. And I think some of it’s social media, I think some of it… Look, I hope that… It’s possible that some very sinister things happened. I don’t know, I think it might just be the effects of social media. But something happened in the last 20 years.
Segment 3417: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6425, Text: Oh, okay, so you’re just being an old man who is worried about the… I think it’s the cycle thing, there’s ups and downs, and I think people rediscover the power of decentralized.
Segment 3418: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6435, Text: Yeah.
Segment 3419: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6435, Text: I mean, that’s kind of what the whole crypto currency’s trying. I think crypto is just carrying the flame of that spirit, of stuff should be decentralized.
Segment 3420: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6445, Text: It’s just such a shame that they all got rich. You know?
Segment 3421: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6448, Text: Yeah.
Segment 3422: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6448, Text: If you took all the money out of crypto, it would’ve been a beautiful place.
Segment 3423: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6452, Text: Yeah.
Segment 3424: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6452, Text: But no, I mean, these people, they sucked all the value out of it and took it.
Segment 3425: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6458, Text: Yeah. Money kind of corrupts the mind somehow. It becomes this drug, and you forget what-
Segment 3426: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6462, Text: Money corrupted all of crypto. You had coins worth billions of dollars that had zero use.
Segment 3427: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6469, Text: You still have hope for crypto?
Segment 3428: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6471, Text: Sure. I have hope for the ideas. I really do. Yeah. I want the US dollar to collapse. I do.
Segment 3429: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6483, Text: George Hotz. Well, let me… sort of on the AI safety. Do you think there’s some interesting questions there though, to solve for the open source community in this case? So alignment for example, or the control problem. If you really have super powerful… you said it’s scary.
Segment 3430: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6501, Text: Oh, yeah.
Segment 3431: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6501, Text: What do we do with it? So not control, not centralized control, but if you were then… You’re going to see some guy or gal release a super powerful language model, open source, and here you are, George Hotz, thinking, “Holy shit, okay, what ideas do I have to combat this thing?” So, what ideas would you have?
Segment 3432: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6524, Text: I am so much not worried about the machine independently doing harm. That’s what some of these AI safety people seem to think. They somehow seem to think that the machine independently is going to rebel against its creator.
Segment 3433: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6537, Text: So you don’t think it will find autonomy?
Segment 3434: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6539, Text: No. This is sci-fi B movie garbage
Segment 3435: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6543, Text: Okay. What if the thing writes code, it basically writes viruses?
Segment 3436: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6548, Text: If the thing writes viruses, it’s because the human told it to write viruses.
Segment 3437: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6554, Text: Yeah, but there’s some things you can’t put back in the box. That’s kind of the whole point, is it kind of spreads. Give it access to the Internet, it spreads, it installs itself, modifies your shit-
Segment 3438: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6564, Text: B, B, B + five. Not real.
Segment 3439: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6567, Text: Listen, I’m trying to get better at my plot writing.
Segment 3440: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6570, Text: The thing that worries me, I mean, we have a real danger to discuss, and that is bad humans using the thing to do whatever bad unaligned AI thing you want.
Segment 3441: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6579, Text: But this goes to your previous concern that, who gets to define who’s a good human and who is a bad human?
Segment 3442: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6585, Text: Nobody does. We give it to everybody. And if you do anything besides give it to everybody, trust me, the bad humans will get it. Because that’s who gets power. It’s always the bad humans who get power.
Segment 3443: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6595, Text: Oh, okay. And power turns even slightly good humans to bad.
Segment 3444: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6601, Text: Sure.
Segment 3445: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6602, Text: That’s the intuition you have. I don’t know.
Segment 3446: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6606, Text: I don’t think everyone. I don’t think everyone. I just think… Here’s the saying that I put in one of my blog posts. It’s, when I was in the hacking world, I found 95% of people to be good and 5% of people to be bad. Just who I personally judged as good people and bad people. They believed about good things for the world. They wanted flourishing, and they wanted growth, and they wanted things I consider good. I came into the business world with Comma, and I found the exact opposite. I found 5% of people good and 95% of people bad. I found a world that promotes psychopathy.
Segment 3447: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6638, Text: I wonder what that means. I wonder if that’s anecdotal, or if there’s truth to that, there’s something about capitalism at the core that promotes, the people that run capitalism that promotes psychopathy.
Segment 3448: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6655, Text: That saying may of course be my own biases. That may be my own biases, that these people are a lot more aligned with me than these other people.
Segment 3449: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6663, Text: Yeah.
Segment 3450: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6664, Text: So, I can certainly recognize that. But in general, this is the common sense maxim, which is the people who end up getting power are never the ones you want with it.
Segment 3451: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6675, Text: But do you have a concern of super intelligent AGI, open sourced, and then what do you do with that? I’m not saying control it, it’s open source. What do we do with it as a human species?
Segment 3452: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6687, Text: That’s not up to me. I’m not a central planner.
Segment 3453: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6691, Text: No, not a central planner, but you’ll probably Tweet, “There’s a few days left to live for the human species.”
Segment 3454: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6695, Text: I have my ideas of what to do with it, and everyone else has their ideas of what to do with it, and may the best ideas win.
Segment 3455: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6700, Text: But at this point, based on… Because it’s not regulation. It can be decentralized regulation, where people agree that this is just… We create tools that make it more difficult for you to… Maybe make it more difficult for code to spread, antivirus software, this kind of thing, but this-
Segment 3456: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6721, Text: Oh, you’re saying that you should build AI firewalls? That sounds good. You should definitely be running an AI firewall.
Segment 3457: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6725, Text: Yeah, right. Exactly.
Segment 3458: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6725, Text: You should be running an AI firewall to your mind.
Segment 3459: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6728, Text: Right.
Segment 3460: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6729, Text: You’re constantly under-
Segment 3461: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6730, Text: That’s such an interesting idea…
Segment 3462: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6731, Text: Infowars, man.
Segment 3463: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6733, Text: Well, I don’t know if you’re being sarcastic or not, but-
Segment 3464: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6734, Text: No, I’m dead serious.
Segment 3465: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6735, Text: … but I think there’s power to that. It’s like, “How do I protect my mind from influence of human-like or superhuman intelligent bots?”
Segment 3466: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6746, Text: I am not being… I would pay so much money for that product. I would pay so much money for that product. You know how much money I’d pay just for a spam filter that works?
Segment 3467: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6755, Text: Well, on Twitter sometimes I would like to have a protection mechanism for my mind from the outrage mobs.
Segment 3468: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6766, Text: Yeah.
Segment 3469: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6766, Text: Because they feel like bot-like behavior.
Segment 3470: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6768, Text: Oh, yeah.
Segment 3471: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6768, Text: There’s a large number of people that will just grab a viral narrative and attack anyone else that believes otherwise.
Segment 3472: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6775, Text: Whenever someone’s telling me some story from the news, I’m always like, “I don’t want to hear it. CIA op, bro. It’s a CIA op, bro.” It doesn’t matter if that’s true or not, it’s just trying to influence your mind. You’re repeating an ad to me. The viral mobs, yeah, they’re…
Segment 3473: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6789, Text: To me, a defense against those mobs is just getting multiple perspectives always from sources that make you feel kind of like you’re getting smarter. And actually, it just basically feels good. A good documentary, just something feels good about it. It’s well done, it’s like, “Oh, okay, I never thought of it this way.” It just feels good. Sometimes the outrage mobs, even if they have a good point behind it, when they’re mocking, and derisive, and just aggressive, “You’re with us or against us,” this fucking-
Segment 3474: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6822, Text: This is why I delete my Tweets.
Segment 3475: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6824, Text: Yeah, why’d you do that? I miss your Tweets.
Segment 3476: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6828, Text: You know what it is? The algorithm promotes toxicity.
Segment 3477: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6832, Text: Yeah.
Segment 3478: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6834, Text: And I think Elon has a much better chance of fixing it than the previous regime.
Segment 3479: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6841, Text: Yeah.
Segment 3480: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6842, Text: But to solve this problem, to build a social network that is actually not toxic, without moderation.
Segment 3481: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6853, Text: Not the stick, but carrots, where people look for goodness. Catalyze the process of connecting cool people being cool to each other.
Segment 3482: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6864, Text: Yeah.
Segment 3483: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6865, Text: Without ever censoring.
Segment 3484: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6866, Text: Without ever censoring. Scott Alexander has a blog post I like, where he talks about moderation is not censorship. All moderation you want to put on Twitter, you could totally make this moderation just a… You don’t have to block it for everybody. You can just have a filter button that people can turn off. It’s like SafeSearch for Twitter. Someone could just turn that off. But then you would take this idea to an extreme. Well, the network should just show you… This is a couch surfing CEO thing. If it shows you… Right now, these algorithms are designed to maximize engagement. Well, it turns out outrage maximizes engagement. Quirk of the human mind. Just, “If I fall for it, everyone falls for it.” So yeah, you’ve got to figure out how to maximize for something other than engagement.
Segment 3485: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6912, Text: And I actually believe that you can make money with that too. I don’t think engagement is the only way to make money.
Segment 3486: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6918, Text: I actually think it’s incredible that we’re starting to see… I think, again, Elon’s doing so much stuff right with Twitter, like charging people money. As soon as you charge people money, they’re no longer the product, they’re the customer. And then they can start building something that’s good for the customer, and not good for the other customer, which is the ad agencies.
Segment 3487: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6934, Text: It hasn’t picked up steam.
Segment 3488: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6938, Text: I pay for Twitter, doesn’t even get me anything. It’s my donation to this new business model hopefully working out.
Segment 3489: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6943, Text: Sure. But for this business model to work, most people should be signed up to Twitter. And so, there was something perhaps not compelling or something like this to people.
Segment 3490: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6954, Text: No, I don’t think you need most people at all. I think that, why do I need most people? Don’t make an 8000 person company, make a 50 person company.
Segment 3491: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6962, Text: Ah.
Segment 3492: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6962, Text: Right.
Segment 3493: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6963, Text: Well, so speaking of which, he worked at Twitter for a bit.
Segment 3494: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6968, Text: I did.
Segment 3495: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6969, Text: As an intern.
Segment 3496: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6970, Text: Mm-hmm.
Segment 3497: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6971, Text: The world’s greatest intern.
Segment 3498: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6974, Text: There’s been better.
Segment 3499: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6975, Text: There’s been better. Tell me about your time at Twitter. How did it come about, and what did you learn from the experience?
Segment 3500: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=6982, Text: So, I deleted my first Twitter in 2010. I had over 100,000 followers back when that actually meant something. I just saw… My coworker summarized it well. He’s like, “Whenever I see someone’s Twitter page, I either think the same of them or less of them. I never think more of them.”
Segment 3501: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7006, Text: Yeah.
Segment 3502: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7009, Text: I don’t know, I don’t want to mention any names, but some people who maybe you would read their books, and you would respect them, you see them on Twitter and you’re like, “Okay, dude…”
Segment 3503: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7018, Text: Yeah. But there’s some people with the same. You know who I respect a lot, are people that just post really good technical stuff.
Segment 3504: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7026, Text: Yeah.
Segment 3505: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7028, Text: And I guess, I don’t know, I think I respect them more for it. Because you realize, “Oh, this wasn’t… There’s so much depth to this person, to their technical understanding of so many different topics.”
Segment 3506: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7041, Text: Okay.
Segment 3507: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7042, Text: So I try to follow people, I try to consume stuff that’s technical machine learning content.
Segment 3508: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7047, Text: There’s probably a few of those people. And the problem is inherently what the algorithm rewards. And people think about these algorithms, people think that they are terrible, awful things. And I love that Elon open sourced it. Because what it does is actually pretty obvious. It just predicts what you are likely to re-Tweet and like, and linger on. That’s what all these algorithms do. It’s what Tik-Tok does, it’s what all these recommendation engines do. And it turns out that the thing that you are most likely to interact with is outrage. And that’s a quirk of the human condition.
Segment 3509: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7084, Text: I mean, and there’s different flavors of outrage. It could be mockery, you could be outraged… The topic of outrage could be different. It could be an idea, it could be a person, it could be… And maybe there’s a better word than outrage. It could be drama, and this kind of stuff.
Segment 3510: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7099, Text: Sure, drama. Yeah.
Segment 3511: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7100, Text: But it doesn’t feel like when you consume it it’s a constructive thing for the individuals that consume it in the long term.
Segment 3512: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7106, Text: Yeah. So my time there, I absolutely couldn’t believe, I got a crazy amount of hate on Twitter for working at Twitter. It seemed like people associated with this, maybe you are exposed to some of this.
Segment 3513: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7121, Text: So connection to Elon, or is it working at Twitter?
Segment 3514: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7124, Text: Twitter and Elon, the whole… There’s just-
Segment 3515: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7127, Text: Because Elon’s gotten a bit spicy during that time. A bit political, a bit-
Segment 3516: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7132, Text: Yeah. Yeah. I remember one of my Tweets, it was, “Never go full Republican,” and Elon liked it. You know?
Segment 3517: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7140, Text: Oh boy. Yeah, I mean, there’s a roller coaster of that. But the being political on Twitter, boy.
Segment 3518: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7150, Text: Yeah. Yeah.
Segment 3519: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7151, Text: And also just attacking anybody on Twitter, it comes back at you, harder. Of his political ad attacks.
Segment 3520: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7160, Text: Sure. Sure, absolutely.
Segment 3521: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7162, Text: And then letting sort of the platform to people back on even adds more fund to the beautiful chaos.
Segment 3522: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7174, Text: I was hoping… And I remember when Elon talked about buying Twitter, six months earlier, he was talking about a principled commitment to free speech. And I’m a big believer and fan of that. I would love to see an actual principled commitment to free speech. Of course, this isn’t quite what happened. Instead of the oligarchy deciding what to ban, you had a monarchy deciding what to ban. Instead of all the Twitterphile, shadow… And really, the oligarchy just decides, what? Cloth masks are ineffective against COVID. That’s a true statement. Every doctor in 2019 knew it and now I’m banned on Twitter for saying it? Interesting. Oligarchy. So now you have a monarchy, and he bends things he doesn’t like. So you know, it’s different power, and maybe I align more with him than with the oligarchy.
Segment 3523: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7225, Text: But it’s not free speech absolutism.
Segment 3524: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7225, Text: It’s not free speech, no.
Segment 3525: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7228, Text: But I feel like being a free speech absolutist on a social network requires you to also have tools for the individuals to control what they consume easier. Not sensor, but just control like, “Oh, I’d like to see more cats and less politics.”
Segment 3526: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7248, Text: And this isn’t even remotely controversial. This is just saying you want to give paying customers for a product what they want.
Segment 3527: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7254, Text: Yeah. And not through the process of censorship, but through the process of-
Segment 3528: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7257, Text: Well, it’s individualized. It’s individualized, transparent censorship, which is honestly what I want. What is an ad blocker? It’s individualized transparent censorship, right?
Segment 3529: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7265, Text: Yeah, but censorship is a strong word, that people are very sensitive to.
Segment 3530: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7270, Text: I know. But you know, I just use words to describe what they functionally are. And what is an ad blocker? It’s just censorship. But I love what you’re censoring.
Segment 3531: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7276, Text: When I look at you right now, I’m looking at you, I’m censoring everything else out when my mind is focused on you. You can use the word censorship that way. But usually, people get very sensitive about the censorship thing. I think when anyone is allowed to say anything, you should probably have tools that maximize the quality of the experience for individuals. For me, what I really value, “Boy, it would be amazing to somehow figure out how to do that,” I love disagreement, and debate, and people who disagree with each other, disagree with me, especially in the space of ideas, but the high quality ones. So not derision.
Segment 3532: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7316, Text: Maslow’s hierarchy of argument. I think there’s a real word for it.
Segment 3533: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7320, Text: Probably.
Segment 3534: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7320, Text: Yeah.
Segment 3535: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7320, Text: There’s just the way of talking that’s snarky, and so somehow gets people on Twitter, and they get excited and so on.
Segment 3536: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7328, Text: You have ad hominem refuting the central point. I’ve seen this as an actual pyramid sometimes.
Segment 3537: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7332, Text: Yeah. And all the wrong stuff is attractive to people.
Segment 3538: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7336, Text: I mean, we can just train a classifier to absolutely say what level of Maslow’s hierarchy of argument are you at. And if it’s ad hominem, like, “Okay, cool. I turned on the no ad hominem filter.”
Segment 3539: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7347, Text: I wonder if there’s a social network that will allow you to have that kind of filter?
Segment 3540: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7351, Text: Yeah. So here’s the problem with that. It’s not going to win in a free market.
Segment 3541: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7358, Text: Yeah.
Segment 3542: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7358, Text: What wins in a free market is… All television today is reality television, because it’s engaging. Engaging is what wins in a free market. So it becomes hard to keep these other more nuanced values.
Segment 3543: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7373, Text: Well, okay, so that’s the experience of being on Twitter. But then you got a chance to also, together with the other engineers and with Elon, sort of look, brainstorm when you step into a code base that’s been around for a long time, there’s other social networks, Facebook, this is old code bases. And you step in and see, “Okay, how do we make, with a fresh mind, progress in this code base?” What did you learn about software engineering, about programming from just experiencing that?
Segment 3544: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7402, Text: So, my technical recommendation to Elon, and I said this on the Twitter spaces afterward, I said this many times during my brief internship, was that you need re-factors before features. This code base was… And look, I’ve worked at Google, I’ve worked at Facebook. Facebook has the best code, then Google, then Twitter. And you know what, you can know this, because look at the machine learning framework. Facebook released PyTorch, Google released TensorFlow, and Twitter released… Okay, so you know, it…
Segment 3545: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7437, Text: It’s a proxy. But yeah, the Google Corp. is quite interesting. There’s a lot of really good software engineers there, but the code base is very large.
Segment 3546: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7444, Text: The code base was good in 2005. It looks like 2005 era [inaudible 02:04:09].
Segment 3547: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7448, Text: But there’s so many products, so many teams, it’s very difficult to… I feel like Twitter does less, obviously, much less than Google in terms of the set of features. So I can imagine the number of software engineers that could re-create Twitter is much smaller than to re-create Google.
Segment 3548: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7470, Text: Yeah. I still believe… and the amount of hate I got for saying this, that 50 people could build and maintain Twitter pretty comfortably.
Segment 3549: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7484, Text: What’s the nature of the hate? That you don’t know what you’re talking about?
Segment 3550: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7484, Text: You know what it is? And this is my summary of the hate I get on Hacker News. When I say I’m going to do something, they have to believe that it’s impossible. Because of doing things was possible, they’d have to do some soul-searching and ask the question, why didn’t they do anything? And I do think that’s where the hate comes from.
Segment 3551: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7506, Text: Yeah, there’s a core truth to that, yeah. So when you say, “I’m going to solve self driving,” people go like, “What are your credentials? What the hell are you talking about? This is an extremely difficult problem. Of course you’re a noob that doesn’t understand the problem deeply.” I mean, that was the same nature of hate that probably Elon got when he first talked about autonomous driving. But you know, there’s pros and cons to that. Because there is experts in this world.
Segment 3552: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7533, Text: No, but the mockers aren’t experts.
Segment 3553: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7535, Text: Yeah.
Segment 3554: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7535, Text: The people who are mocking are not experts With carefully reasoned arguments about why you need 8000 people to run a bird app. They’re, “But the people are going to lose their jobs!”
Segment 3555: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7546, Text: Well that, but also just the software engineers that probably criticize, “No, it’s a lot more complicated than you realize.” But maybe it doesn’t need to be so complicated.
Segment 3556: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7553, Text: You know, some people in the world like to create complexity. Some people in the world thrive under complexity. Like lawyers. Lawyers want the world to be more complex, because you need more lawyers, you need more legal hours. I think that’s another… If there’s two great evils in the world, its centralization and complexity.
Segment 3557: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7569, Text: Yeah. And one of the sort of hidden side effects of software engineering is finding pleasure in complexity. I mean, I remember just taking all the software engineering courses, and just doing programming, and just coming up in this object oriented programming kind of idea. Not often do people tell you, “Do the simplest possible thing.” A professor, a teacher is not going to get in front and like, “This is the simplest way to do it.” They’ll say like, “There’s the right way,” and the right way at least for a long time, especially I came up with Java, is there’s so much boilerplate, so many classes, so many designs and architectures and so on, like planning for features far into the future, and planning poorly, and all this kind of stuff.
Segment 3558: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7628, Text: And then there’s this code base that follows you along and puts pressure on you, and nobody knows what different parts do, which slows everything down. There’s a kind of bureaucracy that’s instilled in the code as a result of that. But then you feel like, “Oh, well I follow good software engineering practices.” It’s an interesting trade-off, because then you look at the ghettoness of Pearl in the old… how quickly you could just write a couple lines and just get stuff done. That trade-off is interesting. Or Bash, or whatever, these kind of ghetto things you could do on Linux.
Segment 3559: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7659, Text: One of my favorite things to look at today is, how much do you trust your tests? We’ve put a ton of effort in Comma, and I’ve put a ton of effort in tinygrad, into making sure if you change the code and the tests pass, that you didn’t break the code.
Segment 3560: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7672, Text: Yeah.
Segment 3561: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7672, Text: Now, this obviously is not always true. But the closer that is to true, the more you trust your tests, the more you’re like, “Oh, I got a pull request, and the tests past, I feel okay to merge that,” the faster you can make progress.
Segment 3562: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7683, Text: So you’re always…
Segment 3563: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7683, Text: Tests pass, I feel okay to merge that, the faster you can make progress.
Segment 3564: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7683, Text: So you’re always programming your tests in mind, developing tests with that in mind, that if it passes, it should be good.
Segment 3565: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7688, Text: And Twitter had a…
Segment 3566: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7690, Text: Not that.
Segment 3567: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7690, Text: It was impossible to make progress in the code base.
Segment 3568: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7695, Text: What other stuff can you say about the code base that made it difficult? What are some interesting sort of quirks broadly speaking from that compared to just your experience with comma and everywhere else?
Segment 3569: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7709, Text: I spoke to a bunch of individual contributors at Twitter. And I just [inaudible 02:08:36]. I’m like, “Okay, so what’s wrong with this place? Why does this code look like this?” And they explained to me what Twitter’s promotion system was. The way that you got promoted to Twitter was you wrote a library that a lot of people used, right? So some guy wrote an Nginx replacement for Twitter. Why does Twitter need an Nginx replacement? What was wrong with Nginx? Well, you see, you’re not going to get promoted if you use Nginx. But if you write a replacement and lots of people start using it as the Twitter front end for their product, then you’re going to get promoted.
Segment 3570: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7748, Text: So interesting because from an individual perspective, how do you create the kind of incentives that will lead to a great code base? Okay, what’s the answer to that?
Segment 3571: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7760, Text: So what I do at comma and at Tiny Corp is you have to explain it to me. You have to explain to me what this code does. And if I can sit there and come up with a simpler way to do it, you have to rewrite it. You have to agree with me about the simpler way. Obviously, we can have a conversation about this. It’s not dictatorial, but if you’re like, “Wow. Wait, that actually is way simpler.” The simplicity is important.
Segment 3572: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7787, Text: But that requires people that overlook the code at the highest levels to be like, okay?
Segment 3573: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7794, Text: It requires technical leadership you trust.
Segment 3574: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7795, Text: Yeah, technical leadership. So managers or whatever should have to have technical savvy, deep technical savvy.
Segment 3575: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7803, Text: Managers should be better programmers than the people who they manage.
Segment 3576: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7805, Text: Yeah. And that’s not always trivial to create, especially large companies, managers get soft.
Segment 3577: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7813, Text: And this is just, I’ve instilled this culture at comma and comma has better programmers than me who work there. But again, I’m like the old guy from Good Will Hunting. It’s like, “Look man, I might not be as good as you, but I can see the difference between me and you.” And this is what you need, this you need at the top. Or you don’t necessarily need the manager to be the absolute best. I shouldn’t say that, but they need to be able to recognize skill.
Segment 3578: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7836, Text: Yeah. And have good intuition, intuition that’s laden with wisdom from all the battles of trying to reduce complexity in code bases.
Segment 3579: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7845, Text: I took a political approach at comma too, that I think is pretty interesting. I think Elon takes the same political approach. Google had no politics and what ended up happening is the absolute worst kind of politics took over. Comma has an extreme amount of politics and they’re all mine and no dissidents is tolerated.
Segment 3580: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7862, Text: And so it’s a dictatorship.
Segment 3581: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7863, Text: Yep. It’s an absolute dictatorship. Right. Elon does the same thing. Now, the thing about my dictatorship is here are my values.
Segment 3582: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7871, Text: Yeah. It’s just transparent.
Segment 3583: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7872, Text: It’s transparent. It’s a transparent dictatorship and you can choose to opt in or you get free exit. That’s the beauty of companies. If you don’t like the dictatorship, you quit.
Segment 3584: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7882, Text: So you mentioned rewrite before or refactor before features.
Segment 3585: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7887, Text: Mm-hmm.
Segment 3586: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7888, Text: If you were to refactor the Twitter code base, what would that look like? And maybe also comment on how difficult is it to refactor.
Segment 3587: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7895, Text: The main thing I would do is first of all, identify the pieces and then put tests in between the pieces. So there’s all these different Twitter as a microservice architecture, all these different microservices. And the thing that I was working on there… Look, like, “George didn’t know any JavaScript. He asked how to fix search,” blah, blah, blah, blah, blah. Look man, the thing is, I’m upset that the way that this whole thing was portrayed because it wasn’t taken by people, honestly. It was taken by people who started out with a bad faith assumption.
Segment 3588: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7932, Text: And you as a program were just being transparent out there, actually having fun, and this is what programming should be about.
Segment 3589: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7938, Text: But I love that Elon gave me this opportunity. Really, it does. And the day I quit, he came on my Twitter spaces afterward and we had a conversation. I respect that so much.
Segment 3590: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7949, Text: Yeah. And it’s also inspiring to just engineers and programmers and it’s cool. It should be fun. The people that are hating on it’s like, oh man.
Segment 3591: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7958, Text: It was fun. It was fun. It was stressful, but I felt like I was at a cool point in history. And I hope I was useful and I probably kind of wasn’t, but maybe [inaudible 02:12:47].
Segment 3592: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7967, Text: Well, you also were one of the people that kind of made a strong case to refactor and that’s a really interesting thing to raise. The timing of that is really interesting. If you look at just the development of autopilot, going from Mobileye… If you look at the history of semi autonomous driving in Tesla, is more and more you could say refactoring or starting from scratch, redeveloping from scratch.
Segment 3593: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7997, Text: It’s refactoring all the way down.
Segment 3594: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=7999, Text: And the question is, can you do that sooner? Can you maintain product profitability and what’s the right time to do it? How do you do it? And one day, it’s like you don’t want to pull off the band aids. It’s like everything works. It’s just little fixed gear and there, but maybe starting from scratch.
Segment 3595: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8021, Text: This is the main philosophy of tinygrad. You have never refactored enough. Your code can get smaller, your code can get simpler, your ideas can be more elegant.
Segment 3596: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8029, Text: But say you are running Twitter development teams, engineering teams, would you go as far as different programming language, just go that far?
Segment 3597: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8043, Text: I mean, the first thing that I would do is build tests. The first thing I would do is get a CI to where people can trust to make changes. Before I touched any code, I would actually say, “No one touches any code. The first thing we do is we test this code base.” This is classic. This is how you approach a legacy code base. This is like how to approach a legacy code base book will tell you.
Segment 3598: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8067, Text: And then you hope that there’s modules that can live on for a while and then you add new ones maybe in a different language or design it.
Segment 3599: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8077, Text: Before we add new ones, we replace the old ones.
Segment 3600: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8079, Text: Yeah. Meaning like, replace old ones with something simpler.
Segment 3601: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8082, Text: We look at this thing that’s a hundred thousand lines and we’re like, “Well, okay, maybe this did even make sense in 2010, but now we can replace this with an open source thing.” Right? And we look at this here, here’s another 50,000 lines. Well, actually, we can replace this with 300 lines a go. And you know what? I trust that the go actually replaces this thing because all the tests still pass. So step one is testing. And then step two is the programming languages in the afterthought, right? You let a whole lot of people compete and be like, “Okay, who wants to rewrite a module, whatever language you want to write it in?” Just the tests have to pass. And if you figure out how to make the test pass, but break the site, we got to go back to step one. Step one is get tests that you trust in order to make changes in the code base.
Segment 3602: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8123, Text: I wonder how hard it is too, because I’m with you on testing, on everything, from tests to asserts to everything. But code is just covered in this because it should be very easy to make rapid changes and know that it’s not going to break everything. And that’s the way to do it. But I wonder how difficult is it to integrate tests into a code base that doesn’t have many of them?
Segment 3603: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8150, Text: So I’ll tell you what my plan was at Twitter. It’s actually similar to something we use at comma. So at comma, we have this thing called process replay, and we have a bunch of routes that’ll be run through. So comma’s a microservice architecture too. We have microservices in the driving. We have one for the cameras, one for the sensor, one for the planner, one for the model. And we have an API which the microservices talk to each other with. We use this custom thing called serial, which uses ZMQ. Twitter uses Thrift, and then it uses this thing called Finagle, which is a Scala RPC backend. But this doesn’t even really matter.
Segment 3604: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8185, Text: The Thrift and Finagle layer was a great place I thought to write tests, to start building something that looks like process replay. So Twitter had some stuff that looked kind of like this, but it wasn’t offline. It was only online. So you could ship a modified version of it, and then you could redirect some of the traffic to your modified version and dif those too, but it was all online. There was no CI in the traditional sense. I mean there was some, but it was not full coverage.
Segment 3605: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8214, Text: So you can’t run all of Twitter offline to test something.
Segment 3606: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8217, Text: Well, then this was another problem. You can’t run all of Twitter.
Segment 3607: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8220, Text: Period. Any one person can’t.
Segment 3608: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8223, Text: Twitter runs in three data centers and that’s it.
Segment 3609: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8225, Text: Yeah.
Segment 3610: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8225, Text: There’s no other place you can run Twitter, which is like, “George, you don’t understand this is modern software development.” No, this is bullshit. Why can’t it run on my laptop? “What do you do? Twitter can run it.” Yeah. Okay. Well, I’m not saying you’re going to download the whole database to your laptop, but I’m saying all the middleware and the front end should run on my laptop, right?
Segment 3611: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8244, Text: That sounds really compelling. But can that be achieved by a code base that grows over the years? I mean, the three data centers didn’t have to be right? Because there’s totally different designs.
Segment 3612: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8257, Text: The problem is more like why did the code base have to grow? What new functionality has been added to compensate for the lines of code that are there?
Segment 3613: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8267, Text: One of the ways to explain is that the incentive for software developers to move up in the companies to add code, to add especially large-
Segment 3614: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8275, Text: And you know what? The incentive for politicians to move up in the political structure is to add laws, same problem.
Segment 3615: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8281, Text: Yeah. Yeah. If the flip side is to simplify, simplify, simplify.
Segment 3616: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8288, Text: You know what? This is something that I do differently from Elon with comma about self-driving cars. I hear the new version’s going to come out and the new version is not going to be better, but at first and it’s going to require a ton of refactors. And I say, “Okay, take as long as you need.” If you convince me this architecture’s better, okay, we have to move to it. Even if it’s not going to make the product better tomorrow, the top priority is getting the architecture right.
Segment 3617: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8314, Text: So what do you think about a thing where the product is online? So I guess, if you ran engineering on Twitter, would you just do a refactor? How long would it take? What would that mean for the running of the actual service?
Segment 3618: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8335, Text: I’m not the right person to run Twitter. I’m just not. And that’s the problem. I don’t really know. A common thing that I thought a lot while I was there was whenever I thought something that was different to what Elon thought. I’d have to run something in the back of my head reminding myself that Elon is the richest man in the world and in general, his ideas are better than mine. Now, there’s a few things I think I do understand and know more about, but in general, I’m not qualified to run Twitter. No, I shouldn’t say qualified, but I don’t think I’d be that good at it. I don’t think I’d be good at it. I don’t think I’d really be good at running an engineering organization at scale.
Segment 3619: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8375, Text: I think, I could lead a very good refactor of Twitter and it would take six months to a year. And the results to show at the end of it would be feature development. In general, it takes 10 x less time, 10 x less man-hours. That’s what I think I could actually do. Do I think that it’s the right decision for the business above my pay grade?
Segment 3620: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8403, Text: But a lot of these kinds of decisions are above everybody’s pay grade.
Segment 3621: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8406, Text: I don’t want to be a manager. I don’t want to do that. If you really forced me to, yeah, it would maybe make me upset if I had to make those decisions. I don’t want to.
Segment 3622: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8419, Text: Yeah. But a refactor is so compelling. If this is to become something much bigger than what Twitter was, it feels like a refactor has to be coming at some point.
Segment 3623: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8432, Text: “George, you’re a junior software engineer. Every junior software engineer wants to come in and refactor all code.” Okay. That’s like your opinion, man.
Segment 3624: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8442, Text: Yeah, sometimes they’re right.
Segment 3625: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8446, Text: Well, whether they’re right or not, it’s definitely not for that reason. It’s definitely not a question of engineering prowess. It is a question of maybe what the priorities are for the company. And I did get more intelligent feedback from people I think in good faith saying that, like actually from Elon. And from Elon sort of people were like, well, I stop the world refactor might be great for engineering, but we have a business to run. And hey, above my pay grade.
Segment 3626: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8473, Text: What’d you think about Elon as an engineering leader having to experience him in the most chaotic of spaces, I would say?
Segment 3627: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8485, Text: My respect for him is unchanged. And I did have to think a lot more deeply about some of the decisions he’s forced to make.
Segment 3628: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8493, Text: About the tensions, the trade-offs within those decisions?
Segment 3629: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8499, Text: About a whole matrix coming at him. I think that’s Andrew Tate’s word for it. Sorry to borrow it.
Segment 3630: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8506, Text: Also, bigger than engineering, just everything.
Segment 3631: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8509, Text: Yeah. Like the war on the woke.
Segment 3632: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8513, Text: Yeah.
Segment 3633: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8514, Text: It’s just man, he doesn’t have to do this. He doesn’t have to. He could go pirogue and go chill at the four seasons of Maui. But see, one person I respect and one person I don’t.
Segment 3634: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8531, Text: So his heart is in the right place fighting in this case for this ideal of the freedom of expression.
Segment 3635: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8537, Text: Well, I wouldn’t define the ideal so simply. I think you can define the ideal no more than just saying Elon’s idea of a good world, freedom of expression is.
Segment 3636: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8548, Text: But it’s still the downsides of that is the monarchy.
Segment 3637: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8553, Text: Yeah. I mean monarchy has problems, right? But I mean, would I trade right now the current oligarchy which runs America for the monarchy? Yeah, I would. Sure. For the Elon monarchy, yeah. You know why? Because power would cost 1 cent a kilowatt-hour, 10th of a cent a kilowatt-hour.
Segment 3638: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8573, Text: What do you mean?
Segment 3639: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8574, Text: Right now, I pay about 20 cents a kilowatt-hour for electricity in San Diego. That’s like the same price you paid in 1980. What the hell?
Segment 3640: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8582, Text: So you would see a lot of innovation with Elon.
Segment 3641: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8585, Text: Yeah. Maybe I’d have some hyperloops.
Segment 3642: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8587, Text: Yeah.
Segment 3643: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8588, Text: Right? And I’m willing to make that trade off. And this is why people think that dictators take power through some untoward mechanism. Sometimes they do, but usually it’s because the people want them. And the downsides of a dictatorship, I feel like we’ve gotten to a point now with the oligarchy wear. Yeah, I would prefer the dictator.
Segment 3644: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8610, Text: What’d you think about scholars, the programming language?
Segment 3645: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8615, Text: I liked it more than I thought. I did the tutorials. I was very new to it. It would take me six months to be able to write good scholar.
Segment 3646: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8621, Text: I mean, what did you learn about learning a new programming language from that?
Segment 3647: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8625, Text: I love doing new programming tutorials and doing them. I did all this for Rust. It keeps some of it’s upsetting JVM Roots, but it is a much nicer… In fact, I almost don’t know why Kotlin took off and not Scala. I think Scala has some beauty that Kotlin lacked, whereas Kotlin felt a lot more… I mean, I don’t know if it actually was a response to Swift, but that’s kind of what it felt like. Kotlin looks more like Swift and Scala looks more like a functional programming language, more like an OCaml or Haskell.
Segment 3648: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8658, Text: Let’s actually just explore. We touched it a little bit, but just on the art, the science and the art of programming. For you personally, how much of your programming is done with GPT currently?
Segment 3649: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8670, Text: None. I don’t use it at all.
Segment 3650: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8672, Text: Because you prioritize simplicity so much.
Segment 3651: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8675, Text: Yeah, I find that a lot of it as noise. I do use VS Code and I do like some amount of auto complete. I do like a very like, feels like rules based auto complete, an auto complete that’s going to complete the variable name for me. So I don’t just type it. I can just press tab. That’s nice. But I don’t want an auto complete. You know what I hate when auto completes, when I type the word four and it puts two parentheses and two semi cones and two braces? I’m like, “Oh man.”
Segment 3652: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8702, Text: Well, I mean, with the VS Code, and GPT, and with Codex, you can kind of brainstorm. I’m probably the same as you, but I like that it generates code and you basically disagree with it and write something simpler. But to me, that somehow is inspiring or makes me feel good. It also gamifies a simplification process. Because I’m like, “Oh yeah, you dumb AI system, you think this is the way to do it.” I have a simpler thing here.
Segment 3653: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8733, Text: It just constantly reminds me of bad stuff. I mean, I tried the same thing with rap, right? I tried the same thing with rap and I actually think I’m a much better programmer than rapper. But I even tried, I was like, “Okay, can we get some inspiration from these things for some rap lyrics?” And I just found that it would go back to the most cringy tropes and dumb rhyme schemes and I’m like, “Yeah, this is what the code looks like too.”
Segment 3654: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8754, Text: I think you and I probably have different threshold for cringe code. You probably hate cringe code.
Segment 3655: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8762, Text: Yeah.
Segment 3656: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8762, Text: I mean, boilerplate as a part of code, and some of it is just faster lookup. Because I don’t know about you, but I don’t remember everything. I’m offloading so much of my memory about different functions, library functions and all that kind of stuff. This GPT just is very fast at standard stuff, at standard library stuff, basic stuff that everybody uses.
Segment 3657: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8798, Text: Yeah. I don’t know. I mean, there’s just a little of this in Python. And maybe if I was coding more in other languages, I would consider it more. But I feel like Python already does such a good job of removing any boilerplate.
Segment 3658: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8815, Text: That’s true.
Segment 3659: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8815, Text: It’s the closest thing you can get to pseudocode, right?
Segment 3660: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8818, Text: Yeah, that’s true. That’s true.
Segment 3661: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8820, Text: And yeah, sure. If I like, “Yeah, I’m great GPT. Thanks for reminding me to free my variables.” Unfortunately, you didn’t really recognize the scope correctly and you can’t free that one, but you put the freeze there and I get it.
Segment 3662: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8834, Text: Fiverr, whenever I’ve used Fiverr for certain things like design or whatever, it’s always you come back. My experience with Fiverr is closer to your experience with programming. With GPT, it’s like you’re just frustrated and feel worse about the whole process of design and art and whatever I use five for. I’m using GPT as much as possible to just learn the dynamics of it, these early versions. Because it feels like in the future you’ll be using it more and more. For the same reason, I gave away all my books and switched to Kindle, because all right, how long are we going to have paper books? Like 30 years from now? I want to learn to be reading on Kindle even though I don’t enjoy it as much and you learn to enjoy it more. In the same way I switched from… Let me just pause. I switched from Emacs to VS Code.
Segment 3663: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8894, Text: Yeah. I switched from Vim to VS Code. I think similar, but…
Segment 3664: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8898, Text: Yeah, it’s tough. And that Vim to VS Code is even tougher because Emacs is old, more outdated, feels like it. The community is more outdated. Vim is like pretty vibrant still.
Segment 3665: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8911, Text: I never used any of the plugins. I still don’t use any of it. Yeah.
Segment 3666: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8913, Text: That’s why I looked at myself in the mirror. I’m like, “Yeah, you wrote some stuff in Lisp. Yeah.
Segment 3667: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8917, Text: No, but I never used any of the plugins in Vim either. I had the most vanilla Vim, I have a syntax eyeliner. I didn’t even have auto complete. These things I feel like help you so marginally. Now, VS Codes auto complete has gotten good enough, that I don’t have to set it up. I can just go into any code base and autocomplete’s right 90% of the time. Okay, cool. I’ll take it. Right? So, I don’t think I’m going to have a problem at all adapting to the tools once they’re good. But the real thing that I want is not something that like tab completes my code and gives me ideas. The real thing that I want is a very intelligent pair programmer that comes up with a little popup saying, “Hey, you wrote a bug on line 14 and here’s what it is.”
Segment 3668: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8963, Text: Yeah.
Segment 3669: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8963, Text: Now I like that. You know what does a good job at this? MyPie. I love MyPie. MyPie, this fancy type checker for Python. And actually, Microsoft released one too, and it was like 60% false positives. MyPie is like 5% false positives. 95% of the time, it recognizes. I didn’t really think about that typing interaction correctly. Thank you, MyPie.
Segment 3670: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8986, Text: So you type hinting, you like pushing the language towards being a typed language.
Segment 3671: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=8991, Text: Oh yeah, absolutely. I think optional typing is great. I mean, look, I think that it’s a meet in the middle, right? Python has these optional type hinting and C++ has auto.
Segment 3672: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9001, Text: C++ allows you to take a step back.
Segment 3673: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9003, Text: Well, C++ would have you brutally type out SGD string iterator, right? Now, I can just type auto, which is nice. And then Python used to just have A. What type is A? It’s an A. A Colon str. Oh, okay. It’s a string. Cool.
Segment 3674: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9020, Text: Yeah.
Segment 3675: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9021, Text: I wish there was a way like a simple way in Python to turn on a mode which would enforce the types.
Segment 3676: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9028, Text: Yeah, like give a warning when there’s no type or something like this.
Segment 3677: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9030, Text: Well, no. Like MyPie was a static type checker, but I’m asking just for a runtime type checker. Like there’s ways to hack this in, but I wish it was just like a flag, like Python three dash T.
Segment 3678: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9040, Text: Oh, I see. Yeah, I see.
Segment 3679: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9042, Text: Enforce the types are on time.
Segment 3680: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9043, Text: Yeah. I feel like that makes you a better programmer. That’s the kind of test that the type remains the same.
Segment 3681: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9050, Text: Well, that I know, that I didn’t mess any types up. But again, MyPie’s getting really good and I love it, and I can’t wait for some of these tools to become AI powered. I want AI reading my code and giving me feedback. I don’t want AI’s writing half-assed autocomplete stuff for me.
Segment 3682: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9066, Text: I wonder if you can now take GPT and give it a code that you wrote for function and say, how can I make this simpler and have it accomplish the same thing? I think you’ll get some good ideas on some code. Maybe not the code you write for tinygrad type of code because that requires so much design thinking, but other kinds of code.
Segment 3683: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9086, Text: I don’t know. I downloaded the plugin maybe two months ago. I tried it again and found the same. Look, I don’t doubt that these models are going to first become useful to me, then be as good as me and then surpass me. But from what I’ve seen today, it’s like someone occasionally taking over my keyboard that I hired from Fiverr. Yeah, I’d rather not.
Segment 3684: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9113, Text: But ideas about how to debug the code or basically a better debugger is it? It is really interesting.
Segment 3685: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9118, Text: But it’s not a better debugger, that yes, I would love a better debugger.
Segment 3686: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9121, Text: Yeah, it’s not yet. Yeah. But it feels like it’s not too far.
Segment 3687: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9124, Text: Yeah. Yeah. One of my coworkers says he uses them for print statements like every time he has to, just when he needs. The only thing I can really write is like, okay, I just want to write the thing to print the state out right now.
Segment 3688: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9134, Text: Oh, that definitely is much faster is print statements. Yeah. I see in myself using that a lot just because it figures out what the rest of the function. You just say, “Okay, print everything.”
Segment 3689: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9144, Text: Yeah, print everything, right? And then if you want a pretty printer, maybe. I’m like, yeah, you know what? I think in two years, I’m going to start using these plugins a little bit. And then in five years, I’m going to be heavily relying on some AI augmented flow. And then in 10 years…
Segment 3690: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9159, Text: Do you think you’ll ever get to a hundred percent? What’s the role of the human that it converges to as a programmer?
Segment 3691: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9168, Text: Nothing.
Segment 3692: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9170, Text: So do you think it’s all generated?
Segment 3693: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9173, Text: I think it’s over for humans in general. It’s not just programming, it’s everything.
Segment 3694: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9177, Text: So niche becomes well…
Segment 3695: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9179, Text: Our niche becomes smaller and smaller and smaller. In fact, I’ll tell you what the last niche of humanity’s going to be.
Segment 3696: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9183, Text: Yeah.
Segment 3697: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9184, Text: There’s a great book. And if I recommended The Metamorphosis of Prime Intellect last time, there is a sequel called A Casino Odyssey in Cyberspace. And I don’t want to give away the ending of this, but it tells you what the last remaining human currency is, and I agree with that.
Segment 3698: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9201, Text: We’ll leave that as the cliffhanger. So no more programmers left, huh? That’s where we’re going.
Segment 3699: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9209, Text: Well, unless you want handmade code, maybe they’ll sell it on Etsy. This is handwritten code. It doesn’t have that machine polished to it. It has those slight imperfections that would only be written by a person.
Segment 3700: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9221, Text: I wonder how far away we are from that. I mean, there’s some aspect to… On Instagram, your title is listed as prompt engineer.
Segment 3701: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9229, Text: Right? Thank you for noticing. Yeah.
Segment 3702: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9234, Text: I don’t know if it’s ironic or non, or sarcastic or non. What do you think of prompt engineering as a scientific and engineering discipline and maybe art form?
Segment 3703: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9248, Text: You know what? I started comma six years ago and I started the Tiny Corp a month ago. So much has changed. I started going through similar comma processes to like starting a company. I’m like, okay, I’m going to get an office in San Diego. I’m going to bring people here. I don’t think so. I think I’m actually going to do remote, right? “George, you’re going to do remote? You hate remote.” Yeah. But I’m not going to do job interviews. The only way you’re going to get a job is if you contribute to the GitHub, right? And then interacting through GitHub, like GitHub being the real project management software for your company. And the thing pretty much just is a GitHub repo is like showing me what the future of… Okay, so a lot of times, I’ll go on Discord or kind of grad Discord. And I’ll throw out some random like, “Hey, can you change, instead of having log an X as LL lops, change it to log to an X2?”
Segment 3704: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9306, Text: It’s pretty small change. You can just change a base formula. That’s the kind of task that I can see in AI being able to do in a few years. In a few years, I could see myself describing that. And then within 30 seconds of pull request, it’s up that does it, and it passes my CI and I merge it, right? So I really started thinking about like what is the future of jobs? How many AIs can I employ at my company? As soon as we get the first tiny box up, I’m going to stand up a 65B LLaMA in the Discord. And it’s like, yeah, here’s the tiny box. He’s just like, he’s chilling with us.
Segment 3705: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9339, Text: Basically, like you said with niches, most human jobs will eventually be replaced with prompt engineering.
Segment 3706: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9348, Text: Well, prompt engineering kind of is this, as you move up the stack, there used to be humans actually doing arithmetic by hand. There used to be big farms of people doing pluses and stuff, right? And then you have spreadsheets, right? And then, okay, the spreadsheet can do the plus for me. And then you have macros, and then you have things that basically just are spreadsheets under the hood like accounting software. As we move further up the abstraction, well, what’s at the top of the abstraction stack? Well, prompt engineer.
Segment 3707: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9382, Text: Yeah.
Segment 3708: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9384, Text: What is the last thing if you think about humans wanting to keep control? Well, what am I really in the company, but a prompt engineer, right?
Segment 3709: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9393, Text: Isn’t there a certain point where the AI will be better at writing prompts?
Segment 3710: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9398, Text: Yeah. But you see the problem with the AI writing prompts, a definition that I always liked of AI was AI is the do what I mean machine. The computer is so pedantic. It does what you say, but you want the do what I mean, machine, right? You want the machine where you say, “Get my grandmother out of the burning house.” It reasonably takes your grandmother and puts her on the ground, not lifts her a thousand feet above the burning house and lets her fall. There’s no Zukowski examples.
Segment 3711: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9431, Text: But it’s not going to find the meaning. I mean, to do what I mean, it has to figure stuff out.
Segment 3712: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9436, Text: Sure.
Segment 3713: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9437, Text: And the thing you’ll maybe ask it to do is run government for me.
Segment 3714: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9443, Text: Oh, and do what I mean very much comes down to how aligned is that AI with you. Of course, when you talk to an AI that’s made by a big company in the cloud, the AI fundamentally is aligned to them, not to you. And that’s why you have to buy a tiny box. So you make sure the AI stays aligned to you. Every time that they start to pass AI regulation or GPU regulation, I’m going to see sales of tiny boxes spike. It’s going to be like guns. Every time they talk about gun regulation, boom. Gun sales.
Segment 3715: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9473, Text: So in the space of AI, you’re an anarchist, anarchism espouser, believer.
Segment 3716: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9478, Text: I’m an informational anarchist. Yes. I’m an informational anarchist and a physical status. I do not think anarchy in the physical world is very good because I exist in the physical world. But I think we can construct this virtual world where anarchy, it can’t hurt you. I love that Tyler, the creator tweet. It was, “Cyber bullying isn’t real, man. Have you tried? Turn it off the screen, close your eyes.”
Segment 3717: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9502, Text: Yeah. But how do you prevent the AI from basically replacing all human prompt engineers where nobody’s the prompt engineer anymore? So autonomy, greater and greater autonomy until it’s full autonomy. And that’s just where it’s headed. Because one person’s going to say, “Run everything for me.”
Segment 3718: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9529, Text: You see, I look at potential futures. And as long as the Ais go on to create a vibrant civilization with diversity and complexity across the universe, more power to them, we’ll die. If the AIs go on to actually turn the world into paperclips and then they die out themselves, well that’s horrific. And we don’t want that to happen. So this is what I mean about robustness. I trust robust machines. The current AIs are so not robust. This comes back to the idea that we’ve never made a machine that can self replicate. But if the machines are truly robust and there is one prompt engineer left in the world, hope you’re doing good, man. Hope you believe in God. Go by God and go forth and conquer the universe.
Segment 3719: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9582, Text: Well, you mentioned, because I talked to Mark about faith and God, and you said you were impressed by that. What’s your own belief in God and how does that affect your work?
Segment 3720: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9594, Text: I never really considered, when I was younger, I guess my parents were atheists, so I was raised kind of atheist. And I never really considered how absolutely silly atheism is because I create-
Segment 3721: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9603, Text: … really atheism is, because I create worlds. Every game creator, “How are you an atheist, bro? You create worlds.” “Well, [inaudible 02:40:10] but no one created the art world, man. That’s different. Haven’t you heard about the Big Bang and stuff?” Yeah. What’s the Skyrim myth origin story in Skyrim? I’m sure there’s some part of it in Skyrim, but it’s not like if you ask the creators… The Big Bang is in universe, right? I’m sure they have some Big Bang notion in Skyrim, right? But that obviously is not at all how Skyrim was actually created. It was created by a bunch of programmers in a room. So it struck me one day how just silly atheism is. Of course, we were created by God. It’s the most obvious thing.
Segment 3722: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9645, Text: That’s such a nice way to put it. We’re such powerful creators ourselves. It’s silly not to conceive that there’s creators even more powerful than us.
Segment 3723: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9654, Text: Yeah. And then I also like that notion. That notion gives me a lot of… I guess you can talk about what it gives a lot of religious people, it just gives me comfort. It’s like, “You know what? If we mess it all up and we die out, yeah.”
Segment 3724: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9669, Text: The same way that a video game has comfort in it.
Segment 3725: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9672, Text: God will try again.
Segment 3726: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9674, Text: Or there’s balance. Somebody figured out a balanced view of it, so it all makes sense in the end. A video game is usually not going to have crazy, crazy stuff.
Segment 3727: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9687, Text: People will come up with, ” Well, yeah, but man, who created God?” I’m like, “That’s God’s problem. What are you asking me? If God believes in God?”
Segment 3728: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9701, Text: I’m just this NPC living in his game.
Segment 3729: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9703, Text: I mean to be fair, if God didn’t believe in God, he’d be as silly as the atheists here.
Segment 3730: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9708, Text: What do you think is the greatest computer game of all time? Do you have any time to play games anymore? Have you played Diablo IV?
Segment 3731: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9717, Text: I have not played Diablo IV.
Segment 3732: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9719, Text: I will be doing that shortly. I have to. There’s just so much history with one, two, and three.
Segment 3733: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9724, Text: You know what? I’m going to say? World of Warcraft. And it’s not that the game is such a great game, it’s not. It’s that I remember, in 2005 when it came out, how it opened my mind to ideas. It opened my mind to this is whole world we’ve created. And there’s almost been nothing like it since. You can look at MMOs today, and I think they all have lower user bases than World of Warcraft. EVE Online’s kind of cool. But to think that everyone know … people are always like, “Look at the Apple headset.” What do people want in this VR? Everyone knows what they want. I want Ready Player One, and that…
Segment 3734: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9771, Text: So I’m going to say World of Warcraft, and I’m hoping that games can get out of this whole mobile gaming dopamine pump thing, and-
Segment 3735: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9780, Text: Create worlds.
Segment 3736: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9780, Text: Create worlds, yeah.
Segment 3737: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9783, Text: Worlds that captivate a very large fraction of the human population.
Segment 3738: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9787, Text: Yeah. And I think it’ll come back, I believe.
Segment 3739: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9789, Text: But MMO really, really pull you in.
Segment 3740: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9793, Text: Games do a good job. I mean okay, other two other games that I think are very noteworthy for me are Skyrim and GTA 5.
Segment 3741: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9799, Text: Skyrim, yeah. That’s probably number one for me. GTA… Hey, what is it about GTA? I guess GTA is real life. I know there’s prostitutes and guns and stuff.
Segment 3742: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9815, Text: Hey, they exist in real life too.
Segment 3743: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9817, Text: Yes, I know. But it’s how I imagine your life to be, actually.
Segment 3744: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9822, Text: I wish it was that cool.
Segment 3745: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9825, Text: Yeah. I guess because there’s Sims, right? Which is also a game I like, but it’s a gamified version of life. I would love a combination of Sims and GTA. So more freedom, more violence, more rawness, but with also ability to have a career and family and this kind of stuff.
Segment 3746: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9845, Text: What I’m really excited about in games is, once we start getting intelligent AIs to interact with. The NPCs in games have never been.
Segment 3747: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9855, Text: But conversationally, in every way.
Segment 3748: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9859, Text: Yeah, in every way. When you are actually building a world and a world imbued with intelligence.
Segment 3749: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9866, Text: Oh, yeah.
Segment 3750: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9867, Text: And it’s just hard. You know running World of Warcraft, you’re limited. You’re running on a penny and four. How much intelligence can you run? How many flops did you have? But now when I’m running a game on a hundred beta flop machine, what’s five people? I’m trying to make this a thing. 20 paid a flops of compute is one person of compute. I’m trying to make that a unit.
Segment 3751: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9887, Text: 20 [inaudible 02:44:49] flops is one person.
Segment 3752: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9890, Text: One Person.
Segment 3753: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9891, Text: One person flop.
Segment 3754: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9892, Text: It’s like a horsepower. But what’s a horsepower? It’s how powerful a horse is. What’s a person of compute? Well, now you know-
Segment 3755: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9898, Text: [inaudible 02:44:58] flop. I got it. That’s interesting. VR also adds a… I mean in terms of creating worlds.
Segment 3756: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9907, Text: What a Quest 2. I put it on and I can’t believe, the first thing they show me is a bunch of scrolling clouds and a Facebook login screen. You had the ability to bring me into a world, and did you give me? A popup. Right. And this is why you’re not cool, Mark Zuckerberg. You could be cool. Just make sure on the Quest 3, you don’t put me into clouds in a Facebook login screen. Bring me to a world.
Segment 3757: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9932, Text: I just tried Quest 3. It was awesome. But hear that guys? I agree with that, so-
Segment 3758: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9936, Text: Wish it didn’t have this clouds in the… It was just so-
Segment 3759: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9937, Text: You know what? I mean, in the beginning, what is it, Todd Howard said this about design of the beginning of the games he creates is as like, “The beginning is so, so important.” I recently played Zelda for the first time, Zelda: Breath of the Wild, the previous one. And it’s very quickly; within 10 seconds, you come out of a cave type place and this world opens up. It’s like, “Hah.” And it pulls you in. You forget. Whatever troubles I was having, whatever…
Segment 3760: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9973, Text: I got to play that from the beginning. I played it for an hour at a friend’s house.
Segment 3761: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9976, Text: No, the beginning. They got it. They did it really well. The expansiveness of that space, the peacefulness of that place, they got this… the music mean. So much of that is creating that world and pulling you right in.
Segment 3762: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9989, Text: I’m going to go buy a Switch. I’m going to go today and buy a Switch.
Segment 3763: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=9992, Text: You should. Well, the new one came out. I haven’t played that yet, but Diablo IV or something… I mean, there’s sentimentality also, but something about VR, really is incredible. But the new Quest 3 is mixed reality, and I got a chance to try that. So it’s augmented reality. And for video games, it’s done really, really well-
Segment 3764: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10013, Text: Is it passthrough or cameras?
Segment 3765: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10015, Text: Cameras.
Segment 3766: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10015, Text: It’s cameras. Okay.
Segment 3767: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10015, Text: Yeah.
Segment 3768: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10016, Text: The Apple one, is that one passthrough or cameras?
Segment 3769: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10018, Text: I don’t know. I don’t know how real it is. I don’t know anything
Segment 3770: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10021, Text: It’s coming out in January.
Segment 3771: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10025, Text: Is it January? Or is it some point?
Segment 3772: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10026, Text: Some point. Maybe not January. Maybe that’s my optimism. But Apple, I will buy it. I don’t care if it’s expensive and does nothing, I will buy it. I’ll support this future endeavor.
Segment 3773: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10034, Text: You’re the meme. Oh, yes. I support competition. It seemed like Quest was the only people doing it. And this is great that they’re like…
Segment 3774: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10045, Text: You know what? And this is another place we’ll give some more respect to Mark Zuckerberg. The two companies that have endured through technology are Apple and Microsoft. And what do they make? Computers and business services, right. All the meme, social ads, they all come and go. But you want to endure, build hardware.
Segment 3775: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10065, Text: Yeah. That’s a really interesting job. Maybe I’m new with this, but it’s a $500 headset, Quest 3. And just having creatures run around the space, our space right here, to me, okay, this is very boomer statement, but it added windows to the place.
Segment 3776: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10089, Text: Oh, I heard about the aquarium. Yeah.
Segment 3777: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10090, Text: Yeah, aquarium. But in this case, it was a zombie game, whatever, it doesn’t matter. But it modifies the space in a way where I can’t… it really feels like a window and you can look out. It’s pretty cool. It is like a zombie game. They’re running at me, whatever. But what I was enjoying is the fact that there’s a window and they’re stepping on objects in this space, that was a different kind of escape. Also, because you can see the other humans. So it’s integrated with the other humans. It’s really interesting-
Segment 3778: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10122, Text: And that’s why it’s more important than ever, that the AI is running on those systems are aligned with you. They’re going to augment your entire world.
Segment 3779: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10128, Text: Oh yeah. And those AIs have a… I mean, you think about all the dark stuff like sexual stuff. If those AIs threaten me, that could be haunting. If they threaten me in a non-video game way, it’s like…
Segment 3780: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10147, Text: Yeah, yeah, yeah, yeah.
Segment 3781: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10149, Text: They’ll know personal information about me. And then you lose track of what’s real, what’s not, what if stuff is hacked?
Segment 3782: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10155, Text: There’s two directions the AI girlfriend company can take, right. There’s the highbrow, something like her, maybe something you kind of talk to. And this is, and then there’s the lowbrow version of it, where I want to set up a brothel in Times Square.
Segment 3783: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10166, Text: Yeah.
Segment 3784: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10167, Text: Yeah. It’s not cheating if it’s a robot, it’s a VR experience.
Segment 3785: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10170, Text: Is there an in between?
Segment 3786: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10172, Text: No. I don’t want to do that one or that one.
Segment 3787: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10175, Text: Have you decided yet?
Segment 3788: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10176, Text: No. I’ll figure it out. We’ll see where the technology goes.
Segment 3789: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10179, Text: I would love to hear your opinions for George’s third company. What to do, the brothel on Times Square or The Hurt Experience? What do you think company number four will be? You think there’ll be a company number four?
Segment 3790: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10194, Text: There’s a lot to do in company number two. I’m talking about company number three now. None of that tech exists yet. There’s a lot to do in company number two. Company number two is going to be the great struggle of the next six years. And if the next six years, how centralized is compute going to be. The less centralized compute is going to be, the better of a chance we all have.
Segment 3791: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10212, Text: So you’re like a flag bearer for open source distributed cent decentralization of compute?
Segment 3792: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10219, Text: We have to. We have to, or they will just completely dominate us. I showed a picture on stream, of a man, in a chicken farm. You ever seen one of those factory farm, chicken farms? Why does he dominate all the chickens? Why does he-
Segment 3793: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10233, Text: Smarter.
Segment 3794: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10233, Text: He’s smarter, right. Some people on Twitch were like, “He’s bigger than the chickens.” Yeah. And now here’s a man in a cow farm, right. So it has nothing to do with their size and everything to do with their intelligence. And if one central organization has all the intelligence, you’ll be the chickens and they’ll be the chicken man. But if we all have the intelligence, we’re all the chickens. We’re not all the men, we’re all the chickens. There’s no chicken man.
Segment 3795: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10261, Text: There’s no chicken man. We’re just chickens in Miami.
Segment 3796: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10265, Text: He was having a good life, man.
Segment 3797: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10267, Text: Yeah, I’m sure he was. I’m sure he was. What have you learned from launching a running Comma AI in Tiny Corp? Starting a company from an idea and scaling it. And by the way, I’m all in on Tiny Box, so I’m your… I guess it’s pre-order only now.
Segment 3798: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10284, Text: I want to make sure it’s good. I want to make sure that the thing that I deliver is not going to be a Quest 2, which you buy and use twice. I mean, it’s better than a Quest which you bought and used less than once. Statistically.
Segment 3799: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10296, Text: Well, if there’s a beta program for Tiny Box, I’m into-
Segment 3800: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10300, Text: Sounds good.
Segment 3801: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10300, Text: So I won’t be the whiny… Yeah, I’ll be the tech-savvy user of the Tiny Box, just to be in the early days-
Segment 3802: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10309, Text: What have I learned?
Segment 3803: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10310, Text: What have you learned from building these companies?
Segment 3804: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10314, Text: The longest time at Comma, I asked, “Why? Why did I start a company? Why did I do this?” But what else was I going to do?
Segment 3805: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10331, Text: So you like bringing ideas to life?
Segment 3806: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10335, Text: With Comma, it really started as an ego battle with Elon. I wanted to beat him. I saw a worthy adversary. Here’s a worthy adversary who I can beat at self-driving cars. And I think we’ve kept pace, and I think he’s kept ahead. I think that’s what’s ended up happening there. But I do think Comma is… I mean, Comma’s profitable. And when this drive GPT stuff starts working, that’s it. There’s no more bugs in a loss function. Right now, we’re using a hand coated simulator. There’s no more bugs. This is going to be it. This is their run-up to driving.
Segment 3807: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10368, Text: I hear a lot of props for openpilot for Comma.
Segment 3808: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10374, Text: It’s better than FSD and autopilot in certain ways. It has a lot more to do with which field you like. We lowered the price on the hardware to 1499. You know how hard it is to ship reliable consumer electronics that go on your windshield? We’re doing more than most cell phone companies.
Segment 3809: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10391, Text: How’d you pull that off, by the way? Shipping a product that goes in a car?
Segment 3810: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10394, Text: I know. I have an SMT line. I make all the boards, in-house, in San Diego.
Segment 3811: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10401, Text: Quality control-
Segment 3812: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10402, Text: I care immensely about it. Actually our-
Segment 3813: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10404, Text: You’re basically a mom and pap shop with great testing.
Segment 3814: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10409, Text: Our head of openpilot is great at, “Okay, I want all the Comma 3s to be identical.” Yeah, I mean… Look, it’s 1499, 30-day money back, guaranteed. It will blow your mind at what it can do.
Segment 3815: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10425, Text: Is it hard to scale?
Segment 3816: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10428, Text: You know what? There’s kind of downsides to scaling it. People are always like, “Why don’t you advertise?” Our mission is to solve self-driving cars while the deliver shippable intermediaries. Our mission has nothing to do with selling a million boxes. It’s [inaudible 02:54:00].
Segment 3817: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10441, Text: Do you think it’s possible that Comma gets sold?
Segment 3818: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10445, Text: Only if I felt someone could accelerate that mission and wanted to keep it open source. And not just wanted to. I don’t believe what anyone says. I believe incentives. If a company wanted to buy Comma with their incentives, were to keep it open source. But comma doesn’t stop at the cars. The cars are just the beginning. The device is a human head. The device has two eyes, two ears, it breathes air, it has a mouth.
Segment 3819: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10470, Text: So you think this goes to embodied robotics?
Segment 3820: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10473, Text: Well sell Common bodies too. They’re very rudimentary. But one of the problems that we are running into, is that the Comma 3 has about as much intelligence as a bee. If you want a human’s worth of intelligence, you’re going to need a tiny rack, not even a tiny box, you’re going to need a tiny rack, maybe even more.
Segment 3821: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10496, Text: How do you put legs on that?
Segment 3822: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10498, Text: You don’t. And there’s no way you can. You connect to it wirelessly. So you put your tiny box or your tiny rack in your house, and then you get your Comma body and your Comma body runs the models on that. It’s close. You don’t have to go to some cloud, which is 30 milliseconds away. You go to a thing which is 0.1 milliseconds away.
Segment 3823: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10518, Text: So the AI girlfriend will have a central hub in the home?
Segment 3824: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10523, Text: I mean, eventually. If you fast-forward 20, 30 years, the mobile chips will get good enough to run these Ais. But fundamentally, it’s not even a question of putting legs on a tiny box, because how are you getting 1.5 kilowatts of power on that thing? Right? So they’re very synergistic businesses. I also want to build all of Comma’s training computers. Right. Comma builds training computers. Right now we use commodity parts. I think I can do it cheaper. So we’re going to build. Tiny Corp is going to not just sell tiny boxes. Tiny boxes is the consumer version. But I’ll build training data centers too.
Segment 3825: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10557, Text: Have you talked to Andre Kaparthy or have you talked to Elon about Tiny Corp?
Segment 3826: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10561, Text: He went to work at OpenAI.
Segment 3827: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10563, Text: What do you love about Andre Kaparthy? To me, he’s one of the truly special humans we got.
Segment 3828: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10569, Text: Oh man. His streams are just a level of quality so far beyond mine. I can’t help myself. It’s just…
Segment 3829: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10579, Text: Yeah, he’s good.
Segment 3830: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10580, Text: He wants to teach you. I want to show you that I’m smarter than you.
Segment 3831: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10586, Text: Yeah, he has no… I mean, thank you for the sort of the raw, authentic honesty. Yeah. I mean, a lot of us have that. I think Andre is as legit as it gets in that he just wants to teach you. And there’s a curiosity that just drives him. At the stage where he is in life, to be still one of the best tinkerers in the world. It’s crazy, to, what is it? Micrograd?
Segment 3832: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10614, Text: Micrograd was… Yeah, inspiration for tinygrad. The whole… I mean, his CS231n was… this was the inspiration. This is what I just took and ran with and ended up writing this, so..
Segment 3833: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10626, Text: But I mean, to me that-
Segment 3834: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10628, Text: Don’t go work for Darth Vader, man.
Segment 3835: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10630, Text: I mean, the flip side, to me, is the fact that he’s going there, is a good sign for OpenAI. I think I like [inaudible 02:57:21] discover a lot. Those guys are really good at what they do.
Segment 3836: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10645, Text: I know they are. And that’s what’s even more… And you know what? It’s not that OpenAI doesn’t open source the weights of GPT-4. It’s that they go in front of Congress. And that is what upsets me. We had two effective altruists [inaudible 02:57:41] go in front of Congress. One’s in jail.
Segment 3837: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10665, Text: I think you’re drawing parallels on there.
Segment 3838: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10667, Text: One’s in jail.
Segment 3839: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10669, Text: You gave me a look. You gave me a look.
Segment 3840: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10671, Text: No, I think a factor of altruism is a terribly evil ideology and yeah.
Segment 3841: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10675, Text: Oh yeah. That’s interesting. Why do you think that is? Why you think there’s something about a thing that sounds pretty good, that kind of gets us into trouble?
Segment 3842: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10684, Text: Because you get [inaudible 02:58:06] freed. [inaudible 02:58:07] freed is the embodiment of effective altruism. Utilitarianism is an abhorrent ideology. Well, yeah, we’re going to kill those three people to save a thousand, of course, right. There’s no underlying, there’s just.. Yeah.
Segment 3843: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10703, Text: Yeah. But to me that’s a bit surprising. But it’s also, in retrospect, not that surprising. But I haven’t heard really clear kind of rigorous analysis why effective altruism is flawed.
Segment 3844: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10720, Text: Oh well, I think charity is bad, right. So what is charity but investment that you don’t expect to have a return on? Right.
Segment 3845: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10728, Text: But you can also think of charity as you would like to see… So allocate resources in optimal way to make a better world.
Segment 3846: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10740, Text: And probably almost always, that involves starting a company, right, because-
Segment 3847: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10744, Text: More efficient,-
Segment 3848: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10745, Text: If you just take the money and you spend it on malaria nets, okay, great. You’ve made a hundred malaria nets. But if you teach-
Segment 3849: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10753, Text: A man, how to fish.
Segment 3850: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10754, Text: Right?
Segment 3851: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10755, Text: Yeah. No, but the problem is teaching amount how to fish might be harder. Starting a company might be harder than allocating money that you already have.
Segment 3852: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10762, Text: I like the flip side of effective altruism; effective accelerationism. I think accelerationism is the only thing that’s ever lifted people out of poverty. The fact that food is cheap. Not, “We’re giving food away because we are kindhearted people.” No, food is cheap. And that’s the world you want to live in. UBI, what a scary idea. What a scary idea. All your power now? If money is power, your only source of power is granted to you by the goodwill of the government. What a scary idea.
Segment 3853: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10794, Text: So you even think long term, even-
Segment 3854: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10797, Text: I’d rather die than need UBI to survive. And I mean it.
Segment 3855: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10804, Text: What if survival is basically guaranteed? What if our life becomes so good?
Segment 3856: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10808, Text: You can make survival guaranteed without UBI. What you have to do, is make housing and food dirt cheap. Right? And that’s the good world. And actually, let’s go into what we should really be making dirt cheap, which is energy. Right. That energy that… Oh my God, that’s…
Segment 3857: Speaker: , Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10827, Text: I’m pretty centrist politically. If there’s one political position I cannot stand, it’s deceleration. It’s people who believe we should use less energy. Not people who believe global warming is a problem, I agree with you. Not people who believe that the saving the environment is good, I agree with you. But people who think we should use less energy, that energy usage is a moral bad. No, no. You are asking, you are diminishing humanity.
Segment 3858: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10854, Text: Yeah. Energy is flourishing. Creative flourishing of the human species.
Segment 3859: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10859, Text: How do we make more of it? How do we make it clean? And how do we make… How I pay 20 cents for a megawatt hour instead of a kilowatt hour?
Segment 3860: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10868, Text: Part of me wishes that Elon went into nuclear fusion versus Twitter, part of me. Or somebody like Elon.
Segment 3861: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10880, Text: I wish there were more Elons in the world. And I think Elon sees it as this is a political battle that needed to be fought. And again, I always ask the question of whenever I disagree with him, I remind myself that he is a billionaire and I’m not. So maybe he’s got something figured out that I don’t, or maybe he doesn’t
Segment 3862: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10898, Text: To have some humility. But at the same time, me as a person who happens to know him, I find myself in that same position. And sometimes even billionaires need friends who disagree and help them grow. And that’s a difficult reality.
Segment 3863: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10917, Text: And it must be so hard. It must be so hard to meet people once you get to that point where-
Segment 3864: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10922, Text: Fame, power, money, everybody’s sucking up to you.
Segment 3865: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10925, Text: See, I love not having shit. I don’t have shit man. Trust me. There’s nothing I can give you. There’s nothing worth taking from me.
Segment 3866: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10932, Text: Yeah. It takes a really special human being, when you have power, when you have fame, when you have money, to still think from first principles. Not all the adoration you get towards you, all the admiration, all the people saying, “Yes, yes, yes.”
Segment 3867: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10946, Text: And all the hate too.
Segment 3868: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10949, Text: And the hate-
Segment 3869: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10949, Text: I think that’s worse.
Segment 3870: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10950, Text: So the hate makes you want to go to the ‘yes’ people because the hate exhausts you. And the kind of hate that Elon’s gotten from the left, is pretty intense. And so that, of course, drives him right, and loses balance, and-
Segment 3871: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10966, Text: And it keeps this absolutely fake siop political divide alive, so that the 1% can keep power.
Segment 3872: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10976, Text: I wish we would be less divided because it is giving powr-
Segment 3873: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10979, Text: It gives power-
Segment 3874: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10979, Text: To the ultra powerful.
Segment 3875: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10981, Text: I know.
Segment 3876: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10982, Text: The rich get richer. You have love in your life. Has love made you a better or a worse programmer? Do you keep productivity metrics?
Segment 3877: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=10993, Text: No, no, no. I’m not that methodical. I think there comes to a point where, if it’s no longer visceral, I just can’t enjoy it. I guess still, viscerally, love programming. The minute I started-
Segment 3878: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11009, Text: So that’s one of the big loves of your life, is programming?
Segment 3879: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11013, Text: I mean, just my computer in general. I mean, I tell my girlfriend, “My first love is my computer,” of course. I sleep with my computer. It’s there for a lot of my sexual experiences. Come on. So is everyone’s right. You got to be real about that. And-
Segment 3880: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11028, Text: Not just the ID for programming, just the entirety of the computational machine?
Segment 3881: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11033, Text: The fact that… Yeah. I wish it was a.. And someday they’ll be smarter, and someday [inaudible 03:03:59]. Maybe I’m weird for this, but I don’t discriminate, man. I’m not going to discriminate BioStack life in Silicon Stack life.
Segment 3882: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11044, Text: So the moment the computer starts to say, “I miss you,” and starts to have some of the basics of human intimacy, it’s over for you. The moment VS Code says, “Hey, George…”
Segment 3883: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11056, Text: No, no, no, but VS Code is… No, Microsoft’s doing that to try to get me hooked on it. I’ll see through it. I’ll see through it. It’s gold digger, man. It’s gold digger.
Segment 3884: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11066, Text: Well, it can be an open source thing.
Segment 3885: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11067, Text: Well, this just gets more interesting, right. If it’s open source, then yeah, it becomes-
Segment 3886: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11071, Text: Though, Microsoft’s done a pretty good job on that.
Segment 3887: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11073, Text: Oh, absolutely. No, no, no. Look, I think Microsoft… Again, I wouldn’t count on it to be true forever, but I think right now, Microsoft is doing the best work in the programming world, between GitHub, GitHub Actions VS Code, the improvements to Python, it was Microsoft.This is-
Segment 3888: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11091, Text: Who would’ve thought, Microsoft and Mark Zuckerberg are spearheading the open source movement.
Segment 3889: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11097, Text: Right? Right? How things change.
Segment 3890: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11101, Text: Oh, it’s beautiful.
Segment 3891: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11103, Text: And by the way, that’s who I bet on to replace Google, by the way.
Segment 3892: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11106, Text: Who?
Segment 3893: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11106, Text: Microsoft.
Segment 3894: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11107, Text: Microsoft.
Segment 3895: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11108, Text: I think Satya Nadella said straight up, “I’m coming for it.”
Segment 3896: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11111, Text: Interesting. So your bet, who wins AGI? That’s [inaudible 03:05:16]-
Segment 3897: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11115, Text: I don’t know about AGI. I think we’re a long way away from that. But I would not be surprised, if in the next five years, Bing overtakes Google as a search engine.
Segment 3898: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11124, Text: Interesting.
Segment 3899: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11125, Text: Wouldn’t surprise me.
Segment 3900: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11126, Text: Interesting. I hope some startup does.
Segment 3901: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11133, Text: It might be some startup too. I would equally bet on some startup.
Segment 3902: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11137, Text: Yeah. I’m like 50 50. But maybe that’s naive. I believe in the power of these language models.
Segment 3903: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11143, Text: Satya is alive. Microsoft’s alive.
Segment 3904: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11145, Text: Yeah, it’s great. It’s great. I like all the innovation in these companies. They’re not being stale, and to the degree they’re being stale, they’re losing. So there’s a huge incentive to do a lot of exciting work and open source work, this is incredible.
Segment 3905: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11161, Text: Only way to win.
Segment 3906: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11162, Text: You’re older, you’re wiser. What’s the meaning of life, George Hotz?
Segment 3907: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11168, Text: To win.
Segment 3908: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11169, Text: It’s still to win?
Segment 3909: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11170, Text: Of course.
Segment 3910: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11172, Text: Always?
Segment 3911: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11173, Text: Of course.
Segment 3912: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11174, Text: What’s winning look like for you?
Segment 3913: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11177, Text: I don’t know. I haven’t figured out what the game is yet, but when I do, I want to win-
Segment 3914: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11179, Text: So it’s bigger than solving self-driving? It’s bigger than democratizing, decentralizing and compute?
Segment 3915: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11189, Text: I think the game is to stand eye to eye with God.
Segment 3916: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11193, Text: I wonder what that means for you. At the end of your life, what that would look like.
Segment 3917: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11201, Text: I mean, this is what… I don’t know. There’s probably some ego trip of mine. “You want to stand eye to eye with God. You’re just blasphemous, man.” Okay. I don’t know. I don’t know. I don’t know. I don’t know if it would upset God. I think he wants that. I mean, I certainly want that from my creations. I want my creations to stand eye to eye with me. So why wouldn’t God want me to stand eye to eye with him? That’s the best I can do, golden rule.
Segment 3918: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11231, Text: I’m just imagining the creator of a video game, having to look, stand eye to eye, with one of the characters.
Segment 3919: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11242, Text: I only watched season one of Westworld. But yeah, we got to find the maze and solve it.
Segment 3920: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11247, Text: Yeah. I wonder what that looks like. It feels like a really special time in human history, where that’s actually possible. There’s something about AI that’s… we’re playing with something weird here. Something really weird.
Segment 3921: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11261, Text: I wrote a blog post, “I reread Genesis and just looked like… they give you some clues at the end of Genesis for finding the Garden of Eden. And I’m interested. I’m interested.”
Segment 3922: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11274, Text: Well, I hope you find just that, George, you’re one of my favorite people. Thank you for doing everything you’re doing and in this case, for fighting for open source or for decentralization of AI. It’s a fight worth fighting, fight worth winning, hashtag. I love you, brother. These conversations are always great. Hope to talk to you many more times. Good luck with Tiny Corp.
Segment 3923: Speaker: George Hotz, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11295, Text: Thank you. Great to be here.
Segment 3924: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=dNrTrx42DGQ&t=11297, Text: Thanks for listening to this conversation with George Hotz. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Albert Einstein, “Everything should be made as simple as possible, but not simpler.” Thank you for listening and hope to see you next time.
Segment 3925: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=0, Text: We’ve never bowed down to government pressure anywhere in the world, and we never will. We understand that we’re hardcore, and actually, there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. If they threaten to block, well, knock yourself out. You’re going to lose Wikipedia.
Segment 3926: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=21, Text: The following is a conversation with Jimmy Wales, co-founder of Wikipedia, one of, if not the most impactful websites ever, expanding the collective knowledge, intelligence, and wisdom of human civilization. This is Lex Fridman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Jimmy Wales.
Segment 3927: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=47, Text: Let’s start at the beginning. What is the origin story of Wikipedia?
Segment 3928: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=51, Text: The origin story of Wikipedia, well, so I was watching the growth of the free software movement, open-source software, and seeing programmers coming together to collaborate in new ways, sharing code, doing that under free license, which is really interesting because it empowers an ability to work together. That’s really hard to do if the code is still proprietary, because then if I chip in and help, we have to figure out how I’m going to be rewarded and what that is. But the idea that everyone can copy it and it just is part of the commons really empowered a huge wave of creative software production. I realized that that kind of collaboration could extend beyond just software to all kinds of cultural works.
Segment 3929: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=98, Text: The first thing that I thought of was an encyclopedia and thought, “Oh, that seems obvious that an encyclopedia, you can collaborate on it.” There’s a few reasons why. One, we all pretty much know what an encyclopedia entry on say, the Eiffel Tower should be like. You should see a picture, a few pictures, maybe, history, location, something about the architect, et cetera, et cetera. So we have a shared understanding of what it is we’re trying to do, and then we can collaborate and different people can chip in and find sources and so on and so forth. So set up first Nupedia, which was about two years before Wikipedia.
Segment 3930: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=138, Text: With Nupedia, we had this idea that in order to be respected, we had to be even more academic than a traditional encyclopedia because a bunch of volunteers on the internet getting it right out of an encyclopedia, you could be made fun of if it’s just every random person. So we had implemented this seven-stage review process to get anything published, and two things came of that. So one thing, one of the earliest entries that we published after this rigorous process, a few days later, we had to pull it because as soon as it hit the web and the broader community took a look at it, people noticed plagiarism and realized that it wasn’t actually that good, even though it had been reviewed by academics and so on. So we had to pull it. So it’s like, “Oh, okay. Well, so much for a seven-stage review process.”
Segment 3931: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=187, Text: I was frustrated, “Why is this taking so long? Why is it so hard?” So I thought, “Okay.” I saw that Robert Merton had won a Nobel Prize in economics for his work on option pricing theory. When I was in academia, that’s what I worked on was option pricing theory, had a published paper. So I’d worked through all of his academic papers, and I knew his work quite well. I thought, “Oh, I’ll write a short biography of Merton.” When I started to do it, I’d been out of academia, I hadn’t been a grad student for a few years then. I felt this huge intimidation because they were going to take my draft and send it to the most prestigious finance professors that we could find to give me feedback for revisions. It felt like being back in grad school. It’s like this really oppressive, like, you’re going to submit it for a review and you’re going to get critiques.
Segment 3932: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=239, Text: A little bit of the bad part of grad school.
Segment 3933: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=241, Text: Yeah, yeah, the bad part of grad school. So I was like, “Oh, this isn’t intellectually fun, this is like the bad part of grad school. It’s intimidating, and there’s a lot of potential embarrassment if I screw something up and so forth.” So that was when I realized, “Okay, look, this is never going to work. This is not something that people are really going to want to do.” So Jeremy Rosenfeld, one of my employees had brought and showed me the Wiki concept in December, and then Larry Sanger brought in the same, said, “What about this Wiki idea?” So in January, we decided to launch Wikipedia, but we weren’t sure. So the original project was called Nupedia. Even though it wasn’t successful, we did have quite a group of academics and really serious people.
Segment 3934: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=285, Text: We were concerned that, “Oh, maybe these academics are going to really hate this idea, and we shouldn’t just convert the project immediately. We should launch this as a side project, the idea of here’s a Wiki where we can start playing around.” But actually, we got more work done in two weeks than we had in almost two years because people were able to just jump on and start doing stuff, and it was actually a very exciting time. Back then, you could be the first person who typed Africa as a continent and hit Save, which isn’t much of an encyclopedia entry, but it’s true, and it’s a start and it’s kind of fun, like put your name down.
Segment 3935: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=320, Text: Actually, a funny story was several years later, I just happened to be online and I saw when, I think his name is Robert Aumann, won the Nobel Prize in economics. We didn’t have an entry on him at all, which was surprising, but it wasn’t that surprising. This was still early days. So I got to be the first person to type Robert Aumann, won Nobel Prize in economics and hit Save, which again, wasn’t a very good article. But then I came back two days later and people had improved it and so forth. So that second half of the experience where with Robert Merton, I never succeeded because it was just too intimidating. It was like, “Oh, no, I was able to chip in and help, other people jumped in. Everybody was interested in the topic, because it’s all in the news at the moment.” So it’s just a completely different model, which worked much, much better.
Segment 3936: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=363, Text: Well, what is it that made that so accessible, so fun, so natural to just add something?
Segment 3937: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=369, Text: Well, I think, especially in the early days, and this, by the way, has gotten much harder because there are fewer topics that are just greenfield available. But you could say, “Oh, well, I know a little bit about this, and I can get it started.” But then it is fun to come back then and see other people have added and improved and so on and so forth. That idea of collaborating where people can, much like open-source software, you put your code out and then people suggest revisions. They change it, and it modifies and it grows beyond the original creator, it’s just a fun, wonderful, quite geeky hobby, but people enjoy it.
Segment 3938: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=411, Text: How much debate was there over the interface, over the details of how to make that, seamless and frictionless?
Segment 3939: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=417, Text: Yeah, not as much as there probably should have been, in a way. During that two years of the failure of Nupedia where very little work got done, what was actually productive was, there was a huge long discussion; email discussion, very clever people talking about things like neutrality, talking about what is an encyclopedia, but also talking about more technical ideas. Back then, XML was all the rage and thinking about shouldn’t you have certain data that might be in multiple articles that gets updated automatically? So for example, the population of New York City, every 10 years there’s a new official census, couldn’t you just update that bit of data in one place and it would update across all languages? That is a reality today. But back then it was just like, “Hmm, how do we do that? How do we think about that?”
Segment 3940: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=467, Text: So that is a reality today where it’s-
Segment 3941: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=468, Text: Yeah-
Segment 3942: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=469, Text: … there’s some-
Segment 3943: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=470, Text: Yeah, so Wikidata-
Segment 3944: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=470, Text: … universal variables? Wikidata.
Segment 3945: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=476, Text: Yeah, Wikidata. From a Wikipedia entry, you can link to that piece of data in Wikidata, and it’s a pretty advanced thing, but there are advanced users who are doing that. Then when that gets updated, it updates in all the languages where you’ve done that.
Segment 3946: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=487, Text: That’s really interesting. There was this chain of emails in the early days of discussing the details of what is. So there’s the interface, there’s the-
Segment 3947: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=494, Text: Yeah, so the interface, so an example, there was some software called UseModWiki, which we started with. It’s quite amusing actually, because the main reason we launched with UseModWiki is that it was a single Perl script, so it was really easy for me to install it on the server and just get running. But it was some guy’s hobby project, it was cool, but it was just a hobby project. All the data was stored in flat text files, so there was no real database behind it. So to search the site, you basically used Grab, which is just the basic Unix utility to look through all the files. So that clearly was never going to scale. But also in the early days, it didn’t have real logins. So you could set your username, but there were no passwords. So I might say Bob Smith, and then someone else comes along and says, “No, I’m Bob Smith,” and they both had it. Now that never really happened.
Segment 3948: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=550, Text: We didn’t have a problem with it, but it was obvious, you can’t grow a big website where everybody can pretend to be everybody. That’s not going to be good for trust and reputation and so forth. So quickly, I had to write a little login, store people’s passwords and things like that so you could have unique identities. Then another example of something you would’ve never thought would’ve been a good idea, and it turned out to not be a problem. But to make a link in Wikipedia in the early days, you would make a link to a page that may or may not exist by just using CamelCase, meaning it’s like upper case, lowercase, and you smash the words together. So maybe New York City, you might type N-E-W, no space, capital Y, York City, and that would make a link, but that was ugly. That was clearly not right. So I was like, “Okay, well that’s just not going to look nice. Let’s just use square brackets, two square brackets makes a link.”
Segment 3949: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=604, Text: That may have been an option in the software. I’m not sure I thought up square brackets. But anyway, we just did that, which worked really well. It makes nice links and you can see in its red links or blue links, depending on if the page exists or not. But the thing that didn’t occur to me even to think about is that, for example, on the German language standard keyboard, there is no square bracket. So for German Wikipedia to succeed, people had to learn to do some alt codes to get the square bracket, or a lot of users cut and paste a square bracket where they could find one and they would just cut and paste one in. Yet. German Wikipedia has been a massive success, so somehow that didn’t slow people down.
Segment 3950: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=640, Text: How is that that the German keyboards don’t have a square bracket. How do you do programming? How do you live life to its fullest without square brackets?
Segment 3951: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=648, Text: It’s a very good question. I’m not really sure. Maybe it does now because keyboard standards have drifted over time and becomes useful to have a certain character. It’s same thing, there’s not really a W character in Italian, and it wasn’t on keyboards or I think it is now. But in general, W is not a letter in Italian language, but it appears in enough international words that it’s crept into Italian.
Segment 3952: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=672, Text: All of these things are probably Wikipedia articles in themselves.
Segment 3953: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=677, Text: Oh, yes. Oh, yeah.
Segment 3954: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=677, Text: The discussion of square brackets-
Segment 3955: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=677, Text: That is a whole-
Segment 3956: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=677, Text: … in German-
Segment 3957: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=679, Text: … whole discussion, I’m sure.
Segment 3958: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=680, Text: … on both the English and the German Wikipedia. The difference between those two might be very-
Segment 3959: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=687, Text: Interesting.
Segment 3960: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=687, Text: … interesting. So Wikidata is fascinating, but even the broader discussion of what is an encyclopedia, can you go to that philosophical question of-
Segment 3961: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=697, Text: Sure.
Segment 3962: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=697, Text: … what is an encyclopedia?
Segment 3963: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=699, Text: What is an encyclopedia? So the way I would put it is an encyclopedia, or what our goal is is the sum of all human knowledge, but sum meaning summary. This was an early debate. Somebody started uploading the full text of Hamlet, for example, and we said, “Mmm, wait, hold on a second. That’s not an encyclopedia article, but why not?” So hence was born Wikisource, which is where you put original texts and things like that, out of copyright text, because they said, “No, an encyclopedia article about Hamlet, that’s a perfectly valid thing. But the actual text of the play is not an encyclopedia article. “So most of it’s fairly obvious, but there are some interesting quirks and differences. So for example, as I understand it, in French language encyclopedias, traditionally it would be quite common to have recipes, which in English language that would be unusual. You wouldn’t find a recipe for chocolate cake in Britannica. So I actually don’t know the current state, haven’t thought about that in many, many years now.
Segment 3964: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=764, Text: State of cake recipes in Wikipedia, in English, Wikipedia?
Segment 3965: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=767, Text: I wouldn’t say there’s chocolate cake recipes. You might find a sample recipe somewhere. I’m not saying there are none, but in general, no, we wouldn’t have recipes-
Segment 3966: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=775, Text: I told myself I would not get outraged in this conversation, but now I’m outraged. I’m deeply upset.
Segment 3967: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=780, Text: It’s actually very complicated. I love to cook. I’m actually quite a good cook. What’s interesting is it’s very hard to have a neutral recipe because [inaudible 00:13:12]
Segment 3968: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=792, Text: Like a canonical recipe for cake-
Segment 3969: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=793, Text: A canonical recipe is-
Segment 3970: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=794, Text: … chocolate cake.
Segment 3971: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=795, Text: … is kind of difficult to come by because there’s so many variants and it’s all debatable and interesting. For something like chocolate cake, you could probably say, “Here’s one of the earliest recipes,” or, “Here’s one of the most common recipes.” But for many, many things, the variants are as interesting as somebody said to me recently, 10 Spaniards, 12 paella recipes. So these are all matters of open discussion.
Segment 3972: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=824, Text: Well, just to throw some numbers, as of May 27, 2023, there are 6.6 million articles in the English Wikipedia containing over 4.3 billion words. Including articles, the total number of pages is 58 million.
Segment 3973: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=845, Text: Yeah.
Segment 3974: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=846, Text: Does that blow your mind?
Segment 3975: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=848, Text: Yes, it does. It doesn’t, because I know those numbers and see them from time to time. But in another sense, a deeper sense, yeah, it does. It’s really remarkable. I remember when English Wikipedia passed 100,000 articles and when German Wikipedia passed 100,000, ’cause I happened to be in Germany with a bunch of Wikipedians that night, and then it seemed quite big. We knew at that time that it was nowhere near complete. I remember at Wikimania in Harvard when we did our annual conference there in Boston, someone who had come to the conference from Poland had brought along with him a small encyclopedia, a single volume encyclopedia of biographies, so short biographies, normally a paragraph or so about famous people in Poland, and there were some 22,000 entries. He pointed out that even then, 2006, Wikipedia felt quite big.
Segment 3976: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=912, Text: He said in English Wikipedia, there’s only a handful of these, less than 10%, I think he said. So then you realized, yeah, actually, who was the mayor of Warsaw in 1873? Don’t know. Probably not in English Wikipedia, but it probably might be today, but there’s so much out there. Of course, what we get into when we’re talking about how many entries there are and how many could there be, is this very deep philosophical issue of notability, which is the question of, well, how do you draw the limit? How do you draw what is there? So sometimes people say, “Oh, there should be no limit.” But I think that doesn’t stand up to much scrutiny if you really pause and think about it. So I see in your hand there you’ve got a BIC pen, pretty standard. Everybody’s seen billions of those in life.
Segment 3977: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=965, Text: Classic though.
Segment 3978: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=965, Text: It’s a classic, clear, BIC pen. So could we have an entry about that BIC pen aisle? I bet we do, that type of BIC pen because it’s classic. Everybody knows it, and it’s got a history. Actually, there’s something interesting about the BIC company. They make pens, they also make kayaks, and there’s something else they’re famous for. Basically, they’re a definition by non-essentials company. Anything that’s long and plastic, that’s what they make.
Segment 3979: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=993, Text: Wow, that’s very-
Segment 3980: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=994, Text: If you want to find the common ground-
Segment 3981: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=996, Text: … platonic form, the platonic form of a BIC.
Segment 3982: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=997, Text: But could we have an article about that very BIC pen in your hand, so Lex Fridman’s BIC pen as of this week?
Segment 3983: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1005, Text: Oh, the very, this instance-
Segment 3984: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1005, Text: The very specific instance, and the answer is no, there’s not much known about it. I dare say, unless it’s very special to you and your great-grandmother gave it to you or something, you probably know very little about it. It’s a pen. It’s just here in the office. So that’s just to show there is a limit. In German Wikipedia, they used to talk about the rear nut of the wheel of [inaudible 00:17:10] bicycle [inaudible 00:17:11] a well-known Wikipedian of the time, to sort of illustrate, you can’t have an article about literally everything. So then it raises the question, what can you have an article about? What can’t you? That can vary depending on the subject matter. One of the areas where we try to be much more careful would be biographies. The reason is a biography of a living person, if you get it wrong, you can actually be quite hurtful, quite damaging.
Segment 3985: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1058, Text: So if someone is a private person and somebody tries to create a Wikipedia entry, there’s no way to update it. There’s not much done. So for example, an encyclopedia article about my mother, my mother, school teacher later, a pharmacist, wonderful woman, but never been in the news, other than me talking about why there shouldn’t be a Wikipedia entry, that’s probably made it in somewhere, standard example. But there’s not enough known. You could imagine a database of genealogy having date of birth, date of death, certain elements like that of private people. But you couldn’t really write a biography. One of the areas this comes up quite often is what we call BLP1E. We’ve got lots of acronyms. Biography of a living person who’s notable for only one event is a real danger zone.
Segment 3986: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1107, Text: Oh.
Segment 3987: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1108, Text: The type of example would be a victim of a crime, so someone who’s a victim of a famous serial killer, but about whom really not much is known. They weren’t a public person, they’re just a victim of a crime, we really shouldn’t have an article about that person. They’ll be mentioned, of course, and maybe this specific crime might have an article. But for that person, no, not really. That’s not really something that makes any sense because how can you write a biography about someone you don’t know much about? It varies from field to field. So for example, for many academics, we will have an entry that we might not have in a different context because for an academic, it’s important to have sort of their career, what papers they’ve published, things like that.
Segment 3988: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1153, Text: You may not know anything about their personal life, but that’s actually not encyclopedically relevant in the same way that it is for member of a royal family where it’s basically all about the family. So we’re fairly nuanced about notability and where it comes in. I’ve always thought that the term notability, I think, is a little problematic. We struggled about how to talk about it. The problem with notability is it can feel insulting. Say, “Oh no, you’re not noteworthy.” Well, my mother’s noteworthy. She’s a really important person in my life, so that’s not right. But it’s more like verifiability. Is there a way to get information that actually makes an encyclopedia entry?
Segment 3989: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1196, Text: It so happens that there’s a Wikipedia page about me as I’ve learned recently, and the first thought I had when I saw that was, “Surely I am not notable enough.” So I was very surprised and grateful that such a page could exist and actually, just allow me to say thank you to all the incredible people that are part of creating and maintaining Wikipedia. It’s my favorite website on the internet. The collection of articles that Wikipedia has created is just incredible. We’ll talk about the various details of that. But the love and care that goes into creating pages for individuals, for a BIC pen, for all this kind of stuff is just really incredible.
Segment 3990: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1243, Text: So I just felt the love when I saw that page. But I also felt just because I do this podcast and I just through this podcast, gotten to know a few individuals that are quite controversial, I’ve gotten to be on the receiving end of something quite … to me as a person who loves other human beings, I’ve gotten to be at the receiving end of some attacks through Wikipedia. Like you said, when you look at living individuals, it can be quite hurtful, the little details of information. Because I’ve become friends with Elon Musk and I’ve interviewed him, but I’ve also interviewed people on the left, far left, people on the right, some would say far right, and so now you take a step, you put your toe into the cold pool of politics and the shark emerges from the depths and pulls you right in.
Segment 3991: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1301, Text: Yeah, the boiling hot pool of politics.
Segment 3992: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1303, Text: I guess it’s hot, and so I got to experience some of that. I think what you also realize is there has to be, for Wikipedia credible sources, verifiable sources, and there’s a dance there because some of the sources are pieces of journalism. Of course, journalism operates under its own complicated incentives such that people can write articles that are not factual or are cherry-picking all the flaws they can have in a journalistic article-
Segment 3993: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1338, Text: For sure.
Segment 3994: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1338, Text: … and those can be used as-
Segment 3995: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1340, Text: For sure.
Segment 3996: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1341, Text: … as sources. It’s like they dance hand-in-hand. So for me, sadly enough, there was a really concerted attack to say that I was never at MIT, never did anything at MIT. Just to clarify, I am a research scientist at MIT. I have been there since 2015. I’m there today. I’m at a prestigious, amazing laboratory called LIDS, and I hope to be there for a long time. I work on AI, robotics, machine learning. There’s a lot of incredible people there. By the way, MIT has been very kind to defend me. Unlike Wikipedia says, it is not an unpaid position. There was no controversy.
Segment 3997: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1383, Text: Right.
Segment 3998: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1383, Text: It was all very calm and happy and almost boring research that I’ve been doing there. The other thing, because I am half-Ukrainian, half-Russian-
Segment 3999: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1394, Text: Oh.
Segment 4000: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1395, Text: … and I’ve traveled to Ukraine and I will travel to Ukraine again, and I will travel to Russia for some very difficult conversations. My heart’s been broken by this war. I have family in both places. It’s been a really difficult time. But the little battle about the biography there also starts becoming important for the first time for me. I also want to clarify personally, I use this opportunity of some inaccuracies there. My father was not born in Chkalovsk, Russia. He was born in Kiev, Ukraine. I was born in Chkalovsk which is a town not in Russia. There is a town called that in Russia. But there’s another town in Tajikistan, which is the former republic of the Soviet Union. That town is now called B-U-S-T-O-N, Buston, which is funny because we’re now in Austin, and I also am in Boston, it seems like my whole life is surrounded by these kinds of towns.
Segment 4001: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1453, Text: So I was born in Tajikistan, and the rest of the biography is interesting, but my family is very evenly distributed between their origins and where they grew up between Ukraine and Russia, which adds a whole beautiful complexity to this whole thing. So I want to just correct that. It’s like the fascinating thing about Wikipedia is in some sense, those little details don’t matter. But in another sense, what I felt when I saw a Wikipedia page about me or anybody I know is there’s this beautiful saving that this person existed, like a community that notices you that says, “Huh.” You see a butterfly that floats, and you’re like, “Huh?” That it’s not just any butterfly, it’s that one. “I like that one,” or you see a puppy or something, or it’s this BIC pen. “I remember this one, it has this scratch. You get noticed in that way and I know it’s a beautiful thing. Maybe it’s very silly of me and naive, but I feel like Wikipedia, in terms of individuals, is an opportunity to celebrate people, to celebrate ideas-
Segment 4002: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1526, Text: For sure. For sure.
Segment 4003: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1526, Text: … and not a battleground of the kind of stuff we might see on Twitter, like the mockery, the derision, this kind of stuff.
Segment 4004: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1535, Text: For sure.
Segment 4005: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1536, Text: Of course, you don’t want to cherry-pick. All of us have flaws and so on, but it just feels like to highlight a controversy of some sort, when that doesn’t at all represent the entirety of the human, in most cases, is sad.
Segment 4006: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1550, Text: Yeah. Yeah. Yeah. So there’s a few to unpack and all that. So first, one of the things I find really, always find very interesting is your status with MIT. Okay, that’s upsetting, and it’s an argument and can be sorted out. But then what’s interesting is you gave as much time to that, which is actually important and relevant to your career and so on to also where your father was born, which most people would hardly notice, but is really meaningful to you. I find that a lot when I talk to people who have a biography in Wikipedia is they’re often as annoyed by a tinier that no one’s going to notice like this town in Tajikistan’s got a new name and so on. Nobody even knows what that means or whatever, but it can be super important. So that’s one of the reasons for biographies, we say human dignity really matters. So some of the things have to do with, and this is a common debate that goes on in Wikipedia, is what we call undue weight. So I’ll give an example.
Segment 4007: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1619, Text: There was a article I stumbled across many years ago about the mayor, or no, he wasn’t a mayor, he was a city council member of, I think it was Peoria, Illinois, but some small town in the Midwest. The entry, he’s been on the city council for 30 years or whatever. He’s frankly, a pretty boring guy and seems like a good local city politician. But in this very short biography, there was a whole paragraph, a long paragraph about his son being arrested for DUI, and it was clearly undue weight. It’s like, “What has this got to do with this guy if it even deserves a mention?” It wasn’t even clear had he done anything hypocritical, had he done himself anything wrong, even was his son, his son got a DUI.
Segment 4008: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1664, Text: That’s never great, but it happens to people, and it doesn’t seem like a massive scandal for your dad. So of course, I just took that out immediately. This is a long, long time ago. That’s the sort of thing where we have to really think about in a biography and about controversies to say, “Is this a real controversy?” So in general, one of the things we tend to say is any section, so if there’s a biography and there’s a section called controversies, that’s actually poor practice because it just invites people to say, “Oh, I want to work on this entry.” It’s either seven sections. “Oh, this one’s quite short. Can I add something?”
Segment 4009: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1703, Text: Right?
Segment 4010: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1704, Text: Go out and find some more controversies. Now that’s nonsense, right?
Segment 4011: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1704, Text: Yeah.
Segment 4012: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1706, Text: In general, putting it separate from everything else makes it seem worse, and also, it doesn’t put it in the right context. Whereas, if it’s a live flaw and there is a controversy, there’s always potential controversy for anyone, it should just be worked into the overall article, ’cause then it doesn’t become a temptation. You can contextualize appropriately and so forth. So that’s part of the whole process. But I think for me, one of the most important things is what I call community health. So yeah, are we going to get it wrong sometimes? Yeah, of course. We’re humans and doing good, quality reference material is hard. The real question is, how do people react to a criticism or a complaint or a concern? If the reaction is defensiveness or combativeness back, or if someone’s really in there being aggressive and in the wrong, like, “No, no, no, hold on, we’ve got to do this the right way.” You got to say, “Okay, hold on. Are there good sources? Is this contextualized appropriately? Is it even important enough to mention? What does it mean?”
Segment 4013: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1780, Text: Sometimes one of the areas where I do think there is a very complicated flaw, and you’ve alluded to it a little bit, but it’s like we know the media is deeply flawed. We know that journalism can go wrong. I would say particularly in the last whatever, 15 years, we’ve seen a real decimation of local media, local newspapers. We’ve seen a real rise in clickbait headlines and eager focus on anything that might be controversial. We’ve always had that with us, of course, there’s always been tabloid newspapers. But that makes it a little bit more challenging to say, “Okay, how do we sort things out when we have a pretty good sense that not every source is valid?” So as an example, a few years ago, it’s been quite a while now, we deprecated the MailOnline as a source and the MailOnline, the digital arm of the Daily Mail, it’s a tabloid.
Segment 4014: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1846, Text: It’s not fake news, but it does tend to run very hyped-up stories. They really love to attack people and go on the attack for political reasons and so on, and it just isn’t great. So by saying deprecated, and I think some people say, “Oh, you banned the Daily Mail? No, we didn’t ban it as a source. We just said, “Look, it’s probably not a great source. You should probably look for a better source.” So certainly if the Daily Mail runs a headline saying, “New Cure for Cancer,” it’s like probably there’s more serious sources than a tabloid newspaper. So in an article about lung cancer, you probably wouldn’t cite the Daily Mail. That’s kind of ridiculous. But also for celebrities and so forth to know, “Oh, well, they do cover celebrity gossip a lot, but they also tend to have vendettas and so forth.” You really have to step back and go, “Is this really encyclopedic or is this just the Daily Mail going on a rant?”
Segment 4015: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1899, Text: Some of that requires a great community health.
Segment 4016: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1901, Text: It requires massive community health.
Segment 4017: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1903, Text: Even for me, for stuff I’ve seen that’s kind of, if actually iffy about people I know, things I know about myself, I still feel like a love for knowledge emanating from the article. I feel the community health, so I will take all slight inaccuracies. I love it because that means there’s people, for the most part, I feel of respect and love in this search for knowledge. Sometimes, ’cause I also love Stack Overflow and Stack Exchange for programming-related things. They can get a little cranky sometimes to a degree where it’s like it’s not as … you could could feel the dynamics of the health of the particular community and sub communities too, like a particular C Sharp or Java or Python or whatever, there’s little communities that emerge. You can feel the levels of toxicity, ’cause a little bit of strictness is good, but a little too much is bad because of the defensiveness, ’cause when somebody writes an answer and then somebody else says, “We’ll modify it,” and then get defensive, and there’s this tension that’s not conducive to improving towards a more truthful depiction of that topic.
Segment 4018: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1982, Text: Yeah, a great example-
Segment 4019: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1980, Text: … truthful depiction of that topic.
Segment 4020: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=1982, Text: Yeah, a great example that I really loved this morning that I saw someone left a note on my user talk page in English Wikipedia saying it was quite a dramatic headline saying racist hook on front page. So we have on the front page of Wikipedia, we have little section called Did You know? And it’s just little tidbits and facts, just things people find interesting. And there’s a whole process for how things get there. And the one that somebody was raising a question about was, it was comparing a very well known US football player, Black. There was a quote from another famous sport person comparing him to a Lamborghini. Clearly a compliment. And so somebody said, “Actually, here’s a study, here’s some interesting information about how Black sports people are far more often compared to inanimate objects. And given that kind of analogy, and I think it’s demeaning to compare a person to a car, et cetera, cetera.”
Segment 4021: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2041, Text: But they said, “I’m not pulling, I’m not deleting it, I’m not removing it. I just want to raise the question.” And then there’s this really interesting conversation that goes on where I think the general consensus was, you know what, this isn’t like the alarming headline racist thing on the front page of Wikipedia, holy moly, that sounds bad. But it’s sort of like, actually yeah this probably isn’t the sort of analogy that we think is great. And so we should probably think about how to improve our language and not compare sports people to inanimate objects and particularly be aware of certain racial sensitivities that there might be around that sort of thing if there is a disparity in the media of how people are called.
Segment 4022: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2080, Text: And I just thought, you know what, nothing for me to weigh in on here. This is a good conversation. Like nobody’s saying people should be banned if they refer to, what was his name, The Fridge, Refrigerator Perry. Very famous comparison to an inanimate object of a Chicago Bears player, many years ago. But they’re just saying, hey, let’s be careful about analogies that we just pick up from the media. I said, “Yeah, that’s good.”
Segment 4023: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2106, Text: On the deprecation of news sources is really interesting because I think what you’re saying is ultimately you want to make a article by article decision, use your own judgment. And it’s such a subtle thing because there’s just a lot of hit pieces written about individuals like myself for example, that masquerade as an objective thorough exploration of a human being. It’s fascinating to watch because controversy and hit pieces just get more clicks.
Segment 4024: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2141, Text: Oh yeah, sure.
Segment 4025: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2141, Text: This is, I guess, as a Wikipedia contributor, you start to deeply become aware of that and start to have a sense, a radar of clickbait versus truth to pick out the truth from the clickbaity type language.
Segment 4026: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2158, Text: Oh, yeah. I mean it’s really important and we talk a lot about weasel words. And actually I’m sure we’ll end up talking about AI and ChatGPT.
Segment 4027: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2170, Text: Yes.
Segment 4028: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2170, Text: But just to quickly mention in this area, I think one of the potentially powerful tool, because it is quite good at this, I’ve played around with and practiced it quite a lot, but ChatGPT-4 is really quite able to take a passage and point out potentially biased terms, to rewrite it to be more neutral. Now it is a bit anodyne and it’s a bit cliched, so sometimes it just takes the spirit out of something that’s actually not bad. It’s just like poetic language and you’re like, okay, that’s not actually helping. But in many cases I think that sort of thing is quite interesting. And I’m also interested in… Can you imagine where you feed in a Wikipedia entry and all the sources and you say, help me find anything in the article that is not accurately reflecting what’s in the sources? And that doesn’t have to be perfect. It only has to be good enough to be useful to community.
Segment 4029: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2237, Text: So if it scans-
Segment 4030: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2239, Text: Beautiful.
Segment 4031: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2239, Text: … an article and all the sources and you say, oh, it came back with 10 suggestions and seven of them were decent and three of them it just didn’t understand, well actually that’s probably worth my time to do. And it can help us really more quickly get good people to review obscure entries and things like that.
Segment 4032: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2261, Text: So just as a small aside on that, and we’ll probably talk about language models a little bit, or a lot more, but one of the articles, one of the hit pieces about me, the journalist actually was very straightforward and honest about having used GPT to write part of the article.
Segment 4033: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2279, Text: Interesting.
Segment 4034: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2279, Text: And then finding that it made an error and apologized for the error, that GPT-4 generated. Which has this kind of interesting loop, which is the articles are used to write Wikipedia pages, GPT is trained on Wikipedia, and there there’s like this interesting loop where the weasel words and the nuances can get lost or can propagate, even though they’re not grounded in reality. Somehow in the generation of the language model, new truths can be created and kind of linger.
Segment 4035: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2315, Text: Yeah, there’s a famous web comic that’s titled cytogenesis, which is about how an errors in Wikipedia and there’s no source for it, but then a lazy journalist reads it and writes the source, and then some helpful Wikipedia spots that it has no source, finds a source and adds it to Wikipedia, and voila, magic. This happened to me once it, well, it nearly happened. There was this, it was really brief. I went back and researched it, I’m like, this is really odd. So Biography Magazine, which is a magazine published by the Biography TV channel, had a pressor profile of me, and it said, “In his spare time,” I’m not quoting exactly, it’s been many years, but, “In his spare time he enjoys playing chess with friends.” I thought, wow, that sounds great. I would like to be that guy. But actually, I play chess with my kids sometimes, but no it’s not a hobby of mine.
Segment 4036: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2371, Text: And I was like, where did they get that? And I contacted the magazine and said, where did that come from? They said, “Oh, it was in Wikipedia.” And I looked in the history, there had been vandalism of Wikipedia, which was not damaging, it’s just false. And it had already been removed. But then I thought, “Oh gosh, well I better mention this to people because otherwise it’s somebody’s going to read that and they’re going to add it, the entry, and is going to take on a life of its own. And then sometimes I wonder if it has, because I’ve been… I was invited a few years ago to do the ceremonial first move in the world chess championship. And I thought, I wonder if they think I’m a really big chess enthusiast because they read this Biography Magazine article.
Segment 4037: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2410, Text: But that problem, when we think about large language models and the ability to quickly generate very plausible but not true content, I think is something that there’s going to be a lot of shakeout and a lot of implications of that.
Segment 4038: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2425, Text: What would be hilarious is because of the social pressure of Wikipedia and the momentum, you would actually start playing a lot more chess. Not only the articles are written based on Wikipedia, but your own life trajectory changes because of the Wikipedia, just to make it more convenient. Aspire to.
Segment 4039: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2445, Text: Aspire to, yes. Yeah, aspirational.
Segment 4040: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2448, Text: If we could just talk about that before we jump back to some other interesting topics in Wikipedia. Let’s talk about GPT-4 and large language models. So they are in part trained on Wikipedia content. What are the pros and cons of these language models? What are your thoughts?
Segment 4041: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2467, Text: Yeah, so I mean, there’s a lot of stuff going on. Obviously the technology has moved very quickly in the last six months and looks poised to do so for some time to come. So first things first, part of our philosophy is the open licensing, the free licensing, the idea that this is what we’re here for. We are a volunteer community and we write this encyclopedia. We give it to the world to do what you like with, you can modify it, redistribute it, redistribute modified versions, commercially, non-commercially. This is the licensing. So in that sense, of course it’s completely fine. Now, we do worry a bit about attribution because it is a Creative Commons Attribution Share-Alike License. So attribution is important, not just because of our licensing model and things like that, but it’s just proper attribution is just good intellectual practice.
Segment 4042: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2522, Text: And that’s a really hard complicated question. If I were to write something about my visit here, I might say in a blog post I was in Austin, which is a city in Texas, I’m not going to put a source for Austin as a city in Texas. That’s just general knowledge. I learned it somewhere, I can’t tell you where. So you don’t have to cite and reference every single thing. But if I actually did research and I used something very heavily, it’s just proper, morally proper, to give your sources. So we would like to see that. And obviously they call it grounding. So particularly people at Google are really keen on figuring out grounding.
Segment 4043: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2568, Text: It’s such a cool term. So any text that’s generated trying to ground it to the Wikipedia quality-
Segment 4044: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2577, Text: A source.
Segment 4045: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2577, Text: … a source. The same kind of standard of what a source means that Wikipedia uses, the same kind of source-
Segment 4046: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2577, Text: The same kind.
Segment 4047: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2577, Text: … would be generated but with a graph.
Segment 4048: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2585, Text: The same kind of thing. And of course, one of the biggest flaws in ChatGPT right now is that it just literally will make things up just to be amiable. I think it’s programmed to be very helpful and amiable and it doesn’t really know or care about the truth.
Segment 4049: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2601, Text: Can get bullied into… it can be convinced into…
Segment 4050: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2605, Text: Well, but this morning, the story I was telling earlier about comparing a football player to a Lamborghini, and I thought, is that really racial? I don’t know, but I’m mulling it over. And I thought, oh, I’m going to go to ChatGPT. So I sent to ChatGPT-4, I said, “This happened in Wikipedia. Can you think of examples where a white athlete has been compared to a fast car inanimate object?” And it comes back with a very plausible essay where it tells why these analogies are common in sport, blah, blah. I said, “No, no, could you give me some specific examples?” So it gives me three specific examples, very plausible, correct names of athletes and contemporaries and all of that could have been true. Googled every single quote and none of them existed. And so I’m like, “Well, that’s really not good.”
Segment 4051: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2654, Text: I wanted to explore a thought process I was in. First I thought, how do I Google? And it’s like, well, it’s kind of a hard thing to Google because unless somebody’s written about this specific topic, it’s large language model, it’s processed all this data, it can probably piece that together for me, but it just can’t yet. So I think, I hope that ChatGPT 5, 6, 7, three to five years, I’m hoping we’ll see a much higher level of accuracy where when you ask a question like that, I think instead of being quite so eager to please by giving you a plausible sounding answer, it’s just like, I don’t know.
Segment 4052: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2695, Text: Or maybe display how much bullshit might be in this generated text. I’m really would like to make you happy right now, but I’m really stretched thin with this generation.
Segment 4053: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2707, Text: Well, it’s one of the things I’ve said for a long time. So in Wikipedia, one of the great things we do may not be great for our reputation, except in a deeper sense for the long term I think it is. But we’ll all be on notice that says the neutrality of this section has been disputed or the following section doesn’t cite in these sources. And I always joke, sometimes I wish the New York Times would run a banner saying the neutrality of this has been disputed. They could give us a… We had a big fight in the newsroom as to whether to run this or not, but we thought it’s important enough to bring it to. But just be aware that not all the journalists are on board with it. Ah, that’s actually interesting, and that’s fine. I would trust them more for that level of transparency. So yeah, similarly ChatGPT should say, yeah, 87% bullshit.
Segment 4054: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2751, Text: Well, the neutrality one is really interesting because that’s basically a summary of the discussions that are going on underneath. It would be amazing if… I should be honest, I don’t look at the talk page often. It would be nice somehow if there was a kind of summary in this banner way of like, this, lots of wars have been fought on this here land for this here paragraph.
Segment 4055: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2776, Text: That’s really interesting, I hadn’t thought of that. Because one of the things I do spend a lot of time thinking about these days, and people have found it, we’re moving slowly, but we are moving. Thinking about, okay, these tools exist, are there ways that this stuff can be useful to our community? Because a part of it is we do approach things in a non-commercial way, in a really deep sense. It’s like it’s been great, that Wikipedia has become very popular, but really we’re a community whose hobby is writing an encyclopedia. That’s first, and if it’s popular, great. If it’s not okay, we might have trouble paying for more servers, but it’ll be fine.
Segment 4056: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2813, Text: And so how do we help the community use these tools? One of the ways that these tools can support people, and one example I never thought about, I’m going to start playing with it, is feed in the article and feed in the talk page and say, can you suggest some warnings in the article based on the conversations in the talk page? I think it might-
Segment 4057: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2813, Text: That’s brilliant.
Segment 4058: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2832, Text: … be good at that. It might get it wrong sometimes. But again, if it’s reasonably successful at doing that, and you can say, oh, actually, yeah, it does suggest the neutrality of this has been disputed on a section that has a seven-page discussion in the back that might be useful, don’t know, worth playing with.
Segment 4059: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2850, Text: Yeah, I mean some more color to the, not neutrality, but also the amount of emotion laden in the exploration of this particular part of the topic. It might actually help you look at more controversial pages, like on a page on the war in Ukraine or a page on Israel and Palestine. There could be parts that everyone agrees on and there’s parts that are just like-
Segment 4060: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2878, Text: Tough.
Segment 4061: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2879, Text: … tough.
Segment 4062: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2879, Text: The hard parts.
Segment 4063: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2880, Text: It would be nice to, when looking at those beautiful long articles to know, all right, let me just take in some stuff where everybody agrees on.
Segment 4064: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2889, Text: I could give an example that I haven’t looked at in a long time, but I was really pleased with what I saw at the time. So the discussion was that they’re building something in Israel and for their own political reasons, one side calls it a wall hearkening back to Berlin Wall, apartheid, the other calls it a security fence. So we can understand quite quickly if we give it a moment’s thought like, okay, I understand why people would have this grappling over the language. Like, okay, you want to highlight the negative aspects of this and you want to highlight the positive aspects, so you’re going to try and choose a different name. And so there was this really fantastic Wikipedia discussion on the talk page. How do we word that paragraph to talk about the different naming? It’s called this by Israeli, it’s called this by Palestinians. And how you explain that to people could be quite charged. You could easily explain, oh, there’s this difference and it’s because this side’s good and this side’s bad and that’s why there’s a difference. Or you could say, actually, let’s just try and really stay as neutral as we can and try to explain the reasons. So you may come away from it with a concept. Oh, okay, I understand what this debate is about now.
Segment 4065: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2966, Text: And just the term Israel- Palestine conflict is still the title of a page in Wikipedia, but the word conflict is something that is a charged word.
Segment 4066: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2981, Text: Of course.
Segment 4067: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=2982, Text: Because from the Palestinian side or from certain sides, the word conflict doesn’t accurately describe the situation. Because if you see it as a genocide one way, genocide is not a conflict because to people that discuss the challenge, the word conflict, they see conflict is when there’s two equally powerful sides fighting.
Segment 4068: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3005, Text: Sure, yeah, yeah. No, it’s hard. And in a number of cases, so this actually speaks to a slightly broader phenomenon, which is there are a number of cases where there is no one word that can get consensus. And in the body of an article, that’s usually okay, because we can explain the whole thing. You can come away with an understanding of why each side wants to use a certain word, but there are some aspects, like the page has to have a title, so there’s that. Same thing with certain things like photos. It’s like, well, there’s different photos, which one’s best? Lot of different views on that. But at the end of the day, you need the lead photo because there’s one slot for a lead photo. Categories is another one. So at one point, I have no idea if it’s in there today, but I don’t think so. I was listed in American entrepreneurs fine.
Segment 4069: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3063, Text: American atheist, and I said, that doesn’t feel right to me, just personally it’s true. I mean, wouldn’t disagree with the objective fact of it, but when you click the category and you see a lot of people who are, you might say American atheist activist because that’s their big issue. So Madalyne Murray O’Hair or various famous people who… Richard Dawkins, who make it a big part of their public argument and persona. But that’s not true of me. It’s just my private personal belief, it doesn’t really… it’s not something I campaign about. So it felt weird to put me in the category, but what category would you put? And do you need that? In this case I argued that doesn’t need that. I don’t speak about it publicly, except incidentally, from time to time, I don’t campaign about it. So it’s weird to put me with this group of people.
Segment 4070: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3114, Text: And that argument carried the day, I hope not just because it was me. But categories can be like that where you’re either in the category or you’re not. And sometimes it’s a lot more complicated than that. And is it, again, we go back to, is it undue weight? If someone who is now prominent in public life and generally considered to be a good person was convicted of something, let’s say DUI when they were young, we normally in normal discourse, we don’t think, oh, this person should be in the category of American criminals because you think, oh, a criminal. Yeah, technically speaking, it’s against the law to drive under the influence of alcohol and you were arrested and you spent a month in prison or whatever. But it’s odd to say that’s a criminal.
Segment 4071: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3165, Text: So just as an example in this area is Mark Wahlberg, Marky Mark is what I always think of him as, because that was his first sort of famous name, who I wouldn’t think should be listed as in the category, American criminal. Even though he did, he was convicted of quite a bad crime when he was a young person, but we don’t think of him as a criminal. Should the entry talk about that? Yeah, it’s actually an important part of his life story that he had a very rough youth and he could have gone down a really dark path and he turned his life around. That’s actually interesting. So categories are tricky.
Segment 4072: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3200, Text: Especially with people because we like to assign labels to people into ideas somehow, and those labels stick. And there’s certain words that have a lot of power, like criminal, like political left, right, center, anarchist, objectivist. What other philosophies are there? Marxist, communist, social democrat, democratic socialist, socialist, and if you add that as a category, all of a sudden it’s like, oh boy, you’re that guy now. And I don’t know if you want to be that guy.
Segment 4073: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3238, Text: Well, there’s definitely some really charged ones like alt-right, I think it’s quite complicated and tough. It’s not completely meaningless label, but boy, I think you really have to pause before you actually put that label on someone, partly because now you’re putting them in a group of people, some of whom are quite, you wouldn’t want to be grouped with.
Segment 4074: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3260, Text: Let’s go into some, you mentioned the hot water of the pool that we’re both tipping a toe in. Do you think Wikipedia has a left leaning political bias, which is something it is sometimes accused of?
Segment 4075: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3271, Text: Yeah, so I don’t think so, not broadly. And I think you can always point to specific entries and talk about specific biases, but that’s part of the process of Wikipedia. Anyone can come and challenge and to go on about that. But I see fairly often on Twitter, some quite extreme accusations of bias. And I think actually I don’t see it. I don’t buy that. And if you ask people for an example, they normally struggle and depending on who they are and what it’s about. So it’s certainly true that some people who have quite fringe viewpoints and who knows the full rush of history in 500 years, they might be considered to be pathbreaking geniuses. But at the moment, quite fringe views. And they’re just unhappy that Wikipedia doesn’t report on their fringe views as being mainstream. And that, by the way, goes across all kinds of fields.
Segment 4076: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3336, Text: I was once accosted on the street outside the TED Conference in Vancouver by a guy who was a homeopath who was very upset that Wikipedia’s entry on homeopathy basically says it’s pseudoscience. And he felt that was biased. And I said, “Well, I can’t really help you because we cite good quality sources to talk about the scientific status, and it’s not very good.” So it depends, and I think it’s something that we should always be vigilant about. But in general, I think we’re pretty good. And I think any time you go to any serious political controversy, we should have a pretty balanced perspective on whose saying what and what the views are and so forth. I would actually argue that the areas where we are more likely to have bias that persists for a long period of time are actually fairly obscure things, or maybe fairly non-political things.
Segment 4077: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3400, Text: I just give, it’s kind of a humorous example, but it’s meaningful. If you read our entries about Japanese anime, they tend to be very, very positive and very favorable because almost no one knows about Japanese anime except for fans. And so the people who come and spend their days writing Japanese anime articles, they love it. They kind of have an inherent love for the whole area. Now they’ll of course, being human beings, they have their internal debates and disputes about what’s better or not. But in general, they’re quite positive because nobody actually cares. On anything that people are quite passionate about, then hopefully there’s quite a lot of interesting stuff.
Segment 4078: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3440, Text: So I’ll give an example, a contemporary example where I think we’ve done a good job as of my most recent sort of look at it, and that is the question about the efficacy of masks during the COVID pandemic. And that’s an area where I would say the public authorities really jerked us all around a bit. In the very first days, they said, “Whatever you do, don’t rush on and buy masks.” And their concern was shortages in hospitals, fair enough. Later it’s like, no, everybody’s got to wear a mask everywhere. It really works really well. And then now I think it’s, the evidence is mixed, right? Masks seem to help, in my personal view, masks seem to help. They’re no huge burden. You might as well wear a mask in any environment where you’re with a giant crowd of people and so forth.
Segment 4079: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3493, Text: But it’s very politicized, that one, and it’s very politicized, where certainly in the US, much more so. I live in the UK, I live in London, I’ve never seen on the streets the kind of the thing that there’s a lot of reports of people actively angry because someone else is wearing a mask, that sort of thing in public. So because it became very politicized, then clearly if Wikipedia… No, so anyway, if you go to Wikipedia and you research this topic, I think you’ll find more or less what I’ve just said. Oh, actually after it’s all to this point in history, it’s mixed evidence like masks seemed to help, but maybe not as much as some of the authorities said. And here we are.
Segment 4080: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3536, Text: And that’s kind of an example where I think, okay, we’ve done a good job, but I suspect there are people on both sides of that very emotional debate who think, this is ridiculous. Hopefully we’ve got quality sources. So then hopefully those people who read this can say, oh, actually it is complicated. If you can get to the point of saying, okay, I have my view, but I understand other views and I do think it’s a complicated question, great, now we’re a little bit more mature as a society.
Segment 4081: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3564, Text: Well, that one is an interesting one because I feel like I hope that that article also contains the meta conversation about the politicization of that topic. To me, it’s almost more interesting than whether masks work or not, at least at this point. It’s like why masks became a symbol of the oppression of a centralized government. If you wear them, you’re a sheep that follows the mask control the mass hysteria of an authoritarian regime. And if you don’t wear a mask, then you are a science denier, anti- vaxxer, an alt-right, probably a Nazi.
Segment 4082: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3607, Text: Exactly. And that whole politicization of society is just so damaging, and I don’t know, in the broader world, how do we start to fix that? That’s a really hard question.
Segment 4083: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3621, Text: Well, at every moment, because you mentioned mainstream and fringe, there seems to be a tension here, and I wonder what your philosophy is on it because there’s mainstream ideas and there’s fringe ideas. You look at lab leak theory for this virus. That could be other things we can discuss where there’s a mainstream narrative where if you just look at the percent of the population or the population with platforms, what they say, and then what is a small percentage in opposition to that, and what is Wikipedia’s responsibility to accurately represent both the mainstream and the fringe, do you think?
Segment 4084: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3665, Text: Well, I think we have to try to do our best to recognize both, but also to appropriately contextualize. And so this can be quite hard, particularly when emotions are high. That’s just a fact about human beings. I’ll give a simpler example, because there’s not a lot of emotion around it. Like our entry on the moon doesn’t say, some say the moon’s made of rocks, some say cheese, who knows? That kind of false neutrality is not what we want to get to. That doesn’t make any sense, but that one’s easy. We all understand. I think there is a Wikipedia entry called something like the moon is made of cheese, where it talks about this is a common sort of joke or thing that children say or that people tell to children or whatever. It’s just a thing. Everyone’s heard moon’s made of cheese, but nobody thinks, wow, Wikipedia is so one-sided it doesn’t even acknowledge the cheese theory. I say the same thing about flat Earth, again, very-
Segment 4085: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3728, Text: That’s exactly what I’m looking up right now.
Segment 4086: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3729, Text: … very little controversy. We will have an entry about flat Earth, theorizing, flat Earth people. My personal view is most of the people who claim to be flat earthers are just having a laugh, trolling and more power to them, have some fun, but let’s not be ridiculous.
Segment 4087: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3751, Text: Then of course, for mostly human history, people believe that the Earth is flat, so the article I’m looking at is actually kind of focusing on this history. Flat Earth is an archaic and scientifically disproven conception of the Earth’s shape as a plain or disc, meaning ancient cultures subscribe to a flat Earth cosmography with pretty cool pictures of what a flat Earth would look like, with dragon, is that a dragon no angels on the edge. There’s a lot of controversy about that. What is it the edge? Is it the wall? Is it angels, is it dragons, is there a dome?
Segment 4088: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3780, Text: And how can you fly from South Africa to Perth? Because on a flat Earth view, that’s really too far for any plane to make it because-
Segment 4089: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3789, Text: What I want to know-
Segment 4090: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3790, Text: It’s all spread out.
Segment 4091: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3791, Text: What I want to know is what’s on the other side, Jimmy, what’s on the other side? That’s what all of us want to know. So I presume there’s probably a small section about the conspiracy theory of flat Earth, because I think there’s a sizeable percent of the population who at least will say they believe in a flat Earth.
Segment 4092: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3811, Text: Yeah.
Segment 4093: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3812, Text: I think it is a movement that just says that the mainstream narrative to have distrust and skepticism about the mainstream narrative, which to a very small degree, is probably a very productive thing to do as part of the scientific process. But you can get a little silly and ridiculous with it.
Segment 4094: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3829, Text: Yeah, I mean it’s exactly right. And so I think I find on many, many cases, and of course I, like anybody else, might quibble about this or that in any Wikipedia article, but in general, I think there is a pretty good sort of willingness and indeed eagerness to say, oh, let’s fairly represent all of the meaningfully important sides. So there’s still a lot to unpack in that, right? So meaningfully important. So people who are raising questions about the efficacy of masks, okay, that’s actually a reasonable thing to have a discussion about, and hopefully we should treat that as a fair conversation to have and actually address which authorities have said what and so on and so forth. And then there are other cases where it’s not meaningful opposition, you just wouldn’t say. I doubt if the main article Moon, it may mention cheese, probably not even because it’s not credible and it’s not even meant to be serious by anyone, or the article on the Earth certainly won’t have a paragraph that says, well, most scientists think it’s round, but certain people think flat.
Segment 4095: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3912, Text: That’s just a silly thing to put in that article. You would want to sort of address that’s an interesting cultural phenomenon. You want to put it somewhere. So this goes into all kinds of things about politics. You want to be really careful, really thoughtful about not getting caught up in the anger of our times and really recognize. Yes, I always thought… I remember being really kind of proud of the US at the time when it was McCain was running against Obama because I thought, “Oh, I’ve got plenty of disagreements with both of them, but they both seem like thoughtful and interesting people who I would have different disagreements with.” But I always felt like, yeah, that that’s good, now we can have a debate. Now we can have an interesting debate. And it isn’t just people slamming each other, personal attacks and so forth.
Segment 4096: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3960, Text: It isn’t just people slamming each other with personal attacks and so forth.
Segment 4097: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3965, Text: You’re saying Wikipedia has also represented that?
Segment 4098: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3969, Text: I hope so. Yeah, and I think so in the main. Obviously, you can always find debate that went horribly wrong because there’s humans involved.
Segment 4099: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=3978, Text: But speaking of those humans, I would venture to guess, I don’t know the data, maybe you can let me know, but the personal political leaning of the group of people who had a Wikipedia probably leans left, I would guess. To me, the question there is, I mean the same is true for Silicon Valley, the task for Silicon Valley is to create platforms that are not politically biased even though there is a bias for the engineers who create it. I believe it’s possible to do that. There’s conspiracy theories that it somehow is impossible, and there’s this whole conspiracy where the left is controlling it, and so on. I think engineers, for the most part, want to create platforms that are open and unbiased that create all kinds of perspective because that’s super exciting to have all kinds of perspectives battle it out, but still is there a degree to which the personal political bias of the editors might seep in in silly ways and in big ways?
Segment 4100: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4042, Text: Silly ways could be, I think, hopefully I’m correct in saying this, but the right will call it the Democrat Party and the left will call it the Democratic Party, right? It always hits my ear weird. Are we children here? We’re literally taking words and just jabbing at each other. Yeah, I could capitalize a thing in a certain way, or I can just take a word and mess with them. That’s a small way of how you use words, but you can also have a bigger way about beliefs, about various perspectives on political events, on Hunter Biden’s laptop, on how big of a story that is or not, how big the censorship of that story is or not, and then there’s these camps to take very strong points and they construct big narratives around that. It’s a very sizable percent of the population believes the two narratives that compete with each other.
Segment 4101: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4101, Text: Yeah. It’s really interesting and it’s hard to judge the sweep of history within your own lifetime, but it feels like it’s gotten much worse, that this idea of two parallel universes where people can agree on certain basic facts feels worse than it used to be. I’m not sure if that’s true or if it just feels that way, but I’m not sure what the causes are. I think I would lay a lot of the blame in recent years on social media algorithms, which reward clickbait headlines, which reward tweets that go viral, and they go viral because they’re cute and clever.
Segment 4102: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4153, Text: My most successful tweet ever by a fairly wide margin, some reporter tweeted at Elon Musk because he was complaining about Wikipedia or something, “You should buy Wikipedia,” and I just wrote, “Bot for sale,” and 90 zillion retweets, and people liked it, and it was all very good, but I’m like, “You know what? It’s cute line and it’s a good mic drop,” and all that, and I was pleased with myself. I’m like, “It’s not really a discourse.” It’s not really what I like to do, but it’s what social media really rewards, which is kind of a let’s you and him have a fight, and that’s more interesting. It’s funny because at the time, I was texting with Elon who’s very pleasant to me, and all of that.
Segment 4103: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4201, Text: He might have been a little bit shitty, the reporter might have been a little bit shitty, but you fed into the shitty with a snarky funny of response, “Not for sale,” and where do you… That’s a funny little exchange, and you can probably after that laugh it off and it’s fun, but that kind of mechanism that rewards the snark can go into viciousness.
Segment 4104: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4222, Text: Yeah. Well, and we certainly see it online. A series of tweets, sort of a tweet thread of 15 tweets that assesses the quality of the evidence for masks, pros and cons, and sort of wear this, that’s not going to go viral, but a SmackDown for a famous politician who was famously in favor of mask, who also went to a dinner and didn’t wear a mask, that’s going to go viral, and that’s partly human nature. People love to call out hypocrisy and all of that, but it’s partly what these systems elevate automatically. I talk about this with respect to Facebook, for example. I think Facebook has done a pretty good job, although it’s taken longer than it should in some cases, but if you have a very large following and you’re really spouting hatred or misinformation, disinformation, they’ve kicked people off.
Segment 4105: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4284, Text: They’ve done some reasonable things there, but actually, the deeper issue of the anger we’re talking about, of the contentiousness of everything, I make of a family example with two great stereotypes. One, the crackpot racist uncle, and one, the sweet grandma. I always want to point out all of my uncles in my family were wonderful people, so I didn’t have a crackpot racist, but everybody knows the stereotype. Well, so grandma, she just posts sweet comments on the kids’ pictures and congratulates people on their wedding anniversary, and crackpot uncle’s posting his nonsense. Normally, it’s at Christmas dinner, everybody rolls their eyes, “Oh, yeah, Uncle Frank’s here, and he is probably going to say some racist comment and we’re going to tell him to shut up, or maybe let’s not invite him this year.” Normal human drama. He’s got his three mates down at the pub who listen to him and all of that, but now grandma’s got 54 followers on Facebook, which is the intimate family, and racist uncle has 714, so he’s not a massive influence or whatever, but how did that happen?
Segment 4106: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4356, Text: It’s because the algorithm notices when she posts, nothing happens. He posts and then everybody jumps in to go, “God, shut up, Uncle Frank. That’s outrageous,” and there’s engagement, there’s page views, there’s ads. Those algorithms, I think they’re working to improve that, but it’s really hard for them. It’s hard to improve that if that actually is working. If the people who are saying things that get engagement, if it’s not too awful, but it’s just, maybe it’s not a racist uncle, but maybe it’s an uncle who posts a lot about what an idiot Biden is, which isn’t necessarily an offensive or blockable or bannable thing, and it shouldn’t be, but if that’s the discourse that gets elevated because it gets a rise out of people, then suddenly in a society, it’s like, “Oh, we get more of what we reward,” so I think that’s a piece of what’s gone on.
Segment 4107: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4408, Text: Well, if we could just take that tangent. I’m having a conversation with Mark Zuckerberg second time. Is there something you can comment on how to decrease toxicity on that particular platform, Facebook? You also have worked on creating a social network that is less toxic yourself, so can we just talk about the different ideas that these already big social network can do and what you have been trying to do?
Segment 4108: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4435, Text: A piece of it is it’s hard. The problem with making a recommendation to Facebook is that I actually believe their business model makes it really hard for them, and I’m not anti-capitalism, I’m not, “Great. Somebody’s got business, they’re making money,” that’s not where I come from, but certain business models mean you are going to prioritize things that maybe aren’t longterm healthful, and so that’s a big piece of it. Certainly, for Facebook, you could say with vast resources, start to prioritize content that’s higher quality, that’s healing, that’s kind. Try not to prioritize content that seems to be just getting a rise out of people. Now, those are vague human descriptions, but I do believe good machine running algorithms, you can optimize in slightly different ways, but to do that, you may have to say, “Actually, we’re not necessarily going to increase page views to the maximum extent right now.”
Segment 4109: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4499, Text: I’ve said this to people at Facebook. It’s like if your actions are convincing people that you’re breaking Western civilization, that’s a really bad for business in the long run. Certainly, these days, I’ll say, Twitter is the thing that’s on people’s minds as being more upsetting at the moment, but I think it’s true. One of the things that’s really interesting about Facebook compared to a lot of companies is that Mark has a pretty unprecedented amount of power. His ability to name members of the board, his control of the company is pretty hard to break even if financial results aren’t as good as they could be because he’s taken a step back from the perfect optimization to say, “Actually, for the longterm health in the next 50 years of this organization, we need to reign in some of the things that are working for us in making money because they’re actually giving us a bad reputation.” One of the recommendations I would say is, and this is not to do with the algorithms and all that, but how about just a moratorium on all political advertising?
Segment 4110: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4571, Text: I don’t think it’s their most profitable segment, but it’s given rise to a lot of deep, hard questions about dark money, about ads that are run by questionable people that push false narratives, or the classic kind of thing is you run… I saw a study about Brexit in the UK where people were talking about there were ads run to animal rights activists saying, “Finally, when we’re out from under Europe, the UK can pass proper animal rights legislation. We’re not constrained by the European process.” Similarly, for people who are advocates of fox hunting to say, “Finally, when we’re out of Europe, we can re-implement…” You’re telling people what they want to hear, and in some cases, it’s really hard for journalists to see that, so it used to be that for political advertising, you really needed to find some kind of mainstream narrative, and this is still true to an extent, mainstream narrative that 60% of people can say, “Oh, I can buy into that,” which meant it pushed you to the center.
Segment 4111: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4640, Text: It pushed you to try and find some nuance balance, but if your main method of recruiting people is a tiny little one-on-one conversation with them, because you’re able to target using targeted advertising, suddenly you don’t need consistent. You just need a really good targeting operation, really good Cambridge analytic style machine learning algorithm data to convince people. That just feels really problematic, so until they can think about how to solve that problem, I would just say, “You know what? It’s going to cost us X amount,” but it’s going to be worth it to kind of say, “You know what? We actually think our political advertising policy hasn’t really helped contribute to discourse and dialogue in finding reasoned middle ground and compromise solutions, so let’s just not do that for a while until we figure that out,” so that’s maybe a piece of advice.
Segment 4112: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4695, Text: Coupled with, as you were saying, recommender systems for the newsfeed and other contexts that don’t always optimize engagement, but optimize the long term mental wellbeing and balance and growth of a human being, but it’s a very difficult problem.
Segment 4113: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4713, Text: It’s a difficult problem. Yeah. With WT Social, WikiTribune Social, we’re launching in a few months time a completely new system, new domain, and new lots of things, but the idea is to say let’s focus on trust. People can rate each other as trustworthy, rate content as trustworthy. You have to start from somewhere so it’ll start with a core base of our tiny community who, I think, are sensible, thoughtful people, want to recruit more, but to say, “You know what? Actually, let’s have that as a pretty strong element,” to say let’s not optimize based on what gets the most paid views in this session, let’s optimize on what the feedback from people is, this is meaningfully enhancing my life. Part of that is, and it’s probably not a good business model, but part of that is say, “Okay, we’re not going to pursue an advertising business model, but a membership model where you don’t have to be a member, but you can pay to be a member.”
Segment 4114: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4776, Text: You maybe get some benefit from that, but in general, to say, actually the problem with… Actually, the division I would say is, and the analogy I would give is broadcast television funded by advertising gives you a different result than paying for HBO, paying for Netflix, paying for whatever. The reason is, if you think about it, what is your incentive as a TV producer? You’re going to make a comedy for ABC Network in the US, you basically say, “I want something that almost everybody will like and listen to,” so it tends to be a little blander, family-friendly, whatever. Whereas if you say, “Oh, actually,” I’m not going to use the HBO example, and an old example, you say, “You know what? Sopranos isn’t for everybody, Sex and the City isn’t for everybody, but between the two shows, we’ve got something for everybody that they’re willing to pay for,” so you can get edgier, higher quality in my own view content rather than saying it’s got to not offend anybody in the world. It’s got to be for everybody, which is really hard.
Segment 4115: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4847, Text: Same thing here in a social network. If your business model is advertising, it’s going to drive you in one direction. If your business model is membership, I think it drives you in a different direction. Actually, and I’ve said this to Elon about Twitter Blue, which I think wasn’t rolled out well and so forth, but the piece of that that I like is to say, look, actually, if there’s a model where your revenue is coming from people who are willing to pay for the service, even if it’s only part of your revenue, if it’s a substantial part, that does change your broader incentives to say, actually, are people going to be willing to pay for something that’s actually just toxicity in their lives? Now, I’m not sure it’s been rolled out well, I’m not sure how it’s going, and maybe I’m wrong about that as a plausible business model, but I do think it’s interesting to think about, just in broad terms, business model drives outcomes in sometimes surprising ways unless you really pause to think about it.
Segment 4116: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4906, Text: If we can just link on Twitter and Elon before… I would love to talk to you about the underlying business model, Wikipedia, which is this brilliant, bold move at the very beginning, but since you mentioned Twitter, what do you think works? What do you think is broken about Twitter?
Segment 4117: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4923, Text: It’s a long conversation, but to start with, one of the things that I always say is it’s a really hard problem, so I concede that right up front. I said this about the old ownership of Twitter and the new ownership of Twitter because unlike Wikipedia, and this is true actually for all social media, there’s a box, and the box basically says, “What do you think? What’s on your mind?” You can write whatever the hell you want, right? This is true, by the way, even for YouTube. I mean the box is to upload a video, but again, it’s just an open-ended invitation to express yourself.
Segment 4118: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4958, Text: What makes that hard is some people have really toxic, really bad, some people are very aggressive, they’re actually stalking, they’re actually abusive, and suddenly, you deal with a lot of problems. Whereas at Wikipedia, there is no box that says, “What’s on your mind?” There’s a box that says, “This is an entry about the moon. Please be neutral. Please set your facts.” Then there’s a talk page which is not coming rant about Donald Trump. If you go on the talk page of the Donald Trump entry and you just start ranting about Donald Trump, people would say, “What are you doing? Stop doing that. We’re not here to discuss. There’s a whole world of the internet out there for you to go and rant about Donald Trump.”
Segment 4119: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=4997, Text: It’s just not fun to do on Wikipedia as somehow as fun on Twitter.
Segment 4120: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5000, Text: Well, also on Wikipedia, people are going to say, “Stop,” and, “Actually, are you here to tell us how can we improve the article or are you just here to rant about Trump? Because that’s not actually interesting.” Because the goal is different, so that’s just admitting and saying upfront, this is a hard problem. Certainly, I’m writing a book on trust. The idea is, in the last 20 years, we’ve lost trust in all kinds of institutions, in politics. The Edelman Trust Barometer Survey has been done for a long time, and trust in politicians, trust in journalism, it’s come declined substantially, and I think in many cases, deservedly, so how do we restore trust and how do we think about that?
Segment 4121: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5047, Text: Does that also include trust in the idea of truth?
Segment 4122: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5053, Text: Trust in the idea of truth. Even the concept of facts and truth is really, really important, and the idea of uncomfortable truths is really important. When we look at Twitter and we can see, okay, this is really hard, so here’s my story about Twitter. It’s a two-part story, and it’s all pre Elon Musk ownership. Many years back, somebody accused me of horrible crimes on Twitter, and like anybody would, I was like… I’m in the public eye. People say bad things. I don’t really… I brush it off, whatever, but I’m like, “This is actually really bad.” Accusing me of pedophilia? That’s just not okay, so I thought, “I’m going to report this,” so I click report, and I report the tweet and there’s five others, and I report, and I go through the process, and then I get an email that says whatever, a couple of hours later saying, “Thank you for your report. We’re looking into this.” Great. Okay, good.
Segment 4123: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5116, Text: Then several hours further, I get an email back saying, “Sorry, we don’t see anything here to violate our terms of use,” and I’m like, “Okay,” so I emailed Jack and I say, “Jack, come on. This is ridiculous,” and he emails back roughly saying, “Yeah, sorry, Jimmy. Don’t worry. We’ll sort this out.” I just thought to myself, “You know what? That’s not the point. I’m Jimmy Wales, I know Jack Dorsey. I can email Jack Dorsey. He’ll listen to me because he’s got an email from me and sorts it out for me.” What about the teenager who’s being bullied and is getting abuse and getting accusations that aren’t true? Are they getting the same kind of really poor result in that case? Fast-forward a few years, same thing happens. The exact quote, it goes, “Please help me. I’m only 10 years old, and Jimmy Wales raped me last week.” I was like, “Come on. Fuck off. That’s ridiculous,” so I report. I’m like, “This time I’m reporting,” but I’m thinking, “Well, we’ll see what happens.”
Segment 4124: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5175, Text: This one gets even worse because then I get a same result email back saying, “Sorry, we don’t see any problems,” so I raised it with other members of the board who I know, and Jack, and like, “This is really ridiculous. This is outrageous,” and some of the board members, friends of mine, sympathetic, and so good for them, but I actually got an email back then from the general counsel head of trust and safety saying, “Actually, there’s nothing in this tweet that violates our terms of service. We don’t regard and gave reference to the Me Too Movement. If we didn’t allow accusations, the Me Too Movement, it’s an important thing,” and I was like, “You know what? Actually, if someone says, ‘I’m 10 years old and someone raped me last week,’ I think the advice should be, ‘Here’s the phone number of the police.’ You need to get the police involved. Twitter’s not the place for that accusation.”
Segment 4125: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5225, Text: Even back then… By the way, they did delete those tweets, but the rationale they gave is spammy behavior, so completely separate from abusing me. It was just like, “Oh, well, they were retweeting too often.” Okay, whatever. That’s just broken. That’s a system that it’s not working for people in the public eye. I’m sure it’s not working for private people who get abuse. Really horrible abuse can happen. How is that today? Well, it hasn’t happened to me since Elon took over, but I don’t see why it couldn’t, and I suspect now if I send a report and email someone, there’s no one there to email me back because he’s gotten rid of a lot of the trust and safety staff, so I suspect that problem is still really hard.
Segment 4126: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5266, Text: Just content moderation at huge scales.
Segment 4127: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5269, Text: At huge scales is really something. I don’t know the full answer to this. A piece of it could be to say, “Actually, making specific allegations of crimes, this isn’t the place to do that. We’ve got a huge database. If you’ve got an accusation of crime, here’s who should call, the police, the FBI, whatever it is. It’s not to be done in public,” and then you do face really complicated questions about Me Too Movement and people coming forward in public and all of that, but again, it’s like probably you should talk to a journalist. Probably there are better avenues than just tweeting from an account that was created 10 days ago, obviously set up to abuse someone. I think they could do a lot better, but I also admit it’s a hard problem.
Segment 4128: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5318, Text: There’s also ways to indirectly or more humorously or a more mocking way to make the same kinds of accusations. In fact, the accusations you mentioned, if I were to guess, don’t go that viral because they’re not funny enough or cutting enough, but if you make it witty and cutting and meme it somehow, sometimes actually indirectly making an accusation versus directly making an accusation, that can go viral and that can destroy reputations, and you get to watch yourself. Just all kinds of narratives take hold.
Segment 4129: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5349, Text: Yeah, no, I remember another case that didn’t bother me because it wasn’t of that nature, but somebody was saying, “I’m sure you’re making millions off of Wikipedia,” and I’m like, “No, actually, I don’t even work there. I have no salary,” and they’re like, “You’re lying. I’m going to check your 990 form,” which is the US form for tax reporting for charities, and I was like, “Yeah, here’s the link. Go read it and you’ll see I’m listed as a board member, and my salary is listed as zero.” Things like that, it’s like, “Okay.” That one, that feels like you’re wrong, but I can take that and we can have that debate quite quickly.
Segment 4130: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5392, Text: Again, it didn’t go viral because it was kind of silly, and if anything would’ve gone viral, it was me responding, but that’s one where it’s like, actually, I’m happy to respond because a lot of people don’t know that I don’t work there and that I don’t make millions, and I’m not a billionaire. Well, they must know that because it’s in most news media about me, but the other one, I didn’t respond to publicly because it’s like Barbara Streisand effect. It’s like sometimes calling attention to someone who’s abusing you who basically has no followers and so on is just a waste.
Segment 4131: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5424, Text: And everything you’re describing now is just something that all of us have to learn because everybody’s in the public eye. I think when you have just two followers and you get bullied by one of the followers, it hurts just as much as when you have a large number, so it’s not… Your situation, I think it’s echoed in the situations of millions of other, especially teenagers and kids and so on.
Segment 4132: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5443, Text: Yeah, no, it’s actually an example. We don’t generally use my picture and the banners anymore on Wikipedia, but we did, and then we did an experiment one year where we tried other people’s pictures, so one of our developers, and one lovely, very sweet guy, and he doesn’t look like your immediate thought of a nerdy Silicon Valley developer. He looks like a heavy metal dude because he’s cool. Suddenly, here he is with long hair and tattoos, and there’s his sort of say, “Here’s what your money goes for. Here’s my letter asking for support,” and he got massive abuse from Wikipedia, like calling him creepy, and really massive. This was being shown to 80 million people a day, his picture, not the abuse. The abuse was elsewhere on the internet. He was bothered by it.
Segment 4133: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5499, Text: I thought, “You know what? There is a difference.” I actually am in the public eye. I get huge benefits from being in the public eye. I go around and make public speeches. Any random thing I think of, I can write and get it published in the New York Times, and I have this interesting life. He’s not a public figure, and so actually he wasn’t mad at us. It was just like, actually, suddenly being thrust in the public eye and you get suddenly lots of abuse, which normally, I think if you’re a teenager and somebody in your class is abusing you, it’s not going to go viral. It’s going to be hurtful because it’s local and it’s your classmates or whatever, but when ordinary people go viral in some abusive way, it’s really, really quite tragic.
Segment 4134: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5544, Text: I don’t know. Even at a small scale, it feels viral. When five people at your school, and there’s a rumor, and there’s this feeling like you’re surrounded, and the feeling of loneliness, I think, which you’re speaking to when you at least feel like you don’t have a platform to defend yourself, and then this powerlessness, that I think a lot of teenagers definitely feel, and a lot of people-
Segment 4135: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5569, Text: I think you’re right.
Segment 4136: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5571, Text: I think even when just two people make up stuff about you or lie about you or say mean things about you or bully you, that can feel like a crowd.
Segment 4137: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5581, Text: Yeah. No, that’s true.
Segment 4138: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5583, Text: Whatever that is in our genetics and our biology and the way our brain works, that just can be a terrifying experience. Somehow, to correct that, I think because everybody feels the pain of that, everybody suffers the pain of that, I think we’ll be forced to fix that as a society, to figure out a way around that.
Segment 4139: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5602, Text: I think it’s really hard to fix because I don’t think that problem isn’t necessarily new. Someone in high school who writes graffiti that says, “Becky is a slut,” and spreads a rumor about what Becky did last weekend, that’s always been damaging, it’s always been hurtful, and that’s really hard.
Segment 4140: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5625, Text: Those kinds of attacks, there is oldest time itself, they proceed the internet. Now, what do you think about this technology that feels Wikipedia like, which is community notes on Twitter? Do you like it? Pros and cons? Do you think it’s scalable?
Segment 4141: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5640, Text: I do like it. I don’t know enough about specifically how it’s implemented to really have a very deep view, but I do think it’s quite… The uses I’ve seen of it, I’ve found quite good, and in some cases, changed my mind. It’s like I see something, and of course, the human tendency is to retweet something that you hope is true or that you are afraid is true, or it’s that kind of quick mental action. Then I saw something that I liked and agreed with, and then a community note under it that made me think, “Oh, actually, this is a more nuanced issue,” so I like that. I think that’s really important. Now, how is it specifically implemented? Is it scalable or that? I don’t really know how they’ve done it, so I can’t really comment on that, but in general, I do think when your only mechanisms on Twitter, and you’re a big Twitter user, we know the platform and you’ve got plenty of followers and all of that, the only mechanisms are retweeting, replying, blocking.
Segment 4142: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5713, Text: It’s a pretty limited scope, and it’s kind of good if there’s a way to elevate a specific thoughtful response. It kind of goes to, again, does the algorithm just pick the retweet or the… I mean retweeting, it’s not even the algorithm that makes it viral. If Paulo Coelho, very famous author, I think he’s got… I don’t know. I haven’t looked lately. He used to have eight million Twitter followers. I think I looked, he’s got 16 million now or whatever. Well, if he retweets something, it’s going to get seen a lot. Elon Musk, if he retweets something, it’s going to get seen a lot. That’s not an algorithm. That’s just the way the platform works. So, it is kind of nice if you have something else, and how that’s something else is designed, that’s obviously complicated question.
Segment 4143: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5758, Text: Well, there’s this interesting thing that I think Twitter is doing, but I know Facebook is doing for sure, which is really interesting. What are the signals that a human can provide at scale? In Twitter, it’s retweet. In Facebook, I think you can share. I think, yeah, but there’s basic interactions, you can have comment and so on, but there’s also, in Facebook, and YouTube has this too is, “Would you like to see more of this or would you like to see less of this?” They post that sometimes. The thing that the neural net that’s learning from that has to figure out is the intent behind you saying, “I want to see less of this.”
Segment 4144: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5799, Text: Did you see too much of this content already? You like it, but you don’t want to see so much of it. You already figured it out, great. Or does this content not make you feel good? There’s so many interpretations that I would like to see less of this, but if you get that kind of signal, this actually can create a really powerfully curated list of content that is fed to you every day that doesn’t create an echo chamber or a silo, that actually just makes you feel good in the good way, which it challenges you, but it doesn’t exhaust you and make you this weird animal.
Segment 4145: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5840, Text: I’ve been saying for a long time, if I went on Facebook one morning and they said, Ooh, we’re testing a new option. Rather than showing you things we think you’re going to like, we want to show you some things that we think you will disagree with, but which we have some signals that suggest it’s of quality,” I’m like, “Now, that sounds interesting.”
Segment 4146: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5860, Text: Yeah, that sounds really interesting.
Segment 4147: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5861, Text: I want to see something where… Oh, I don’t agree with… Larry Lessig is a good friend of mine, founder of Creative Commons, and he’s moved on to doing stuff about corruption and politics and so on. I don’t always agree with Larry, but I always grapple with Larry because he’s so interesting and he’s so thoughtful, that even when we don’t agree, I’m like, “Actually, I want to hear him out because I’m going to learn from it,” and that doesn’t mean I always come around to agree with him, but I’m going to understand a perspective, and that’s really great feeling.
Segment 4148: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5892, Text: Yeah, there’s this interesting thing on social media where people accuse others of saying, “Well, you don’t want to hear opinions that you disagree with or ideas you disagree with.” I think this is something that’s thrown at me all the time. The reality is there’s literally almost nothing I enjoy more.
Segment 4149: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5909, Text: It seems an odd thing to accuse you of because you have quite a wide range of long conversations with a very diverse bunch of people.
Segment 4150: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5915, Text: But there is a very, very harsh drop off because what I like is high quality disagreement. That really makes me think. At a certain point, there’s a threshold, it’s a kind of a gray area when the quality of the disagreement, it just sounds like mocking, and you’re not really interested in a deep understanding of the topic, or you yourself don’t seem to carry deep understanding of the topic. There’s something called intelligence square debates that may-
Segment 4151: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5940, Text: There’s something called Intelligence Squared debates. The main one is the British version. With the British accent, everything always sounds better. And the Brits seem to argue more intensely, like they’re invigorated, they’re energized by the debate. Those people I often disagree with, basically everybody involved, and it’s so fun. I learned something. That’s high quality. If we could do that, if there’s some way for me to click a button that says, “Filter out lower quality just today,” just sometimes show it to me because I want to be able to, but today I’m just not in the mood for the mockery.
Segment 4152: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=5978, Text: Just high quality stuff, because even flat Earth, I want to get high quality arguments for the flat Earth. It would make me feel good because I would see, “Oh, that’s really interesting. I never really thought in my mind to challenge the mainstream narrative of general relativity, of a perception of physics. Maybe all of reality, maybe all of space is an illusion. That’s really interesting. I never really thought about, let me consider that fully. Okay, what’s the evidence? How would you test that? What are the alternatives? How would you be able to have such consistent perception of a physical reality, if it’s all of it is an illusion? All of us seem to share the same kind of perception of reality,” that’s the kind of stuff I love, but not the mockery of it that cheap, that it seems that social media can inspire.
Segment 4153: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6034, Text: Yeah. I talk sometimes about how people assume that the big debates in Wikipedia or the arguments are between the party of the left and the party of the right. And I would say no, it’s actually the party of the kind and thoughtful and the party of the jerks, is really it. Left and yeah, yeah, bring me somebody I disagree with politically. As long as they’re thoughtful, kind, we’re going to have a real discussion. I give an example of our article on abortion: so, if you can bring together a kind and thoughtful Catholic priest and a kind and thoughtful Planned Parenthood activist and they’re going to work together on the article on abortion, that can be a really great thing, if they’re both kind and thoughtful. That’s the important part. They’re never going to agree on the topic, but they will understand, okay, Wikipedia is not going to take a side, but Wikipedia is going to explain what the debate is about, and we’re going to try to characterize it fairly.
Segment 4154: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6096, Text: And it turns out your kind and thoughtful people, even if they’re quite ideological, like a Catholic priest is generally going to be quite ideological on the subject of abortion, but they can grapple with ideas and they can discuss, and they may feel very proud of the entry at the end of the day, not because they suppress the other side’s views, but because they think the case has been stated very well that other people can come to understand it. And if you’re highly ideological, you assume, I think naturally, “If people understood as much about this as I do, they’ll probably agree with me.” You may be wrong about that, but that’s often the case. So, that’s what I think we need to encourage more of in society generally, is grappling with ideas in a really thoughtful way.
Segment 4155: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6141, Text: So is it possible if the majority of volunteers, editors of Wikipedia really disliked Donald Trump, are they still able to write an article that empathizes with the perspective of, for time at least, a very large percentage of the United States that were supported of Donald Trump, and to have a full broad representation of him as a human being, him as a political leader, him as a set of policies promised and implemented, all that kind of stuff?
Segment 4156: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6175, Text: Yeah, I think so. And I think if you read the article, it’s pretty good. And I think a piece of that is within our community, if people have the self-awareness to understand. So, I personally wouldn’t go and edit the entry on Donald Trump. I get emotional about it and I’m like, “I’m not good at this,” and if I tried to do it, I would fail. I wouldn’t be a good Wikipedian, so it’s better if I just step back and let people who are more dispassionate on this topic edit it. Whereas there are other topics that are incredibly emotional to some people where I can actually do quite well. I’m going to be okay. Maybe we were discussing earlier the efficacy of masks. I’m like, “Oh, I think that’s an interesting problem. And I don’t know the answer, but I can help catalog what’s the best evidence and so on.”
Segment 4157: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6228, Text: I’m not going to get upset. I’m not going to get angry, able to be a good Wikipedian, so I think that’s important. And I do think though in a related framework that the composition of the community is really important. Not because Wikipedia is or should be a battleground, but because blind spots, like maybe I don’t even realize what’s biased if I’m particularly of a certain point of view, and I’ve never thought much about it. So one of the things we focus on a lot, the Wikipedia volunteers are, we don’t know the exact number, but let’s say 80% plus male, and they’re a certain demographic: they tend to be college educated, heavier on tech geeks than not, et cetera. So, there is a demographic to the community, and that’s pretty much global. Somebody said to me once, “Why is it only white men who edit Wikipedia?”, and I said, “You’ve obviously not met the Japanese Wikipedia community.”
Segment 4158: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6291, Text: It’s a joke because the broader principle still stands, who edits Japanese Wikipedia? A bunch of geeky men, and women as well. So, we do have women in the community, and that’s very important. But we do think, “Okay, you know what, that does lead to some problems,” it leads to some content issues simply because people write more about what they know and what they’re interested in. They’ll tend to be dismissive of things as being unimportant if it’s not something that they personally have an interest in. I like the example, as a parent I would say our entries on early childhood development probably aren’t as good as they should be because a lot of the Wikipedia volunteers… Actually we’re getting older, the Wikipedians, so that demographic has changed a bit. But if you’ve got a bunch of 25 year old tech geek dudes who don’t have kids, they’re just not going to be interested in early childhood development. And if they tried to write about it, they probably wouldn’t do a good job, ’cause they don’t know anything about it.
Segment 4159: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6353, Text: And somebody did a look at our entries on novelists who’ve won a major literary prize, and they looked at the male novelist versus the female, and the male novelists had longer and higher quality entries. And why is that? Well, it’s not because, ’cause I know hundreds of Wikipedian, it’s not because these are a bunch of biased, sexist men who like, “Books by women are not important.” No. Actually, there is a gender breakdown of readership. There are books, like hard science fiction’s a classic example, hard science fiction: mostly read by men. Other types of novels, more read by women. And if we don’t have women in the community, then these award-winning clearly important novelists may have less coverage. And not because anybody consciously thinks, “We don’t like a book by Maya Angelou. Who cares? She’s a poet. That’s not interesting.”
Segment 4160: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6415, Text: No, but just because, well, people write what they know, they write what they’re interested in it. So, we do think diversity in the community is really important. And that’s one area where I do think it’s really clear. But I can also say, actually that also applies in the political sphere, to say, actually, we do want kind and thoughtful Catholic priests, kind and thoughtful conservatives, kind and thoughtful libertarians, kind and thoughtful Marxists to come in. But the key is the kind and thoughtful piece, so when people sometimes come to Wikipedia outraged by some dramatic thing that’s happened on Twitter, they come to Wikipedia with a chip on their shoulder ready to do battle, and it just doesn’t work out very well.
Segment 4161: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6458, Text: And there’s tribes in general where I think there’s a responsibility on the larger group to be even kinder and more welcoming to the smaller group.
Segment 4162: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6468, Text: Yeah, we think that’s really important. And so oftentimes, people come in and there’s a lot… When I talk about community health, one of the aspects of that that we do think about a lot, that I think about a lot is not about politics. It’s just like, how are we treating newcomers to the community? And so, I can tell you what our ideals are, what our philosophy is, but do we live up to that? So the ideal is you come to Wikipedia, we have rules. One of our fundamental rules is ignore all rules, which is partly written that way because it piques people’s attention, like, “Oh, what the hell kind of rule is that?” But basically says, “Look, don’t get nervous and depressed about a bunch of what’s the formatting of your footnote?”, so you shouldn’t come to Wikipedia, add a link, and then get banned or yelled at because it’s not the right format.
Segment 4163: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6526, Text: Instead, somebody should go, “Oh, hey. Yeah, thanks for helping, but here’s the link to how to format. If you want to keep going, you might want to learn how to format a footnote,” and to be friendly and to be open and to say, “Oh, right, oh, you’re new and you clearly don’t know everything about Wikipedia,” and sometimes in any community, that can be quite hard. So, people come in and they’ve got a great big idea, and they’re going to propose this to the Wikipedia community, and they have no idea. That’s basically a perennial discussion we’ve had 7,000 times before. And so then ideally, you would say to the person, “Oh yeah, great, thanks.” A lot of people have, and here’s where we got to and here’s the nuanced conversation we’ve had about that in the past that I think you’ll find interesting, and sometimes people are just like, “Oh God, another one, who’s come in with this idea which doesn’t work, and they don’t understand why.”
Segment 4164: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6579, Text: You can lose patience, but you shouldn’t.
Segment 4165: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6580, Text: And that’s human, but I think it just does require really thinking in a self-aware manner of, “Oh, I was once a newbie.” Actually, I just did an interview with Emily Temple Woods, she was Wikipedian of the year, she’s just like a great, well-known Wikipedian. And I interviewed her for my book and she told me something I never knew, apparently it’s not secret, she didn’t reveal it to me, but it’s that when she started Wikipedia, she was a vandal. She came in and vandalized Wikipedia. And then basically what happened was she’d vandalized a couple of articles, and then somebody popped up on her talk page and said, “Hey, why are you doing this? We’re trying to make an encyclopedia here, and and this wasn’t very kind.”
Segment 4166: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6629, Text: And she felt so bad. She’s like, “Oh, right. I didn’t really think of it that way.” She just was coming in, and she was 13 years old, combative and having fun, and trolling a bit. And then she’s like, “Oh, actually, I see your point,” and became a great Wikipedian. So that’s the ideal really, is that you don’t just go throw a block, “Fuck off.” You go, “Hey, what gives?”, which is I think the way we tend to treat things in real life, if you’ve got somebody who’s doing something obnoxious in your friend group, you probably go, “Hey, really, I don’t know if you’ve noticed, but I think this person is actually quite hurt that you keep making that joke about them.” And then they usually go, “Oh, I thought that was okay,” and then they stop, or they keep it up and then everybody goes, “Well, you’re the asshole.”
Segment 4167: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6681, Text: Well, yeah, that’s just an example that gives me faith in humanity that we’re all capable and wanting to be kind to each other. And in general, the fact that there’s a small group of volunteers, they’re able to contribute so much to the organization, the collection, the discussion of all of human knowledge is so it makes me so grateful to be part of this whole human project. That’s one of the reasons I love Wikipedia is gives me faith in humanity.
Segment 4168: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6713, Text: Yeah, no, I once was at Wikimania is our annual conference and people come from all around the world, really active volunteers. I was at the dinner, we were in Egypt at Wikimania and Alexandria at the closing dinner or whatever, and a friend of mine came and sat at the table, and she’s been in the movement more broadly, creative commons, she’s not really a Wikipedian, she’d come to the conference because she’s into creative commons and all that. So we have dinner, and it just turned out I sat down at the table with most of the members of the English language arbitration committee, and they’re a bunch of very sweet, geeky Wikipedians.
Segment 4169: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6751, Text: And as we left the table, I said to her, “I still find this sense of amazement, we just had dinner with some of the most powerful people in English language media,” because they’re the people who are the final court of appeal in English Wikipedia. And thank goodness they’re not media moguls. They’re just a bunch of geeks who are just well-liked in the community because they’re kind and they’re thoughtful and they really think about things. I was like, “This is great. Love Wikipedia.”
Segment 4170: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6781, Text: To the degree that geeks run the best aspect of human civilization brings me joy in all aspects. And this is true programming, like Linux programmers, people that kind of specialize in a thing, and they don’t really get caught up into the mess of the bickering of society. They just do their thing, and they value the craftsmanship of it, the competence of it.
Segment 4171: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6809, Text: Yeah. If you’ve never heard of this or looked into it, you’ll enjoy it, I read something recently that I didn’t even know about, but the fundamental time zones, and they change from time to time. Sometimes, a country will pass daylight savings or move it by a week, whatever. There’s a file that’s on all Unix based computers, and basically all computers end up using this file, it’s the official time zone file. But why is it official? It’s just this one guy. It’s like this guy and a group of community around him.
Segment 4172: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6844, Text: And basically, something weird happened and it broke something because he was on vacation. And I’m just like, isn’t that wild that you would think… First of all, most people never even think about how do computers know about time zones? Well, they know because they just use this file which tells all the time zones and which dates they change and all of that. But there’s this one guy, and he doesn’t get paid for it. With all the billions of people on the planet, he put his hand up and goes, “Yo, I’ll take care of the time zones.”
Segment 4173: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6876, Text: And there’s a lot of programmers listening to this right now with PTSD about time zones. On top of this one guy, there’s other libraries, the different programming languages that help manage the time zones for you. But still, within those, it’s amazing just the packages, the libraries, how few people build them out of their own love for building, for creating, for community and all of that. I almost like don’t want to interfere with the natural habitat of the geek. When you spot him in the wild, you just want to be like, “Well, careful, that thing needs to be treasured.”
Segment 4174: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6916, Text: No, I met a guy many years ago, lovely, really sweet guy, and he was running a bot on English Wikipedia that I thought, “Wow, that’s actually super clever.” And what he had done is his bot was like spell checking, but rather than simple spell checking, what he had done is create a database of words that are commonly mistaken for other words. They’re spelled wrong, so I can’t even give an example. And so, the word is people often spell it wrong, but no spell checker catches it because it is another word. And so, what he did is he wrote a bot that looks for these words and then checks the sentence around it for certain keywords. So in some context, this isn’t correct, but buoy and boy: people sometimes type B-O-Y when they mean B-O-U-Y, so if he sees the word boy, B-O-Y in an article, he would look in the context and see, is this a nautical reference? And if it was, he didn’t autocorrect, he just would flag it up to himself to go, “Oh, check this one out.”
Segment 4175: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=6983, Text: And that’s not a great example, but he had thousands of examples, and I was like, “That’s amazing. I would’ve never thought to do that.” And I’m glad that somebody did. And that’s also part of the openness of the system, and also I think being a charity, being this idea of actually, this is a gift to the world that makes someone go, “Oh, well, I’ll put my hand up. I see a little piece of things I can make better because I’m a good programmer and I can write this script to do this thing, and I’ll find it fun,” amazing.
Segment 4176: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7015, Text: Well, I got to ask about this big, bold decision at the very beginning to not do advertisements on the website. And just in general, the philosophy of the business model of Wikipedia, what went behind that?
Segment 4177: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7026, Text: Yeah, so I think most people know this, but we’re a charity, so in the US, registered as a charity. And we don’t have any ads on the site. And the vast majority of the money is from donations, but the vast majority from small donors. So, people giving $25 or whatever.
Segment 4178: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7049, Text: If you’re listening to this, go donate.
Segment 4179: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7051, Text: Go donate.
Segment 4180: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7051, Text: Donate now.
Segment 4181: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7053, Text: $25.
Segment 4182: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7053, Text: I’ve donated so many times
Segment 4183: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7054, Text: And we have millions of donors every year, but it’s a small percentage of people. I would say in the early days, a big part of it was aesthetic, almost as much as anything else. It was just like, “I don’t really want ads in Wikipedia. There’s a lot of reasons why it might not be good.” And even back then, I didn’t think as much as I have since about a business model can tend to drive you in a certain place, and really thinking that through in advance is really important because you might say, “Yeah, we’re really, really keen on community control and neutrality,” but if we had an advertising based business model, probably that would begin to erode. Even if I believe in it very strongly, organizations tend to follow the money in the DNA in the long run.
Segment 4184: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7105, Text: And so things like, it’s easy to think about some of the immediate problems. So if you go to read about, I don’t know, Nissan car company, and if you saw an ad for the new Nissan at the top of the page, you might be like, “Did they pay for this?”, or, “Do the advertisers have influence over the content?”, because of wonder about that for all kinds of media.
Segment 4185: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7133, Text: And that undermines trust.
Segment 4186: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7135, Text: Undermines trust, right. But also, things like we don’t have clickbait headlines in Wikipedia. You’ve never seen Wikipedia entries with all these kind of listicles, “The 10 funniest cat pictures, number seven will make you cry,” none of that kind of stuff, because there’s no incentive, no reason to do that. Also, there’s no reason to have an algorithm to say, “Actually, we’re going to use our algorithm to drive you to stay on the website longer. We’re going to use the algorithm to drive you to…”, It’s like, “Oh, you’re reading about Queen Victoria. There’s nothing to sell you when you’re reading about Queen Victoria. Let’s move you on to Las Vegas because actually, the ad revenue around hotels in Las Vegas is quite good,” so there’s no incentive for the organization to go, “Oh, let’s move people around to things that have better ad revenue.”
Segment 4187: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7188, Text: Instead, it’s just like, “Oh, well, what’s most interesting to the community?,” just to make those links. So, that decision just seemed obvious to me, but as I say, it was less of a business decision and more of an aesthetic. It’s like, “I like Wikipedia that doesn’t have ads.” In these early days, a lot of the ads, that was well before the era of really quality ad targeting and all that, so you got a lot of-
Segment 4188: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7218, Text: Banners.
Segment 4189: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7218, Text: Banners, punch the monkey ads and all that kind of nonsense. But there was no guarantee. It was not really clear, how could we fund this? It was pretty cheap. It still is quite cheap compared to most. We don’t have 100,000 employees and all of that, but would we be able to raise money through donations? And so, I remember the first time that we really did a donation campaign was on a Christmas Day in 2003, I think it was. We had three servers, database servers, and two front end servers, and they were all the same size or whatever, and two of them crashed. They broke, I don’t even know, remember now, the hard drive. It was Christmas Day, so I scrambled on Christmas Day to go onto the database server, which fortunately survived, and have it become a front end server as well. And then, the site was really slow and it wasn’t working very well.
Segment 4190: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7288, Text: And I was like, “Okay, it’s time. We need to do a fundraiser,” and so I was hoping to raise $20,000 in a month’s time, but we raised nearly $30,000 within two, three weeks time. So that was the first proof point of, “Oh, we put a batter up and people will donate,” we just explained we need the money. And we were very small back then, and people were like, “Oh yeah, I love this. I want to contribute.” Then over the years, we’ve become more sophisticated about the fundraising campaigns, and we’ve tested a lot of different messaging and so forth. What we used to think, I remember one year we really went heavy with, “The idea of Wikipedia is a free encyclopedia for every single person on the planet. So what about the languages of Sub-Saharan Africa?”
Segment 4191: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7340, Text: So I thought, “Okay, we’re trying to raise money. We need to talk about that because it’s really important and near and dear to my heart,” and just instinctively knowing nothing about charity fundraising, you see it all around, it’s like, oh, charity’s always mentioned the poor people they’re helping, so let’s talk about. Didn’t really work as well. This is very vague and very broad, but the pitch that works better than any other in general is a fairness pitch of, “You use it all the time, you should probably chip in.” And most people are like, “Yeah, you know what? My life would suck without Wikipedia. I use it constantly and whatever. I should chip in, it just seems like the right thing to do.”
Segment 4192: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7382, Text: And there’s many variants on that, obviously. And it works. And people are like, “Oh yeah, Wikipedia, I love Wikipedia, and I shouldn’t.” So sometimes people say, “Why are you always begging for money on the website?”, and it’s not that often, it’s not that much, but it does happen. They’re like, “Why don’t you just get Google and Facebook and Microsoft, why don’t they pay for it?”, and I’m like, “I don’t think that’s really the right answer.”
Segment 4193: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7414, Text: Influence starts to creep in.
Segment 4194: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7415, Text: Influence starts to creep in, and questions start to creep in. The best funding for Wikipedia is the small donors. We also have major donors. We have high net worth people who donate, but we always are very careful about that sort of thing to say, “Wow, that’s really great and really important, but we can’t let that become influence because that would just be really quite not good for Wikipedia.”
Segment 4195: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7441, Text: I would love to know how many times I’ve visited Wikipedia, how much time I’ve spent on it, because I have a general sense that it’s the most useful site I’ve ever used, competing maybe with Google search, which ultimately lands on Wikipedia.
Segment 4196: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7441, Text: Yeah, right.
Segment 4197: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7460, Text: But if I would just be reminded of like, “Hey, remember all those times your life was make better because of the site?”, I think I would be much more like, “Yeah, why did I waste money on site X, Y, Z when I should be giving a lot of it here?”
Segment 4198: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7473, Text: Well, the Guardian newspaper has a similar model, which is they have ads. There’s no paywall, but they just encourage people to donate, and they do that. I’ve sometimes seen a banner saying, “Oh, this is your 134th article you’ve read this year, would you like to donate?” And I think it’s effective-
Segment 4199: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7495, Text: [inaudible 02:04:55].
Segment 4200: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7494, Text: … they’re testing. But also, I wonder just for some people, if they just don’t feel like guilty and then think, “Oh, I shouldn’t bother them so much.” I don’t know. It’s a good question. I don’t know the answer.
Segment 4201: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7506, Text: I guess that’s the thing I could also turn on, ’cause that would make me… I feel like legitimately, there’s some sites, this speaks to our social media discussion: Wikipedia unquestionably makes me feel better about myself if I spend time on it. There’s some websites where I’m like, if I spend time on Twitter, sometimes I’m like, I regret. I think Elon talks about this, minimize the number of regretted minutes. My number of regretted minutes on Wikipedia is zero. I don’t remember a time… I’ve just discovered this. I started following on Instagram, a page, depthsofwikipedia.
Segment 4202: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7546, Text: Oh, yeah.
Segment 4203: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7547, Text: There’s crazy Wikipedia pages. There’s no Wikipedia page that [inaudible 02:05:51]-
Segment 4204: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7551, Text: Yeah, I gave her a media contributor of the year award this year because she’s so great.
Segment 4205: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7555, Text: Yeah, she’s amazing.
Segment 4206: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7557, Text: Depthsofwikipedia is so fun.
Segment 4207: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7559, Text: Yeah, that’s the interesting point that I don’t even know if there’s a competitor. There may be the programming, Stack Overflow type of websites, but everything else, there’s always a trade-off. It’s probably because of the ad driven model because there’s an incentive to pull you into clickbait, and Wikipedia has no clickbait. It’s all about the quality of the knowledge and the wisdom.
Segment 4208: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7582, Text: Yeah. No, that’s right. And I also Stack Overflow. Although I wonder what you think of this, so I only program for fun as a hobby, and I don’t have enough time to do it, but I do, and I’m not very good at it. So therefore, I end up on Stack Overflow quite a lot trying to figure out what’s gone wrong. And I have really transitioned to using ChatGPT much more for that because I can often find the answer clearly explained, and it works better than sifting through threads, and I feel bad about that because I do love Stack Overflow and their community. I’m assuming, I haven’t read anything about in the news about it, but I’m assuming they are keenly aware of this, and they’re thinking about, “How can we use this chunk of knowledge that we’ve got here and provide a new type of interface where you can query it with a question and actually get an answer that’s based on the answers that we’ve had?” I don’t know.
Segment 4209: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7639, Text: Mm-hmm. And I think Stack Overflow currently has policies against using GPT. There’s a contentious kind of tension.
Segment 4210: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7648, Text: Of course, yeah.
Segment 4211: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7649, Text: But they’re trying to figure that out.
Segment 4212: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7650, Text: Well, and so we are similar in that regard. Obviously, all the things we’ve talked about like ChatGPT makes stuff up and it makes up references, so our community has already put into place some policies about it. But roughly speaking, there’s always more nuance. But roughly speaking, it’s, you the human are responsible for what you put into Wikipedia. So, if you use ChatGPT, you better check it, ’cause there’s a lot of great use cases of like, “Oh, well, I’m not a native speaker of German, but I am pretty good,” I’m not talking about myself, a hypothetical me that’s pretty good, and I just want to run my edit through ChatGPT in German to go make sure my grammar’s okay. That’s actually cool.
Segment 4213: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7695, Text: Does it make you sad that people might use, increasingly use ChatGPT for something where they would previously use Wikipedia? So basically, use it to answer basic questions about the Eiffel Tower?
Segment 4214: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7712, Text: Yeah. No-
Segment 4215: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7712, Text: And where the answer really comes at the source of it from Wikipedia, but they’re using this as an interface.
Segment 4216: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7718, Text: Yeah. No, that’s completely fine. Part of it is our ethos has always been, “Here’s our gift of the world. Make something,” so if the knowledge is more accessible to people, even if they’re not coming through us, that’s fine. Now, obviously we do have certain business model concerns, and where we’ve had more conversation about this, this whole GPT thing is new, things like if you ask Alexa, “What is the Eiffel Tower?”, and she reads you the first two sentences from Wikipedia and doesn’t say it’s from Wikipedia, and they’ve recently started citing Wikipedia, then we worry, “Oh, if people don’t know they’re getting the knowledge from us, are they going to donate money? Or are they just going to think, oh, what’s Wikipedia for? I can just ask Alexa.” It’s like, well, Alexa only knows anything because she read Wikipedia. So we do think about that, but it doesn’t bother me in the sense of like, oh, I want people to always come to Wikipedia first.
Segment 4217: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7773, Text: But we had a great demo, literally just hacked together over a weekend by our head of machine learning where he did this little thing to say, you could ask any question, and he was just knocking it together, so he used OpenAI’s API just to make a demo, asked a question, “Why do ducks fly south for winter?”, which is the kind of thing you think, “Oh, I might just Google for that, or I might start looking in Wikipedia. I don’t know.” And so what he did, he asked ChatGPT, “What are some Wikipedia entries that might answer this?” Then, he grabbed those Wikipedia entries, said, “Here’s some Wikipedia entries. Answer this question based only on the information in this,” and he had pretty good results, and it prevented the making stuff up. Now, it’s just he hacked it together on a weekend, but what it made me think about was, “Oh, okay, so now we’ve got this huge body of knowledge that in many cases you’re like, oh I really I want to know about Queen Victoria. I’m just going to go read the Wikipedia entry and it’s going to take me through her life and so forth.”
Segment 4218: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7844, Text: But other times, you’ve got a specific question, and maybe we could have a better search experience where you can come to Wikipedia, ask your specific question, get your specific answer that’s from Wikipedia, including links to the articles you might want to read next. And that’s just a step forward. That’s just using new type of technology to make the extraction of information from this body of text into my brain faster and easier. So, I think that’s cool.
Segment 4219: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7870, Text: I would love to see a ChatGPT grounding into websites like Wikipedia. And the other comparable website to me will be like Wolfram Alpha for more mathematical knowledge, that kind of stuff. So, taking you to a page that is really crafted as opposed to the moment you start actually taking you to journalist websites like news websites, it starts getting a little iffy, because you’re now in a land that has a wrong incentive.
Segment 4220: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7904, Text: Right, yeah.
Segment 4221: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7905, Text: You’re pulled in.
Segment 4222: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7905, Text: Yeah, and you need somebody to have filtered through that and tried to knock off the rough edges. Yeah, I think that’s exactly right. And I think that kind of grounding, I think they’re working really hard on it. I think that’s really important-
Segment 4223: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7920, Text: … is, I think they’re working really hard on it. I think that’s really important. And that actually… So if you ask me to step back and be like very business-like about our business model and where’s it going to go for us, and are we going to lose half our donations because everybody’s just going to stop coming to Wikipedia and go to ChatGPT? Well, grounding will help a lot because frankly, most questions people have, if they provide proper links, we’re going to be at the top of that, just like we are in Google. So we’re still going to get tons of recognition and tons of traffic just from… Even if it’s just the moral properness of saying, “Here’s my source.” So I think we’re going to be all right in that.
Segment 4224: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7959, Text: Yeah, in the close partnership if the model is fine-tuned, is constantly retrained that Wikipedia is one of the primary places where if you want to change what the model knows, one of the things you should do is contribute to Wikipedia or clarify Wikipedia.
Segment 4225: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7973, Text: Yeah, yeah. No, that’s [inaudible 02:12:55].
Segment 4226: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7974, Text: Or elaborate, expand, all that kind of stuff.
Segment 4227: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7976, Text: Yeah.
Segment 4228: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7977, Text: You mentioned all of us have controversies. I have to ask, do you find the controversy of whether you are the sole founder or the co-founder of Wikipedia ironic, absurd, interesting, important? What are your comments?
Segment 4229: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=7993, Text: I would say unimportant. Not that interesting. I mean, one of the things that people are sometimes surprised to hear me say is I actually think Larry Sanger doesn’t get enough credit for his early work in Wikipedia, even though I think co-founder’s not the right title for that. So he had a lot of impact and a lot of great work, and I disagree about a lot of things since and all that, and that’s fine. So yeah. No, to me that’s like, it’s one of these things that the media love a falling out story, so they want to make a big deal out of it, and I’m just like, yeah, no.
Segment 4230: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8031, Text: So there’s a lot of interesting engineering contributions in the early days, like you were saying, there’s debates about how to structure it, what the heck is this thing that we’re doing? And there’s important people that contributed to that.
Segment 4231: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8042, Text: Yeah, definitely.
Segment 4232: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8043, Text: So he also, you said you’ve had some disagreements. Larry Sanger said that nobody should trust Wikipedia, and that Wikipedia seems to assume that there’s only one legitimate, defensible version of the truth on any controversial question. That’s not how Wikipedia used to be. I presume you disagree with that analysis.
Segment 4233: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8061, Text: Yeah. I mean, just straight up, I disagree. Go and read any Wikipedia entry on a controversial topic, and what you’ll see is a really diligent effort to explain all the relevant sides. So yeah, just disagree.
Segment 4234: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8072, Text: So on controversial questions, you think perspectives are generally represented?
Segment 4235: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8076, Text: Yeah.
Segment 4236: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8077, Text: Because it has to do with the tension between the mainstream and the non-mainstream that we were talking about.
Segment 4237: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8083, Text: Yeah. No, I mean for sure. To take this area of discussion seriously is to say, yeah, you know what? Actually that is a big part of what Wikipedia and spend their time grappling with is to say, how do we figure out whether a less popular view is pseudoscience? Is it just a less popular view that’s gaining acceptance in the mainstream? Is it fringe versus crackpot, et cetera, et cetera? And that debate is what you’ve got to do. There’s no choice about having that debate of grappling with something. And I think we do. And I think that’s really important. And I think if anybody said to the Wikipedia community, “Gee, you should stop covering minority viewpoints on this issue,”
Segment 4238: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8139, Text: I think they would say, “I don’t even understand why you would say that. We have to grapple with minority viewpoints in science and politics and so on.” And this is one of the reasons why there is no magic simple answer to all these things. It’s really contextual. It’s case by case. It’s like you’ve got to really say, okay, what is the context here? How do you do it? And you’ve always got to be open to correction and to change and to challenge and always be sort of serious about that.
Segment 4239: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8173, Text: I think what happens, again, with social media is when there is that grappling process in Wikipedia and a decision is made to remove a paragraph or to remove a thing or to say a thing, you’re going to notice the one direction of the oscillation of the grappling and not the correction. And you’re going to highlight that and say, how come this person… I don’t know, maybe legitimacy of elections that’s the thing that comes up. Donald Trump maybe previously-
Segment 4240: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8202, Text: Yeah, I can give a really good example, which is, there was this sort of dust up about the definition of recession in Wikipedia. The accusation was often quite ridiculous and extreme, which is, under pressure from the Biden administration Wikipedia changed the definition of recession to make Biden look good, or we did it not under pressure, but because we’re a bunch of lunatic leftists and so on. And then when I see something like that in the press, I’m like, “Oh dear, what’s happened here? How do we do that?” Because I always just accept things for five seconds first, and then I go and I look and I’m like, “You know what? That’s literally completely not what happened.” What happened was, one editor thought the article needed restructuring. So the article is always said, so the traditional kind of loose definition of recession is two quarters of negative growth, but there’s always been within economics, within important agencies and different countries around the world, a lot of nuance around that.
Segment 4241: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8263, Text: And there’s other factors that go into it and so forth. And then it’s just an interesting complicated topic. And so the article has always had the definition of two quarters. And the only thing that really changed was moving that from the lead, from the top paragraph to further down. And then news stories appeared saying, “Wikipedia has changed the definition of recession.” And then we got a huge rush of trolls coming in. So the article was temporarily protected, I think, only semi protected, and people were told, “Go to the talk page to discuss.” So anyway, it was a dust up that was… When you look at it as a Wikipedian, you’re like, “Oh, this is a really routine kind of editorial debate.” Another example, which unfortunately our friend Elon fell for, I would say, is the Twitter files. So there was an article called the Twitter files, which is about these files that were released once Elon took control of Twitter, and he released internal documents.
Segment 4242: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8316, Text: And what happened was somebody nominated it for deletion, but even the nomination said, “This is mainly about the Hunter Biden laptop controversy, shouldn’t this information be there instead?” So anyone can… It takes exactly one human being anywhere on the planet to propose something for deletion, and that triggers a process where people discuss it, which within a few hours, it was what we call snowball closed i.e, this doesn’t have a snowball’s chance in hell of passing. So an admin goes, “Yeah, wrong,” and closed the debate, and that was it. That was the whole thing that happened. And so nobody proposed suppressing the information. Nobody proposed it wasn’t important, it was just editorially boring internal questions. So sometimes people read stuff like that and they’re like, “Oh, you see, look at these leftists. They’re trying to suppress the truth again.” It’s like, well slow down a second and come and look, literally, it’s not what happened.
Segment 4243: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8376, Text: So I think the right is more sensitive to censorship, and so they will more likely highlight there’s more virality to highlighting something that looks like censorship in any walks of life. And this moving a paragraph from one place to another, or removing it and so on, as part of the regular grappling of Wikipedia can make a hell of a good article or YouTube video.
Segment 4244: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8401, Text: Oh, yeah. Yeah. No, it sounds really in enticing and intriguing and surprising to most people because they’re like, “Oh, no, I’m reading Wikipedia. It doesn’t seem like a crackpot leftist website. It seems pretty kind of dull, really in its own geeky way.” And so that makes a good story. It’s like, oh, am I being misled? Because there’s a shadowy cabal of Jimmy Wales.
Segment 4245: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8425, Text: I generally, I read political stuff. I mentioned to you that I’m traveling to have some very difficult conversation with high profile figures both in the war in Ukraine and in Israel and Palestine. And I read the Wikipedia articles around that, and I also read books on the conflict and the history of the different regions. And I find the Wikipedia articles to be very balanced, and there’s many perspectives being represented. But then I ask myself, “Well, am I one of them leftist crackpots?” They can’t see the truth. I mean, it’s something I ask myself all the time, forget the leftist, just crackpot in general. Am I just being a sheep and accepting it? And I think that’s an important question to always ask, but not too much.
Segment 4246: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8472, Text: Yeah. No, I agree.
Segment 4247: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8472, Text: A little bit, but not too much.
Segment 4248: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8475, Text: Yeah. No, I think we always have to challenge ourselves of what do I potentially have wrong?
Segment 4249: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8480, Text: Well, you mentioned pressure from government. You’ve criticized Twitter for giving in to Turkey’s government censorship. There’s also conspiracy theories or accusations of Wikipedia being open to pressure from government to government organizations, FBI and all this kind of stuff. What is the philosophy about pressure from government and censorship?
Segment 4250: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8510, Text: So we’re super hardcore on this. We’ve never bowed down to government pressure anywhere in the world, and we never will. And we understand that we’re hardcore. And actually there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. And if they threaten to block, well, knock yourself out, you’re going to lose Wikipedia. And that’s been very successful for us as a strategy because governments know they can’t just casually threaten to block Wikipedia or block us for two days, and we’re going to cave in immediately to get back into the market. And that’s what a lot of companies have done. And I don’t think that’s good that we can go one level deeper and say, I’m actually quite sympathetic. If you have staff members in a certain country and they are at physical risk, you’ve got to put that into your equation.
Segment 4251: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8563, Text: So I understand that. If Elon said, “Actually, I’ve got a hundred staff members on the ground in such and such a country, and if we don’t comply, somebody’s going to get arrested. And it could be quite serious.” Okay, that’s a tough one. That’s actually really hard. But yeah, no. And then the FBI one, no, the criticism I saw. I kind of prepared for this because I saw people responding to your request for questions, and I was like, somebody’s like, “Oh, well, don’t you think it was really bad that you da da da, da?” I actually reached out to [inaudible 02:23:18] and said, “Can you just make sure I’ve got my facts right?” And the answer is, we received zero requests of any kind from the FBI or any of the other government agencies for any changes to content in Wikipedia. And had we received those requests at the level of the Wikipedia Foundation, we would’ve said, “We can’t do anything because Wikipedia is written by the community.”
Segment 4252: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8620, Text: And so the Wikimedia Foundation can’t change the content of Wikipedia without causing… I mean, God, that would be a massive controversy, you can’t even imagine. What we did do, and this is what I’ve done, I’ve been to China and met with the Minister of Propaganda. We’ve had discussions with governments all around the world, not because we want to do their bidding, but because we don’t want to do their bidding, but we also don’t want to be blocked. And we think actually having these conversations are really important. There’s no threat of being blocked in the US. That’s just never going to happen. There is the First Amendment. But in other countries around the world, it’s like, “Okay, what are you upset about? Let’s have the conversation. Let’s understand, and let’s have a dialogue about it so that you can understand where we come from and what we’re doing and why.”
Segment 4253: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8666, Text: And then sometimes it’s like, gee, if somebody complains that something’s bad in Wikipedia, whoever they are, don’t care who they are. It could be you, it could be the government, it could be the Pope. I don’t care who they are. It’s like, oh, okay. Well, our responsibility as Wikipedia is to go, “Oh, hold on, let’s check is that right or wrong? Is there something that we’ve got wrong in Wikipedia? Not because you’re threatening to block us, but because we want Wikipedia to be correct.” So we do have these dialogues with people. And a big part of what was going on with, you might call it pressure on social media companies or dialogue with, as we talked earlier, grapple with the language depending on what your view is. In our case, it was really just about, oh, okay, they want to have a dialogue about COVID information, misinformation.
Segment 4254: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8722, Text: We are this enormous source of information which the world depends on. We’re going to have that conversation. We’re happy to say, here’s… If they say, how do you know that Wikipedia is not going to be pushing some crazy anti-vax narrative first? I mean, I think it’s somewhat inappropriate for a government to be asking pointed questions in a way that implies possible penalties. I’m not sure that ever happened because we would just go, I don’t know, the Chinese blocked us. So it goes, right? We’re not going to cave into any kind of government pressure, but whatever the appropriateness of what they were doing, I think there is a rule for government in just saying, let’s understand the information ecosystem. Let’s think about the problem of misinformation, disinformation in society, particularly around election security, all these kinds of things. So I think it would be irresponsible of us to get a call from a government agency and say, “Yeah, why don’t you just fuck off? You’re the government.” But it would also be irresponsible to go, “Oh, dear, government agent’s not happy. Let’s fix Wikipedia so the FBI loves us.”
Segment 4255: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8795, Text: And when you say you want to have discussions with the Chinese government or with organizations like CDC and WHO, it’s to thoroughly understand what the mainstream narrative is so that it can be properly represented, but not drive what the articles are?
Segment 4256: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8810, Text: Well, it’s actually important to say whatever the Wikimedia Foundation thinks has no impact on what’s in Wikipedia. So it’s more about saying to them, “We understand you’re the World Health Organization, or you’re whoever, and part of your job is to… Public health is about communications. You want to understand the world.” So it’s more about, “Well, let’s explain how Wikipedia works.”
Segment 4257: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8838, Text: So it’s more about explaining how Wikipedia works and like, “Hey, it’s the volunteers”?
Segment 4258: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8842, Text: Yeah, exactly.
Segment 4259: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8843, Text: It’s a battle of ideas, and here’s how the sources are used.
Segment 4260: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8849, Text: Yeah, exactly.
Segment 4261: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8850, Text: What are the legitimate sources and what not a legitimate source is.
Segment 4262: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8852, Text: Yeah, exactly.
Segment 4263: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8853, Text: I mean, I suppose there’s some battle about what is a legitimate source. There could be statements made that CDC… There’s government organizations in general have sold themselves to be the place where you go for expertise. And some of that has been to small degree, raised in question over the response to the pandemic.
Segment 4264: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8877, Text: Well, I think in many cases, and this goes back to my topic of trust. So there were definitely cases of public officials, public organizations where I felt like they lost the trust of the public because they didn’t trust the public. And so the idea is, we really need people to take this seriously and take actions, therefore, we’re going to put out some overblown claims because it’s going to scare people into behaving correctly. You know what? That might work for a little while, but it doesn’t work in the long run because suddenly people go from a default stance of… Like the Center for Disease Control, very well respected scientific organization. I don’t know. They’ve got fault in Atlanta with the last file of smallpox or whatever it is that people think about them. And to go, “Oh, right, these are scientists we should actually take seriously and listen to, and they’re not politicized.”
Segment 4265: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8938, Text: It’s like, okay. And if you put out statements, and I don’t know if the CDC did, but Who Health Organization, whoever, that are provably false and also provably, you kind of knew they were false, but you did it to scare people because you wanted them to do the right thing. It’s like, no, you know what? That’s not going to work in the long run. You’re going to lose people, and now you’ve got a bigger problem, which is a lack of trust in science, a lack of trust in authorities who are, by and large, they’re like quite boring government bureaucrat scientists who just are trying to help the world.
Segment 4266: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=8971, Text: Well, I’ve been criticized, and I’ve been torn on this. I’ve been criticized for criticizing Anthony Fauci too hard. The degree to which I criticized him is because he’s a leader. And I’m just observing the effect in the loss of trust in the institutions like the NIH that where I personally know there’s a lot of incredible scientists doing incredible work, and I have to blame the leaders for the effects on the distrust and the scientific work that they’re doing because of what I perceive as basic human flaws of communication, of arrogance, of ego, of politics, all those kinds of things. Now, you could say, “You’re being too harsh,” possible, but I think that’s the whole point of free speech is you can criticize people who lead. Leaders, unfortunately or fortunately, are responsible for the effects on society.
Segment 4267: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9028, Text: To me, Anthony Fauci or whoever in the scientific position around the pandemic had an opportunity to have a FDR moment or to get everybody together, inspire about the power of science to rapidly develop a vaccine that saves us from this pandemic and future pandemic that can threaten the wellbeing of human civilization. This was epic and awesome and sexy. And to me, when I’m talking to people about science, it’s anything but sexy in terms of the virology and biology development because it’s been politicized. It’s icky, and people just don’t want to… “Don’t talk to me about the vaccine. I understand. I understand. I got vaccinated.” There’s just, “Let’s switch topics quick.”
Segment 4268: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9071, Text: Yeah, yeah. Well, it’s interesting because as I say, I live in the UK and I think all these things are a little less politicized there. And I haven’t paid close enough attention to Fauci to have a really strong view. I’m sure I would disagree with some things. I remember hearing at the beginning of the pandemic as I’m unwrapping my Amazon package with these masks I bought because I heard there’s a pandemic. And I just was like, “I want some N95 mask, please.” And they were saying, “Don’t buy masks.” And the motivation was because they didn’t want there to be shortages in hospitals. Fine. But there were also statements of masks, they’re not effective and they won’t help you. And then the complete about phase two, you’re ridiculous if you’re not wearing a… It’s just like, no, that about face just lost people from day one.
Segment 4269: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9126, Text: The distrust in the intelligence of the public to deal with nuance, to deal with the uncertainty.
Segment 4270: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9131, Text: Yeah. This is exactly what… I think this is where the Wikipedia neutral point of view is and should be in ideally. And obviously every article and everything we could… You know me now and you know how I am about these things, but ideally, it’s to say, look, we’re happy to show you all the perspectives. This is Planned Parenthood’s view, and this is Catholic Church view, and we’re going to explain that, and we’re going to try to be thoughtful and put in the best arguments from all sides, because I trust you. You read that and you’re going to be more educated and you’re going to begin to make a decision. I mean, I can just talk in the UK, the government, da, da, da. When we found out in the UK that very high level government officials were not following the rules they had put on everyone else. I had just become a UK citizen just a little while before the pandemic, and it’s kind of emotional. You get a passport in a new country and you feel quite good.
Segment 4271: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9189, Text: I did my oath to the Queen, and then they dragged the poor old lady out to tell us all to be good. I was like, “We’re British and we’re going to do the right things, and it’s going to be tough, but going to…” So you have that kind of Dunkirk spirit moment, and you’re following the rules to a T, and then suddenly it’s like, well, they’re not following the rules. And so suddenly I shifted personally from, “I’m going to follow the rules, even if I don’t completely agree with them, but I’ll still follow because I think we’ve got to all chip in together,” to, “You know what? I’m going to make wise and thoughtful decisions for myself and my family.” And that generally is going to mean following the rules. But it’s basically when they’re at certain moments in time, you’re not allowed to be in an outside space unless you’re exercising. I’m like, I think I can sit in a park and read a book. It’s going to be fine. That’s irrational rule, which I would’ve been following just personally of like, I’m just going to do the right thing.
Segment 4272: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9246, Text: And the loss of trust, I think, at scale was probably harmful to science. And to me, the scientific method and the scientific community is one of the biggest hopes, at least to me, for the survival and the thriving of human civilization.
Segment 4273: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9262, Text: Absolutely. And I think you see some of the ramifications of this. There’s always been pretty anti-science, anti-vax people. That’s always been a thing, but I feel like it’s bigger now simply because of that lowering of trust. So a lot of people, maybe it’s like you say, a lot of people are like, “Yeah, I got vaccinated, but I really don’t want to talk about this because it’s so toxic.” And that’s unfortunate because I think people should say, “What an amazing thing.” There’s also a whole range of discourse around if this were a disease that was primarily killing babies, I think people’s emotions about it would’ve been very different, right or wrong. Then the fact that when you really looked at the death rate of getting COVID, wow, it’s really dramatically different. If you’re late in life, this was really dangerous. And if you’re 23 years old, yeah, well, it’s not great. And long COVID is a thing and all of that. And I think some of the public communications, again, were failing to properly contextualize it. Not all of it. It’s a complicated matter, but yeah.
Segment 4274: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9345, Text: Let me read you a Reddit comment that received two likes.
Segment 4275: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9348, Text: Oh, two whole people liked it.
Segment 4276: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9352, Text: Yeah, two people liked it. And I don’t know, maybe you can comment on whether there’s truth to it, but I just found it interesting because I’ve been doing a lot of research on World War II recently. So this is about Hitler.
Segment 4277: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9366, Text: Oh, okay.
Segment 4278: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9366, Text: It’s a long statement. “I was there when a big push was made to fight bias at Wikipedia. Our target became getting the Hitler article to be Wiki’s featured article. The idea was that the voting body only wanted articles that were good PR and especially articles about socially liberal topics. So the Hitler article had to be two to three times better and more academically researched to beat the competition. This bias seems to hold today, for example, the current list of political featured articles at a glance seems to have only two books, one on anarchism and one on Karl Marx. Surely we’re not going to say there have only ever been two articles about political non-biography books worth being featured, especially compared to 200 plus video games. And that’s the only topics with good books are socialism and anarchy.” Do you have any interesting comments on this kind of-
Segment 4279: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9366, Text: Oh, yeah.
Segment 4280: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9420, Text: [inaudible 02:37:00] featured, how the featured is selected, maybe Hitler, because he is a special figure [inaudible 02:37:09] kind of stuff.
Segment 4281: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9429, Text: I love that. No, I love the comparison to how many video games, and that definitely speaks to my earlier is like, if you’ve got a lot of young geeky men who really like video games, that doesn’t necessarily get you to the right place in every respect. Certainly. Yeah. So here’s a funny story. I woke up one morning to a bunch of journalists in Germany trying to get in touch with me because German language, Wikipedia chose to have as the featured article of the day, Swastika. And people were going crazy about it, and some people were saying, “It’s illegal. Has German Wikipedia been taken over by Nazi sympathizers,” and so on? And it turned out it’s not illegal, discussing the swastika. Using the swastika as a political campaign and using it in certain ways is illegal in Germany in a way that it wouldn’t be in the US because the First Amendment, but in this case, it was like actually part of the point is the swastika symbol is from other cultures as well.
Segment 4282: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9497, Text: I just thought it was interesting. I did joke to the community, I’m like, “Please don’t put the swastika on the front page without warning me because I’m going to get [inaudible 02:38:25].” It wouldn’t be me, it’s the foundation. I’m not that much on the front lines. So I would say that to put Hitler on the front page of Wikipedia, it is a special topic. And you would want to say, “Yeah, let’s be really careful that it’s really, really good before we do that,” because if we put it on the front page and it’s not good enough, that could be a problem. There’s no inherent reason. Clearly, World War II is a very popular topic in Wikipedia. It’s like, turn on the history channel. People, it’s a fascinating period of history that people are very interested in. And then on the other piece, like anarchism and Karl Marx.
Segment 4283: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9545, Text: Karl Marx. Yeah.
Segment 4284: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9546, Text: Oh, yeah. I mean, that’s interesting. I’m surprised to hear that not more political books or topics have made it to the front page.
Segment 4285: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9555, Text: Now we’re taking this Reddit a comment.
Segment 4286: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9556, Text: I mean, as if-
Segment 4287: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9557, Text: That’s face value.
Segment 4288: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9558, Text: … it’s completely… But I’m trusting. So I think that’s probably is right. They probably did have the list up. No, I think that piece… The piece about how many of those featured articles have been video games, and if it’s disproportionate, I think the community should go, “Actually, what’s gone? That doesn’t seem quite right.” I mean, you can imagine that because you’re looking for an article to be on the front page of Wikipedia, you want to have a bit of diversity in it. You want it to be not always something that’s really popular that week, so I don’t know, the last couple of weeks, maybe succession, the big finale of succession might lead you think, oh, let’s put succession on the front page, that’s going to be popular. In other cases, you kind of want to pick something super obscure and quirky because people also find that interesting and fun. Yeah, I don’t know. But you don’t want it to be video games most of the time. That sounds quite bad.
Segment 4289: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9617, Text: Well, let me ask you just as somebody who’s seen the whole thing, the development of the millions of articles. Big impossible question, what’s your favorite article?
Segment 4290: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9633, Text: My favorite article? Well, I’ve got an amusing answer, which is possibly also true. There’s an article in Wikipedia called Inherently Funny Words, and one of the reasons I love it is when it was created early in the history of Wikipedia, it kind of became like a dumping ground. People would just come by and write in any word that they thought sounded funny. And then it was nominated for deletion because somebody’s like, “This is just a dumping ground. People are putting all kinds of nonsense in.” And in that deletion debate, somebody came forward and said essentially, “Wait a second, hold on. This is actually a legitimate concept in the theory of humor and comedy. And a lot of famous comedians and humorists have written about it.” And it’s actually a legitimate topic. So then they went through and they meticulously referenced every word that was in there and threw out a bunch that weren’t.
Segment 4291: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9689, Text: And so it becomes this really interesting. And now my biggest disappointment, and it’s the right decision to make because there was no source, but it was a picture of a cow, but there was a rope around its head tying on some horns onto the cow. So it was kind of a funny looking picture. It looked like a bull with horns, but it’s just a normal milk cow. And below it, the caption said, “According to some, cow is an inherently funny word,” which is just hilarious to me, partly because the “According to some” sounds a lot like Wikipedia, but there was no source. So it went away, and I know I feel very sad about that, but I’ve always liked that. And actually the reason Depths of Wikipedia amuses me so greatly is because it does highlight really interesting obscure stuff, and you’re like, “Wow, I can’t believe somebody wrote about that in Wikipedia. It’s quite amusing.” And sometimes there’s a bit of rye humor in Wikipedia. There’s always a struggle. You’re not trying to be funny, but occasionally a little inside humor can be quite healthy.
Segment 4292: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9760, Text: Apparently words with the letter K are funny. There’s a lot of really well researched stuff on this page. It’s actually exciting. And I should mention for Depths of the Wikipedia, it’s run by Annie Rauwerda.
Segment 4293: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9776, Text: That’s right, Annie.
Segment 4294: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9777, Text: And let me just read off some of the pages. Octopolis and Octlantis-
Segment 4295: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9785, Text: Oh yeah, that was…
Segment 4296: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9785, Text: … are two separate non-human underwater settlements built by the gloomy octopuses in Jarvis Bay East Australia. The first settlement named Octopolis by a biologist was founded in 2009. The individual structures in Octopolis consists of borrows around a piece of human detritus believed to be scrap metal, and it goes on in this way.
Segment 4297: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9809, Text: That’s great.
Segment 4298: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9810, Text: Satiric misspelling, least concerned species. Humans were formally assessed as a species of least concern in 2008. I think Hitchhiker’s Guide to the Galaxy would slightly disagree. And the last one, let me just say, friendship paradox is the phenomena first observed by the sociologist Scott Feld in 1991, that on average an individual’s friends have more friends than that individual.
Segment 4299: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9838, Text: Oh, that’s really interesting.
Segment 4300: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9838, Text: That’s very lonely.
Segment 4301: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9840, Text: That’s the kind of thing that makes you want to… It sounds implausible at first because shouldn’t everybody have on average, about the same number of friends as all their friends? So you really want to dig into the math of that and really think, oh, why would that be true?
Segment 4302: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9853, Text: And it’s one way to feel more lonely in a mathematically rigorous way. Somebody else on Reddit asks, “I would love to hear some war stories from behind the scenes.” Is there something that we haven’t mentioned that was particularly difficult in this entire journey you’re on with Wikipedia?
Segment 4303: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9872, Text: I mean, yeah, it’s hard to say. So part of what I always say about myself is that I’m a pathological optimist, so I always think everything is fine. And so things that other people might find a struggle, I’m just like, “Oh, well, this is the thing we’re doing today.” So that’s kind of about me, and it’s actually… I’m aware of this about myself, so I do like to have a few pessimistic people around me to keep me a bit on balance. I mean, I would say some of the hard things, I mean, there were hard moments like when two…
Segment 4304: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9900, Text: I would say some of the hard things. I mean, there were hard moments when two out of three servers crashed on Christmas Day and then we needed to do a fundraiser and no idea what was going to happen. I would say as well, in that early period of time, the growth of the website and the traffic to the website was phenomenal and great. The growth of the community and in fact the healthy growth of the community was fine.
Segment 4305: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9929, Text: And then the Wikimedia Foundation, the nonprofit I set up to own and operate Wikipedia as a small organization, it had a lot of growing pains. That was the piece that’s just many companies or many organizations that are in a fast growth. It’s like you’ve hired the wrong people, or there’s this conflict that’s arisen and nobody has got experience to do this and all that. So, no specific stories to tell, but I would say growing the organization was harder than growing the community and growing the website, which is interesting.
Segment 4306: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9962, Text: Well, yeah. It’s kind of miraculous and inspiring that a community can emerge and be stable, and that has so much kind of productive, positive output. Kind of makes you think. It’s one of those things you don’t want to analyze too much because you don’t want to mess with a beautiful thing, but it gives me faith in communities. I think that they can spring up in other domains as well.
Segment 4307: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=9989, Text: Yeah, I think that’s exactly right. At Fandom, my for-profit wiki company where it’s all these communities about pop culture mainly, sort of entertainment, gaming and so on, there’s a lot of small communities. So, I went last year to our Community Connect conference and just met some of these people, and here’s one of the leaders of the Star Wars wiki, which is called Wookieepedia, which I think is great. And he’s telling me about his community and all that. And I’m like, “Oh, right. Yeah, I love this.”
Segment 4308: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10023, Text: So, it’s not the same purpose as Wikipedia of a neutral, high quality encyclopedia, but a lot of the same values are there of like, “Oh, people should be nice to each other.” It’s like when people get upset, just remember we’re working on Star Wars wiki together, there’s no reason to get too outraged. And just kind people just, just geeky people with a hobby.
Segment 4309: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10047, Text: Where do you see Wikipedia in 10 years, 100 years, and 1,000 years?
Segment 4310: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10055, Text: Right. So, 10 years, I would say pretty much the same. We’re not going to become TikTok with entertainment deals, scroll by video humor, and blah-blah-blah, and encyclopedia. I think in 10 years, we probably will have a lot more AI supporting tools like I’ve talked about, and probably your search experience would be you can ask a question and get the answer rather than from our body of work.
Segment 4311: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10089, Text: So, search and discovery, a little bit improved, interface, some of that.
Segment 4312: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10092, Text: Yeah, all that. I always say one of the things that most people won’t notice, because already they don’t notice it, is the growth of Wikipedia in the languages of the developing world. So, you probably don’t speak Swahili, so you’re probably not checking out that Swahili Wikipedia is doing very well, and it is doing very well. And I think that kind of growth is actually super important. It’s super interesting, but most people won’t notice that.
Segment 4313: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10121, Text: If we can just link on that if we could, do you think there’s so much incredible translation work is being done with AI, with language models? Do you think that can accelerate Wikipedia?
Segment 4314: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10135, Text: Yeah, I do.
Segment 4315: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10135, Text: So, you start with the basic draft of the translation of articles and then build on top of that.
Segment 4316: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10140, Text: What I used to say is machine translation for many years wasn’t much used to the community, because it just wasn’t good enough. As it’s gotten better, it’s tended to be a lot better in what we might call economically important languages, that’s because the corpus that they train on and all of that.
Segment 4317: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10160, Text: So, to translate from English to Spanish, if you’ve tried Google Translate recently Spanish to English is what I would do, it’s pretty good. It’s actually not bad. It used to be half a joke and then for a while it was kind of like, “Well, you can get the gist of something.” And now, actually, it’s pretty good. However, we’ve got a huge Spanish community who write in native Spanish, so they’re able to use it and they find it useful, but they’re writing.
Segment 4318: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10184, Text: But if you tried to do English to Zulu where there’s not that much investment, there’s loads of reasons to invest in English-Spanish, because they’re both huge, economically important languages. Zulu not so much. So, for those smaller languages, it was just still terrible. My understanding is it’s improved dramatically and also because the new methods of training don’t necessarily involve identical corpuses to try to match things up, but rather reading and understanding with tokens and large language models, and then reading and understanding, and then you get a much richer …
Segment 4319: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10222, Text: Anyway, apparently it’s quite improved, so I think that now, it is quite possible that these smaller language communities are going to say, “Oh, well finally, I can put something in an English and I can get out Zulu that I feel comfortable sharing with my community because it’s actually good enough, or I can edit it a bit here and there.” So, I think that’s huge. So, I do think that’s going to happen a lot and that’s going to accelerate, again, what will remain to most people an invisible trend, but that’s the growth in all these other languages. So, then move on to 100 years.
Segment 4320: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10252, Text: I was starting to get scary.
Segment 4321: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10254, Text: Well, the only thing I’d say about 100 years is we’ve built the Wikimedia Foundation, and we run it in a quite cautious, and financially conservative, and careful way. So, every year, we build our reserves. Every year, we put aside a little bit of more money. We also have the endowment fund, which we just passed 100 million, that’s a completely separate fund with a separate board. So, it’s not just a big fat bank account for some future profligate CEO to blow through. The foundation will have to get the approval of a second order board to be able to access that money, and that board can make other grants through the community and things like that.
Segment 4322: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10298, Text: So, the point of all that is I hope and believe that we are building in a financially stable way that we can weather various storms along the way, so that hopefully we’re not taking the kind of risks. And by the way, we’re not taking too few risks either. That’s always hard. I think the Wikimedia Foundation and Wikipedia will exist in 100 years if anybody exists in 100 years, we’ll be there.
Segment 4323: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10326, Text: Do you think the internet just looks a predictably different, just the web?
Segment 4324: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10331, Text: I do. I think right now, this sort of enormous step forward we’ve seen and has become public in the last year of the large language models really is something else. It’s really interesting. You and I have both talked today about the flaws and the limitations, but still it’s … As someone who’s been around technology for a long time, it’s sort of that feeling of the first time I saw a web browser, the first time I saw the iPhone, the first time the internet was really usable on a phone. And it’s like, “Wow, that’s a step change difference.” There’s a few other …
Segment 4325: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10368, Text: Maybe a Google Search.
Segment 4326: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10369, Text: Google Search was actually one.
Segment 4327: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10371, Text: I remember the first Search.
Segment 4328: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10371, Text: Because I remember Alta Vista was kind of cool for a while, then it just got more and more useless, because the algorithm wasn’t good. And it’s like, “Oh, Google Search, now I like the internet, it works again.” And so, large language model, it feels like that to me. Like, “Oh, wow, this is something new and really pretty remarkable.” And it’s going to have some downsides. The negative use case …
Segment 4329: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10394, Text: People in the area who are experts, they’re giving a lot of warnings. I’m not that worried, but I’m a pathological optimist. But I do see some really low-hanging fruit bad things that can happen. My example is, how about some highly customized spam where the email that you receive isn’t just misspelled words and trying to get through filters, but actually as a targeted email to you that knows something about you by reading your LinkedIn profile and writes a plausible email that will get through the filters. And it’s like suddenly, “Oh, that’s a new problem. That’s going to be interesting.”
Segment 4330: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10435, Text: Just on the Wikipedia editing side, does it make the job of the volunteer of the editor more difficult in a world where larger and larger percentage of the internet is written by an LLM?
Segment 4331: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10448, Text: One of my predictions, and we’ll see, ask me again in five years how this panned out, is that in a way, this will strengthen the value and importance of some traditional brands. So, if I see a news story and it’s from the Wall Street Journal, from the New York Times, from Fox News, I know what I’m getting and I trust it to whatever extent I might have, trust or distrust in any of those.
Segment 4332: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10483, Text: And if I see a brand new website that looks plausible, but I’ve never heard of it, and it could be machine generated content that may be full of errors, I think I’ll be more cautious. I think I’m more interested. And we can also talk about this around photographic evidence. So, obviously, there will be scandals where major media organizations get fooled by a fake photo.
Segment 4333: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10504, Text: However, if I see a photo of the recent ones, the Pope wearing an expensive puffer jacket, I’m going to go, “Yeah, that’s amazing that a fake like that could be generated.” But my immediate thought is not, “Oh, so the Pope is dipping into the money, eh? Partly because this particular Pope doesn’t seem like he’d be the type.”
Segment 4334: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10525, Text: My favorite is extensive pictures of Joe Biden and Donald Trump hanging out and having fun together.
Segment 4335: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10531, Text: Yeah. Brilliant. So, I think people will care about the provenance of a photo. And if you show me a photo and you say, “Yeah, this photo is from Fox News,” even though I don’t necessarily think that’s the highest, but I’m like, “Wow, it’s a news organization and they’re going to have journalism, and they’re going to make sure the photo is what it purports to be.”
Segment 4336: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10555, Text: That’s very different from a photo randomly circulating on Twitter. Whereas I would say, 15 years ago, a photo randomly circulating on Twitter, in most cases, the worst you could do, and this did happen, is misrepresent the battlefield. So, like, “Oh, here’s a bunch of injured children. Look what Israel has done.” But actually, it wasn’t Israel, it was another case 10 years ago. That has happened, that has always been around. But now, we can have much more specifically constructed, plausible looking photos that if I just see them circulating on Twitter, I’m going to go, “I just don’t know. Not sure. I can make that in five minutes.”
Segment 4337: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10592, Text: Well, I also hope that it’s kind of like what you’re writing about in your book that we could also have citizen journalists that have a stable, verifiable trust that builds up. So, it doesn’t have to be in New York Times with this organization that you could be in an organization of one as long as it’s stable and carries through time and it builds up or it goes up.
Segment 4338: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10612, Text: No, I agree. But the one thing I’ve said in the past, and this depends on who that person is and what they’re doing, but it’s like I think my credibility, my general credibility in the world should be the equal of a New York Times reporter. So, if something happens, and I witness it, and I write about it, people are going to go, “Well, Jimmy Wales said it. That’s just like if a New York Times reporter said it. I’m going to tend to think he didn’t just make it up.”
Segment 4339: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10638, Text: The truth is nothing interesting ever happens around me. I don’t go to war zones. I don’t go to big press conferences. I don’t interview Putin and Zelenskyy. To an extent, yes. Whereas I do think for other people, those traditional models of credibility are really, really important. And then there is this sort of citizen journalism. I don’t know if you think of what you do as journalism. I kind of think it is, but you do interviews, you do long form interviews.
Segment 4340: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10669, Text: If you come and you say, “Here’s my tape,” but you wouldn’t hand out a tape. I just gesture to you as if I’m handing you a cassette tape. But if you put it into your podcast, ” Here’s my interview with Zelenskyy.” And people aren’t going to go, “Yeah, how do we know? That could be a deep fake. You could have faked that.” Because people are like, “Well, no, you’re a well known podcaster and you do interview interesting people. Yeah, you wouldn’t think that.” So, that your brand becomes really important.
Segment 4341: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10699, Text: Whereas if suddenly, and I’ve seen this already, I’ve seen sort of video with subtitles in English, and apparently the Ukrainian was the same and it was Zelenskyy saying something really outrageous. And I’m like, “Yeah, I don’t believe that. I don’t think he said that in a meeting with whatever. I think that’s Russian propaganda or probably just trolls.”
Segment 4342: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10722, Text: Yeah. And then building platforms and mechanisms of how that trust can be verified. If something appears on a Wikipedia page, that means something. If something appears on my Twitter account, that means something. That means I, this particular human, have signed off on it.
Segment 4343: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10738, Text: Yeah, exactly.
Segment 4344: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10738, Text: And then the trust you have in this particular human transfers to the piece of content. Hopefully, there’s millions of people with different metrics of trust. And then you could see that there’s a certain kind of bias in the set of conversations you’re having. So, maybe okay, I trust this person, I have this kind of bias and I’ll go to this other person with this other kind of bias and I can integrate them in this kind of way. Just like you said with Fox News and whatever [inaudible 02:59:24].
Segment 4345: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10763, Text: Yeah. Wall Street Journal, New York Times, they’ve all got where they sit. Yeah.
Segment 4346: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10769, Text: So, you have built, I would say, one of if not the most impactful website in the history of human civilization. So, let me ask for you to give advice to young people how to have impact in this world. High schoolers, college students wanting to have a big positive impact on the world.
Segment 4347: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10790, Text: Yeah, great. If you want to be successful, do something you’re really passionate about rather than some kind of cold calculation of what can make you the most money. Because if you go and try to do something and you’re like, “I’m not that interested, but I’m going to make a lot of money doing it,” you’re probably not going to be that good at it. And so, that is a big piece of it.
Segment 4348: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10812, Text: For startups, I give this advice. And this is a career startup, any kind of young person just starting out is be persistent. There will be moments when it’s not working out and you can’t just give up too easily. You’ve got to persist through some hard times. Maybe two servers crash on a Sunday, and you’ve got to scramble to figure it out, but persist through that, and then also be prepared to pivot. That’s a newer word, new for me. But when I pivoted from Nupedia to Wikipedia it’s like, “This isn’t working. I’ve got to completely change.” So, be willing to completely change direction when something is not working.
Segment 4349: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10854, Text: Now, the problem with these two wonderful pieces of advice is, which situation am I in today? Is this a moment when I need to just power through and persist because I’m going to find a way to make this work? Or is this a moment where I need to go, “Actually, this is totally not working and I need to change direction?” But also, I think for me, that always gives me a framework of like, “Okay, here’s the problem. Do we need to change direction, or do we need to power through it?” And just knowing those are the choices. Not always the only choices, but those choices.
Segment 4350: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10887, Text: I think it can be helpful to say, “Okay, am I chickening out because I’m having a little bump, and I’m feeling unemotional, and I’m just going to give up too soon?” Ask yourself that question. And also, it’s like, “Am I being pigheaded and trying to do something that actually doesn’t make sense?” Okay. Ask yourself that question too. Even though they’re contradictory questions, sometimes it will be one, sometimes it will be the other, and you got to really think it through.
Segment 4351: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10913, Text: I think persisting with the business model behind Wikipedia is such an inspiring story, because we live in a capitalist world. We live in a scary world, I think, for an internet business. And so, to do things differently than a lot of websites are doing, what Wikipedia has lived through this excessive explosion of many websites that are basically ad driven. Google is ad driven. Facebook, Twitter, all of these websites are ad driven. And to see them succeed, become these incredibly rich, powerful companies that if I could just have that money, you would think as somebody running Wikipedia, “I could do so much positive stuff.” And so, to persist through that is … I think from my perspective now, Monday night quarterback or whatever was the right decision, but boy is that a tough decision.
Segment 4352: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10976, Text: It seemed easy at the time.
Segment 4353: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10978, Text: And then you just kind of stay with it. Stick with it.
Segment 4354: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10980, Text: Yeah, just stay with it. It’s working.
Segment 4355: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10981, Text: So now, when you chose persistent.
Segment 4356: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=10986, Text: Yeah. I always like to give an example of MySpace, because I just think it’s an amusing story. MySpace was poised, I would say, to be Facebook. It was huge. It was viral, it was lots of things. Kind of foreshadowed a bit of maybe even TikTok because it was a lot of entertainment, content, casual. And then Rupert Murdoch bought it and it collapsed within a few years. And part of that I think was because they were really, really heavy on ads and less heavy on the customer experience.
Segment 4357: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11020, Text: So, I remember, to accept a friend request was like three clicks where you saw three ads. And on Facebook, you accept the friend request, you didn’t even leave the page, like that’s just accepted. So, I used to give this example of like, “Yeah, well, Rupert Murdoch really screwed that one up.” And in a sense, maybe he did, but somebody said, “You know what, actually, he bought it for …” And I don’t remember the numbers he bought it for, 800 million, and it was very profitable through its decline. He actually made his money back and more. From a financial point of view, it was a bad investment in the sense of you could have been Facebook. But on more mundane metrics, it’s like, “Actually, it worked out for him.”
Segment 4358: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11058, Text: It all matters how you define success.
Segment 4359: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11060, Text: It does. That is also advice to young people. One of the things I would say when we have our mental models of success as an entrepreneur, for example, and your examples in your mind are Bill Gates, Mark Zuckerberg. So, people who at a very young age had one really great idea that just went straight to the moon and it became one of the richest people in the world. That is really unusual, like really, really rare.
Segment 4360: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11092, Text: And for most entrepreneurs, that is not a life path you’re going to take. You’re going to fail, you’re going to reboot, you’re going to learn from what you failed at. You’re going to try something different. And that is really important, because if your standard of success is, “Well, I feel sad because I’m not as rich as Elon Musk.” It’s like, “Well, so should almost everyone, possibly everyone except Elon Musk is not as rich as Elon Musk.”
Segment 4361: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11117, Text: Realistically, you can set a standard of success. Even in a really narrow sense, which I don’t recommend of thinking about your financial success. It’s like if you measure your financial success by thinking about billionaires, that’s heavy. That’s probably not good. I don’t recommend it.
Segment 4362: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11140, Text: Personally, for me, when journalists say, “Oh, how does it feel to not be a billionaire?” I usually say, “I don’t know how does it feel to you.” Because they’re not. But also, I live in London. The number of bankers that no one has ever heard of who live in London, who make far more money than I ever will is quite a large number, and I wouldn’t trade my life for theirs at all, because mine is so interesting.
Segment 4363: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11167, Text: “Oh, right, Jimmy, we need you to go and meet the Chinese propaganda minister.” “Oh, okay. That’s super interesting.” Like, “Yeah, Jimmy, here’s the situation. You can go to this country. And why you’re there, the President has asked to see you.” It’s like, “God, that’s super interesting.” “Jimmy, you’re going to this place and there’s a local Wikipedia who said, ‘Do you want to stay with me and my family?'” And I’m like, “Yeah, that’s really cool. I would like to do that. That’s really interesting.” I don’t do that all the time, but I’ve done it and it’s great. So, for me, that’s arranging your life so that you have interesting experiences. It’s just great.
Segment 4364: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11210, Text: This is more to the question of what Wikipedia looks like in 1,000 years. What do you think is the meaning of this whole thing? Why are we here, human civilization? What’s the meaning of life?
Segment 4365: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11220, Text: Yeah. I don’t think there is external answer to that question.
Segment 4366: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11225, Text: And I should mention that there’s a very good Wikipedia page on the different philosophies in the meaning of life.
Segment 4367: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11231, Text: Oh, interesting. I have to read that and see what I think. Hopefully, it’s actually neutral and gives a wide range …
Segment 4368: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11236, Text: Oh, it’s a really good reference to a lot of different philosophies about meaning. The 20th century philosophy in general, from Nietzsche to the existentialist, to Simone de Beauvoir, all of them have an idea of meaning. They really struggle with it systematically, rigorously, and that’s what the page … And obviously, a shout-out to the Hitchhiker’s Guide and all that kind of stuff.
Segment 4369: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11257, Text: Yeah. I think there’s no external answer to that. I think it’s internal. I think we decide what meaning we will have in our lives and what we’re going to do with ourselves. If we’re talking about 1,000 years, millions of years, Yuri Milner wrote a book. He’s a big internet investor guy. He wrote a book advocating quite strongly for humans exploring the universe, and getting off the planet. And he funds projects to using lasers to send little cameras, and interesting stuff. And he talks a lot in the book about meaning. His view is that the purpose of the human species is to broadly survive and get off the planet.
Segment 4370: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11311, Text: Well, I don’t agree with everything he has to say, because I think that’s not a meaning that can motivate most people in their own lives. It’s like, “Okay, great.” The distances of space are absolutely enormous, so I don’t know. Shall we build generation ships to start flying places? I can’t do that. Even if I’m Elon Musk and I could devote all my wealth to build, I’ll be dead on the ship on the way. So, is that really a meaning?
Segment 4371: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11337, Text: But I think it’s really interesting to think about. And reading his little book, it’s quite a short little book. Reading his book, it did make me think about, “Wow, this is big. This is not what you think about in your day-to-day life. Where is the human species going to be in 10 million years?” And it does make you sort of turn back to Earth and say, “Gee, let’s not destroy the planet. We’re stuck here for at least a while, and therefore we should really think about sustainability.” I mean, one million year sustainability.
Segment 4372: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11377, Text: And we don’t have all the answers. We have nothing close to the answers. I’m actually excited about AI in this regard, while also bracketing, yeah, I understand there’s also risks and people are terrified of AI. But I actually think it is quite interesting this moment in time that we may have in the next 50 years to really, really solve some really long-term human problems, for example, in health. The progress that’s being made in cancer treatment, because we are able to at scale model molecules, and genetics, and things like this, it gets huge. It’s really exciting. So, if we can hang on for a little while, and certain problems that seem completely intractable today, like climate change may end up being actually not that hard.
Segment 4373: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11430, Text: And we just might be able to alleviate the full diversity of human suffering.
Segment 4374: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11435, Text: For sure. Yeah.
Segment 4375: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11437, Text: In so doing, help increase the chance that we can propagate the flame of human consciousness out towards the stars. And I think another important one, if we fail to do that. For me, it’s propagating, maintaining the full diversity, and richness, and complexity, and expansiveness of human knowledge. So, if we destroy ourselves, it would make me feel a little bit okay if the human knowledge persists.
Segment 4376: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11469, Text: It just triggered me to say something really interesting, which is when we talked earlier about translating and using machines to translate, we mostly talked about small languages and translating into English, but I always like to tell this story of something inconsequential, really.
Segment 4377: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11488, Text: I was in Norway, in Bergen, Norway, where every year they’ve got this annual festival called [foreign language 03:11:33], which is young groups drumming, and they have a drumming competition. It’s the 17 sectors of the city, and they’ve been doing it for a couple hundred years or whatever. They wrote about it in the three languages of Norway. And then from there, it was translated into English, into German, et cetera, et cetera.
Segment 4378: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11513, Text: And so, what I love about that story is what it reminds me is this machine translation goes both ways. And when you talk about the richness and broadness of human culture, we’re already seeing some really great pieces of this. So, like Korean soap operas, really popular, not with me, but with people.
Segment 4379: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11537, Text: Imagine taking a very famous, very popular, very well known Korean drama. I literally mean now, we’re just about there technologically where we use a machine to redub it in English in an automated way, including digitally editing the faces so it doesn’t look dubbed. And so, suddenly you say, “Oh, wow, here’s a piece of …” It’s the Korean equivalent of maybe it’s Friends as a comedy, or maybe it’s Succession, just to be very contemporary. It’s something that really impacted a lot of people, and they really loved it, and we have literally no idea what it’s about. And suddenly, it’s like, “Wow.” Music, street music from wherever in the world can suddenly become accessible to us all in new ways. It’s so cool.
Segment 4380: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11589, Text: It’s really exciting to get access to the richness of culture in China, in the many different subcultures of Africa, South America.
Segment 4381: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11599, Text: One of my unsuccessful arguments with the Chinese government is by blocking Wikipedia, you aren’t just stopping people in China from reading Chinese Wikipedia and other language versions of Wikipedia, you’re also preventing the Chinese people from telling their story. So, is there a small festival in a small town in China like [foreign language 03:13:41]? I don’t know. But by the way, the people who live in that village, that small town of 50,000, they can’t put that in Wikipedia and get it translated into other places. They can’t share their culture and their knowledge.
Segment 4382: Speaker: , Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11634, Text: And I think for China, this should be a somewhat influential argument, because China does feel misunderstood in the world. And it’s like, “Okay, well, there’s one way. If you want to help people understand, put it in Wikipedia. That’s what people go to when they want to understand.”
Segment 4383: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11648, Text: And give the amazing, incredible people of China a voice.
Segment 4384: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11653, Text: Exactly.
Segment 4385: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11654, Text: Jimmy, I thank you so much. I’m such a huge fan of everything you’ve done.
Segment 4386: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11658, Text: Oh, thank you. That’s really great.
Segment 4387: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11658, Text: I keep saying Wikipedia. I’m deeply, deeply, deeply, deeply grateful for Wikipedia. I love it. It brings me joy. I donate all the time. You should donate too. It’s a huge honor to finally talk with you, and this is just amazing. Thank you so much for today.
Segment 4388: Speaker: Jimmy Wales, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11671, Text: Thanks for having me.
Segment 4389: Speaker: Lex Fridman, Timestamp: https://youtube.com/watch?v=diJp4zoQPqo&t=11673, Text: Thanks for listening to this conversation with Jimmy Wales. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from the world historian, Daniel Boorstin. The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge. Thank you for listening, and hope to see you next time.
